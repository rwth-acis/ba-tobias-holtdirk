@article{rayyan-727967007,
  title={The pains and gains of microservices: A Systematic grey literature review},
  year={2018},
  journal={Journal of Systems and Software},
  issn={01641212},
  volume={146},
  pages={215-232},
  author={Soldani, Jacopo and Tamburri, Damian Andrew and Van Den Heuvel, Willem-Jan},
  url={https://linkinghub.elsevier.com/retrieve/pii/S0164121218302139},
  language={en},
  keywords={Systematic literature review, Microservices, Microservices design, Microservices development, Microservices operation, Systematic grey literature review},
  abstract={The design, development, and operation of microservices are picking up more and more momentum in the IT industry. At the same time, academic work on the topic is at an early stage, and still on the way to distilling the actual “Pains & Gains” of microservices as an architectural style. Having witnessed this gap, we set forth to systematically analyze the industrial grey literature on microservices, to identify the technical/operational pains and gains of the microservice-based architectural style. We conclude by discussing research directions stemming out from our analysis.}
}

@article{rayyan-727967185,
  title={Function-as-a-Service performance evaluation: A multivocal literature review},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={170},
  pages={110708},
  author={Scheuner, Joel and Leitner, Philipp},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220301527},
  keywords={Cloud computing, Multivocal literature review, Benchmarking, Function-as-a-Service, Performance, Serverless},
  abstract={Function-as-a-Service (FaaS) is one form of the serverless cloud computing paradigm and is defined through FaaS platforms (e.g., AWS Lambda) executing event-triggered code snippets (i.e., functions). Many studies that empirically evaluate the performance of such FaaS platforms have started to appear but we are currently lacking a comprehensive understanding of the overall domain. To address this gap, we conducted a multivocal literature review (MLR) covering 112 studies from academic (51) and grey (61) literature. We find that existing work mainly studies the AWS Lambda platform and focuses on micro-benchmarks using simple functions to measure CPU speed and FaaS platform overhead (i.e., container cold starts). Further, we discover a mismatch between academic and industrial sources on tested platform configurations, find that function triggers remain insufficiently studied, and identify HTTP API gateways and cloud storages as the most used external service integrations. Following existing guidelines on experimentation in cloud systems, we discover many flaws threatening the reproducibility of experiments presented in the surveyed studies. We conclude with a discussion of gaps in literature and highlight methodological suggestions that may serve to improve future FaaS performance evaluation studies.}
}

@article{rayyan-727967218,
  title={Software test maturity assessment and test process improvement: A multivocal literature review},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={85},
  pages={16-42},
  author={Garousi, Vahid and Felderer, Michael and Hacaloğlu, Tuna},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917300162},
  keywords={Software testing, Systematic literature review, Multivocal literature review, Test management, Test maturity, Test process, Test process assessment, Test process improvement, Software},
  abstract={Context Software testing practices and processes in many companies are far from being mature and are usually conducted in ad-hoc fashions. Such immature practices lead to various negative outcomes, e.g., ineffectiveness of testing practices in detecting all the defects, and cost and schedule overruns of testing activities. To conduct test maturity assessment (TMA) and test process improvement (TPI) in a systematic manner, various TMA/TPI models and approaches have been proposed. Objective It is important to identify the state-of-the-art and the –practice in this area to consolidate the list of all various test maturity models proposed by practitioners and researchers, the drivers of TMA/TPI, the associated challenges and the benefits and results of TMA/TPI. Our article aims to benefit the readers (both practitioners and researchers) by providing the most comprehensive survey of the area, to this date, in assessing and improving the maturity of test processes. Method To achieve the above objective, we have performed a Multivocal Literature Review (MLR) study to find out what we know about TMA/TPI. A MLR is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). We searched the academic literature using the Google Scholar and the grey literature using the regular Google search engine. Results Our MLR and its results are based on 181 sources, 51 (29%) of which were grey literature and 130 (71%) were formally published sources. By summarizing what we know about TMA/TPI, our review identified 58 different test maturity models and a large number of sources with varying degrees of empirical evidence on this topic. We also conducted qualitative analysis (coding) to synthesize the drivers, challenges and benefits of TMA/TPI from the primary sources. Conclusion We show that current maturity models and techniques in TMA/TPI provides reasonable advice for industry and the research community. We suggest directions for follow-up work, e.g., using the findings of this MLR in industry-academia collaborative projects and empirical evaluation of models and techniques in the area of TMA/TPI as reported in this article.}
}

@article{rayyan-727967259,
  title={When and what to automate in software testing? A multi-vocal literature review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={76},
  pages={92-117},
  author={Garousi, Vahid and Mäntylä, Mika V},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916300702},
  keywords={Systematic literature review, Decision support, Multivocal literature review, Software test automation, Systematic Mapping study, What to automate, When to automate, Software},
  abstract={Context Many organizations see software test automation as a solution to decrease testing costs and to reduce cycle time in software development. However, establishment of automated testing may fail if test automation is not applied in the right time, right context and with the appropriate approach. Objective The decisions on when and what to automate is important since wrong decisions can lead to disappointments and major wrong expenditures (resources and efforts). To support decision making on when and what to automate, researchers and practitioners have proposed various guidelines, heuristics and factors since the early days of test automation technologies. As the number of such sources has increased, it is important to systematically categorize the current state-of-the-art and -practice, and to provide a synthesized overview. Method To achieve the above objective, we have performed a Multivocal Literature Review (MLR) study on when and what to automate in software testing. A MLR is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). We searched the academic literature using the Google Scholar and the grey literature using the regular Google search engine. Results Our MLR and its results are based on 78 sources, 52 of which were grey literature and 26 were formally published sources. We used the qualitative analysis (coding) to classify the factors affecting the when- and what-to-automate questions to five groups: (1) Software Under Test (SUT)-related factors, (2) test-related factors, (3) test-tool-related factors, (4) human and organizational factors, and (5) cross-cutting and other factors. The most frequent individual factors were: need for regression testing (44 sources), economic factors (43), and maturity of SUT (39). Conclusion We show that current decision-support in software test automation provides reasonable advice for industry, and as a practical outcome of this research we have summarized it as a checklist that can be used by practitioners. However, we recommend developing systematic empirically-validated decision-support approaches as the existing advice is often unsystematic and based on weak empirical evidence.}
}

@article{rayyan-727967261,
  title={Smells in software test code: A survey of knowledge in industry and academia},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={138},
  pages={52-81},
  author={Garousi, Vahid and Küçük, Barış},
  url={https://www.sciencedirect.com/science/article/pii/S0164121217303060},
  keywords={Software testing, Systematic mapping, Survey, Automated testing, Multivocal literature mapping, Test anti-patterns, Test automation, Test scripts, Test smells, Smell, Software},
  abstract={As a type of anti-pattern, test smells are defined as poorly designed tests and their presence may negatively affect the quality of test suites and production code. Test smells are the subject of active discussions among practitioners and researchers, and various guidelines to handle smells are constantly offered for smell prevention, smell detection, and smell correction. Since there is a vast grey literature as well as a large body of research studies in this domain, it is not practical for practitioners and researchers to locate and synthesize such a large literature. Motivated by the above need and to find out what we, as the community, know about smells in test code, we conducted a ‘multivocal' literature mapping (classification) on both the scientific literature and also practitioners' grey literature. By surveying all the sources on test smells in both industry (120 sources) and academia (46 sources), 166 sources in total, our review presents the largest catalogue of test smells, along with the summary of guidelines/techniques and the tools to deal with those smells. This article aims to benefit the readers (both practitioners and researchers) by serving as an “index” to the vast body of knowledge in this important area, and by helping them develop high-quality test scripts, and minimize occurrences of test smells and their negative consequences in large test automation projects.}
}

@article{rayyan-727967300,
  title={A multivocal literature review on serious games for software process standards education},
  year={2018},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={57},
  pages={36-48},
  author={Calderón, Alejandro and Ruiz, Mercedes and O'Connor, Rory V},
  url={https://www.sciencedirect.com/science/article/pii/S092054891730332X},
  keywords={Systematic literature review, Multivocal literature review, Education, Serious game, Software process standard, Software},
  abstract={Context: The interest in the use of serious games as learning resources for software process standards education and training has increased significantly in recent years. Objective: The main purpose of this work is to record, analyze and characterize the state of the art related to serious games for software process standards education with the goal of identifying the current serious games in terms of the scope, their main features and the perceived benefits of integrating them in software process education, as well as, identifying new research opportunities. Method: The study was conducted as a multivocal literature review that follows a predefined procedure in which studies from the scientific and grey literature are analyzed. Results: A new selection process within the search strategy was defined to conduct this review. 190 papers were retrieved from the literature and 7 papers were selected as primary studies. Our multivocal literature review identified six different serious games for software process education, at the same time analyzed the main methods used to assess them as well as their main outcomes as learning resources. Conclusion: The results of this review reveal that serious games have potential as supporting tools for software process standards education, but that more research and experimental outcomes are needed in order to observe the full potential of serious games as learning resources.}
}

@article{rayyan-727968020,
  title={Consensus mechanisms in distributed ledgers for the protection of confidential data: A multivocal literature review},
  year={2020},
  pages={166-173},
  author={Vargas-Gómez, Renato and Peréz-Arriaga, Juan Carlos and Ocharán-Hernández, Jorge Octavio and Sánchez-García, Angel J},
  keywords={Software, Systematics, Bibliographies, Multivocal literature review, Blockchain, Distributed ledger, Privacy, Distributed ledger technology, Proposals, Data protection, Distributed databases, Confidentiality},
  abstract={Distributed Ledger Technologies (DLT) open new opportunities for data protection since they bring decentralization and sovereignty over the ownership of data. On the practical side, implementations of this technology are limited. Due to its novelty, the fundamentals for their design and development are still emerging. An essential feature of DLT is the consensus mechanism, which is used so that the members of the DLT network validate and append data to the ledger. The design decision of which mechanism to use will significantly impact the functionality of the system. Therefore, it is a decision that cannot be taken lightly. Software engineers, developers, and other practitioners in the field can use the knowledge and understanding of the implementations that already exist to help with these decisions. This paper presents the results of a multivocal literature review carried out to identify the consensus mechanisms used in DLT for the protection of confidential data. Twenty-seven studies were selected; in those studies, twenty-one different consensus mechanisms were identified. The review showcases the mechanisms that have been identified and their contexts, alongside a discussion of their relevance and characteristics.}
}

@article{rayyan-727968239,
  title={On the understanding of how to measure the benefits of behavior-driven development adoption: Preliminary literature results from a grey literature study},
  year={2020},
  issn={978-1-4503-8923-5},
  author={Couto, Thiciane and Marczak, Sabrina and Gomes, Fabio},
  url={https://doi.org/10.1145/3439961.3440000},
  publisher={Association for Computing Machinery},
  series={SBQS'20},
  keywords={Benefits, Grey Literature Review, BDD Adoption, Behavior-Driven Development, Quality Measurement},
  abstract={Behavior-Driven Development (BDD) is the integration of a ubiquitous language with Test-Driven Development and Automated Testing. From this integration, BDD supports software teams to build and deliver software. Although the perceived arguments of better results and of a more efficient development process, we still have no consolidated evidence of such benefits and how to measure them. Therefore, this long-term research aims to characterize how BDD adoption benefits can be measured. To do so, our research design includes a Multivocal Literature Review, composed of a Grey Literature to explore how industry tackles the topic and a Systematic Review to gather scientific evidences, followed of a Snowballing Review to supplement the search. Next, we will conduct empirical studies to characterize the topic from practice. This paper introduces our research and presents the results from our exploratory Grey Literature. We learned from these preliminary results that there are no models or frameworks defined to measure BDD adoption benefits but that teams indeed perceive improvements in software quality, communication, rework rates, among others. We also found that these teams also perceive that team engagement improves with the adoption of BDD and that although there is a certain cost (e.g., time and financial) involved, the investment pays off in the end. These results will inform the design of our Systematic Review and of our downstream empirical studies.}
}

