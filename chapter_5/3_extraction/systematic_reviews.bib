@article{rayyan-727967003,
  title={Systematic literature reviews in software engineering - A systematic literature review},
  year={2009},
  journal={Information and Software Technology},
  volume={51},
  number={1},
  pages={7-15},
  author={Kitchenham, Barbara and Pearl Brereton, O. and Budgen, David and Turner, Mark and Bailey, John and Linkman, Stephen},
  url={http://dx.doi.org/10.1016/j.infsof.2008.09.009},
  keywords={~guide, systematic review, Cost estimation, Evidence-based software engineering, Tertiary study, Systematic literature review, Systematic review quality, Software},
  abstract={Background: In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference. Aims: This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence. Method: We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings. Results: Of 20 relevant studies, eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4. Conclusions: Currently, the topic areas covered by SLRs are limited. European researchers, particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence and making it available to practitioners. © 2008 Elsevier B.V. All rights reserved.}
}

@article{rayyan-727967010,
  title={A systematic review of systematic review process research in software engineering},
  year={2013},
  journal={Information and Software Technology},
  issn={09505849},
  volume={55},
  number={12},
  pages={2049-2075},
  author={Kitchenham, Barbara and Brereton, Pearl},
  url={https://linkinghub.elsevier.com/retrieve/pii/S0950584913001560},
  language={en},
  keywords={~guide, Systematic literature review, Systematic review, Mapping study, Systematic review methodology, Software},
  abstract={Context: Many researchers adopting systematic reviews (SRs) have also published papers discussing problems with the SR methodology and suggestions for improving it. Since guidelines for SRs in software engineering (SE) were last updated in 2007, we believe it is time to investigate whether the guidelines need to be amended in the light of recent research.     Objective: To identify, evaluate and synthesize research published by software engineering researchers concerning their experiences of performing SRs and their proposals for improving the SR process.     Method: We undertook a systematic review of papers reporting experiences of undertaking SRs and/or discussing techniques that could be used to improve the SR process. Studies were classified with respect to the stage in the SR process they addressed, whether they related to education or problems faced by novices and whether they proposed the use of textual analysis tools.     Results: We identified 68 papers reporting 63 unique studies published in SE conferences and journals between 2005 and mid-2012. The most common criticisms of SRs were that they take a long time, that SE digital libraries are not appropriate for broad literature searches and that assessing the quality of empirical studies of different types is difficult.     Conclusion: We recommend removing advice to use structured questions to construct search strings and including advice to use a quasi-gold standard based on a limited manual search to assist the construction of search stings and evaluation of the search process. Textual analysis tools are likely to be useful for inclusion/exclusion decisions and search string construction but require more stringent evaluation. SE researchers would benefit from tools to manage the SR process but existing tools need independent validation. Quality assessment of studies using a variety of empirical methods remains a major problem.}
}

@article{rayyan-727967012,
  title={A systematic literature review of literature reviews in software testing},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={80},
  pages={195-216},
  author={Garousi, Vahid and Mäntylä, Mika V.},
  url={http://www.sciencedirect.com/science/article/pii/S0950584916301446},
  language={en},
  keywords={Tertiary study, Software testing, Secondary studies, Surveys, Systematic literature reviews, Systematic mapping, Software},
  abstract={Context     Any newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area.     Objective     The goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting evidence-based decision making in any given area of software engineering. Our research questions (RQs) investigate: (1) Software-testing-specific areas, (2) Types of RQs investigated, (3) Numbers and Trends, and (4) Citations of the secondary studies.     Method     To conduct the tertiary study, we use the systematic-mapping approach. Additionally, we contrast the testing topics to the number of Google hits to address a general popularity of a testing topic and study the most popular papers in terms of citations. We furthermore demonstrate the practicality and usefulness of our results by mapping them to ISTQB foundation syllabus and to SWEBOK to provide implications for practitioners, testing educators, and researchers.     Results     After a systematic search and voting process, our study pool included 101 secondary studies in the area of software testing between 1994 and 2015. Among our results are the following: (1) In terms of number of secondary studies, model-based approach is the most popular testing method, web services are the most popular system under test (SUT), while regression testing is the most popular testing phase; (2) The quality of secondary studies, as measured by a criteria set established in the community, is slowly increasing as the years go by; and (3) Analysis of research questions, raised and studied in the pool of secondary studies, showed that there is a lack of ‘causality’ and ‘relationship’ type of research questions, a situation which needs to be improved if we, as a community, want to advance as a scientific field. (4) Among secondary studies, we found that regular surveys receive significantly more citations than SMs (p=0.009) and SLRs (p=0.014).     Conclusion     Despite the large number of secondary studies, we found that many important areas of software testing currently lack secondary studies, e.g., test management, role of product risk in testing, human factors in software testing, beta-testing (A/B-testing), exploratory testing, testability, test stopping criteria, and test-environment development. Having secondary studies in those areas is important for satisfying industrial and educational needs in software testing. On the other hand, education material of ISTQB foundation syllabus and SWEBOK could benefit from the inclusion of the latest research topics, namely search-based testing, use of cloud-computing for testing and symbolic execution.}
}

@article{rayyan-727967015,
  title={Automated Selection and Quality Assessment of Primary Studies: A Systematic Literature Review},
  year={2019},
  journal={Journal of Data and Information Quality},
  issn={1936-1955},
  volume={12},
  number={1},
  pages={4:1-4:26},
  author={Shakeel, Yusra and Krüger, Jacob and Nostitz-Wallwitz, Ivonne Von and Saake, Gunter and Leich, Thomas},
  url={https://doi.org/10.1145/3356901},
  keywords={Systematic literature review, primary study assessment, quality assessment, software engineering, tertiary study},
  abstract={Researchers use systematic literature reviews (SLRs) to synthesize existing evidence regarding a research topic. While being an important means to condense knowledge, conducting an SLR requires a large amount of time and effort. Consequently, researchers have proposed semi-automatic techniques to support different stages of the review process. Two of the most time-consuming tasks are (1) to select primary studies and (2) to assess their quality. In this article, we report an SLR in which we identify, discuss, and synthesize existing techniques of the software-engineering domain that aim to semi-automate these two tasks. Instead of solely providing statistics, we discuss these techniques in detail and compare them, aiming to improve our understanding of supported and unsupported activities. To this end, we identified eight primary studies that report unique techniques that have been published between 2007 and 2016. Most of these techniques rely on text mining and can be beneficial for researchers, but an independent validation using real SLRs is missing for most of them. Moreover, the results indicate the necessity of developing more reliable techniques, providing access to their implementations, and extending their scope to further activities to facilitate the selection and quality assessment of primary studies.}
}

@article{rayyan-727967018,
  title={Systematic review toolbox: a catalogue of tools to support systematic reviews},
  year={2015},
  issn={978-1-4503-3350-4},
  pages={1-6},
  author={Marshall, Christopher and Brereton, Pearl},
  url={https://doi.org/10.1145/2745802.2745824},
  publisher={Association for Computing Machinery},
  series={EASE '15},
  keywords={documentation},
  abstract={Systematic review is a widely used research method in software engineering, and in other disciplines, for identifying and analysing empirical evidence. The method is data intensive and time consuming, and hence is usually supported by a wide range of software-based tools. However, systematic reviewers have found that finding and selecting tools can be quite challenging. In this paper, we present the Systematic Review Toolbox; a web-based catalogue of tools, to help reviewers find appropriate tools based on their particular needs.}
}

@article{rayyan-727967024,
  title={Text-Mining Techniques and Tools for Systematic Literature Reviews: A Systematic Literature Review},
  year={2017},
  journal={2017 24th Asia-Pacific Software Engineering Conference (APSEC)},
  pages={41-50},
  author={Feng, L. and Chiam, Y. K. and Lo, S. K.},
  keywords={~tool, systematic literature review, software engineering, Systematics, Systematic Literature Review, appropriate SLR automation strategies, Bibliographies, data mining, Data mining, Guidelines, mixed search strategy, Search problems, SLR activities, software engineering research, text analysis, Text mining techniques, text-mining techniques, Tool support, Tools},
  abstract={Despite the importance of conducting systematic literature reviews (SLRs) for identifying the research gaps in software engineering (SE) research, SLRs are a complex, multi-stage, and time-consuming process if performed manually. Conducting an SLR in line with the guidelines and practice in the SE domain requires considerable effort and expertise. The objective of this SLR is to identify and classify text-mining techniques and tools that can help facilitate SLR activities. This study also investigates the adoption of text-mining (TM) techniques to support SLR in the SE domain. We performed a mixed search strategy to identify relevant studies published from January 1, 2004, to December 31, 2016. We shortlisted 32 papers into the final set of relevant studies published in the SE, medicine and social science disciplines. The majority of the text-mining techniques attempted to support the study selection stage. Only 12 out of the 14 studies in the SE domain applied text-mining techniques, focusing primarily on facilitating the search and study selection stages. By learning from the experience of applying TM techniques in clinical medicine and social science fields, we believe that SE researchers can adopt appropriate SLR automation strategies for use in the SE field.}
}

@article{rayyan-727967026,
  title={An SLR-tool: search process in practice: a tool to conduct and manage systematic literature review (SLR)},
  year={2020},
  issn={978-1-4503-7122-3},
  pages={81-84},
  author={Hinderks, Andreas and Mayo, Francisco José Domínguez and Thomaschewski, Jörg and Escalona, María José},
  url={https://doi.org/10.1145/3377812.3382137},
  publisher={Association for Computing Machinery},
  series={ICSE '20},
  keywords={tool, systematic literature review, SLR},
  abstract={Systematic Literature Reviews (SLRs) have established themselves as a method in the field of software engineering. The aim of an SLR is to systematically analyze existing literature in order to answer a research question. In this paper, we present a tool to support an SLR process. The main focus of the SLR tool (https://www.slr-tool.com/) is to create and manage an SLR project, to import search results from search engines, and to manage search results by including or excluding each paper. A demo video of our SLR tool is available at https://youtu.be/Jan8JbwiE4k.}
}

@article{rayyan-727967145,
  title={Revisiting software ecosystems Research: A longitudinal literature study},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={117},
  pages={84-103},
  author={Manikas, Konstantinos},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216000406},
  keywords={Longitudinal literature study, Software ecosystem maturity, Software ecosystems, Software},
  abstract={‘Software ecosystems' is argued to first appear as a concept more than 10 years ago and software ecosystem research started to take off in 2010. We conduct a systematic literature study, based on the most extensive literature review in the field up to date, with two primarily aims: (a) to provide an updated overview of the field and (b) to document evolution in the field. In total, we analyze 231 papers from 2007 until 2014 and provide an overview of the research in software ecosystems. Our analysis reveals a field that is rapidly growing, both in volume and empirical focus, while becoming more mature. We identify signs of field maturity from the increase in: (i) the number of journal articles, (ii) the empirical models within the last two years, and (iii) the number of ecosystems studied. However, we note that the field is far from mature and identify a set of challenges that are preventing the field from evolving. We propose means for future research and the community to address them. Finally, our analysis shapes the view of the field having evolved outside the existing definitions of software ecosystems and thus propose the update of the definition of software ecosystems.}
}

@article{rayyan-727967153,
  title={A hybrid method for evaluating enterprise architecture implementation},
  year={2017},
  journal={Evaluation and Program Planning},
  issn={0149-7189},
  volume={60},
  pages={1-16},
  author={Nikpay, Fatemeh and Ahmad, Rodina and Yin Kia, Chiam},
  url={https://www.sciencedirect.com/science/article/pii/S014971891630012X},
  keywords={Decision making, Evaluation, Enterprise architecture, Hybrid method, Information system},
  abstract={Enterprise Architecture (EA) implementation evaluation provides a set of methods and practices for evaluating the EA implementation artefacts within an EA implementation project. There are insufficient practices in existing EA evaluation models in terms of considering all EA functions and processes, using structured methods in developing EA implementation, employing matured practices, and using appropriate metrics to achieve proper evaluation. The aim of this research is to develop a hybrid evaluation method that supports achieving the objectives of EA implementation. To attain this aim, the first step is to identify EA implementation evaluation practices. To this end, a Systematic Literature Review (SLR) was conducted. Second, the proposed hybrid method was developed based on the foundation and information extracted from the SLR, semi-structured interviews with EA practitioners, program theory evaluation and Information Systems (ISs) evaluation. Finally, the proposed method was validated by means of a case study and expert reviews. This research provides a suitable foundation for researchers who wish to extend and continue this research topic with further analysis and exploration, and for practitioners who would like to employ an effective and lightweight evaluation method for EA projects.}
}

@article{rayyan-727967159,
  title={On the declarative paradigm in hybrid business process representations: A conceptual framework and a systematic literature study},
  year={2020},
  journal={Information Systems},
  issn={0306-4379},
  volume={91},
  pages={101505},
  author={Abbad Andaloussi, Amine and Burattin, Andrea and Slaats, Tijs and Kindler, Ekkart and Weber, Barbara},
  url={https://www.sciencedirect.com/science/article/pii/S0306437920300168},
  keywords={Business process modeling, Declarative process modeling, Hybrid process model, Process flexibility, Understandability of process models},
  abstract={Process modeling plays a central role in the development of today's process-aware information systems both on the management level (e.g., providing input for requirements elicitation and fostering communication) and on the enactment level (providing a blue-print for process execution and enabling simulation). The literature comprises a variety of process modeling approaches proposing different modeling languages (i.e., imperative and declarative languages) and different types of process artifact support (i.e., process models, textual process descriptions, and guided simulations). However, the use of an individual modeling language or a single type of process artifact is usually not enough to provide a clear and concise understanding of the process. To overcome this limitation, a set of so-called “hybrid” approaches combining languages and artifacts have been proposed, but no common grounds have been set to define and categorize them. This work aims at providing a fundamental understanding of these hybrid approaches by defining a unified terminology, providing a conceptual framework and proposing an overarching overview to identify and analyze them. Since no common terminology has been used in the literature, we combined existing concepts and ontologies to define a “Hybrid Business Process Representation” (HBPR). Afterwards, we conducted a Systematic Literature Review (SLR) to identify and investigate the characteristics of HBPRs combining imperative and declarative languages or artifacts. The SLR resulted in 30 articles which were analyzed. The results indicate the presence of two distinct research lines and show common motivations driving the emergence of HBPRs, a limited maturity of existing approaches, and diverse application domains. Moreover, the results are synthesized into a taxonomy classifying different types of representations. Finally, the outcome of the study is used to provide a research agenda delineating the directions for future work.}
}

@article{rayyan-727967169,
  title={The state of the art in automated requirements elicitation},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={10},
  pages={1695-1709},
  author={Meth, Hendrik and Brhel, Manuel and Maedche, Alexander},
  url={https://www.sciencedirect.com/science/article/pii/S0950584913000827},
  keywords={Automation, Requirements Elicitation, Requirements Engineering, Requirements Reuse, Systematic Review},
  abstract={Context In large software development projects a huge number of unstructured text documents from various stakeholders becomes available and needs to be analyzed and transformed into structured requirements. This elicitation process is known to be time-consuming and error-prone when performed manually by a requirements engineer. Consequently, substantial research has been done to automate the process through a plethora of tools and technologies. Objective This paper aims to capture the current state of automated requirements elicitation and derive future research directions by identifying gaps in the existing body of knowledge and through relating existing works to each other. More specifically, we are investigating the following research question: What is the state of the art in research covering tool support for automated requirements elicitation from natural language documents? Method A systematic review of the literature in automated requirements elicitation is performed. Identified works are categorized using an analysis framework comprising tool categories, technological concepts and evaluation approaches. Furthermore, the identified papers are related to each other through citation analysis to trace the development of the research field. Results We identified, categorized and related 36 relevant publications. Summarizing the observations we made, we propose future research to (1) investigate alternative elicitation paradigms going beyond a pure automation approach (2) compare the effects of different types of knowledge on elicitation results (3) apply comparative evaluation methods and multi-dimensional evaluation measures and (4) strive for a closer integration of research activities across the sub-fields of automatic requirements elicitation. Conclusion Through the results of our paper, we intend to contribute to the Requirements Engineering body of knowledge by (1) conceptualizing an analysis framework for works in the area of automated requirements elicitation, going beyond former classifications (2) providing an extensive overview and categorization of existing works in this area (3) formulating concise directions for future research.}
}

@article{rayyan-727967208,
  title={Chapter 11 - managing trade-offs in self-adaptive software architectures: A systematic mapping study},
  year={2017},
  journal={Managing trade-offs in adaptable software architectures},
  issn={978-0-12-802855-1},
  pages={249-297},
  author={Salama, M and Bahsoon, R and Bencomo, N and Mistrik, Ivan and Ali, Nour and Kazman, Rick and Grundy, John and Schmerl, Bradley},
  url={https://www.sciencedirect.com/science/article/pii/B9780128028551000113},
  publisher={Morgan Kaufmann},
  address={Boston},
  keywords={Systematic mapping study, Software architecture, Long-living software, Self-adaptation, Self-adaptive architecture, Self-awareness, Trade-offs management, Software},
  abstract={Self-adaptation has been driven by the need to achieve and maintain quality attributes in the face of the continuously changing requirements, as well as the uncertain demand during run-time. Designing architectures that exhibit a good trade-off between multiple quality attributes is challenging, especially in the case of self-adaptive software systems, due to the complexity, heterogeneity, and ultra-large scale of modern software systems. This challenge increases with the dynamic, open, and uncertain operating environment, as well as the need for complying to environmental, regulatory, and sustainability requirements; such as energy consumption regulations. This study aims at analyzing the research landscape that have explicitly addressed trade-offs management for self-adaptive software architectures, to obtain a comprehensive overview on the current state of research on this specialized area. A systematic mapping study was conducted to identify and analyze research works related to analyzing and managing trade-offs to support decision-making for self-adaptive software architectures. Twenty primary studies were evidently selected and analyzed to classify software paradigms, quality attributes considered, and the self-* properties that drive trade-offs management. The results show constant interest in finding solutions for trade-offs management at design-time and run-time, as well as the success of research initiatives even when new research challenges are found. The findings call for foundational framework to analyze and manage trade-offs for self-adaptive software architectures that can explicitly consider specific multiple quality attributes, the run-time dynamics, the uncertainty of the environment and the complex challenges of modern, ultra-large scale systems in particular given software paradigms.}
}

@article{rayyan-727967219,
  title={Reverse engineering database queries from examples: State-of-the-art, challenges, and research opportunities},
  year={2019},
  journal={Information Systems},
  issn={0306-4379},
  volume={83},
  pages={89-100},
  author={Martins, Denis Mayr Lima},
  url={https://www.sciencedirect.com/science/article/pii/S0306437918300978},
  keywords={Databases, Query discovery, Query learning, Query synthesis, Reverse engineering database queries},
  abstract={With the popularization of data access and usage, an increasing number of users without expert knowledge of databases is required to perform data interactions. Often, these users face the challenges of writing and reformulating database queries, which consume a considerable amount of time and frequently yield unsatisfactory results. To facilitate this human–database interaction, researchers have investigated the Query By Example (QBE) paradigm in which database queries are (semi) automatically discovered from data examples given by users. This paradigm allows non-database experts to formulate queries without relying on complex query languages. In this context, this work aims to present a systematic review of the recent developments, open challenges, and research opportunities of the QBE reported in the literature. This work also describes strategies employed to leverage efficient example acquisition and query reverse engineering. The obtained results show that recent research developments have focused on enhancing the expressiveness of produced queries, minimizing user interaction, and enabling efficient query learning in the context of data retrieval, exploration, integration, and analytics. Our findings indicate that future research should concentrate efforts to provide innovative solutions to the challenges of improving controllability and transparency, considering diverse user preferences in the processes of learning personalized queries, ensuring data quality, and improving the support of additional SQL features and operators.}
}

@article{rayyan-727967220,
  title={On dynamic consensus processes in group decision making problems},
  year={2018},
  journal={Information Sciences},
  issn={0020-0255},
  volume={459},
  pages={20-35},
  author={Pérez, I J and Cabrerizo, F J and Alonso, S and Dong, Y C and Chiclana, F and Herrera-Viedma, E},
  url={https://www.sciencedirect.com/science/article/pii/S0020025518303724},
  keywords={Group decision making, Adaptive consensus models, Consensus process, Dynamic decision support systems, Multi period decision making, Decision Making, Group Processes},
  abstract={Consensus in group decision making requires discussion and deliberation between the group members with the aim to reach a decision that reflects the opinions of every group member in order for it to be acceptable by everyone. Traditionally, the consensus reaching problem is theoretically modelled as a multi stage negotiation process, i.e. an iterative process with a number of negotiation rounds, which ends when the consensus level achieved reaches a minimum required threshold value. In real world decision situations, both the consensus process environment and specific parameters of the theoretical model can change during the negotiation period. Consequently, there is a need for developing dynamic consensus process models to represent effectively and realistically the dynamic nature of the group decision making problem. Indeed, over the past few years, static consensus models have given way to new dynamic approaches in order to manage parameter variability or to adapt to environment changes. This paper presents a systematic literature review on the recent evolution of consensus reaching models under dynamic environments and critically analyse their advantages and limitations.}
}

@article{rayyan-727967221,
  title={Factors affecting the results of food preference tests in cats},
  year={2020},
  journal={Research in Veterinary Science},
  issn={0034-5288},
  volume={130},
  pages={247-254},
  author={Pires, Kássia Amariz and Miltenburg, Tânia Zóia and Miranda, Pamela Dieckow and Abade, Cristiane Caroline and Janeiro, Vanderly and Menolli, André Luis Andrade and Mizubuti, Ivone Yurika and Ribeiro, Leonir Bueno and Vasconcellos, Ricardo Souza},
  url={https://www.sciencedirect.com/science/article/pii/S0034528819311178},
  keywords={Domestic felines, Palatability test, Pet food, Taste preference, Two-bowl test, Cats},
  abstract={The aim of this study was to (i) gain an overview of the protocols of food preference tests in cats through a systematic review, (ii) assess the effects of test duration, time of day, and sex, and (iii) propose a statistical approach based on power analysis to determine sample size and analyze the results. The manuscripts included in this review had marked variations in the number of days (2–56), sample size (9–60 cats), feeding times (2.5–1440 min), and number of meals per day (1–2) during the test. Additionally to the literature review, three palatability tests (lasting 10 days each) were conducted with 40 cats (22 males and 18 females, 1.8 ± 0.16 years, 3.73 ± 0.90 kg) to assess the effects of test duration, time of day, and gender on the results. From the second day of the test, the sensitivity of the results was higher, because on the first day the results in one of the tests differed from the others (p = .0058). There was no difference (p ¿ .05) between times of day (morning vs afternoon) or gender (males vs females) on the results of the feed intake ratio. For a SD of 0.20, p ¡ .05, and delta of 0.10, the minimum number of cats for two-bowl assays is 23 (test power higher than 0.75).The sample size and test duration are critical factors in the decision making by the investigators about the design of food preference tests in cats. The use of a power test is recommended upon planning a food preference test protocol in cats.}
}

@article{rayyan-727967223,
  title={A review of machine learning algorithms for identification and classification of non-functional requirements},
  year={2019},
  journal={Expert Systems with Applications: X},
  issn={2590-1885},
  volume={1},
  pages={100001},
  author={Binkhonain, Manal and Zhao, Liping},
  url={https://www.sciencedirect.com/science/article/pii/S2590188519300010},
  keywords={Machine learning, Requirements engineering, Non-functional requirements, Requirements documents, Requirements identification Requirements classification, Algorithms},
  abstract={Context Recent developments in requirements engineering (RE) methods have seen a surge in using machine-learning (ML) algorithms to solve some difficult RE problems. One such problem is identification and classification of non-functional requirements (NFRs) in requirements documents. ML-based approaches to this problem have shown to produce promising results, better than those produced by traditional natural language processing (NLP) approaches. Yet, a systematic understanding of these ML approaches is still lacking. Method This article reports on a systematic review of 24 ML-based approaches for identifying and classifying NFRs. Directed by three research questions, this article aims to understand what ML algorithms are used in these approaches, how these algorithms work and how they are evaluated. Results (1) 16 different ML algorithms are found in these approaches; of which supervised learning algorithms are most popular. (2) All 24 approaches have followed a standard process in identifying and classifying NFRs. (3) Precision and recall are the most used matrices to measure the performance of these approaches. Finding The review finds that while ML-based approaches have the potential in the classification and identification of NFRs, they face some open challenges that will affect their performance and practical application. Impact The review calls for the close collaboration between RE and ML researchers, to address open challenges facing the development of real-world ML systems. Significance The use of ML in RE opens up exciting opportunities to develop novel expert and intelligent systems to support RE tasks and processes. This implies that RE is being transformed into an application of modern expert systems.}
}

@article{rayyan-727967224,
  title={A systematic examination of knowledge loss in open source software projects},
  year={2019},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={46},
  pages={104-123},
  author={Rashid, Mehvish and Clarke, Paul M and O'Connor, Rory V},
  url={https://www.sciencedirect.com/science/article/pii/S0268401217310095},
  keywords={Knowledge Management, Open Source Software, Contributor turnover, Knowledge loss, Knowledge loss impact, Knowledge retention, Software},
  abstract={Context Open Source Software (OSS) development is a knowledge focused activity which relies heavily on contributors who can be volunteers or paid workers and are geographically distributed. While working on OSS projects contributors acquire project related individualistic knowledge and gain experience and skills, which often remains unshared with others and is usually lost once contributors leave a project. All software development organisations face the problem of knowledge loss as employees leave, but this situation is exasperated in OSS projects where most contributors are volunteers with largely unpredictable engagement durations. Contributor turnover is inevitable due to the transient nature of OSS project workforces causing knowledge loss, which threatens the overall sustainability of OSS projects and impacts negatively on software quality and contributor productivity. Objective The objective of this work is to deeply and systematically investigate the phenomenon of knowledge loss due to contributor turnover in OSS projects as presented in the state-of-the-art literature and to synthesise the information presented on the topic. Furthermore, based on the learning arising from our investigation it is our intention to identify mechanisms to reduce the overall effects of knowledge loss in OSS projects. Methodology We use the snowballing methodology to identify the relevant literature on knowledge loss due to contributor turnover in OSS projects. This robust methodology for a literature review includes research question, search strategy, inclusion, exclusion, quality criteria, and data synthesis. The search strategy, and inclusion, exclusions and quality criteria are applied as a part of snowballing procedure. Snowballing is considered an efficient and reliable way to conduct a systematic literature review, providing a robust alternative to mechanically searching individual databases for given topics. Result Knowledge sharing in OSS projects is abundant but there is no evidence of a formal strategy or practice to manage knowledge. Due to the dynamic and diverse nature of OSS projects, knowledge management is considered a challenging task and there is a need for a proactive mechanism to share knowledge in the OSS community for knowledge to be reused in the future by the OSS project contributors. From the collection of papers found using snowballing, we consolidated various themes on knowledge loss due to contributor turnover in OSS projects and identified 11 impacts due to knowledge loss in OSS projects, and 10 mitigations to manage with knowledge loss in OSS projects. Conclusion In this paper, we propose future research directions to investigate integration of proactive knowledge retention practices with the existing OSS practices to reduce the current knowledge loss problem. We suggest that there is insufficient attention paid to KM in general in OSS, in particular there would appear to an absence of proactive measures to reduce the potential impact of knowledge loss. We also propose the need for a KM evaluation metric in OSS projects, similar to the ones that evaluate health of online communities, which should help to inform potential consumers of the OSS of the KM status on a project, something that is not existent today.}
}

@article{rayyan-727967228,
  title={Evaluating and selecting software packages: A review},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={3},
  pages={555-563},
  author={Jadhav, Anil S and Sonar, Rajendra M},
  url={https://www.sciencedirect.com/science/article/pii/S0950584908001262},
  keywords={Evaluation criteria, Software evaluation, Software selection, Software selection tools, Software},
  abstract={Evaluating and selecting software packages that meet an organization's requirements is a difficult software engineering process. Selection of a wrong software package can turn out to be costly and adversely affect business processes. The aim of this paper is to provide a basis to improve the process of evaluation and selection of the software packages. This paper reports a systematic review of papers published in journals and conference proceedings. The review investigates methodologies for selecting software packages, software evaluation techniques, software evaluation criteria, and systems that support decision makers in evaluating software packages. The key findings of the review are: (1) analytic hierarchy process has been widely used for evaluation of the software packages, (2) there is lack of a common list of generic software evaluation criteria and its meaning, and (3) there is need to develop a framework comprising of software selection methodology, evaluation technique, evaluation criteria, and system to assist decision makers in software selection.}
}

@article{rayyan-727967229,
  title={Knowledge management support for enterprise resource planning implementation},
  year={2015},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={72},
  pages={613-621},
  author={Saide and Mahendrawathi, E R},
  url={https://www.sciencedirect.com/science/article/pii/S1877050915036315},
  keywords={Enterprise Resource Planning (ERP), Knowledge Management (KM), Knowledge Transfer, Knowledge Worker, SECI Model},
  abstract={This study addresses the issues of Enterprise Resource Planning (ERP), Knowledge Management (KM) and SECI model (socialization, externalization, combination, internalization). Various research have highlighted the importance of knowledge of ERP users for successful ERP implementation, however a major obstacle from the perspective of integration or knowledge transfer cycle still exists. The main problem in ERP implementation is the difficult integration of tacit (embedded) and explicit knowledge cause most of this knowledge are embedded in ERP external parties (such as consultants, vendors, suppliers, supervisors, experts, and other working partners). The focus of this study is to propose process for transfer knowledge from external organizations into organizations based on the model of SECI. To note that this paper is not to modify the basic model of SECI, but SECI model to making as a function of mediator between the external and internal ERP system implementation in company. The authors used a systematic literature review approach, starts with literature review, problems identification, selection process, assess, synthesize and write down the ideas proposed, and then make conclusions. Finally, the output of this research is a new model (schematic and technical) of the process and transfer knowledge order to maintain and re-use assets from external knowledge obtained during the pre to post ERP implementation to be used jointly by the company.}
}

@article{rayyan-727967253,
  title={Testing embedded software: A survey of the literature},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={104},
  pages={14-45},
  author={Garousi, Vahid and Felderer, Michael and Karapıçak, Çağrı Murat and Yılmaz, Uğur},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301265},
  keywords={Software testing, Systematic literature review, Systematic mapping, Embedded software, Embedded systems, Systematic literature mapping, Software},
  abstract={Context Embedded systems have overwhelming penetration around the world. Innovations are increasingly triggered by software embedded in automotive, transportation, medical-equipment, communication, energy, and many other types of systems. To test embedded software in an effective and efficient manner, a large number of test techniques, approaches, tools and frameworks have been proposed by both practitioners and researchers in the last several decades. Objective However, reviewing and getting an overview of the entire state-of-the-art and the –practice in this area is challenging for a practitioner or a (new) researcher. Also unfortunately, as a result, we often see that many companies reinvent the wheel (by designing a test approach new to them, but existing in the domain) due to not having an adequate overview of what already exists in this area. Method To address the above need, we conducted and report in this paper a systematic literature review (SLR) in the form of a systematic literature mapping (SLM) in this area. After compiling an initial pool of 588 papers, a systematic voting about inclusion/exclusion of the papers was conducted among the authors, and our final pool included 312 technical papers. Results Among the various aspects that we aim at covering, our review covers the types of testing topics studied, types of testing activity, types of test artifacts generated (e.g., test inputs or test code), and the types of industries in which studies have focused on, e.g., automotive and home appliances. Furthermore, we assess the benefits of this review by asking several active test engineers in the Turkish embedded software industry to review its findings and provide feedbacks as to how this review has benefitted them. Conclusion The results of this review paper have already benefitted several of our industry partners in choosing the right test techniques / approaches for their embedded software testing challenges. We believe that it will also be useful for the large world-wide community of software engineers and testers in the embedded software industry, by serving as an “index” to the vast body of knowledge in this important area. Our results will also benefit researchers in observing the latest trends in this area and for identifying the topics which need further investigations.}
}

@article{rayyan-727967263,
  title={Analyzing impact of experience curve on ROI in the software product line adoption process},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={59},
  pages={136-148},
  author={Tüzün, Eray and Tekinerdogan, Bedir},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914002079},
  keywords={Productivity, Software reuse, Cost models, Experience curve, Learning curve, Software product line engineering, Software},
  abstract={Context Experience curve is a well-known concept in management and education science, which explains the phenomenon of increased worker efficiency with repetitive production of a good or service. Objective We aim to analyze the impact of the experience curve effect on the Return on Investment (ROI) in the software product line engineering (SPLE) process. Method We first present the results of a systematic literature review (SLR) to explicitly depict the studies that have considered the impact of experience curve effect on software development in general. Subsequently, based on the results of the SLR, the experience curve effect models in the literature, and the SPLE cost models, we define an approach for extending the cost models with the experience curve effect. Finally, we discuss the application of the refined cost models in a real industrial context. Results The SLR resulted in 15 primary studies which confirm the impact of experience curve effect on software development in general but the experience curve effect in the adoption of SPLE got less attention. The analytical discussion of the cost models and the application of the refined SPLE cost models in the industrial context showed a clear impact of the experience curve effect on the time-to-market, cost of development and ROI in the SPLE adoption process. Conclusions The proposed analysis with the newly defined cost models for SPLE adoption provides a more precise analysis tool for the management, and as such helps to support a better decision making.}
}

@article{rayyan-727967266,
  title={VIVACE: A framework for the systematic evaluation of variability support in process-aware information systems},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={57},
  pages={248-276},
  author={Ayora, Clara and Torres, Victoria and Weber, Barbara and Reichert, Manfred and Pelechano, Vicente},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001268},
  keywords={Systematic literature review, Business process, Business process variability, Process family, Process-aware information systems, Information Systems},
  abstract={abstract Context The increasing adoption of process-aware information systems (PAISs) such as workflow management systems, enterprise resource planning systems, or case management systems, together with the high variability in business processes (e.g., sales processes may vary depending on the respective products and countries), has resulted in large industrial process model repositories. To cope with this business process variability, the proper management of process variants along the entire process lifecycle becomes crucial. Objective The goal of this paper is to develop a fundamental understanding of business process variability. In particular, the paper will provide a framework for assessing and comparing process variability approaches and the support they provide for the different phases of the business process lifecycle (i.e., process analysis and design, configuration, enactment, diagnosis, and evolution). Method We conducted a systematic literature review (SLR) in order to discover how process variability is supported by existing approaches. Results The SLR resulted in 63 primary studies which were deeply analyzed. Based on this analysis, we derived the VIVACE framework. VIVACE allows assessing the expressiveness of a process modeling language regarding the explicit specification of process variability. Furthermore, the support provided by a process-aware information system to properly deal with process model variants can be assessed with VIVACE as well. Conclusions VIVACE provides an empirically-grounded framework for process engineers that enables them to evaluate existing process variability approaches as well as to select that variability approach meeting their requirements best. Finally, it helps process engineers in implementing PAISs supporting process variability along the entire process lifecycle.}
}

@article{rayyan-727967267,
  title={Empirical evaluation of a decision support model for adopting software product line engineering},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={60},
  pages={77-101},
  author={Tüzün, Eray and Tekinerdogan, Bedir and Kalender, Mert Emin and Bilgen, Semih},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915000026},
  keywords={Systematic literature review, Decision support system, Software product line engineering, Case study design, Software product line engineering feasibility analysis, Software product line transition strategies, Software, Decision Support Techniques},
  abstract={Context The software product line engineering (SPLE) community has provided several different approaches for assessing the feasibility of SPLE adoption and selecting transition strategies. These approaches usually include many rules and guidelines which are very often implicit or scattered over different publications. Hence, for the practitioners it is not always easy to select and use these rules to support the decision making process. Even in case the rules are known, the lack of automated support for storing and executing the rules seriously impedes the decision making process. Objective We aim to evaluate the impact of a decision support system (DSS) on decision-making in SPLE adoption. In alignment with this goal, we provide a decision support model (DSM) and the corresponding DSS. Method First, we apply a systematic literature review (SLR) on the existing primary studies that discuss and present approaches for analyzing the feasibility of SPLE adoption and transition strategies. Second, based on the data extraction and synthesis activities of the SLR, the required questions and rules are derived and implemented in the DSS. Third, for validation of the approach we conduct multiple case studies. Results In the course of the SLR, 31 primary studies were identified from which we could construct 25 aspects, 39 questions and 312 rules. We have developed the DSS tool Transit-PL that embodies these elements. Conclusions The multiple case study validation showed that the adoption of the developed DSS tool is justified to support the decision making process in SPLE adoption.}
}

@article{rayyan-727967270,
  title={A review of cross organizational healthcare data sharing},
  year={2015},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={63},
  pages={425-432},
  author={Azarm-Daigle, Mana and Kuziemsky, Craig and Peyton, Liam},
  url={https://www.sciencedirect.com/science/article/pii/S1877050915024989},
  keywords={Cross-organizational healthcare data sharing, interoperability, literature review, patient privacy, quality of care, technology adoption, Information Dissemination},
  abstract={Increasingly, healthcare is provided by a team of care providers from different organizations. Cross-organizational healthcare data sharing is a major issue in interoperable healthcare organizations. Studies have shown that quality of care can be put at risk when patients are transferred from one organization to another, while the need for protecting patient privacy is sometimes an inhibitor to providing information computing technology (ICT) solutions. This paper presents a systematic literature review of cross-organizational healthcare data sharing. The review includes research related to laws and regulations as well as proposed methodological and ICT solutions. Our methodology for querying, filtering and selecting relevant papers from scientific, academic and general repositories is explained and the selected papers are categorized and compared in terms of scope, contributions, and future directions. Based on this analysis, we outline a possible research direction for developing ICT solutions that healthcare providers and regulators would be willing to adopt. Based on our review, we concluded that inspite of the liberal regulations around data sharing among authorized healthcare providers, these organizations are utterly reluctant to collaborate on patient information. Fear of a breech of personal health information, and the shortage of technological facilitators that are compatible with the existing health information systems, are the main causes of the cross-organizational interoperability problems in the healthcare sector. The existing collaborative technologies require considerable initial investments that the current healthcare system is not willing to spend funds on.}
}

@article{rayyan-727967281,
  title={Software outsourcing partnership model: An evaluation framework for vendor organizations},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={117},
  pages={402-425},
  author={Ali, Sikandar and Khan, Siffat Ullah},
  url={https://www.sciencedirect.com/science/article/pii/S016412121630019X},
  keywords={Systematic literature review, Critical success factors, Software outsourcing partnership, Software},
  abstract={Software Outsourcing Partnership (SOP) is a new software development paradigm for developing high quality software products. A SOP is different to ordinary software development outsourcing (SDO) relationship. SOP is the enhanced form of conventional outsourcing relationship. The objective of this research paper is to develop a software outsourcing partnership model (SOPM) to identify and analyze factors that are important for vendors in conversion of their existing outsourcing relationship to partnership. We have performed a systematic literature review (SLR) process for the identification of critical success factors (CSFs) from a sample of 111 articles. Further we have categorized the identified CSFs into five partnership levels based on Capability Maturity Model Integration (CMMI) and Software Outsourcing Vendors' Readiness Model (SOVRM). To validate the SLR findings and to find practices for the identified CSFs a questionnaire survey was conducted in the outsourcing industry in which 35 experts, from 8 different countries participated. Two case studies were conducted for evaluation of the SOPM. In this paper our newly developed model, SOPM, has been presented in detail. SOPM has been built with the intent to assist SDO vendor organizations in measuring their capabilities for successful conversion of their contractual outsourcing relationship to outsourcing partnership.}
}

@article{rayyan-727967282,
  title={Architectural design space for modelling and simulation as a service: A review},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={170},
  pages={110752},
  author={Shahin, Mojtaba and Babar, M Ali and Chauhan, Muhammad Aufeef},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220301746},
  keywords={Systematic review, Architecture, Modelling and Simulation as a Service, MSaaS},
  abstract={Modelling and Simulation as a Service (MSaaS) is a promising approach to deploy and execute Modelling and Simulation (M&S) applications quickly and on-demand. An appropriate software architecture is essential to deliver quality M&S applications following the MSaaS concept to a wide range of users. This study aims to characterize the state-of-the-art MSaaS architectures by conducting a systematic review of 31 papers published from 2010 to 2018. Our findings reveal that MSaaS applications are mainly designed using layered architecture style, followed by service-oriented architecture, component-based architecture, and pluggable component-based architecture. We also found that interoperability and deployability have the greatest importance in the architecture of MSaaS applications. In addition, our study indicates that the current MSaaS architectures do not meet the critical user requirements of modern M&S applications appropriately. Based on our results, we recommend that there is a need for more effort and research to (1) design the user interfaces that enable users to build and configure simulation models with minimum effort and limited domain knowledge, (2) provide mechanisms to improve the deployability of M&S applications, and (3) gain a deep insight into how M&S applications should be architected to respond to the emerging user requirements in the military domain.}
}

@article{rayyan-727967283,
  title={Definitions and approaches to model quality in model-based software development – A review of literature},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={12},
  pages={1646-1669},
  author={Mohagheghi, Parastoo and Dehlen, Vegard and Neple, Tor},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909000457},
  keywords={Systematic review, Modelling, UML, Model-driven development, Model quality, Software},
  abstract={More attention is paid to the quality of models along with the growing importance of modelling in software development. We performed a systematic review of studies discussing model quality published since 2000 to identify what model quality means and how it can be improved. From forty studies covered in the review, six model quality goals were identified; i.e., correctness, completeness, consistency, comprehensibility, confinement and changeability. We further present six practices proposed for developing high-quality models together with examples of empirical evidence. The contributions of the article are identifying and classifying definitions of model quality and identifying gaps for future research.}
}

@article{rayyan-727967284,
  title={Management of quality requirements in agile and rapid software development: A systematic mapping study},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={123},
  pages={106225},
  author={Behutiye, Woubshet and Karhapää, Pertti and López, Lidia and Burgués, Xavier and Martínez-Fernández, Silverio and Vollmer, Anna Maria and Rodríguez, Pilar and Franch, Xavier and Oivo, Markku},
  url={https://www.sciencedirect.com/science/article/pii/S095058491930240X},
  keywords={Systematic mapping study, Systematic literature reviews, Agile software development, Non-functional requirements, Quality requirements, Rapid software development, Software},
  abstract={Context Quality requirements (QRs) describe the desired quality of software, and they play an important role in the success of software projects. In agile software development (ASD), QRs are often ill-defined and not well addressed due to the focus on quickly delivering functionality. Rapid software development (RSD) approaches (e.g., continuous delivery and continuous deployment), which shorten delivery times, are more prone to neglect QRs. Despite the significance of QRs in both ASD and RSD, there is limited synthesized knowledge on their management in those approaches. Objective This study aims to synthesize state-of-the-art knowledge about QR management in ASD and RSD, focusing on three aspects: bibliometric, strategies, and challenges. Research method Using a systematic mapping study with a snowballing search strategy, we identified and structured the literature on QR management in ASD and RSD. Results We found 156 primary studies: 106 are empirical studies, 16 are experience reports, and 34 are theoretical studies. Security and performance were the most commonly reported QR types. We identified various QR management strategies: 74 practices, 43 methods, 13 models, 12 frameworks, 11 advices, 10 tools, and 7 guidelines. Additionally, we identified 18 categories and 4 non-recurring challenges of managing QRs. The limited ability of ASD to handle QRs, time constraints due to short iteration cycles, limitations regarding the testing of QRs and neglect of QRs were the top categories of challenges. Conclusion Management of QRs is significant in ASD and is becoming important in RSD. This study identified research gaps, such as the need for more tools and guidelines, lightweight QR management strategies that fit short iteration cycles, investigations of the link between QRs challenges and technical debt, and extension of empirical validation of existing strategies to a wider context. It also synthesizes QR management strategies and challenges, which may be useful for practitioners.}
}

@article{rayyan-727967297,
  title={Systematic review of organizational motivations for adopting CMM-based SPI},
  year={2008},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={50},
  number={7},
  pages={605-620},
  author={Staples, Mark and Niazi, Mahmood},
  url={https://www.sciencedirect.com/science/article/pii/S0950584907000778},
  keywords={Capability Maturity Model, CMM, CMMI, Software Process Improvement},
  abstract={Background: Software Process Improvement (SPI) is intended to improve software engineering, but can only be effective if used. To improve SPI's uptake, we should understand why organizations adopt SPI. CMM-based SPI approaches are widely known and studied. Objective: We investigated why organizations adopt CMM-based SPI approaches, and how these motivations relate to organizations' size. Method: We performed a systematic review, examining reasons reported in more than forty primary studies. Results: Reasons usually related to product quality and project performance, and less commonly, to process. Organizations reported customer reasons infrequently and employee reasons very rarely. We could not show that reasons related to size. Conclusion: Despite its origins in helping to address customer-related issues for the USAF, CMM-based SPI has mostly been adopted to help organizations improve project performance and product quality issues. This reinforces a view that the goal of SPI is not to improve process per se, but instead to provide business benefits.}
}

@article{rayyan-727967301,
  title={A systematic review of domain analysis tools},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={1},
  pages={1-13},
  author={Lisboa, Liana Barachisio and Garcia, Vinicius Cardoso and Lucrédio, Daniel and de Almeida, Eduardo Santana and de Lemos Meira, Silvio Romero and de Mattos Fortes, Renata Pontin},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909000834},
  keywords={Tools, Systematic review, Domain analysis},
  abstract={The domain analysis process is used to identify and document common and variable characteristics of systems in a specific domain. In order to achieve an effective result, it is necessary to collect, organize and analyze several sources of information about different applications in this domain. Consequently, this process involves distinct phases and activities and also needs to identify which artifacts, arising from these activities, have to be traceable and consistent. In this context, performing a domain analysis process without tool support increases the risks of failure, but the used tool should support the complete process and not just a part of it. This article presents a systematic review of domain analysis tools that aims at finding out how the available tools offer support to the process. As a result, the review identified that these tools are usually focused on supporting only one process and there are still gaps in the complete process support. Furthermore, the results can provide insights for new research in the domain engineering area for investigating and defining new tools, and the study also aids in the identification of companies' needs for a domain analysis tool.}
}

@article{rayyan-727967304,
  title={All-Learning: The state of the art of the models and the methodologies educational with ICT},
  year={2018},
  journal={Telematics and Informatics},
  issn={0736-5853},
  volume={35},
  number={4},
  pages={944-953},
  author={Ramirez, Gabriel M and Collazos, Cesar A and Moreira, Fernando},
  url={https://www.sciencedirect.com/science/article/pii/S073658531730271X},
  keywords={Integration, Education, ICT, Methodology, Model},
  abstract={This paper presents a systematic review of models and methodologies that integrate information and communication technologies (ICT) and education. The systematic review was based on the methodology of Kitchenham. The steps used and developed correspond to the steps proposed in the methodology. The starting point of the review are the research questions, then keywords, selection of the databases, definition of the inclusion and exclusion criteria, the definition of the search chains, search process and selection of papers, the analyzes of the paper and the results of the systematic review to answer the questions posed. In the systematic review, 919 papers were found in 6 academic databases and 129 relevant papers were selected. The work developed intends to know the different models and methodologies that integrate the ICT and the education. Develop an analysis and characterize to find common elements among models and methodologies. The idea is to find limitations, disadvantages and spaces that allow to propose a new model. This systematic review is the first step in the development of a doctoral research in which the development of a U-Learning model based on Connective Learning and Experience Learning is proposed.}
}

@article{rayyan-727967305,
  title={Service composition approaches in IoT: A systematic review},
  year={2018},
  journal={Journal of Network and Computer Applications},
  issn={1084-8045},
  volume={120},
  pages={61-77},
  author={Asghari, Parvaneh and Rahmani, Amir Masoud and Javadi, Hamid Haj Seyyed},
  url={https://www.sciencedirect.com/science/article/pii/S1084804518302376},
  keywords={Systematic literature review, QoS, Internet of things, Service composition, Smart objects},
  abstract={The Internet of Things (IoT) signifies to an overall system of interconnected physical Things utilizing existing correspondence conventions. One critical inquiry remains in what manner can make and communicate the management of provided services for smart devices by an assortment of protest things that substituted and joined capably. Service composition process permits the interaction between user requirements and smart objects of IoT environment. Leveraging on the service discovery procedure can be influenced on finding the desired services. Consequently, choosing suitable services is the main challenge that covers functionality and required quality to combine several services as the integrated composite service in the IoT. The service composition process has been broadly considered with regards to web suppliers and business processes in the IoT. Currently, the IoT environment identifies the dynamic relationship topics on physical processes that are combined as the enhanced web services heterogeneously. This paper focuses on several service composition approaches that are applied in the IoT environment based on the Systematic Literature Review (SLR) method. The aim of this study is to analytically and statistically categorize and analyze the current research techniques on the service composition in the IoT (published between 2012 and 2017). A technical taxonomy is presented for the service composition approaches according to content of the existing studies that are selected with SLR method in this review with respect to functional and non-functional aspects in service composition approaches. The functional aspect emphasizes on verifying the behavior of service composition approach and the non-functional aspect considers the Quality of Service (QoS) in IoT environment. The approaches are compared with each other according to some technical aspects such as system correctness factors in functional properties approaches, and (QoS) factors, presented algorithms, and existing platforms in non-functional approaches. The advantages and disadvantages of each selected approach discussed as well as providing some hints for solving their weaknesses. A brief contribution to this literature is as follows: (1) Presenting a SLR method for the service composition approaches in IoT, (2) Addressing a discussion of the main challenges, (3) Providing the future research directions and open perspectives.}
}

@article{rayyan-727967306,
  title={Toward semantic IoT load inference attention management for facilitating healthcare and public health collaboration: A survey},
  year={2020},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={177},
  pages={371-378},
  author={Lim, Sachiko and Rahmani, Rahim},
  url={https://www.sciencedirect.com/science/article/pii/S1877050920323188},
  keywords={Crisis management, Federated edge-cloud computing, Healthcare, Public Health, semantic interoperability, Semantic IoT, Semantics},
  abstract={The health of individuals and populations requires concerted and collaborative efforts by healthcare, public health, social care, and personal health management. The inter-sectoral collaborations are more crucial than ever, especially when facing public health crises, including the ongoing pandemic of coronavirus disease-2019 (COVID-19). Although the capabilities of healthcare and public health systems have increased with a dramatic boost in the use of the Internet of Things (IoT), such IoT-enabled systems are often operating in silos. A pressing need, thus, is the seamless integration of those currently incompatible systems. A promising solution is to leverage semantic technologies to increase interoperability among such systems. Therefore, this article aims to: conduct a systematic review on the current state-of-the-art semantic IoT solutions used in health domain; identify the associated challenges; propose a federated edge-cloud semantic IoT architecture to facilitate the healthcare and public health (HC-PH) collaborations for the health and well-being of the individuals and populations.}
}

@article{rayyan-727967307,
  title={A systematic review of shared visualisation to achieve common ground},
  year={2015},
  journal={Journal of Visual Languages & Computing},
  issn={1045-926X},
  volume={28},
  pages={83-99},
  author={Yusoff, Nor'ain Mohd and Salim, Siti Salwah},
  url={https://www.sciencedirect.com/science/article/pii/S1045926X1400158X},
  keywords={Human–computer interaction, Collaborative design, Shared visualisation, Teamwork},
  abstract={This paper reports a systematic review of shared visualisation based on fifteen papers from 2000 to 2013. The findings identified five shared visualisation strategies that represent the ways implemented to process data sharing and knowledge to arrive at the desired level of understanding. Four visualisation techniques were also identified to show how shared cognition is made possible in designing tools for mediating data or knowledge among the users involved. These findings provide research opportunities in integrating rich interactive data visualisation for mobile-based technologies as an effective mean in supporting collaborative work. Finally, social, task and cognitive elements which can be significantly supported by shared visualisation and a guideline for future researchers seeking to design shared visualisation-based systems are presented.}
}

@article{rayyan-727967308,
  title={A systematic review of search-based testing for non-functional system properties},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={6},
  pages={957-976},
  author={Afzal, Wasif and Torkar, Richard and Feldt, Robert},
  url={https://www.sciencedirect.com/science/article/pii/S0950584908001833},
  keywords={Systematic review, Non-functional system properties, Search-based software testing},
  abstract={Search-based software testing is the application of metaheuristic search techniques to generate software tests. The test adequacy criterion is transformed into a fitness function and a set of solutions in the search space are evaluated with respect to the fitness function using a metaheuristic search technique. The application of metaheuristic search techniques for testing is promising due to the fact that exhaustive testing is infeasible considering the size and complexity of software under test. Search-based software testing has been applied across the spectrum of test case design methods; this includes white-box (structural), black-box (functional) and grey-box (combination of structural and functional) testing. In addition, metaheuristic search techniques have also been applied to test non-functional properties. The overall objective of undertaking this systematic review is to examine existing work into non-functional search-based software testing (NFSBST). We are interested in types of non-functional testing targeted using metaheuristic search techniques, different fitness functions used in different types of search-based non-functional testing and challenges in the application of these techniques. The systematic review is based on a comprehensive set of 35 articles obtained after a multi-stage selection process and have been published in the time span 1996–2007. The results of the review show that metaheuristic search techniques have been applied for non-functional testing of execution time, quality of service, security, usability and safety. A variety of metaheuristic search techniques are found to be applicable for non-functional testing including simulated annealing, tabu search, genetic algorithms, ant colony methods, grammatical evolution, genetic programming (and its variants including linear genetic programming) and swarm intelligence methods. The review reports on different fitness functions used to guide the search for each of the categories of execution time, safety, usability, quality of service and security; along with a discussion of possible challenges in the application of metaheuristic search techniques.}
}

@article{rayyan-727967309,
  title={Towards innovation measurement in the software industry},
  year={2013},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={86},
  number={5},
  pages={1390-1407},
  author={Edison, Henry and bin Ali, Nauman and Torkar, Richard},
  url={https://www.sciencedirect.com/science/article/pii/S0164121213000058},
  keywords={Systematic literature review, Empirical study, Measurement, Metrics, Innovation, Software},
  abstract={In today's highly competitive business environments with shortened product and technology life cycle, it is critical for software industry to continuously innovate. This goal can be achieved by developing a better understanding and control of the activities and determinants of innovation. Innovation measurement initiatives assess innovation capability, output and performance to help develop such an understanding. This study explores various aspects relevant to innovation measurement ranging from definitions, measurement frameworks and metrics that have been proposed in literature and used in practice. A systematic literature review followed by an online questionnaire and interviews with practitioners and academics were employed to identify a comprehensive definition of innovation that can be used in software industry. The metrics for the evaluation of determinants, inputs, outputs and performance were also aggregated and categorised. Based on these findings, a conceptual model of the key measurable elements of innovation was constructed from the findings of the systematic review. The model was further refined after feedback from academia and industry through interviews.}
}

@article{rayyan-727967310,
  title={Considering rigor and relevance when evaluating test driven development: A systematic review},
  year={2014},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={56},
  number={4},
  pages={375-394},
  author={Munir, Hussan and Moayyed, Misagh and Petersen, Kai},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914000135},
  keywords={Productivity, External code quality, Internal code quality, Test-driven development (TDD), Test-last development (TLD)},
  abstract={Context Test driven development (TDD) has been extensively researched and compared to traditional approaches (test last development, TLD). Existing literature reviews show varying results for TDD. Objective This study investigates how the conclusions of existing literature reviews change when taking two study quality dimension into account, namely rigor and relevance. Method In this study a systematic literature review has been conducted and the results of the identified primary studies have been analyzed with respect to rigor and relevance scores using the assessment rubric proposed by Ivarsson and Gorschek 2011. Rigor and relevance are rated on a scale, which is explained in this paper. Four categories of studies were defined based on high/low rigor and relevance. Results We found that studies in the four categories come to different conclusions. In particular, studies with a high rigor and relevance scores show clear results for improvement in external quality, which seem to come with a loss of productivity. At the same time high rigor and relevance studies only investigate a small set of variables. Other categories contain many studies showing no difference, hence biasing the results negatively for the overall set of primary studies. Given the classification differences to previous literature reviews could be highlighted. Conclusion Strong indications are obtained that external quality is positively influenced, which has to be further substantiated by industry experiments and longitudinal case studies. Future studies in the high rigor and relevance category would contribute largely by focusing on a wider set of outcome variables (e.g. internal code quality). We also conclude that considering rigor and relevance in TDD evaluation is important given the differences in results between categories and in comparison to previous reviews.}
}

@article{rayyan-727967311,
  title={A systematic review of security requirements engineering},
  year={2010},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={32},
  number={4},
  pages={153-165},
  author={Mellado, Daniel and Blanco, Carlos and Sánchez, Luis E and Fernández-Medina, Eduardo},
  url={https://www.sciencedirect.com/science/article/pii/S0920548910000255},
  keywords={Systematic review, Requirements engineering, Security, Security requirements, Secure development, Security engineering, Security requirements engineering},
  abstract={One of the most important aspects in the achievement of secure software systems in the software development process is what is known as Security Requirements Engineering. However, very few reviews focus on this theme in a systematic, thorough and unbiased manner, that is, none of them perform a systematic review of security requirements engineering, and there is not, therefore, a sufficiently good context in which to operate. In this paper we carry out a systematic review of the existing literature concerning security requirements engineering in order to summarize the evidence regarding this issue and to provide a framework/background in which to appropriately position new research activities.}
}

@article{rayyan-727967315,
  title={A systematic review of foresight in project management literature},
  year={2015},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={64},
  pages={792-799},
  author={Silva, Marisa},
  url={https://www.sciencedirect.com/science/article/pii/S1877050915027659},
  keywords={Foresight, Project Management, systematic review.},
  abstract={Projects, like companies, do not fail overnight. When a company fails, this is often not much related to operational aspects but to an inability to think holistically about the driving forces that may change its business landscape in a disruptive way. Based on this, organizations are nowadays seeking different approaches to cope with uncertainty, and as a result, Foresight as a supporting tool to long range planning is gaining popularity at corporate and governmental level. Given that projects share with Foresight the same orientation towards the future and both lead with uncertainty, it is thus relevant to ask whether Foresight can be used to improve Project Management practice. In order to research into these questions, this paper conducted a systematic review on the topic of Foresight in leading Project Management literature. The review revealed that an explicit relationship between Foresight and Project Management exists, and although with limitations, evidence suggests that there is value in adopting Foresight. This study makes a contribution to the body of empirical works in this field and is intended to be primarily used by Project Management practitioners and practically-oriented academics who are interested in developing fresh insights into new approaches for better management of projects.}
}

@article{rayyan-727967316,
  title={Modelling and simulation considerations for an end-to-end supply chain system},
  year={2020},
  journal={Computers & Industrial Engineering},
  issn={0360-8352},
  volume={150},
  pages={106870},
  author={Chilmon, Barbara and Tipi, Nicoleta S},
  url={https://www.sciencedirect.com/science/article/pii/S0360835220305659},
  keywords={Systematic literature review, End-to-end supply chain, Simulation},
  abstract={The efforts of this review paper are twofold: to provide an insightful examination of various contributions to knowledge surrounding simulation methods within an end-to-end supply chain and to guide research agenda by indicating generic elements required to model such systems using simulation. The authors examined 255 publications from 21 peer-reviewed journals in the field of an end-to-end supply chain and simulation using a systematic literature review approach. Each publication was thoroughly reviewed to capture best practices and key characteristics relative to simulation modelling techniques used in the context of complex end-to-end supply chain systems. This allowed for identification of generic elements required to model such systems, which were grouped into Structural, Computational and System Organization pillars. This research contributes to the body of knowledge by defining generic aspects of simulation modelling techniques used to study properties and attributes of complex end-to-end supply chains. The paper advances the theoretical understanding of the simulation methods used and applicability of simulation methodology in modelling end-to-end supply chain systems. The research presents the key findings from the use of simulation in modelling end-to-end supply chains and the main ways in which this modelling technique has informed research and practise.}
}

@article{rayyan-727967317,
  title={Game theory applications in systems-of-systems engineering: A literature review and synthesis},
  year={2019},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={153},
  pages={154-165},
  author={Axelsson, Jakob},
  url={https://www.sciencedirect.com/science/article/pii/S1877050919307252},
  keywords={literature review, game theory, System-of-systems},
  abstract={Systems-of-systems (SoS) are becoming increasingly common in more and more domains, spreading from the initial focus on government-controlled areas such as defense to open market industries. This implies that collaborative SoS are becoming more important, where the constituents need to be given incentives to join and remain within the SoS. Game theory has been proposed as a framework to model and analyze such SoS mechanisms. It aims at providing incentives to the independently operated and managed constituents. This paper presents a systematic literature review on the applications of game theory to SoS engineering, together with a synthesis aiming at capturing the best practices for doing such an analysis. The main conclusions are that game theory can be applied to SoS in a wide range of application areas, and deal with problems related to acquisition, design, and operations. In particular, the operational formation of SoS are well suited for this kind of analysis, and it often requires the use of simulation techniques. However, most results in the field lack a validation in practice.}
}

@article{rayyan-727967323,
  title={The use of machine learning algorithms in recommender systems: A systematic review},
  year={2018},
  journal={Expert Systems with Applications},
  issn={0957-4174},
  volume={97},
  pages={205-227},
  author={Portugal, Ivens and Alencar, Paulo and Cowan, Donald},
  url={https://www.sciencedirect.com/science/article/pii/S0957417417308333},
  keywords={Machine learning, Application domains, Machine learning algorithms, Performance metrics, Recommender systems, Systematic review of the literature, Algorithms, Learning},
  abstract={Recommender systems use algorithms to provide users with product or service recommendations. Recently, these systems have been using machine learning algorithms from the field of artificial intelligence. However, choosing a suitable machine learning algorithm for a recommender system is difficult because of the number of algorithms described in the literature. Researchers and practitioners developing recommender systems are left with little information about the current approaches in algorithm usage. Moreover, the development of recommender systems using machine learning algorithms often faces problems and raises questions that must be resolved. This paper presents a systematic review of the literature that analyzes the use of machine learning algorithms in recommender systems and identifies new research opportunities. The goals of this study are to (i) identify trends in the use or research of machine learning algorithms in recommender systems; (ii) identify open questions in the use or research of machine learning algorithms; and (iii) assist new researchers to position new research activity in this domain appropriately. The results of this study identify existing classes of recommender systems, characterize adopted machine learning approaches, discuss the use of big data technologies, identify types of machine learning algorithms and their application domains, and analyzes both main and alternative performance metrics.}
}

@article{rayyan-727967324,
  title={Continuous experimentation and the cyber–physical systems challenge: An overview of the literature and the industrial perspective},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={170},
  pages={110781},
  author={Giaimo, Federico and Andrade, Hugo and Berger, Christian},
  url={https://www.sciencedirect.com/science/article/pii/S016412122030193X},
  keywords={Software engineering, Cyber–physical systems, Continuous Experimentation},
  abstract={Context: New software development patterns are emerging aiming at accelerating the process of delivering value. One is Continuous Experimentation, which allows to systematically deploy and run instrumented software variants during development phase in order to collect data from the field of application. While currently this practice is used on a daily basis on web-based systems, technical difficulties challenge its adoption in fields where computational resources are constrained, e.g., cyber–physical systems and the automotive industry. Objective: This paper aims at providing an overview of the engagement on the Continuous Experimentation practice in the context of cyber–physical systems. Method: A systematic literature review has been conducted to investigate the link between the practice and the field of application. Additionally, an industrial multiple case study is reported. Results: The study presents the current state-of-the-art regarding Continuous Experimentation in the field of cyber–physical systems. The current perspective of Continuous Experimentation in industry is also reported. Conclusions: The field has not reached maturity yet. More conceptual analyses are found than solution proposals and the state-of-practice is yet to be achieved. However it is expected that in time an increasing number of solutions will be proposed and validated.}
}

@article{rayyan-727967327,
  title={A systematic review to merge discourses: Interoperability, integration and cyber-physical systems},
  year={2018},
  journal={Journal of Industrial Information Integration},
  issn={2452-414X},
  volume={9},
  pages={14-23},
  author={Gürdür, Didem and Asplund, Fredrik},
  url={https://www.sciencedirect.com/science/article/pii/S2452414X17300687},
  keywords={Maturity models, Data visualization, Interoperability assessment, Interoperability measurement, Tool integration, Tool interoperability},
  abstract={Cyber-physical systems (CPS) are developed through the cooperation of several engineering disciplines. Powerful software tools are utilized by each individual discipline, but it remains challenging to connect these into tool chains for increased efficiency. To support this endeavour, the literature on interoperability assessment was surveyed to identify concepts valuable to transfer from the interoperability to the tool integration research field. Implementation options, types of interoperability and domains described in interoperability assessment models were concepts identified as directly transferable. To avoid the problems with uptake that plague the models identified, visual analytics is suggested as a vehicle for the transfer. Furthermore, based on the use of non-functional properties as an underlying motivation for these models, cost, performance and sustainability are suggested as a common base for future research in both discourses.}
}

@article{rayyan-727967328,
  title={A model for evaluation of enterprise architecture quality},
  year={2020},
  journal={Evaluation and Program Planning},
  issn={0149-7189},
  volume={83},
  pages={101853},
  author={Mirsalari, Seyedeh Reyhaneh and Ranjbarfard, Mina},
  url={https://www.sciencedirect.com/science/article/pii/S0149718920301579},
  keywords={Enterprise architecture, Enterprise architecture evaluation, Enterprise architecture measurement, Enterprise architecture quality attributes},
  abstract={Today, most organizations use an enterprise architecture (EA) approach as a tool to increase the power of management on the organization's information technology. Enterprise architecture is a set of processes that helps an organization to translate its vision into an effective change in the organization's scope by providing a clear understanding of its current state. The purpose of this research is to identify EA quality attributes and its evaluation indicators in the organization. This study was conducted by using mixed method, including qualitative and quantitative parts. In the qualitative section, a variety of EA evaluation indicators were identified by a systematic literature review (SLR) approach, then in the quantitative section the survey data were collected by a questionnaire prepared based on the qualitative part and then exploratory factor analysis (EFA) and confirmatory factor analysis (CFA) were performed. This research presents an EA evaluation model that has seven main quality attributes including alignment and integrity, quality of EA products and services, security, maintainability and portability, reliability, reusability and scalability, and 30 indicators that address all aspects of enterprise architecture. Through this model, organizations can evaluate the quality of implemented EA or AS-IS status of EA and take steps to improve it.}
}

@article{rayyan-727967329,
  title={Capturing software architecture knowledge for pattern-driven design},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={169},
  pages={110714},
  author={Farshidi, Siamak and Jansen, Slinger and van der Werf, Jan Martijn},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220301552},
  keywords={Quality attributes, Architectural patterns, Architectural styles, Design decisions, Knowledge acquisition, Software},
  abstract={Context: Software architecture is a knowledge-intensive field. One mechanism for storing architecture knowledge is the recognition and description of architectural patterns. Selecting architectural patterns is a challenging task for software architects, as knowledge about these patterns is scattered among a wide range of literature. Method: We report on a systematic literature review, intending to build a decision model for the architectural pattern selection problem. Moreover, twelve experienced practitioners at software-producing organizations evaluated the usability and usefulness of the extracted knowledge. Results: An overview is provided of 29 patterns and their effects on 40 quality attributes. Furthermore, we report in which systems the 29 patterns are applied and in which combinations. The practitioners confirmed that architectural knowledge supports software architects with their decision-making process to select a set of patterns for a new problem. We investigate the potential trends among architects to select patterns. Conclusion: With the knowledge available, architects can more rapidly select and eliminate combinations of patterns to design solutions. Having this knowledge readily available supports software architects in making more efficient and effective design decisions that meet their quality concerns.}
}

@article{rayyan-727967330,
  title={Requirements monitoring frameworks: A systematic review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={80},
  pages={89-109},
  author={Vierhauser, Michael and Rabiser, Rick and Grünbacher, Paul},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916301288},
  keywords={Systematic literature review, Requirements monitoring, Systems of systems},
  abstract={Context Software systems today often interoperate with each other, thus forming a system of systems (SoS). Due to the scale, complexity, and heterogeneity of SoS, determining compliance with their requirements is challenging, despite the range of existing monitoring approaches. The fragmented research landscape and the diversity of existing approaches, however, make it hard to understand and analyze existing research regarding its suitability for SoS. Objective The aims of this paper are thus to systematically identify, describe, and classify existing approaches for requirements-based monitoring of software systems at runtime. Specifically, we (i) analyze the characteristics and application areas of monitoring approaches proposed in different domains, we (ii) systematically identify frameworks supporting requirements monitoring, and finally (iii) analyze their support for requirements monitoring in SoS. Method We performed a systematic literature review (SLR) to identify existing monitoring approaches and to classify their key characteristics and application areas. Based on this analysis we selected requirements monitoring frameworks, following a definition by Robinson, and analyzed them regarding their support for requirements monitoring in SoS. Results We identified 330 publications, which we used to produce a comprehensive overview of the landscape of requirements monitoring approaches. We analyzed these publications regarding their support for Robinson's requirements monitoring layers, resulting in 37 identified frameworks. We investigated how well these frameworks support requirements monitoring in SoS. Conclusions We conclude that most existing approaches are restricted to certain kinds of checks, particular types of events and data, and mostly also limited to one particular architectural style and technology. This lack of flexibility makes their application in an SoS context difficult. Also, systematic and automated variability management is still missing. Regarding their evaluation, many existing frameworks focus on measuring the performance overhead, while only few frameworks have been assessed in cases studies with real-world systems.}
}

@article{rayyan-727967331,
  title={Exploring principles of user-centered agile software development: A literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={61},
  pages={163-181},
  author={Brhel, Manuel and Meth, Hendrik and Maedche, Alexander and Werder, Karl},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915000129},
  keywords={Systematic literature review, Agile software development, User-centered design, Software},
  abstract={Context In the last decade, software development has been characterized by two major approaches: agile software development, which aims to achieve increased velocity and flexibility during the development process, and user-centered design, which places the goals and needs of the system's end-users at the center of software development in order to deliver software with appropriate usability. Hybrid development models, referred to as user-centered agile software development (UCASD) in this article, propose to combine the merits of both approaches in order to design software that is both useful and usable. Objective This paper aims to capture the current state of the art in UCASD approaches and to derive generic principles from these approaches. More specifically, we investigate the following research question: Which principles constitute a user-centered agile software development approach? Method We conduct a systematic review of the literature on UCASD. Identified works are analyzed using a coding scheme that differentiates four levels of UCASD: the process, practices, people/social and technology dimensions. Through subsequent synthesis, we derive generic principles of UCASD. Results We identified and analyzed 83 relevant publications. The analysis resulted in a comprehensive coding system and five principles for UCASD: (1) separate product discovery and product creation, (2) iterative and incremental design and development, (3) parallel interwoven creation tracks, (4) continuous stakeholder involvement, and (5) artifact-mediated communication. Conclusion Our paper contributes to the software development body of knowledge by (1) providing a broad overview of existing works in the area of UCASD, (2) deriving an analysis framework (in form a coding system) for works in this area, going beyond former classifications, and (3) identifying generic principles of UCASD and associating them with specific practices and processes.}
}

@article{rayyan-727967332,
  title={A systematic review of domain analysis solutions for product lines},
  year={2009},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={82},
  number={12},
  pages={1982-2003},
  author={Khurum, Mahvish and Gorschek, Tony},
  url={https://www.sciencedirect.com/science/article/pii/S016412120900154X},
  keywords={Systematic review, Domain analysis, Domain modeling, Domain scoping, Empirical evidence, Usability, Usefulness},
  abstract={Domain analysis is crucial and central to software product line engineering (SPLE) as it is one of the main instruments to decide what to include in a product and how it should fit in to the overall software product line. For this reason many domain analysis solutions have been proposed both by researchers and industry practitioners. Domain analysis comprises various modeling and scoping activities. This paper presents a systematic review of all the domain analysis solutions presented until 2007. The goal of the review is to analyze the level of industrial application and/or empirical validation of the proposed solutions with the purpose of mapping maturity in terms of industrial application, as well as to what extent proposed solutions might have been evaluated in terms of usability and usefulness. The finding of this review indicates that, although many new domain analysis solutions for software product lines have been proposed over the years, the absence of qualitative and quantitative results from empirical application and/or validation makes it hard to evaluate the potential of proposed solutions with respect to their usability and/or usefulness for industry adoption. The detailed results of the systematic review can be used by individual researchers to see large gaps in research that give opportunities for future work, and from a general research perspective lessons can be learned from the absence of validation as well as from good examples presented. From an industry practitioner view, the results can be used to gauge as to what extent solutions have been applied and/or validated and in what manner, both valuable as input prior to industry adoption of a domain analysis solution.}
}

@article{rayyan-727967333,
  title={A systematic review of requirements change management},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={93},
  pages={163-185},
  author={Jayatilleke, Shalinka and Lai, Richard},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917304664},
  keywords={Systematic review, Agile, Requirements change management},
  abstract={Context Software requirements are often not set in concrete at the start of a software development project; and requirements changes become necessary and sometimes inevitable due to changes in customer requirements and changes in business rules and operating environments; hence, requirements development, which includes requirements changes, is a part of a software process. Previous work has shown that failing to manage software requirements changes well is a main contributor to project failure. Given the importance of the subject, there's a plethora of research work that discuss the management of requirements change in various directions, ways and means. An examination of these works suggests that there's a room for improvement. Objective In this paper, we present a systematic review of research in Requirements Change Management (RCM) as reported in the literature. Method We use a systematic review method to answer four key research questions related to requirements change management. The questions are: (1) What are the causes of requirements changes? (2) What processes are used for requirements change management? (3) What techniques are used for requirements change management? and (4) How do organizations make decisions regarding requirements changes? These questions are aimed at studying the various directions in the field of requirements change management and at providing suggestions for future research work. Results The four questions were answered; and the strengths and weaknesses of existing techniques for RCM were identified. Conclusions This paper has provided information about the current state-of-the-art techniques and practices for RCM and the research gaps in existing work. Benefits, risks and difficulties associated with RCM are also made available to software practitioners who will be in a position of making better decisions on activities related to RCM. Better decisions will lead to better planning which will increase the chance of project success.}
}

@article{rayyan-727967336,
  title={A systematic review of strategies and computer-based intervention (CBI) for reading comprehension of children with autism},
  year={2013},
  journal={Research in Autism Spectrum Disorders},
  issn={1750-9467},
  volume={7},
  number={9},
  pages={1111-1121},
  author={Khowaja, Kamran and Salim, Siti Salwah},
  url={https://www.sciencedirect.com/science/article/pii/S1750946713001116},
  keywords={Systematic review, Autism, Computer-based intervention, Reading comprehension, Vocabulary, Only Child, Child, Autistic Disorder},
  abstract={This paper presents a systematic review of relevant published studies on reading comprehension for children with autism, focusing on vocabulary instruction and text comprehension instruction from years 2000 to 2011. This systematic review attempts to address three specific research questions: strategies of vocabulary instruction and text comprehension instruction used, computer-based intervention (CBI) used or developed during study, and the effectiveness of using CBI for teaching children with autism. There are five strategies of vocabulary instruction and seven strategies of text comprehension instruction. Results indicate that two strategies of vocabulary instruction, multimedia methods and explicit instruction were found to be more commonly used than the other three. On the same note, question answering strategy of text comprehension instruction was discovered to be used more often than the other six. Results also indicate that children with autism can benefit from the strategies of reading comprehension and that the use of CBI as a mode of instruction for reading comprehension improved learning of children. This is clearly evident judging from the performance of children between pre-tests and post-tests of studies in which CBI was used. However, due to heterogeneity of participants, this is not always the case; a few studies reported no improvement in the learning of children with autism.}
}

@article{rayyan-727967338,
  title={Explaining the privacy paradox: A systematic review of literature investigating privacy attitude and behavior},
  year={2018},
  journal={Computers & Security},
  issn={0167-4048},
  volume={77},
  pages={226-261},
  author={Gerber, Nina and Gerber, Paul and Volkamer, Melanie},
  url={https://www.sciencedirect.com/science/article/pii/S0167404818303031},
  keywords={Literature review, Information privacy, Predictor variables, Privacy paradox, User psychology, Privacy},
  abstract={Although survey results show that the privacy of their personal data is an important issue for online users worldwide, most users rarely make an effort to protect this data actively and often even give it away voluntarily. Privacy researchers have made several attempts to explain this dichotomy between privacy attitude and behavior, usually referred to as ‘privacy paradox'. While they proposed different theoretical explanations for the privacy paradox, as well as empirical study results concerning the relationship of individual factors on privacy behavior and attitude, no comprehensive explanation for the privacy paradox has been found so far. We aim to shed light on the privacy paradox phenomenon by summarizing the most popular theoretical privacy paradox explanations and identifying the factors that are most relevant for the prediction of privacy attitude and behavior. Since many studies focus on the behavioral intention instead of the actual behavior, we decided to consider this topic as well. Based on a literature review, we identify all factors that significantly predict one of the three privacy aspects and report the corresponding standardized effect sizes (β). The results provide strong evidence for the theoretical explanation approach called ‘privacy calculus', with possibly gained benefits being among the best predictors for disclosing intention as well as actual disclosure. Other strong predictors for privacy behavior are privacy intention, willingness to disclose, privacy concerns and privacy attitude. Demographic variables play a minor role, only gender was found to weakly predict privacy behavior. Privacy attitude was best predicted by internal variables like trust towards the website, privacy concerns or computer anxiety. Despite the multiplicity of survey studies dealing with user privacy, it is not easy to draw overall conclusions, because authors often refer to slightly different constructs. We suggest the privacy research community to agree on a shared definition of the different privacy constructs to allow for conclusions beyond individual samples and study designs.}
}

@article{rayyan-727967339,
  title={A systematic review of immersive virtual reality applications for higher education: Design elements, lessons learned, and research agenda},
  year={2020},
  journal={Computers & Education},
  issn={0360-1315},
  volume={147},
  pages={103778},
  author={Radianti, Jaziar and Majchrzak, Tim A and Fromm, Jennifer and Wohlgenannt, Isabell},
  url={https://www.sciencedirect.com/science/article/pii/S0360131519303276},
  keywords={Augmented and virtual reality, Cooperative/collaborative learning, Distance education and online learning, Human–computer interface, Media in education, Immersion},
  abstract={Researchers have explored the benefits and applications of virtual reality (VR) in different scenarios. VR possesses much potential and its application in education has seen much research interest lately. However, little systematic work currently exists on how researchers have applied immersive VR for higher education purposes that considers the usage of both high-end and budget head-mounted displays (HMDs). Hence, we propose using systematic mapping to identify design elements of existing research dedicated to the application of VR in higher education. The reviewed articles were acquired by extracting key information from documents indexed in four scientific digital libraries, which were filtered systematically using exclusion, inclusion, semi-automatic, and manual methods. Our review emphasizes three key points: the current domain structure in terms of the learning contents, the VR design elements, and the learning theories, as a foundation for successful VR-based learning. The mapping was conducted between application domains and learning contents and between design elements and learning contents. Our analysis has uncovered several gaps in the application of VR in the higher education sphere—for instance, learning theories were not often considered in VR application development to assist and guide toward learning outcomes. Furthermore, the evaluation of educational VR applications has primarily focused on usability of the VR apps instead of learning outcomes and immersive VR has mostly been a part of experimental and development work rather than being applied regularly in actual teaching. Nevertheless, VR seems to be a promising sphere as this study identifies 18 application domains, indicating a better reception of this technology in many disciplines. The identified gaps point toward unexplored regions of VR design for education, which could motivate future work in the field.}
}

@article{rayyan-727967340,
  title={A systematic review on search-based refactoring},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={83},
  pages={14-34},
  author={Mariani, Thainá and Vergilio, Silvia Regina},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916303779},
  keywords={Refactoring, Evolutionary algorithms, Search-based software engineering},
  abstract={Context: To find the best sequence of refactorings to be applied in a software artifact is an optimization problem that can be solved using search techniques, in the field called Search-Based Refactoring (SBR). Over the last years, the field has gained importance, and many SBR approaches have appeared, arousing research interest. Objective: The objective of this paper is to provide an overview of existing SBR approaches, by presenting their common characteristics, and to identify trends and research opportunities. Method: A systematic review was conducted following a plan that includes the definition of research questions, selection criteria, a search string, and selection of search engines. 71 primary studies were selected, published in the last sixteen years. They were classified considering dimensions related to the main SBR elements, such as addressed artifacts, encoding, search technique, used metrics, available tools, and conducted evaluation. Results: Some results show that code is the most addressed artifact, and evolutionary algorithms are the most employed search technique. Furthermore, most times, the generated solution is a sequence of refactorings. In this respect, the refactorings considered are usually the ones of the Fowler's Catalog. Some trends and opportunities for future research include the use of models as artifacts, the use of many objectives, the study of the bad smells effect, and the use of hyper-heuristics. Conclusions: We have found many SBR approaches, most of them published recently. The approaches are presented, analyzed, and grouped following a classification scheme. The paper contributes to the SBR field as we identify a range of possibilities that serve as a basis to motivate future researches.}
}

@article{rayyan-727967341,
  title={Prioritization based taxonomy of cloud-based outsource software development challenges: Fuzzy AHP analysis},
  year={2020},
  journal={Applied Soft Computing},
  issn={1568-4946},
  volume={95},
  pages={106557},
  author={Akbar, Muhammad Azeem and Shameem, Mohammad and Mahmood, Sajjad and Alsanad, Ahmed and Gumaei, Abdu},
  url={https://www.sciencedirect.com/science/article/pii/S1568494620304968},
  keywords={Challenges, Cloud-based outsource software development (COSD), Fuzzy analytical hierarchy process (FAHP), Software},
  abstract={Cloud-Based Outsource Software Development (COSD) is a new methodology adopted by organizations to develop software using teams of knowledge workers located across the globe using cloud computing services. However, there is a lack of understanding of challenges associated with successful execution of COSD projects. The objective of this study is to identify and prioritize the challenges that influence COSD projects. First, we conducted a Systematic Literature Review (SLR) and identified 21 challenges that impact COSD projects. Next, a questionnaire survey was developed based on the SLR findings to collect feedback from industry practitioners. Finally, we applied the Fuzzy Analytical Hierarchy Process (FAHP) to rank the identified challenges for COSD projects. We also present a prioritization-based taxonomy of the identified challenges which will help practitioners to focus on the critical areas for successful implementation of COSD projects.}
}

@article{rayyan-727967342,
  title={A systematic review of IP traceback schemes for denial of service attacks},
  year={2016},
  journal={Computers & Security},
  issn={0167-4048},
  volume={56},
  pages={111-139},
  author={Singh, Karanpreet and Singh, Paramvir and Kumar, Krishan},
  url={https://www.sciencedirect.com/science/article/pii/S0167404815000930},
  keywords={Systematic review, Distributed denial-of-service attacks, IP traceback, Packet logging, Packet marking},
  abstract={Internet has always been vulnerable to a variety of security threats as it was originally designed without apprehending the prospect of security concerns. Modern era has seen diverse nature of attacks possible on the Internet, including the most perilous attack, Distributed Denial of Service (DDoS) attacks. In such an attack, a large number of compromised systems coordinate with each other so as to direct gigantic magnitude of attack traffic toward the victim, depleting its tangible and intangible network resources. To further exacerbate the situation, these compromised systems usually disguise their identity by capitalizing on IP address spoofing. IP traceback is the class of techniques used to identify the actual source of network packets. In this paper, we followed a systematic approach to comprehensively review and categorize 275 works representing existing IP traceback literature. The paper also provides an in-depth analysis of different IP traceback approaches, their functional classes and the evaluation metrics. Based on the literature review, we also answered a set of research questions to understand the current trends in IP traceback. Various issues, challenges and avenues for future research in the area of IP traceback are also discussed.}
}

@article{rayyan-727967347,
  title={Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={127},
  pages={106368},
  author={Lwakatare, Lucy Ellen and Raj, Aiswarya and Crnkovic, Ivica and Bosch, Jan and Olsson, Helena Holmström},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920301373},
  keywords={Software engineering, SLR, Challenges, Industrial settings, Machine learning systems, Solutions},
  abstract={Background: Developing and maintaining large scale machine learning (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems. Objective: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges. Method: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four quality attributes: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment. Results: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions. Conclusion: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in ML system development practice and the lack of solutions point to directions for future research.}
}

@article{rayyan-727967348,
  title={Inner source software development: Current thinking and an agenda for future research},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={163},
  pages={110520},
  author={Edison, Henry and Carroll, Noel and Morgan, Lorraine and Conboy, Kieran},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220300030},
  keywords={Systematic literature review, Inner source, Inner source software development, Research agenda, Software, Thinking},
  abstract={Context Inner source software development (ISSD) has been viewed as an alternative approach in which organisations adopt open source software development (OSSD) practices and exploit its benefits internally. Objective In this paper, we aim to provide an extensive review of current research on ISSD and to establish a research agenda on this domain. Method The review is primarily performed using a systematic literature review protocol. Results We identified, critically evaluated and integrated the findings of 37 primary studies, describing 25 empirical research papers, 10 frameworks/methods, models and tools to support the implementation of inner source, as well as a set of benefits and challenges associated with ISSD. Conclusion This study presents four main contributions. First, the study provides an in-depth review of ISSD to date, i.e. the evolution of research across inner source, contributions of existing research developments, and theories, models and frameworks used to study inner source. Second, our review applies the OSSD approach framework as the lens to analyse ISSD. Third, the review updates the key challenges associated with ISSD from a management perspective. The final contribution is the establishment of a research agenda to advance knowledge on ISSD.}
}

@article{rayyan-727967350,
  title={A survey of model transformation design patterns in practice},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={140},
  pages={48-73},
  author={Lano, Kevin and Kolahdouz-Rahimi, Shekoufeh and Yassipour-Tehrani, Sobhan and Sharbaf, Mohammadreza},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218300438},
  keywords={Design Patterns, Empirical Software Engineering, Model Transformations},
  abstract={Model transformation design patterns have been proposed by a number of researchers, but their usage appears to be sporadic and sometimes patterns are applied without recognition of the pattern. In this paper we provide a systematic literature review of transformation design pattern applications. We evaluate how widely patterns have been used, and how their use differs in different transformation languages and for different categories of transformation. We identify what benefits appear to arise from the use of patterns, and consider how the application of patterns can be improved. The paper also identifies several new patterns which have not previously been catalogued.}
}

@article{rayyan-727967352,
  title={A systematic review on regression test selection techniques},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={1},
  pages={14-30},
  author={Engström, Emelie and Runeson, Per and Skoglund, Mats},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909001219},
  keywords={Systematic review, Empirical studies, Regression testing, Test selection},
  abstract={Regression testing is verifying that previously functioning software remains after a change. With the goal of finding a basis for further research in a joint industry-academia research project, we conducted a systematic review of empirical evaluations of regression test selection techniques. We identified 27 papers reporting 36 empirical studies, 21 experiments and 15 case studies. In total 28 techniques for regression test selection are evaluated. We present a qualitative analysis of the findings, an overview of techniques for regression test selection and related empirical evidence. No technique was found clearly superior since the results depend on many varying factors. We identified a need for empirical studies where concepts are evaluated rather than small variations in technical implementations.}
}

@article{rayyan-727967356,
  title={Process models in the practice of distributed software development: A systematic review of the literature},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={8},
  pages={779-791},
  author={Prikladnicki, Rafael and Audy, Jorge Luis Nicolas},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910000492},
  keywords={Distributed software development, Global software engineering, Offshoring, Process improvement, Process models, Software},
  abstract={Context Distributed Software Development (DSD) has recently become an active research area. Although considerable research effort has been made in this area, as yet, no agreement has been reached as to an appropriate process model for DSD. Purpose This paper is intended to identify and synthesize papers that describe process models for distributed software development in the context of overseas outsourcing, i.e. “offshoring”. Method We used a systematic review methodology to search seven digital libraries and one topic-specific conference. Results We found 27 primary studies describing stage-related DSD process models. Only five of such studies looked into outsourcing to a subsidiary company (i.e. “internal offshoring”). Nineteen primary studies addressed the need for DSD process models. Eight primary studies and three literature surveys described stage-based DSD process models, but only three of such models were empirically evaluated. Conclusion We need more research aimed at internal offshoring. Furthermore, proposed models need to be empirically validated.}
}

@article{rayyan-727967359,
  title={Software component and the semantic Web: An in-depth content analysis and integration history},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={125},
  pages={152-169},
  author={Kaur, Loveleen and Mishra, Ashutosh},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216302308},
  keywords={Ontology, Component-based software engineering, Linked Data, Reasoners, Semantic Web, Web services, Software, Semantics},
  abstract={With the advent of Component-based software engineering (CBSE), large software systems are being built by integrating pre-built software components. The Semantic Web in association with CBSE has shown to offer powerful representation facilities and reasoning techniques to enhance and support querying, reasoning, discovery, etc. of software components. The goal of this paper is to research the applicability of Semantic Web technologies in performing the various tasks of CBSE and review the experimental results of the same in an easy and effective manner. To the best of our knowledge, this is the first study which provides an extensive review of the application of Semantic Web in CBSE from different perspectives. A systematic literature review of the Semantic Web approaches, employed for use in CBSE, reported from 2001 until 2015, is conducted in this research article. Empirical results have been drawn through the question-answer based analysis of the research, which clearly tells the year wise trend of the research articles, with the possible justification of the usage of Semantic Web technology and tools for a particular phase of CBSE. To conclude, gaps in the current research and potential future prospects have been discussed.}
}

@article{rayyan-727967361,
  title={A maturity model for secure requirements engineering},
  year={2020},
  journal={Computers & Security},
  issn={0167-4048},
  volume={95},
  pages={101852},
  author={Niazi, Mahmood and Saeed, Ashraf Mohammed and Alshayeb, Mohammad and Mahmood, Sajjad and Zafar, Saad},
  url={https://www.sciencedirect.com/science/article/pii/S0167404820301243},
  abstract={Security is considered to be a critical software quality attribute. Tackling security at the requirements phase helps to avoid the need to rework secure software development issues. The aim of this paper is to develop a Requirements Engineering (RE) Security Maturity Model (RESMM) to assist software development organizations to better specify the requirements for secure software development. To achieve this objective, first, we conducted a systematic literature review (SLR) to identify the requirement practices for secure software development. Then we modified Sommerville's requirements engineering practices. We also conducted a questionnaire survey based on the identified security requirements practices. Next, the RESMM was built based on the results of the SLR, the modified Sommerville practices and feedback from the security practitioners. Finally, two case studies were conducted to assess RESMM. RESMM has 79 practices classified into 7 RE categories. The case study results show that RESMM has a clear structure and is easy to comprehend and use. In addition, the case study participants recommended that software organizations adopt RESMM. RESMM has the ability to identify the RE security maturity levels in software organizations. RESMM can also help software development organizations deliver secure software.}
}

@article{rayyan-727967362,
  title={A survey on software coupling relations and tools},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={107},
  pages={159-178},
  author={Fregnan, Enrico and Baum, Tobias and Palomba, Fabio and Bacchelli, Alberto},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918302441},
  keywords={Software engineering, Software metrics, Coupling relations, Software},
  abstract={Context Coupling relations reflect the dependencies between software entities and can be used to assess the quality of a program. For this reason, a vast amount of them has been developed, together with tools to compute their related metrics. However, this makes the coupling measures suitable for a given application challenging to find. Goals The first objective of this work is to provide a classification of the different kinds of coupling relations, together with the metrics to measure them. The second consists in presenting an overview of the tools proposed until now by the software engineering academic community to extract these metrics. Method This work constitutes a systematic literature review in software engineering. To retrieve the referenced publications, publicly available scientific research databases were used. These sources were queried using keywords inherent to software coupling. We included publications from the period 2002 to 2017 and highly cited earlier publications. A snowballing technique was used to retrieve further related material. Results Four groups of coupling relations were found: structural, dynamic, semantic and logical. A fifth set of coupling relations includes approaches too recent to be considered an independent group and measures developed for specific environments. The investigation also retrieved tools that extract the metrics belonging to each coupling group. Conclusion This study shows the directions followed by the research on software coupling: e.g., developing metrics for specific environments. Concerning the metric tools, three trends have emerged in recent years: use of visualization techniques, extensibility and scalability. Finally, some coupling metrics applications were presented (e.g., code smell detection), indicating possible future research directions. Public preprint [https://doi.org/10.5281/zenodo.2002001].}
}

@article{rayyan-727967364,
  title={Basis for an integrated security ontology according to a systematic review of existing proposals},
  year={2011},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={33},
  number={4},
  pages={372-388},
  author={Blanco, Carlos and Lasheras, Joaquín and Fernández-Medina, Eduardo and Valencia-García, Rafael and Toval, Ambrosio},
  url={https://www.sciencedirect.com/science/article/pii/S0920548911000043},
  keywords={Systematic review, Security, Ontologies},
  abstract={The use of ontologies to represent knowledge provides us with organization, communication and reusability. The concepts and relations managed by any scientific community need to be formally defined. Since security in information technologies has evolved as a critical aspect and many related topics have been developed, this paper applies the method of systematic review for identifying, extracting and analyzing the principal proposals for security ontologies. The most mature proposals have been selected and compared by using a formal framework, extracting the key requirements that an integrated and unified security ontology should have, and providing the first steps towards its definition.}
}

@article{rayyan-727967365,
  title={Challenges and recommended practices for software architecting in global software development},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={106},
  pages={234-253},
  author={Sievi-Korte, Outi and Beecham, Sarah and Richardson, Ita},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918302209},
  keywords={Systematic literature review, Software architecture, Software design, Global software development, Design practice, Software},
  abstract={Context Global software development (GSD), although now a norm in the software industry, carries with it enormous challenges mostly regarding communication and coordination. Aforementioned challenges are highlighted when there is a need to transfer knowledge between sites, particularly when software artifacts assigned to different sites depend on each other. The design of the software architecture and associated task dependencies play a major role in reducing some of these challenges. Objective The current literature does not provide a cohesive picture of how the distributed nature of software development is taken into account during the design phase: what to avoid, and what works in practice. The objective of this paper is to gain an understanding of software architecting in the context of GSD, in order to develop a framework of challenges and solutions that can be applied in both research and practice. Method We conducted a systematic literature review (SLR) that synthesises (i) challenges which GSD imposes on software architecture design, and (ii) recommended practices to alleviate these challenges. Results We produced a comprehensive set of guidelines for performing software architecture design in GSD based on 55 selected studies. Our framework comprises nine key challenges with 28 related concerns, and nine recommended practices, with 22 related concerns for software architecture design in GSD. These challenges and practices were mapped to a thematic conceptual model with the following concepts: Organization (Structure and Resources), Ways of Working (Architecture Knowledge Management, Change Management and Quality Management), Design Practices, Modularity and Task Allocation. Conclusion The synthesis of findings resulted in a thematic conceptual model of the problem area, a mapping of the key challenges to practices, and a concern framework providing concrete questions to aid the design process in a distributed setting. This is a first step in creating more concrete architecture design practices and guidelines.}
}

@article{rayyan-727967366,
  title={The impact of course-taking on academic achievements a systematic review and Meta analysis},
  year={2010},
  journal={Procedia - Social and Behavioral Sciences},
  issn={1877-0428},
  volume={2},
  number={2},
  pages={3401-3406},
  author={Shulruf, Boaz and Keuskamp, Dominic and Brake, Dulcie},
  url={https://www.sciencedirect.com/science/article/pii/S187704281000563X},
  keywords={academic achievements, Australia, educational career, Meta analysis, Systematically reviews},
  abstract={Students choose subjects in secondary schools that can be major determinants for their future educational career. This paper systematically reviews the literature on the effect of secondary school course-taking on educational outcomes in secondary and tertiary institutions. The findings of the review and the meta analysis suggest that course-taking predicts a number of educational outcomes such as further course-taking in secondary school, tertiary course-taking, and secondary school grades. However, these effects could not be easily disentangled from the diversity of factors, such as ethnicity, socioeconomic status (SES) and prior achievement that are co-correlated with course-taking and its outcomes.}
}

@article{rayyan-727967367,
  title={The roles of conceptual modelling in improving construction simulation studies: A comprehensive review},
  year={2020},
  journal={Advanced Engineering Informatics},
  issn={1474-0346},
  volume={46},
  pages={101175},
  author={Abdelmegid, M A and González, V A and O'Sullivan, M and Walker, C G and Poshdar, M and Ying, F},
  url={https://www.sciencedirect.com/science/article/pii/S1474034620301464},
  keywords={Systematic literature review, Benefits, Conceptual modeling, Construction simulation},
  abstract={The conceptual modelling phase of simulation studies has proven to be effective in enhancing the impact of simulation modelling in different domains. However, this simulation phase did not receive much attention in the construction simulation domain. The objective of this paper is to identify the roles that conceptual modelling can play in advancing the engagement, accuracy, and adoption (among other things) of discrete-event simulation studies in construction. In this paper, a Systematic Literature Review (SLR) is conducted, which involves a comprehensive search of databases and researchers' profiles to identify journal papers, conference articles, books, and theses that have reported the benefits of conceptual modelling for discrete-event simulation studies. The review resulted in 82 documents that were published from 2000 to 2020. Results indicate that the benefits of conceptual modelling include facilitating communications between stakeholders, capturing sufficient information for the simulation model, improving the quality of simulation models, guiding other simulation modelling activities, and facilitating verification and validation of simulation models. By linking these benefits to the current research agenda in construction simulation, this paper shows the significance and potential of the conceptual modelling phase to enhance the impact of discrete-event simulation studies in construction.}
}

@article{rayyan-727967368,
  title={State of the art in the research of formal verification},
  year={2014},
  journal={Ingeniería, Investigación y Tecnología},
  issn={1405-7743},
  volume={15},
  number={4},
  pages={615-623},
  author={Edgar, Serna-M. and David, Morales-V.},
  url={https://www.sciencedirect.com/science/article/pii/S1405774314706596},
  keywords={software engineering, formal verification, enfoques de investigación, engineering techniques, formal methods, ingeniería de software, métodos formales, research approaches, técnicas de ingenieréa, verificación formal},
  abstract={In recent years research in formal verification of hardware and software has reached important progresses in the development of methodologies and tools to meet the increasing complexity of systems. The explicit role of Formal Verification is to find errors and to improve the reliability on the accuracy of system design, which implies a challenge for software engineering of this century. The purpose of this research is to perform a systematic review of the literature to establish the state of the art of research in formal verification during the last 10 years and to identify the approaches, methods, techniques and methodologies used, as well as the intensity of those research activities. During the process it was found that research in this field has doubled since 2005, and that the mean value of researches conducted year after year remains the same and that prevail the application in control and interaction systems. Additionally it was found that, the case study is the most used method and that empirical research is the most applied type. Resumen En años recientes, la investigación en verificación formal de hardware y software ha logrado importantes progresos en el desarrollo de metodologías y herramientas para hacer frente a la creciente complejidad de los sistemas. La función explícita de la verificación formal es encontrar errores y mejorar la confianza en la exactitud del diseño del sistema, lo que supone un reto para la ingeniería de software de este siglo. El objetivo de esta investigación fue realizar una revisión sistemática a la literatura para determinar el estado del arte de la investigación en verificación formal en los últimos 10 años e identificar los enfoques, métodos, técnicas y metodologías empleadas, lo mismo que la intensidad de esa investigación. En el proceso se encontró que la investigación en esta área se duplicó a partir del año 2005, que hasta el momento mantiene un número promedio de investigaciones año tras año y que predomina la aplicación en sistemas de control e interacción. Además, que el estudio de caso es el método más utilizado y que la investigación empírica es la más aplicada.}
}

@article{rayyan-727967369,
  title={Non-functional requirements in model-driven development of service-oriented architectures},
  year={2018},
  journal={Science of Computer Programming},
  issn={0167-6423},
  volume={168},
  pages={18-37},
  author={Ameller, David and Burgués, Xavier and Costal, Dolors and Farré, Carles and Franch, Xavier},
  url={https://www.sciencedirect.com/science/article/pii/S0167642318303034},
  keywords={Systematic literature review, Model-driven development, Service-oriented architecture, Non-functional requirements, Quality requirement},
  abstract={Any software development process needs to consider non-functional requirements (NFR) in order to deliver a system that complies with its stakeholders' expectations. In a previous mapping study about model-driven development (MDD) for service-oriented architectures (SOA) we found a limited number of approaches managing NFR. The present work aims at analyzing in detail the state of the art in the management of NFR in MDD processes which produce SOA. We have conducted a systematic literature review following a rigorous protocol. We have taken as initial point the mapping study mentioned above and have used the subset of the 31 papers from this study (clustered into 15 approaches) that referred to NFR. We have analyzed them qualitatively in order to answer six research questions. We have built a Software Engineering theory to formalize this analysis. As result we highlight that most of approaches focus exclusively on security and reliability and we observe that NFR are expressed mainly as annotations of functional models represented in UML. From our perspective, existing research on the topic of this study is still scarce and without any evidence of transferability to industry. This situation suggests the need for further investigation efforts in order to produce validated MDD methods capable of generating SOA satisfying NFR stated by stakeholders.}
}

@article{rayyan-727967374,
  title={Fintechs: A literature review and research agenda},
  year={2019},
  journal={Electronic Commerce Research and Applications},
  issn={1567-4223},
  volume={34},
  pages={100833},
  author={Milian, Eduardo Z and de M. Spinola, Mauro and de Carvalho, Marly M},
  url={https://www.sciencedirect.com/science/article/pii/S1567422319300109},
  keywords={Systematic literature review, Blockchain, Innovation, Crowdfunding, Cryptocurrency, Financial services, Financial technologies, Fintech, Loans, Payment technologies},
  abstract={Although the fintech subject has been widely discussed in the press and communications media, there is a lack of consensus on the definition of the term in the scientific literature and the key research topics and trends. Aiming to narrow this gap, the objective of this study is to investigate the concept of fintech, to map the literature and point out new routes and opportunities in the field. For this purpose, a Systematic Literature Review (SLR) is performed, attempting to describe the areas of fintech activities, propose a categorization for this literature, highlight the main issues dealt with to date in the sample publications, as well as to point out new questions for continuing research in this field. The results show a set of definitions for the term fintech and suggest as a comprehensive understanding of fintech, as innovative companies active in the financial industry making use of the availability of communication, the ubiquity of the internet, and the automated processing of information. Moreover, the literature focuses on financial services and innovations, dealing with issues of financial industry regulation and local legislation or the financial system globally. The innovation of research subcategories (technology adoption/network externalities), blockchain and security appear with great emphasis in this work and represent the current most sensitive aspects also linked to the more global theme of digital transformation. Finally, subjects related to financial services operation particularly deal with risks of financial loss related to different factors involved in the business environment of these organizations.}
}

@article{rayyan-727967376,
  title={Literature review of the situation research faces in the application of ITIL in Small and Medium Enterprises},
  year={2016},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={48},
  pages={124-138},
  author={Cruz-Hinojosa, Nancy Judith and Gutiérrez-de-Mesa, José Antonio},
  url={https://www.sciencedirect.com/science/article/pii/S0920548916300356},
  keywords={Systematic Literature Review, ITIL, Method, Small and Medium Enterprises},
  abstract={This paper carries out a review of the issues that Small and Medium Enterprises (SMEs) face when trying to ensure their alignment with Information Technology Infrastructure Library (ITIL) guidelines. It is well-known that SMEs experience different challenges to those experienced by Large Enterprises, however their demands are the same as larger companies. Given that they have less labor and technological resources, they must optimize their service levels and adapt the activities of their IT departments to the needs of the company without negatively impacting service commitments. In this context our main objective is to establish a complete review concerning the important information that exists in relation to ITIL and its use in Small and Medium Enterprises, evaluating methods for the collection of evidence and analysis. For this reason we have conducted a systematic literature review with the automated search in the range 2007–2015 which has led us to identify thirty-nine articles of relevance. It is noted that, although it was initially expected that there might be enough information that would help us validate and interpret the way that ITIL functions for Small and Medium Enterprises, the reality is that there are not many publications of relevance that deal with the topic of ITIL and SMEs.}
}

@article{rayyan-727967378,
  title={A systematic literature review of actionable alert identification techniques for automated static code analysis},
  year={2011},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={53},
  number={4},
  pages={363-387},
  author={Heckman, Sarah and Williams, Laurie},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910002235},
  keywords={Systematic literature review, Actionable alert identification, Actionable alert prediction, Automated static analysis, Unactionable alert mitigation, Warning prioritization},
  abstract={Context Automated static analysis (ASA) identifies potential source code anomalies early in the software development lifecycle that could lead to field failures. Excessive alert generation and a large proportion of unimportant or incorrect alerts (unactionable alerts) may cause developers to reject the use of ASA. Techniques that identify anomalies important enough for developers to fix (actionable alerts) may increase the usefulness of ASA in practice. Objective The goal of this work is to synthesize available research results to inform evidence-based selection of actionable alert identification techniques (AAIT). Method Relevant studies about AAITs were gathered via a systematic literature review. Results We selected 21 peer-reviewed studies of AAITs. The techniques use alert type selection; contextual information; data fusion; graph theory; machine learning; mathematical and statistical models; or dynamic detection to classify and prioritize actionable alerts. All of the AAITs are evaluated via an example with a variety of evaluation metrics. Conclusion The selected studies support (with varying strength), the premise that the effective use of ASA is improved by supplementing ASA with an AAIT. Seven of the 21 selected studies reported the precision of the proposed AAITs. The two studies with the highest precision built models using the subject program's history. Precision measures how well a technique identifies true actionable alerts out of all predicted actionable alerts. Precision does not measure the number of actionable alerts missed by an AAIT or how well an AAIT identifies unactionable alerts. Inconsistent use of evaluation metrics, subject programs, and ASAs in the selected studies preclude meta-analysis and prevent the current results from informing evidence-based selection of an AAIT. We propose building on an actionable alert identification benchmark for comparison and evaluation of AAIT from literature on a standard set of subjects and utilizing a common set of evaluation metrics.}
}

@article{rayyan-727967379,
  title={Distributed pair programming: A systematic literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={63},
  pages={1-10},
  author={da Silva Estácio, Bernardo José and Prikladnicki, Rafael},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915000476},
  keywords={Distributed Software Development, Distributed Pair Programming, Extreme Programming, Pair Programming},
  abstract={Context Geographically distributed teams have adopted agile practices as a work strategy. One of these practices is Distributed Pair Programming (DPP). DPP consists in two developers working remotely on the same design, algorithm or code. Objective In this paper we sought to identify and synthesize papers that describe and analyze DPP both from teaching and practice perspectives. Method We conducted a Systematic Literature Review to search for empirical evidence in eight digital libraries. Results Most of the 34 DPP primary studies identified explore DPP from a teaching perspective. We found that DPP requires a specific infrastructure, but the existing studies do not explore the impact of the distribution in the details. There are many tools proposed that support DPP practice, but few of them are evaluated within a software development team. Conclusion We need more studies that explore the effects of Pair Programming in the context of Distributed Software Development, such as coordination and communication. Most of the studies do not empirically evaluate DPP in industry. There is also a need to propose guidelines to use DPP in industry and as a teaching strategy.}
}

@article{rayyan-727967380,
  title={Time series forecasting using artificial neural networks methodologies: A systematic review},
  year={2018},
  journal={Future Computing and Informatics Journal},
  issn={2314-7288},
  volume={3},
  number={2},
  pages={334-340},
  author={Tealab, Ahmed},
  url={https://www.sciencedirect.com/science/article/pii/S2314728817300715},
  keywords={Neural networks, Forecasting, Moving averages, Nonlinear time series, Nerve Net, Neural Networks (Computer)},
  abstract={This paper studies the advances in time series forecasting models using artificial neural network methodologies in a systematic literature review. The systematic review has been done using a manual search of the published papers in the last 11 years (2006–2016) for the time series forecasting using new neural network models and the used methods are displayed. In the covered period in the study, the results obtained found 17 studies that meet all the requirements of the search criteria. Only three of the obtained proposals considered a process different to the autoregressive of a neural networks model. These results conclude that, although there are many studies that presented the application of neural network models, but few of them proposed new neural networks models for forecasting that considered theoretical support and a systematic procedure in the construction of model. This leads to the importance of formulating new models of neural networks.}
}

@article{rayyan-727967382,
  title={Business intelligence and analytics in small and medium-sized enterprises: A systematic literature review},
  year={2017},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={121},
  pages={194-205},
  author={Llave, Marilex Rea},
  url={https://www.sciencedirect.com/science/article/pii/S1877050917322184},
  keywords={analytics, BI&A adoption, BI&A benefits, BI&A implementation, BI&A review, BI&A solutions, Business intelligence, SMEs, Intelligence},
  abstract={Despite much interest in business intelligence and analytics (BI&A), empirical research shows that small and medium-sized enterprises (SMEs) are still lagging behind in the proliferation of BI&A. However, there are no studies found on literature reviewing research on BI&A in SMEs. This paper collects, categorizes, synthesizes, and analyzes 62 articles related to BI&A in SMEs. The identified research topics being addressed in BI&A include: BI&A components, BI&A solutions, Mobile BI&A, Cloud BI&A, BI&A application, BI&A adoption, BI&A implementation, and BI&A benefits. Further, research gaps and directions for future research are presented to facilitate the progression of BI&A in SMEs research.}
}

@article{rayyan-727967383,
  title={Toward the tools selection in model based system engineering for embedded systems—A systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={106},
  pages={150-163},
  author={Rashid, Muhammad and Anwar, Muhammad Waseem and Khan, Aamir M},
  url={https://www.sciencedirect.com/science/article/pii/S016412121500103X},
  keywords={Tools, Embedded systems, MBSE},
  abstract={Model based system engineering (MBSE) is a systematic approach of modeling which is frequently used to support requirement specification, design, verification and validation activities of system development. However, it is difficult to customize MBSE approach for the development of embedded systems due to their diverse behavioral aspects. Furthermore, appropriate tools selection to perform particular MBSE activities is always challenging. This paper focuses on the identification and classification of recent research practices pertaining to embedded systems development through MBSE approach. Consequently, a comprehensive analysis of various MBSE tools has been presented. Systematic literature review (SLR) has been used to identify 61 research practices published during 2008–2014. The identified researches have been classified into six different categories to analyze various aspects of MBSE approach for embedded systems. Consequently, 39 preliminary tools are identified that have been used in recent researches. Furthermore, classification and evaluation of tools have been presented. This research highlights important trends and approaches of MBSE to support development of embedded systems. A comprehensive investigation of tools in this article facilitates researchers, practitioners and developers to select appropriate tools according to their requirements.}
}

@article{rayyan-727967384,
  title={A systematic review of software robustness},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={1},
  pages={1-17},
  author={Shahrokni, Ali and Feldt, Robert},
  url={https://www.sciencedirect.com/science/article/pii/S0950584912001048},
  keywords={Systematic review, Robustness, Software robustness, Software},
  abstract={Context With the increased use of software for running key functions in modern society it is of utmost importance to understand software robustness and how to support it. Although there have been many contributions to the field there is a lack of a coherent and summary view. Objective To address this issue, we have conducted a literature review in the field of robustness. Method This review has been conducted by following guidelines for systematic literature reviews. Systematic reviews are used to find and classify all existing and available literature in a certain field. Results From 9193 initial papers found in three well-known research databases, the 144 relevant papers were extracted through a multi-step filtering process with independent validation in each step. These papers were then further analyzed and categorized based on their development phase, domain, research, contribution and evaluation type. The results indicate that most existing results on software robustness focus on verification and validation of Commercial of the shelf (COTS) or operating systems or propose design solutions for robustness while there is a lack of results on how to elicit and specify robustness requirements. The research is typically solution proposals with little to no evaluation and when there is some evaluation it is primarily done with small, toy/academic example systems. Conclusion We conclude that there is a need for more software robustness research on real-world, industrial systems and on software development phases other than testing and design, in particular on requirements engineering.}
}

@article{rayyan-727967385,
  title={Software development project success and failure from the supplier's perspective: A systematic literature review},
  year={2012},
  journal={International Journal of Project Management},
  issn={0263-7863},
  volume={30},
  number={4},
  pages={458-469},
  author={Savolainen, Paula and Ahonen, Jarmo J and Richardson, Ita},
  url={https://www.sciencedirect.com/science/article/pii/S0263786311000901},
  keywords={Literature review, Project management, Customer, Outsourcing, Project failure, Project success, Software development project, Supplier, Software},
  abstract={In this paper, we consider software development project success and failure from the supplier's perspective. First we clarified concepts in order to be able to exclude review articles on in-house projects, continuous services, the customer's perspective, and software product development, with the aim of providing valid results for supplier firms. We divided success criteria into project success and project management (PM) success, and, in seven articles, identified three success criteria from the supplier's perspective: customer satisfaction, short-term business benefits, and long-term business benefits. In contrast, no definition of software development project failure was found. Articles were found in seven different journals, showing that knowledge on software development project success from the supplier's perspective is fragmented. This impedes the growth of knowledge on this topic.}
}

@article{rayyan-727967386,
  title={Software clone detection: A systematic review},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={7},
  pages={1165-1199},
  author={Rattan, Dhavleesh and Bhatia, Rajesh and Singh, Maninder},
  url={https://www.sciencedirect.com/science/article/pii/S0950584913000323},
  keywords={Systematic literature review, Clone detection, Model based clone, Semantic clones, Software clone, Software},
  abstract={Context Reusing software by means of copy and paste is a frequent activity in software development. The duplicated code is known as a software clone and the activity is known as code cloning. Software clones may lead to bug propagation and serious maintenance problems. Objective This study reports an extensive systematic literature review of software clones in general and software clone detection in particular. Method We used the standard systematic literature review method based on a comprehensive set of 213 articles from a total of 2039 articles published in 11 leading journals and 37 premier conferences and workshops. Results Existing literature about software clones is classified broadly into different categories. The importance of semantic clone detection and model based clone detection led to different classifications. Empirical evaluation of clone detection tools/techniques is presented. Clone management, its benefits and cross cutting nature is reported. Number of studies pertaining to nine different types of clones is reported. Thirteen intermediate representations and 24 match detection techniques are reported. Conclusion We call for an increased awareness of the potential benefits of software clone management, and identify the need to develop semantic and model clone detection techniques. Recommendations are given for future research.}
}

@article{rayyan-727967387,
  title={A systematic review of gamification in e-Health},
  year={2017},
  journal={Journal of Biomedical Informatics},
  issn={1532-0464},
  volume={71},
  pages={31-48},
  author={Sardi, Lamyae and Idri, Ali and Fernández-Alemán, José Luis},
  url={https://www.sciencedirect.com/science/article/pii/S1532046417301065},
  keywords={Systematic literature review, e-Health, Serious game, Gamification, Application},
  abstract={Gamification is a relatively new trend that focuses on applying game mechanics to non-game contexts in order to engage audiences and to inject a little fun into mundane activities besides generating motivational and cognitive benefits. While many fields such as Business, Marketing and e-Learning have taken advantage of the potential of gamification, the digital healthcare domain has also started to exploit this emerging trend. This paper aims to summarize the current knowledge regarding gamified e-Health applications. A systematic literature review was therefore conducted to explore the various gamification strategies employed in e-Health and to address the benefits and the pitfalls of this emerging discipline. A total of 46 studies from multiple sources were then considered and thoroughly investigated. The results show that the majority of the papers selected reported gamification and serious gaming in health and wellness contexts related specifically to chronic disease rehabilitation, physical activity and mental health. Although gamification in e-Health has attracted a great deal of attention during the last few years, there is still a dearth of valid empirical evidence in this field. Moreover, most of the e-Health applications and serious games investigated have been proven to yield solely short-term engagement through extrinsic rewards. For gamification to reach its full potential, it is therefore necessary to build e-Health solutions on well-founded theories that exploit the core experience and psychological effects of game mechanics.}
}

@article{rayyan-727967388,
  title={Analyzing the concept of technical debt in the context of agile software development: A systematic literature review},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={82},
  pages={139-158},
  author={Behutiye, Woubshet Nema and Rodríguez, Pilar and Oivo, Markku and Tosun, Ayşe},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916302890},
  keywords={Systematic literature review, Agile software development, Technical debt, Technical debt management, Software},
  abstract={Context Technical debt (TD) is a metaphor that is used to communicate the consequences of poor software development practices to non-technical stakeholders. In recent years, it has gained significant attention in agile software development (ASD). Objective The purpose of this study is to analyze and synthesize the state of the art of TD, and its causes, consequences, and management strategies in the context of ASD. Research Method Using a systematic literature review (SLR), 38 primary studies, out of 346 studies, were identified and analyzed. Results We found five research areas of interest related to the literature of TD in ASD. Among those areas, “managing TD in ASD” received the highest attention, followed by “architecture in ASD and its relationship with TD”. In addition, eight categories regarding the causes and five categories regarding the consequences of incurring TD in ASD were identified. “Focus on quick delivery” and “architectural and design issues” were the most popular causes of incurring TD in ASD. “Reduced productivity”, “system degradation” and “increased maintenance cost” were identified as significant consequences of incurring TD in ASD. Additionally, we found 12 strategies for managing TD in the context of ASD, out of which “refactoring” and “enhancing the visibility of TD” were the most significant. Conclusion The results of this study provide a structured synthesis of TD and its management in the context of ASD as well as potential research areas for further investigation.}
}

@article{rayyan-727967389,
  title={Virtual and digital outcrops in the petroleum industry: A systematic review},
  year={2020},
  journal={Earth-Science Reviews},
  issn={0012-8252},
  volume={208},
  pages={103260},
  author={Marques, Ademir and Horota, Rafael Kenji and de Souza, Eniuce Menezes and Kupssinskü, Lucas and Rossa, Pedro and Aires, Alysson Soares and Bachi, Leonardo and Veronez, Mauricio Roberto and Gonzaga, Luiz and Cazarin, Caroline Lessio},
  url={https://www.sciencedirect.com/science/article/pii/S0012825220303068},
  keywords={Systematic, Modeling, Review, 3D model, Digital outcrop, Fluid flow, LiDAR, Petroleum, Photogrammetry, Reservoir, UAV, Virtual outcrop},
  abstract={The study of outcrop analogues of petroleum reservoirs is well established in the petroleum industry through the use of digital outcrop models (DOMs). These models, which are also known as virtual outcrop models (VOMs) or 3D outcrops, are of great importance for understanding the behavior of actual reservoirs. This topic has been reviewed by many authors, and the studies vary in detail according to the technologies involved. The present study applies systematic review methodology traversing a number of articles to find the trends in studies utilizing DOMs. The articles included in this review indicate that the technologies used to generate DOMs are still predominantly classified as Light Detection and Ranging (LiDAR) and digital photogrammetry, with the first being present in most of the works, and the latter attracting attention owing to the popularity of unmanned aerial vehicles (UAVs). These studies have attracted a significant amount of attention to outcrop analysis, and the information acquired can be used to better fit reservoir simulations. Furthermore, a trend is identified with a focus on outcrop geometry and structural data. This work also discusses some of the available opportunities related to the generation of DOMs as well as emerging technologies that can improve the quality of the outcrop models in order to provide better reservoir simulations. Finally, this work discusses the findings and highlights of the articles answering the initially raised research questions.}
}

@article{rayyan-727967391,
  title={The experimental applications of search-based techniques for model-based testing: Taxonomy and systematic literature review},
  year={2016},
  journal={Applied Soft Computing},
  issn={1568-4946},
  volume={49},
  pages={1094-1117},
  author={Saeed, Aneesa and Ab Hamid, Siti Hafizah and Mustafa, Mumtaz Begum},
  url={https://www.sciencedirect.com/science/article/pii/S1568494616304240},
  keywords={Software testing, Systematic literature review, Model-based testing, Taxonomy, Search-based techniques, Test case generation},
  abstract={Context Model-based testing (MBT) aims to generate executable test cases from behavioral models of software systems. MBT gains interest in industry and academia due to its provision of systematic, automated, and comprehensive testing. Researchers have successfully applied search-based techniques (SBTs) by automating the search for an optimal set of test cases at reasonable cost compared to other more expensive techniques. Thus, there is a recent surge toward the applications of SBTs for MBT because the generated test cases are optimal and have low computational cost. However, successful, future SBTs for MBT applications demand deep insight into its existing experimental applications that underlines stringent issues and challenges, which is lacking in the literature. Objective The objective of this study is to comprehensively analyze the current state-of-the-art of the experimental applications of SBTs for MBT and present the limitations of the current literature to direct future research. Method We conducted a systematic literature review (SLR) using 72 experimental papers from six data sources. We proposed a taxonomy based on the literature to categorize the characteristics of the current applications. Results The results indicate that the majority of the existing applications of SBTs for MBT focus on functional and structural coverage purposes, as opposed to stress testing, regression testing and graphical user interface (GUI) testing. We found research gaps in the existing applications in five areas: applying multi-objective SBTs, proposing hybrid techniques, handling complex constraints, addressing data and requirement-based adequacy criteria, and adapting landscape visualization. Only twelve studies proposed and empirically evaluated the SBTs for complex systems in MBT. Conclusion This extensive systematic analysis of the existing literature based on the proposed taxonomy enables to assist researchers in exploring the existing research efforts and reveal the limitations that need additional investigation.}
}

@article{rayyan-727967392,
  title={The impact of knowledge management processes on information systems: A systematic review},
  year={2018},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={43},
  pages={173-187},
  author={Al-Emran, Mostafa and Mezhuyev, Vitaliy and Kamaludin, Adzhar and Shaalan, Khaled},
  url={https://www.sciencedirect.com/science/article/pii/S0268401217308186},
  keywords={Systematic review, Information systems, Knowledge management processes, Information Systems},
  abstract={Knowledge Management (KM) processes play a significant role in the implementation of various Information Systems (IS). Several review studies were carried out to afford a better understanding of the current research trend of KM processes. However, this issue still needs to be examined from other perspectives. It is observed that previous research neglects the examination of KM processes studies with regard to ISs. The current study systematically reviews and sheds the light on KM processes studies related to ISs aiming to provide a comprehensive analysis of 41 research articles published in peer-reviewed journals from 2001 to 2018. The main findings of this study indicate that knowledge sharing is the most frequent KM process studied, followed by knowledge acquisition and knowledge application. Besides, questionnaire surveys were found to be the primarily relied research methods for data collection in the context of KM processes. In addition, 78% of the analyzed studies registered positive research outcomes. In terms of IS type, most of the analyzed studies focused on investigating the impact of KM processes on E-business systems, knowledge management systems, and IS outsourcing, respectively. Additionally, in terms of data collection, the majority of the analyzed studies were primarily focused on the participants who are IS executives/managers. Furthermore, most of the analyzed studies that achieved positive outcomes were carried out in China. To that end, this review study attempts to demonstrate and detail the recent increase in the interest and the advancement made in KM processes research considering ISs studies, which form an essential reference for scholars in KM field.}
}

@article{rayyan-727967393,
  title={Factors influencing clients in the selection of offshore software outsourcing vendors: An exploratory study using a systematic literature review},
  year={2011},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={84},
  number={4},
  pages={686-699},
  author={Khan, Siffat Ullah and Niazi, Mahmood and Ahmad, Rashid},
  url={https://www.sciencedirect.com/science/article/pii/S0164121210003298},
  keywords={Systematic literature review, Offshore software development outsourcing (OSDO), SOVRM, Vendors, Software},
  abstract={Context Offshore software development outsourcing is a modern business strategy for developing high quality software at low cost. Objective The objective of this research paper is to identify and analyse factors that are important in terms of the competitiveness of vendor organisations in attracting outsourcing projects. Method We performed a systematic literature review (SLR) by applying our customised search strings which were derived from our research questions. We performed all the SLR steps, such as the protocol development, initial selection, final selection, quality assessment, data extraction and data synthesis. Results We have identified factors such as cost-saving, skilled human resource, appropriate infrastructure, quality of product and services, efficient outsourcing relationships management, and an organisation's track record of successful projects which are generally considered important by the outsourcing clients. Our results indicate that appropriate infrastructure, cost-saving, and skilled human resource are common in three continents, namely Asia, North America and Europe. We identified appropriate infrastructure, cost-saving, and quality of products and services as being common in three types of organisations (small, medium and large). We have also identified four factors-appropriate infrastructure, cost-saving, quality of products and services, and skilled human resource as being common in the two decades (1990–1999 and 2000–mid 2008). Conclusions Cost-saving should not be considered as the driving factor in the selection process of software development outsourcing vendors. Vendors should rather address other factors in order to compete in the OSDO business, such as skilled human resource, appropriate infrastructure and quality of products and services.}
}

@article{rayyan-727967394,
  title={Robotics applications grounded in learning theories on tertiary education: A systematic review},
  year={2017},
  journal={Computers & Education},
  issn={0360-1315},
  volume={112},
  pages={97-107},
  author={Spolaôr, Newton and Benitti, Fabiane B.Vavassori},
  url={https://www.sciencedirect.com/science/article/pii/S0360131517300970},
  keywords={Improving classroom teaching, Evaluation methodologies, Post-secondary education, Teaching/learning strategies, Robotics, Learning},
  abstract={Empirical evidence suggests the effectiveness of robotics as a learning complementary tool in tertiary education. In this context, some experiences benefited from the link between educational practice and theory. However, a comprehensive survey on initiatives that explores this link in universities and colleges is missing. This work systematically reviews quantitatively assessed robots applications, grounded in learning theories, in tertiary institutions. By applying a protocol review in different bibliographic databases, 15 papers were selected for synthesis. As a result, experiences developing non-robotic concepts and skills in universities and colleges were found. In most of the cases, Computer Science and Engineering undergraduate courses were involved. In addition, empirical results reported by the selected publications suggest that some literature proposals can be useful in practice. Based on the panorama obtained, this work also points out future directions for practitioners and researchers in education.}
}

@article{rayyan-727967395,
  title={Static analysis of android apps: A systematic literature review},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={88},
  pages={67-95},
  author={Li, Li and Bissyandé, Tegawendé F and Papadakis, Mike and Rasthofer, Siegfried and Bartel, Alexandre and Octeau, Damien and Klein, Jacques and Traon, Le},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917302987},
  keywords={Methyltestosterone},
  abstract={Context Static analysis exploits techniques that parse program source code or bytecode, often traversing program paths to check some program properties. Static analysis approaches have been proposed for different tasks, including for assessing the security of Android apps, detecting app clones, automating test cases generation, or for uncovering non-functional issues related to performance or energy. The literature thus has proposed a large body of works, each of which attempts to tackle one or more of the several challenges that program analyzers face when dealing with Android apps. Objective We aim to provide a clear view of the state-of-the-art works that statically analyze Android apps, from which we highlight the trends of static analysis approaches, pinpoint where the focus has been put, and enumerate the key aspects where future researches are still needed. Method We have performed a systematic literature review (SLR) which involves studying 124 research papers published in software engineering, programming languages and security venues in the last 5 years (January 2011–December 2015). This review is performed mainly in five dimensions: problems targeted by the approach, fundamental techniques used by authors, static analysis sensitivities considered, android characteristics taken into account and the scale of evaluation performed. Results Our in-depth examination has led to several key findings: 1) Static analysis is largely performed to uncover security and privacy issues; 2) The Soot framework and the Jimple intermediate representation are the most adopted basic support tool and format, respectively; 3) Taint analysis remains the most applied technique in research approaches; 4) Most approaches support several analysis sensitivities, but very few approaches consider path-sensitivity; 5) There is no single work that has been proposed to tackle all challenges of static analysis that are related to Android programming; and 6) Only a small portion of state-of-the-art works have made their artifacts publicly available. Conclusion The research community is still facing a number of challenges for building approaches that are aware altogether of implicit-Flows, dynamic code loading features, reflective calls, native code and multi-threading, in order to implement sound and highly precise static analyzers.}
}

@article{rayyan-727967396,
  title={A systematic review on the profiling of digital news portal for big data veracity},
  year={2015},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={72},
  pages={390-397},
  author={Jamil, Normala Binti Che Eembi @ and Ishak, Iskandar Bin and Sidi, Fatimah and Affendey, Lilly Suriani and Mamat, Ali},
  url={https://www.sciencedirect.com/science/article/pii/S1877050915036157},
  keywords={Big Data, Profiling, Ranking, Veracity},
  abstract={Currently, digital news portals have been one of the most important news sources for Internet users. However, the way it is written depends on the direction of the content. One approach to news reporting is through manipulative writing. Such method of writing has created a number of adverse outcomes such as political unrest, slander and negative perception towards the particular organization, personnel, and country. It is important for readers to choose and select news portal that is reporting positively and to neglect portals which practices manipulative writing approach for their own gains or causing negative impact towards the community. The aim of this study is to structure and analyzed the literature related to data veracity research that can be used to the profile of digital news portal. The method that has been used in this paper is to classify and define data veracity; a systematic literature review is a conduct. It includes journal and conference proceedings. The results come out with objectives in data veracity, the structure of research topics, research trends with publications and framework veracity model validated. This paper provides a complete review of literature related to profiling digital news portal in data veracity.}
}

@article{rayyan-727967397,
  title={A systematic review and an expert survey on capabilities supporting multi product lines},
  year={2012},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={54},
  number={8},
  pages={828-852},
  author={Holl, Gerald and Grünbacher, Paul and Rabiser, Rick},
  url={https://www.sciencedirect.com/science/article/pii/S095058491200033X},
  keywords={Systematic literature review, Large-scale systems, Multi product lines, Product line engineering},
  abstract={Context Complex software-intensive systems comprise many subsystems that are often based on heterogeneous technological platforms and managed by different organizational units. Multi product lines (MPLs) are an emerging area of research addressing variability management for such large-scale or ultra-large-scale systems. Despite the increasing number of publications addressing MPLs the research area is still quite fragmented. Objective The aims of this paper are thus to identify, describe, and classify existing approaches supporting MPLs and to increase the understanding of the underlying research issues. Furthermore, the paper aims at defining success-critical capabilities of infrastructures supporting MPLs. Method Using a systematic literature review we identify and analyze existing approaches and research issues regarding MPLs. Approaches described in the literature support capabilities needed to define and operate MPLs. We derive capabilities supporting MPLs from the results of the systematic literature review. We validate and refine these capabilities based on a survey among experts from academia and industry. Results The paper discusses key research issues in MPLs and presents basic and advanced capabilities supporting MPLs. We also show examples from research approaches that demonstrate how these capabilities can be realized. Conclusions We conclude that approaches supporting MPLs need to consider both technical aspects like structuring large models and defining dependencies between product lines as well as organizational aspects such as distributed modeling and product derivation by multiple stakeholders. The identified capabilities can help to build, enhance, and evaluate MPL approaches.}
}

@article{rayyan-727967399,
  title={Architectural tactics for cyber-foraging: Results of a systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={107},
  pages={158-186},
  author={Lewis, Grace and Lago, Patricia},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215001211},
  keywords={Software architecture, Cyber-foraging, Mobile cloud computing},
  abstract={Mobile devices have become for many the preferred way of interacting with the Internet, social media and the enterprise. However, mobile devices still do not have the computing power and battery life that will allow them to perform effectively over long periods of time, or for executing applications that require extensive communication, computation, or low latency. Cyber-foraging is a technique to enable mobile devices to extend their computing power and storage by offloading computation or data to more powerful servers located in the cloud or in single-hop proximity. This article presents the results of a systematic literature review (SLR) on architectures that support cyber-foraging. Elements of the identified architectures were codified in the form of Architectural Tactics for Cyber-Foraging. These tactics will help architects extend their design reasoning toward cyber-foraging as a way to support the mobile applications of the present and the future.}
}

@article{rayyan-727967400,
  title={Clinical text classification research trends: Systematic literature review and open issues},
  year={2019},
  journal={Expert Systems with Applications},
  issn={0957-4174},
  volume={116},
  pages={494-520},
  author={Mujtaba, Ghulam and Shuib, Liyana and Idris, Norisma and Hoo, Wai Lam and Raj, Ram Gopal and Khowaja, Kamran and Shaikh, Khairunisa and Nweke, Henry Friday},
  url={https://www.sciencedirect.com/science/article/pii/S0957417418306110},
  keywords={Performance metrics, Clinical text classification, Feature engineering, Rule-based text classification, Supervised machine learning},
  abstract={The pervasive use of electronic health databases has increased the accessibility of free-text clinical reports for supplementary use. Several text classification approaches, such as supervised machine learning (SML) or rule-based approaches, have been utilized to obtain beneficial information from free-text clinical reports. In recent years, many researchers have worked in the clinical text classification field and published their results in academic journals. However, to the best of our knowledge, no comprehensive systematic literature review (SLR) has recapitulated the existing primary studies on clinical text classification in the last five years. Thus, the current study aims to present SLR of academic articles on clinical text classification published from January 2013 to January 2018. Accordingly, we intend to maximize the procedural decision analysis in six aspects, namely, types of clinical reports, data sets and their characteristics, pre-processing and sampling techniques, feature engineering, machine learning algorithms, and performance metrics. To achieve our objective, 72 primary studies from 8 bibliographic databases were systematically selected and rigorously reviewed from the perspective of the six aspects. This review identified nine types of clinical reports, four types of data sets (i.e., homogeneous–homogenous, homogenous–heterogeneous, heterogeneous–homogenous, and heterogeneous–heterogeneous), two sampling techniques (i.e., over-sampling and under-sampling), and nine pre-processing techniques. Moreover, this review determined bag of words, bag of phrases, and bag of concepts features when represented by either term frequency or term frequency with inverse document frequency, thereby showing improved classification results. SML-based or rule-based approaches were generally employed to classify the clinical reports. To measure the performance of these classification approaches, we used precision, recall, F-measure, accuracy, AUC, and specificity in binary class problems. In multi-class problems, we primarily used micro or macro-averaging precision, recall, or F-measure. Lastly, open research issues and challenges are presented for future scholars who are interested in clinical text classification. This SLR will definitely be a beneficial resource for researchers engaged in clinical text classification.}
}

@article{rayyan-727967402,
  title={Higher order mutation testing: A systematic literature review},
  year={2017},
  journal={Computer Science Review},
  issn={1574-0137},
  volume={25},
  pages={29-48},
  author={Ghiduk, Ahmed S and Girgis, Moheb R and Shehata, Marwa H},
  url={https://www.sciencedirect.com/science/article/pii/S1574013716301095},
  keywords={First-order mutants, Higher-order mutants, Higher-order mutation testing, Mutation testing, Mutation},
  abstract={Mutation testing is the process whereby a fault is deliberately inserted into a software system, in order to assess the quality of test data, in terms of its ability to find this fault. Mutation testing is also used as a way to drive the test data development process. Traditionally, faults were inserted one by one into a software system, but more recently there has been an upsurge of interest by the area of higher-order mutation, in which multiple faults are inserted into the system at once. Originally, this was thought to be too expensive, as there was already a concern that the size of the pool of mutants for traditional mutation was already too large to handle. However, following a seminal publication in 2008, it was realized that the space of higher-order mutants (HOMs) could be searched for useful mutants that drive testing harder, and to reduce the overall test effort, by clever combination of first-order mutants. As a result, many authors examined the way in which HOM testing could find subtle hard to kill faults, capture partial fault masking, reduce equivalent mutants problem, reduce test effort while increasing effectiveness, and capture more realistic faults than those captured by simple insertion of first-order mutants. Because of the upsurge of interest in the previous issues, this paper presents the first Systematic Literature Review research specifically targeted at a higher-order mutation. This Systematic Literature Review analyzes the results of more than one hundred sixty research articles in this area. The current paper presents qualitative results and bibliometric analysis for the surveyed articles. In addition, it augments these results with scientific findings and quantitative results from the primary literature. As a result of this work, this SLR presents an outline for many future work.}
}

@article{rayyan-727967403,
  title={A systematic literature review: Refactoring for disclosing code smells in object oriented software},
  year={2018},
  journal={Ain Shams Engineering Journal},
  issn={2090-4479},
  volume={9},
  number={4},
  pages={2129-2151},
  author={Singh, Satwinder and Kaur, Sharanpreet},
  url={https://www.sciencedirect.com/science/article/pii/S2090447917300412},
  keywords={Code smells, Refactoring, Anti-patterns, Smell, Software},
  abstract={Context Reusing a design pattern is not always in the favor of developers. Thus, the code starts smelling. The presence of “Code Smells” leads to more difficulties for the developers. This racket of code smells is sometimes called Anti-Patterns. Objective The paper aimed at a systematic literature review of refactoring with respect to code smells. However the review of refactoring is done in general and the identification of code smells and anti-patterns is performed in depth. Method A systematic literature survey has been performed on 238 research items that includes articles from leading Conferences, Workshops and premier journals, theses of researchers and book chapters. Results Several data sets and tools for performing refactoring have been revealed under the specified research questions. Conclusion The work done in the paper is an addition to prior systematic literature surveys. With the study of paper the attentiveness of readers about code smells and anti-patterns will be enhanced.}
}

@article{rayyan-727967404,
  title={Obstacles in data distribution service middleware: A systematic review},
  year={2017},
  journal={Future Generation Computer Systems},
  issn={0167-739X},
  volume={68},
  pages={191-210},
  author={Köksal, Ömer and Tekinerdogan, Bedir},
  url={https://www.sciencedirect.com/science/article/pii/S0167739X1630351X},
  keywords={Systematic literature review, Data Distribution Service (DDS), Middleware},
  abstract={Context: Data Distribution Service (DDS) is a standard data-centric publish–subscribe programming model and specification for distributed systems. DDS has been applied for the development of high performance distributed systems such as in the defense, finance, automotive, and simulation domains. Various papers have been written on the application of DDS, however, there has been no attempt to systematically review and categorize the identified obstacles. Objective: The overall objective of this paper is to identify the state of the art of DDS, and describe the main lessons learned and obstacles in applying DDS. In addition, we aim to identify the important open research issues. Method: A systematic literature review (SLR) is conducted by a multiphase study selection process using the published literature since the introduction of DDS in 2003. Results: We reviewed 468 papers that are discovered using a well-planned review protocol, and 34 of them were assessed as primary studies related to our research questions. Conclusions: We have identified 11 basic categories for describing the identified obstacles and the corresponding research challenges that can be used to depict the state-of-the-art in DDS and provide a vision for further research.}
}

@article{rayyan-727967406,
  title={On strategies for testing software product lines: A systematic literature review},
  year={2014},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={56},
  number={10},
  pages={1183-1199},
  author={do Carmo Machado, Ivan and McGregor, John D and Cavalcanti, Yguaratã Cerqueira and de Almeida, Eduardo Santana},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914000834},
  keywords={Software product lines, Software testing, Systematic literature review, Software quality, Software},
  abstract={Context Testing plays an important role in the quality assurance process for software product line engineering. There are many opportunities for economies of scope and scale in the testing activities, but techniques that can take advantage of these opportunities are still needed. Objective The objective of this study is to identify testing strategies that have the potential to achieve these economies, and to provide a synthesis of available research on SPL testing strategies, to be applied towards reaching higher defect detection rates and reduced quality assurance effort. Method We performed a literature review of two hundred seventy-six studies published from the year 1998 up to the 1st semester of 2013. We used several filters to focus the review on the most relevant studies and we give detailed analyses of the core set of studies. Results The analysis of the reported strategies comprised two fundamental aspects for software product line testing: the selection of products for testing, and the actual test of products. Our findings indicate that the literature offers a large number of techniques to cope with such aspects. However, there is a lack of reports on realistic industrial experiences, which limits the inferences that can be drawn. Conclusion This study showed a number of leveraged strategies that can support both the selection of products, and the actual testing of products. Future research should also benefit from the problems and advantages identified in this study.}
}

@article{rayyan-727967408,
  title={Systematic literature review and empirical investigation of barriers to process improvement in global software development: Client–vendor perspective},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={87},
  pages={180-205},
  author={Khan, Arif Ali and Keung, Jacky and Niazi, Mahmood and Hussain, Shahid and Ahmad, Awais},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917302483},
  keywords={Systematic literature review, Software process improvement, Global software development, Barriers, Client, Vendor, Software},
  abstract={Context Increasingly, software development organizations are adopting global software development (GSD) strategies, mainly because of the significant return on investment they produce. However, there are many challenges associated with GSD, particularly with regards to software process improvement (SPI). SPI can play a significant role in the successful execution of GSD projects. Objective The aim of the present study was to identify barriers that can negatively affect SPI initiatives in GSD organizations from both client and vendor perspectives. Method A systematic literature review (SLR) and survey questionnaire were used to identify and validate the barriers. Results Twenty-two barriers to successful SPI programs were identified. Results illustrate that the barriers identified using SLR and survey approaches have more similarities However, there were significant differences between the ranking of these barriers in the SLR and survey approaches, as indicated by the results of t-tests (for instance, t = 2.28, p = 0.011 ¡ 0.05). Our findings demonstrate that there is a moderate positive correlation between the ranks obtained from the SLR and the empirical study (rs (22)= 0.567, p = 0.006). Conclusions The identified barriers can assist both client and vendor GSD organizations during initiation of an SPI program. Client-vendor classification was used to provide a broad picture of SPI programs, and their respective barriers. The top-ranked barriers can be used as a guide for GSD organizations prior to the initiation of an SPI program. We believe that the results of this study can be useful in tackling the problems associated with the implementation of SPI, which is vital to the success and progression of GSD organizations.}
}

@article{rayyan-727967409,
  title={Agile requirements engineering: A systematic literature review},
  year={2017},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={49},
  pages={79-91},
  author={Schön, Eva-Maria and Thomaschewski, Jörg and Escalona, María José},
  url={https://www.sciencedirect.com/science/article/pii/S0920548916300708},
  keywords={Systematic literature review, Agile software development, Human-computer interaction, Requirements Engineering, User-centered design},
  abstract={Nowadays, Agile Software Development (ASD) is used to cope with increasing complexity in system development. Hybrid development models, with the integration of User-Centered Design (UCD), are applied with the aim to deliver competitive products with a suitable User Experience (UX). Therefore, stakeholder and user involvement during Requirements Engineering (RE) are essential in order to establish a collaborative environment with constant feedback loops. The aim of this study is to capture the current state of the art of the literature related to Agile RE with focus on stakeholder and user involvement. In particular, we investigate what approaches exist to involve stakeholder in the process, which methodologies are commonly used to present the user perspective and how requirements management is been carried out. We conduct a Systematic Literature Review (SLR) with an extensive quality assessment of the included studies. We identified 27 relevant papers. After analyzing them in detail, we derive deep insights to the following aspects of Agile RE: stakeholder and user involvement, data gathering, user perspective, integrated methodologies, shared understanding, artifacts, documentation and Non-Functional Requirements (NFR). Agile RE is a complex research field with cross-functional influences. This study will contribute to the software development body of knowledge by assessing the involvement of stakeholder and user in Agile RE, providing methodologies that make ASD more human-centric and giving an overview of requirements management in ASD.}
}

@article{rayyan-727967410,
  title={Characterizing testing methods for context-aware software systems: Results from a quasi-systematic literature review},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={131},
  pages={1-21},
  author={Matalonga, Santiago and Rodrigues, Felyppe and Travassos, Guilherme Horta},
  url={https://www.sciencedirect.com/science/article/pii/S016412121730095X},
  keywords={Software testing, Systematic literature review, Context-aware, Test case design, Software},
  abstract={Context-Aware Software Systems (CASS) use environmental information to provide better service to the systems' actors to fulfill their goals. Testing of ubiquitous software systems can be challenging since it is unlikely that, while designing the test cases, the tester can identify all possible context variations. A quasi-Systematic Literature Review has been undertaken to characterize the methods usually used for testing CASS. The analysis and generation of knowledge in this work rely on classifying the extracted information. Established taxonomies of software testing and context-aware were used to characterize and interpret the findings. The results show that, although it is possible to observe the utilization of some software testing methods, few empirical studies are evaluating such methods when testing CASS. The selected technical literature conveys a lack of consensus on the understanding of context and CASS, and on the meaning of software testing. Furthermore, context variation in CASS has only been partially addressed by the identified approaches. They either rely on simulating context or in fixing the values of context variables during testing. We argue that the tests of context-aware software systems need to deal with the diversity of context instead of mitigating their effects.}
}

@article{rayyan-727967411,
  title={Agile development in the cloud computing environment: A systematic review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={103},
  pages={142-158},
  author={Younas, Muhammad and Jawawi, Dayang N A and Ghani, Imran and Fries, Terrence and Kazmi, Rafaqut},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301319},
  keywords={Systematic review, Cloud computing, Agile software development, Agile, Agile methodology},
  abstract={Background: Agile software development is based on a set of values and principles. The twelve principles are inferred from agile values. Agile principles are composition of evolutionary requirement, simple design, continuous delivery, self-organizing team and face-to-face communication. Due to changing market demand, agile methodology faces problems such as scalability, more effort and cost required in setting up hardware and software infrastructure, availability of skilled resource and ability to build application from multiple locations. Twelve (12) principles may be practiced more appropriately with the support of cloud computing. This merger of agile and cloud computing may provide infrastructure optimization and automation benefits to agile practitioners. Objective: This Systematic Literature Review (SLR) identifies the techniques employed in cloud computing environment that are useful for agile development. In addition, SLR discusses the significance of cloud and its challenges. Method: By applying the SLR procedure, the authors select thirty-seven (37) studies out of six-hundred-forty-seven (647) from 2010 to 2017. Result: The result of SLR shows that the techniques using existing tools were reported in 35%, simulations in 20% and application developed in 15% of the studies. Evaluation of techniques was reported in 32% of the studies. The impact of cloud computing was measured by the classification of four major categories such as transparency 32%, collaboration 50%, development infrastructure 29% and cloud quality attributes in 39%. Furthermore, a large number of tools were reported in primary studies. The challenges posed by cloud adoption in agile was reported as interoperability 13%, security & privacy 18% and rest of the primary studies did not report any other research gaps. Conclusions: The study concludes that agile development in cloud computing environment is an important area in software engineering. There are many open challenges and gaps. In particular, more quality tools, evaluation research and empirical studies are required in this area.}
}

@article{rayyan-727967413,
  title={Requirements engineering for software product lines: A systematic literature review},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={8},
  pages={806-820},
  author={Alves, Vander and Niu, Nan and Alves, Carina and Valença, George},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910000625},
  keywords={Software product lines, Systematic literature review, Requirements engineering, Software},
  abstract={Context Software product line engineering (SPLE) is a growing area showing promising results in research and practice. In order to foster its further development and acceptance in industry, it is necessary to assess the quality of the research so that proper evidence for adoption and validity are ensured. This holds in particular for requirements engineering (RE) within SPLE, where a growing number of approaches have been proposed. Objective This paper focuses on RE within SPLE and has the following goals: assess research quality, synthesize evidence to suggest important implications for practice, and identify research trends, open problems, and areas for improvement. Method A systematic literature review was conducted with three research questions and assessed 49 studies, dated from 1990 to 2009. Results The evidence for adoption of the methods is not mature, given the primary focus on toy examples. The proposed approaches still have serious limitations in terms of rigor, credibility, and validity of their findings. Additionally, most approaches still lack tool support addressing the heterogeneity and mostly textual nature of requirements formats as well as address only the proactive SPLE adoption strategy. Conclusions Further empirical studies should be performed with sufficient rigor to enhance the body of evidence in RE within SPLE. In this context, there is a clear need for conducting studies comparing alternative methods. In order to address scalability and popularization of the approaches, future research should be invested in tool support and in addressing combined SPLE adoption strategies.}
}

@article{rayyan-727967414,
  title={On evaluating commercial Cloud services: A systematic review},
  year={2013},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={86},
  number={9},
  pages={2371-2393},
  author={Li, Zheng and Zhang, He and O'Brien, Liam and Cai, Rainbow and Flint, Shayne},
  url={https://www.sciencedirect.com/science/article/pii/S0164121213000915},
  keywords={Systematic literature review, Cloud Computing, Cloud service evaluation},
  abstract={Background Cloud Computing is increasingly booming in industry with many competing providers and services. Accordingly, evaluation of commercial Cloud services is necessary. However, the existing evaluation studies are relatively chaotic. There exists tremendous confusion and gap between practices and theory about Cloud services evaluation. Aim To facilitate relieving the aforementioned chaos, this work aims to synthesize the existing evaluation implementations to outline the state-of-the-practice and also identify research opportunities in Cloud services evaluation. Method Based on a conceptual evaluation model comprising six steps, the systematic literature review (SLR) method was employed to collect relevant evidence to investigate the Cloud services evaluation step by step. Results This SLR identified 82 relevant evaluation studies. The overall data collected from these studies essentially depicts the current practical landscape of implementing Cloud services evaluation, and in turn can be reused to facilitate future evaluation work. Conclusions Evaluation of commercial Cloud services has become a world-wide research topic. Some of the findings of this SLR identify several research gaps in the area of Cloud services evaluation (e.g., Elasticity and Security evaluation of commercial Cloud services could be a long-term challenge), while some other findings suggest the trend of applying commercial Cloud services (e.g., compared with PaaS, IaaS seems more suitable for customers and is particularly important in industry). This SLR study itself also confirms some previous experiences and records new evidence-based software engineering (EBSE) lessons.}
}

@article{rayyan-727967415,
  title={Knowledge transfer challenges and mitigation strategies in global software development—A systematic literature review and industrial validation},
  year={2013},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={33},
  number={2},
  pages={333-355},
  author={Nidhra, Srinivas and Yanamadala, Muralidhar and Afzal, Wasif and Torkar, Richard},
  url={https://www.sciencedirect.com/science/article/pii/S0268401212001466},
  keywords={Systematic literature review, Global software development, Interviews, Knowledge transfer, Software},
  abstract={Context In this article we considered knowledge transfer (KT) in global software development (GSD) from two perspectives, state-of-the-art and state-of-the-practice, in order to identify what are the challenges that hamper the success of KT in global software teams, as well as to find out what are the mitigation strategies that can be used to overcome such challenges. Objectives The overall aim of this work is to provide a body of knowledge for enabling successful KT in GSD settings. This is achieved by an in-depth understanding of KT challenges and mitigation strategies, both from the perspective of literature and industry. It also identifies the similarities and differences in challenges and strategies gathered from literature studies and industrial experts. Methods In order to fulfill the aim of the research, we collected data through a systematic literature review (SLR) and conducted interviews with industrial experts. Through the SLR we found 35 primary studies relevant to our objectives. We also conducted eight interviews of experienced industrial professionals from eight different multinational companies world-wide. For analyzing the data we used grounded theory and cross-case analysis. Results In total, 60 different challenges and 79 unique mitigation strategies are identified from both SLR and interview results. The challenges and mitigation strategies are grouped into three core categories of personnel, project and technology factors, thus giving rise to a conceptualization called as 2PT factors. There are greater numbers of challenges and mitigation strategies in the project and personnel factors, highlighting the complex interplay of project-related and human-intensive issues in GSD projects, while the technology factor plays the role as facilitator in transferring knowledge. The study also maps the mitigation strategies to challenges, which can guide practitioners in their selection of strategies to use for overcoming KT challenges in GSD. Conclusions We conclude that effective management of project and personnel factors, facilitated by technological factors, are crucial for a successful transfer of knowledge in GSD projects. Thus in future, the researchers and practitioners need to focus on the 2PT factors for ensuring effective KT in GSD settings.}
}

@article{rayyan-727967417,
  title={Identifying refactoring opportunities in object-oriented code: A systematic literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={58},
  pages={231-249},
  author={Al Dallal, Jehad},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001918},
  keywords={Systematic literature review, Refactoring activity, Refactoring opportunity},
  abstract={Context Identifying refactoring opportunities in object-oriented code is an important stage that precedes the actual refactoring process. Several techniques have been proposed in the literature to identify opportunities for various refactoring activities. Objective This paper provides a systematic literature review of existing studies identifying opportunities for code refactoring activities. Method We performed an automatic search of the relevant digital libraries for potentially relevant studies published through the end of 2013, performed pilot and author-based searches, and selected 47 primary studies (PSs) based on inclusion and exclusion criteria. The PSs were analyzed based on a number of criteria, including the refactoring activities, the approaches to refactoring opportunity identification, the empirical evaluation approaches, and the data sets used. Results The results indicate that research in the area of identifying refactoring opportunities is highly active. Most of the studies have been performed by academic researchers using nonindustrial data sets. Extract Class and Move Method were found to be the most frequently considered refactoring activities. The results show that researchers use six primary existing approaches to identify refactoring opportunities and six approaches to empirically evaluate the identification techniques. Most of the systems used in the evaluation process were open-source, which helps to make the studies repeatable. However, a relatively high percentage of the data sets used in the empirical evaluations were small, which limits the generality of the results. Conclusions It would be beneficial to perform further studies that consider more refactoring activities, involve researchers from industry, and use large-scale and industrial-based systems.}
}

@article{rayyan-727967418,
  title={Variability in quality attributes of service-based software systems: A systematic literature review},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={2},
  pages={320-343},
  author={Mahdavi-Hezavehi, Sara and Galster, Matthias and Avgeriou, Paris},
  url={https://www.sciencedirect.com/science/article/pii/S0950584912001772},
  keywords={Systematic literature review, Quality attributes, Variability, Service-based systems, Software},
  abstract={Context Variability is the ability of a software artifact (e.g., a system, component) to be adapted for a specific context, in a preplanned manner. Variability not only affects functionality, but also quality attributes (e.g., security, performance). Service-based software systems consider variability in functionality implicitly by dynamic service composition. However, variability in quality attributes of service-based systems seems insufficiently addressed in current design practices. Objective We aim at (a) assessing methods for handling variability in quality attributes of service-based systems, (b) collecting evidence about current research that suggests implications for practice, and (c) identifying open problems and areas for improvement. Method A systematic literature review with an automated search was conducted. The review included studies published between the year 2000 and 2011. We identified 46 relevant studies. Results Current methods focus on a few quality attributes, in particular performance and availability. Also, most methods use formal techniques. Furthermore, current studies do not provide enough evidence for practitioners to adopt proposed approaches. So far, variability in quality attributes has mainly been studied in laboratory settings rather than in industrial environments. Conclusions The product line domain as the domain that traditionally deals with variability has only little impact on handling variability in quality attributes. The lack of tool support, the lack of practical research and evidence for the applicability of approaches to handle variability are obstacles for practitioners to adopt methods. Therefore, we suggest studies in industry (e.g., surveys) to collect data on how practitioners handle variability of quality attributes in service-based systems. For example, results of our study help formulate hypotheses and questions for such surveys. Based on needs in practice, new approaches can be proposed.}
}

@article{rayyan-727967419,
  title={Analyzing and documenting the systematic review results of software testing ontologies},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={123},
  pages={106298},
  author={Tebes, Guido and Peppino, Denis and Becker, Pablo and Matturro, Gerardo and Solari, Martin and Olsina, Luis},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300495},
  keywords={Systematic literature review, Secondary study, Analysis, Software testing ontology, Systematic literature review process, Testing strategy, Software},
  abstract={Context Software testing is a complex area since it has a large number of specific methods, processes and strategies, involving a lot of domain concepts. Therefore, it would be valuable to have a conceptualized software testing ontology that explicitly and unambiguously defines the concepts. Consequently, it is important to find out the available evidence in the literature on primary studies for software testing ontologies. In particular, we are looking for research that has a rich ontological coverage that includes Non-Functional Requirements (NFRs) and Functional Requirements (FRs) concepts in conjunction with static and dynamic testing concepts, which can be used in method and process specifications for a family of testing strategies. Objective The main goal for this secondary study is to identify, evaluate and synthesize the available primary studies on conceptualized software testing ontologies. Method To conduct this study, we use the Systematic Literature Review (SLR) approach, which follows our enhanced SLR process. We set three research questions. Additionally, to quantitatively evaluate the quality of the selected conceptualized ontologies, we designed a NFRs tree and its associated metrics and indicators. Results We obtained 12 primary studies documenting conceptualized testing ontologies by using three different retrieval methods. In general, we noted that most of them have a lack of NFRs and static testing terminological coverage. Finally, we observe that none of them is directly linked with FRs and NFRs conceptual components. Conclusion A general benefit of having the suitable software testing ontology is to minimize the current heterogeneity, ambiguity and incompleteness problems in terms, properties and relationships. We have confirmed that exists heterogeneity, ambiguity, and incompleteness for concepts dealing with testing artifacts, roles, activities, and methods. Moreover, we did not find the suitable ontology for our aim since none of the conceptualized ontologies are directly linked with NFRs and FRs components.}
}

@article{rayyan-727967420,
  title={Requirements traceability technologies and technology transfer decision support: A systematic review},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={146},
  pages={59-79},
  author={Wang, Bangchao and Peng, Rong and Li, Yuanbang and Lai, Han and Wang, Zhuo},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301754},
  keywords={Systematic literature review, Quality assessment, Requirements traceability challenges, Requirements traceability technology, Technology transfer},
  abstract={Requirements traceability (RT) is a core activity in Requirements Engineering. Various types of RT technologies have been extensively studied for decades. In this paper, we present a systematic literature review from 114 papers between 2006 and 2016 on RT techniques. We summarized 10 major challenges in current RT activities, and categorized existing RT techniques into 6 groups and 25 sub-groups. Moreover, we built mapping relations between these challenges and techniques, and identified 7 potential future research directions. Based on 83 empirical studies, the evaluations for technology transfer are conducted. The main conclusions are: (1) The “trustworthy” and “automated” challenges are the most widely investigated ones, while “scalable”, “coordinated”, “dynamic” and “lightweight” challenges receive much less attention; (2) “Trace link generation”, especially information retrieval-based (IR-based) methods, are the most studied techniques; (3) IR-based methods have the most potential to be adopted by industry, as they have been validated from multiple viewpoints; (4) Seven promising future research directions are identified, which include developing scalable, dynamic and lightweight tracing techniques, introducing new approaches in other disciplines to meet the RT challenges, improving the express ability of trace links, promoting the industry adoption of RT technologies and developing new techniques to support developers' coordination.}
}

@article{rayyan-727967421,
  title={A systematic literature review of software visualization evaluation},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={144},
  pages={165-180},
  author={Merino, L and Ghafari, M and Anslow, C and Nierstrasz, O},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301237},
  keywords={Literature review, Evaluation, Software visualisation, Software},
  abstract={Context:Software visualizations can help developers to analyze multiple aspects of complex software systems, but their effectiveness is often uncertain due to the lack of evaluation guidelines. Objective: We identify common problems in the evaluation of software visualizations with the goal of formulating guidelines to improve future evaluations. Method:We review the complete literature body of 387 full papers published in the SOFTVIS/VISSOFT conferences, and study 181 of those from which we could extract evaluation strategies, data collection methods, and other aspects of the evaluation. Results:Of the proposed software visualization approaches, 62% lack a strong evaluation. We argue that an effective software visualization should not only boost time and correctness but also recollection, usability, engagement, and other emotions. Conclusion:We call on researchers proposing new software visualizations to provide evidence of their effectiveness by conducting thorough (i) case studies for approaches that must be studied in situ, and when variables can be controlled, (ii) experiments with randomly selected participants of the target audience and real-world open source software systems to promote reproducibility and replicability. We present guidelines to increase the evidence of the effectiveness of software visualization approaches, thus improving their adoption rate.}
}

@article{rayyan-727967422,
  title={An extensive systematic review on the Model-Driven Development of secure systems},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={68},
  pages={62-81},
  author={Nguyen, Phu H and Kramer, Max and Klein, Jacques and Traon, Yves Le},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915001482},
  keywords={Systematic review, Model-Driven Engineering, MDE, MDS, Model-Driven Security, Software security engineering},
  abstract={Context: Model-Driven Security (MDS) is as a specialised Model-Driven Engineering research area for supporting the development of secure systems. Over a decade of research on MDS has resulted in a large number of publications. Objective: To provide a detailed analysis of the state of the art in MDS, a systematic literature review (SLR ) is essential. Method: We conducted an extensive SLR on MDS. Derived from our research questions, we designed a rigorous, extensive search and selection process to identify a set of primary MDS studies that is as complete as possible. Our three-pronged search process consists of automatic searching, manual searching, and snowballing. After discovering and considering more than thousand relevant papers, we identified, strictly selected, and reviewed 108 MDS publications. Results: The results of our SLR show the overall status of the key artefacts of MDS, and the identified primary MDS studies. For example, regarding security modelling artefact, we found that developing domain-specific languages plays a key role in many MDS approaches. The current limitations in each MDS artefact are pointed out and corresponding potential research directions are suggested. Moreover, we categorise the identified primary MDS studies into 5 significant MDS studies, and other emerging or less common MDS studies. Finally, some trend analyses of MDS research are given. Conclusion: Our results suggest the need for addressing multiple security concerns more systematically and simultaneously, for tool chains supporting the MDS development cycle, and for more empirical studies on the application of MDS methodologies. To the best of our knowledge, this SLR is the first in the field of Software Engineering that combines a snowballing strategy with database searching. This combination has delivered an extensive literature study on MDS.}
}

@article{rayyan-727967423,
  title={Problems, causes and solutions when adopting continuous delivery—A systematic literature review},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={82},
  pages={55-79},
  author={Laukkanen, Eero and Itkonen, Juha and Lassenius, Casper},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916302324},
  keywords={Systematic literature review, Continuous integration, Continuous deployment, Continuous delivery},
  abstract={Context: Continuous delivery is a software development discipline in which software is always kept releasable. The literature contains instructions on how to adopt continuous delivery, but the adoption has been challenging in practice. Objective: In this study, a systematic literature review is conducted to survey the faced problems when adopting continuous delivery. In addition, we identify causes for and solutions to the problems. Method: By searching five major bibliographic databases, we identified 293 articles related to continuous delivery. We selected 30 of them for further analysis based on them containing empirical evidence of adoption of continuous delivery, and focus on practice instead of only tooling. We analyzed the selected articles qualitatively and extracted problems, causes and solutions. The problems and solutions were thematically synthesized into seven themes: build design, system design, integration, testing, release, human and organizational and resource. Results: We identified a total of 40 problems, 28 causal relationships and 29 solutions related to adoption of continuous delivery. Testing and integration problems were reported most often, while the most critical reported problems were related to testing and system design. Causally, system design and testing were most connected to other themes. Solutions in the system design, resource and human and organizational themes had the most significant impact on the other themes. The system design and build design themes had the least reported solutions. Conclusions: When adopting continuous delivery, problems related to system design are common, critical and little studied. The found problems, causes and solutions can be used to solve problems when adopting continuous delivery in practice.}
}

@article{rayyan-727967424,
  title={Systematic literature review of usability capability/maturity models},
  year={2018},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={55},
  pages={95-105},
  author={Lacerda, Thaísa C and von Wangenheim, Christiane Gresse},
  url={https://www.sciencedirect.com/science/article/pii/S0920548916302355},
  keywords={Literature review, Usability, Capability/maturity model, Human-centered-design, Process assessment},
  abstract={A world becoming more digitally transformed and connected poses significant challenges for IT organizations, requiring increased attention to the usability of their software products and, consequently, to the systematic establishment of usability engineering (UE) processes. Typically, the establishment of software processes is guided by software process capability/maturity models (SPCMMs), such as CMMI or ISO/IEC 15504. However, it seems that these commonly adopted models do not explicitly cover usability engineering (UE) processes. Thus, a question that arises is, if there exist process capability/maturity models focusing explicitly on usability engineering? If yes, to which degree do they assist in the assessment process? To answer this, we conducted a systematic literature review on usability capability/maturity models (UCMMs). A total of 15 UCMMs were identified and analyzed, synthesizing information on their measurement framework and process reference model, usage support and how they have been developed/validated. We observed that most of the models are based on consolidated SPCMMs, such as CMMI or ISO/IEC 15504. Only few UCMMs customized for specific contexts were found. Although all UCMMs propose or reference a measurement framework, only 5 UCMMs define a proper process reference model. Most of the models also do not offer support for their usage, which may hinder their larger scale adoption in practice. Furthermore, we noted a lack of information on how most of the models have been developed and validated, which leaves their validity questionable. These results indicate the need for further research on UCMMs taking into consideration the increased importance of usability in software product quality.}
}

@article{rayyan-727967426,
  title={Systematic literature review of machine learning based software development effort estimation models},
  year={2012},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={54},
  number={1},
  pages={41-59},
  author={Wen, Jianfeng and Li, Shixian and Lin, Zhiyong and Hu, Yong and Huang, Changqin},
  url={https://www.sciencedirect.com/science/article/pii/S0950584911001832},
  keywords={Systematic literature review, Machine learning, Software effort estimation, Software},
  abstract={Context Software development effort estimation (SDEE) is the process of predicting the effort required to develop a software system. In order to improve estimation accuracy, many researchers have proposed machine learning (ML) based SDEE models (ML models) since 1990s. However, there has been no attempt to analyze the empirical evidence on ML models in a systematic way. Objective This research aims to systematically analyze ML models from four aspects: type of ML technique, estimation accuracy, model comparison, and estimation context. Method We performed a systematic literature review of empirical studies on ML model published in the last two decades (1991–2010). Results We have identified 84 primary studies relevant to the objective of this research. After investigating these studies, we found that eight types of ML techniques have been employed in SDEE models. Overall speaking, the estimation accuracy of these ML models is close to the acceptable level and is better than that of non-ML models. Furthermore, different ML models have different strengths and weaknesses and thus favor different estimation contexts. Conclusion ML models are promising in the field of SDEE. However, the application of ML models in industry is still limited, so that more effort and incentives are needed to facilitate the application of ML models. To this end, based on the findings of this review, we provide recommendations for researchers as well as guidelines for practitioners.}
}

@article{rayyan-727967427,
  title={A systematic review of comparative evidence of aspect-oriented programming},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={9},
  pages={871-887},
  author={Ali, Muhammad Sarmad and Ali Babar, Muhammad and Chen, Lianping and Stol, Klaas-Jan},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910000819},
  keywords={Evidence-based software engineering, Systematic literature review, Aspect-oriented programming},
  abstract={Context Aspect-oriented programming (AOP) promises to improve many facets of software quality by providing better modularization and separation of concerns, which may have system wide affect. There have been numerous claims in favor and against AOP compared with traditional programming languages such as Objective Oriented and Structured Programming Languages. However, there has been no attempt to systematically review and report the available evidence in the literature to support the claims made in favor or against AOP compared with non-AOP approaches. Objective This research aimed to systematically identify, analyze, and report the evidence published in the literature to support the claims made in favor or against AOP compared with non-AOP approaches. Method We performed a systematic literature review of empirical studies of AOP based development, published in major software engineering journals and conference proceedings. Results Our search strategy identified 3307 papers, of which 22 were identified as reporting empirical studies comparing AOP with non-AOP approaches. Based on the analysis of the data extracted from those 22 papers, our findings show that for performance, code size, modularity, and evolution related characteristics, a majority of the studies reported positive effects, a few studies reported insignificant effects, and no study reported negative effects; however, for cognition and language mechanism, negative effects were reported. Conclusion AOP is likely to have positive effect on performance, code size, modularity, and evolution. However its effect on cognition and language mechanism is less likely to be positive. Care should be taken using AOP outside the context in which it has been validated.}
}

@article{rayyan-727967428,
  title={The use of software product lines for business process management: A systematic literature review},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={8},
  pages={1355-1373},
  author={dos Santos Rocha, Roberto and Fantinato, Marcelo},
  url={https://www.sciencedirect.com/science/article/pii/S0950584913000402},
  keywords={Software product line, BPM, Business process management, PL, Software},
  abstract={Context Business Process Management (BPM) is a potential domain in which Software Product Line (PL) can be successfully applied. Including the support of Service-oriented Architecture (SOA), BPM and PL may help companies achieve strategic alignment between business and IT. Objective Presenting the results of a study undertaken to seek and assess PL approaches for BPM through a Systematic Literature Review (SLR). Moreover, identifying the existence of dynamic PL approaches for BPM. Method A SLR was conducted with four research questions formulated to evaluate PL approaches for BPM. Results 63 papers were selected as primary studies according to the criteria established. From these primary studies, only 15 papers address the specific dynamic aspects in the context evaluated. Moreover, it was found that PLs only partially address the BPM lifecycle since the last business process phase is not a current concern on the found approaches. Conclusions The found PL approaches for BPM only cover partially the BPM lifecycle, not taking into account the last phase which restarts the lifecycle. Moreover, no wide dynamic PL proposal was found for BPM, but only the treatment of specific dynamic aspects. The results indicate that PL approaches for BPM are still at an early stage and gaining maturity.}
}

@article{rayyan-727967430,
  title={Using CMMI together with agile software development: A systematic review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={58},
  pages={20-43},
  author={Selleri Silva, Fernando and Soares, Felipe Santana Furtado and Peres, Angela Lima and de Azevedo, Ivanildo Monteiro and Vasconcelos, Ana Paula L F and Kamei, Fernando Kenji and de Lemos Meira, Silvio Romero},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914002110},
  keywords={Systematic review, Software process improvement, CMMI, Benefits, Agile methodology, Limitations, Software},
  abstract={Background The search for adherence to maturity levels by using lightweight processes that require low levels of effort is regarded as a challenge for software development organizations. Objective This study seeks to evaluate, synthesize, and present results on the use of the Capability Maturity Model Integration (CMMI) in combination with agile software development, and thereafter to give an overview of the topics researched, which includes a discussion of their benefits and limitations, the strength of the findings, and the implications for research and practice. Methods The method applied was a Systematic Literature Review on studies published up to (and including) 2011. Results The search strategy identified 3193 results, of which 81 included studies on the use of CMMI together with agile methodologies. The benefits found were grouped into two main categories: those related to the organization in general and those related to the development process, and were organized into subcategories, according to the area to which they refer. The limitations were also grouped into these categories. Using the criteria defined, the strength of the evidence found was considered low. The implications of the results for research and practice are discussed. Conclusion Agile methodologies can be used by companies to reduce efforts in getting to levels 2 and 3 of CMMI, there even being reports of applying agile practices that led to achieving level 5. However, agile methodologies alone, according to the studies, were not sufficient to obtain a rating at a given level, it being necessary to resort to additional practices to do so.}
}

@article{rayyan-727967432,
  title={A systematic literature review on enterprise architecture implementation methodologies},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={62},
  pages={1-20},
  author={Rouhani, Babak Darvish and Mahrin, Mohd Naz'ri and Nikpay, Fatemeh and Ahmad, Rodina Binti and Nikfard, Pourya},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915000282},
  keywords={SLR, Methodology, EAIM, Enterprise Architecture, Enterprise Architecture Implementation Methodology},
  abstract={Context Enterprise Architecture (EA) is a strategy to align business and Information Technology (IT) within an enterprise. EA is managed, developed, and maintained throughout the EA Implementation Methodology (EAIM). Objective The aims of this study are to identify the existing effective practices that are used by existing EAIMs, identify the factors that affect the effectiveness of EAIM, identify the current tools that are used by existing EAIMs, and identify the open problems and areas related to EAIM for improvement. Method A Systematic Literature Review (SLR) was carried out. 669 papers were retrieved by a manual search in 6 databases and 46 primary studies were finally included. Result From these studies 33% were journal articles, 41% were conference papers while 26% were contributions from the studies consisted of book chapters. Consequently, 28 practices, 19 factors, and 15 tools were identified and analysed. Conclusion Several rigorous researches have been done in order to provide effective EAIM, however there are still problems in components of EAIM, including: there is lack of tool support for whole part of EA implementation, there are deficiency in addressing the EAIM's practices especially in modeling, management, and maintenance, there is lack of consideration on non-functional requirement in existing EAIM, there is no appropriate consideration on requirement analysis in most existing EAIM. This review provides researchers with some guidelines for future research on this topic. It also provides broad information on EAIM, which could be useful for practitioners.}
}

@article{rayyan-727967434,
  title={A systematic literature review on software measurement programs},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={73},
  pages={101-121},
  author={Tahir, Touseef and Rasool, Ghulam and Gencel, Cigdem},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916300131},
  keywords={Software measurement, Systematic Literature Review, GQM, Software measurement program, Software metrics, Software},
  abstract={Context Software measurement programs (MPs) are an important means for understanding, evaluating, managing, and improving software processes, products and resources. However, implementing successful MPs still remains a challenge. Objectives To make a comprehensive review of the studies on MPs for bringing into light the existing measurement planning models and tools used for implementing MPs,the accumulated knowledge on the success/failure factors of MPs and mitigation strategies to address their challenges. Methods A Systematic Literature Review (SLR) was conducted. In total, 65primary studies were reviewed and analyzed. Results We identified 35 measurement planning models and 11 associated tools, most of which either proposed extensions or improvements for goal based approaches. The identified success factors include (a) organizational adoption of MP, (b) integration of MP with SDLC, (c) synchronization of MP with SPI and (d) design of MP. The mostly mentioned mitigation strategies for addressing challenges are effective change management and measurement stakeholder management, automated tool support and incorporation of engineering mechanisms for designing sustainable, effective, scalable and extendible MPs, and measurement expertise and standards development. Conclusion Most of the success factors and mitigation strategies have interdependencies. Therefore, for successful MP implementation, software organizations should consider these factors in combination and make a feasibility study at the very beginning.}
}

@article{rayyan-727967436,
  title={Design science research contribution to business intelligence in the cloud — A systematic literature review},
  year={2016},
  journal={Future Generation Computer Systems},
  issn={0167-739X},
  volume={63},
  pages={108-122},
  author={Sangupamba Mwilu, Odette and Comyn-Wattiau, Isabelle and Prat, Nicolas},
  url={https://www.sciencedirect.com/science/article/pii/S0167739X15003623},
  keywords={Systematic literature review, Cloud computing, Design science research, Business intelligence, Analytics},
  abstract={Business intelligence (BI) helps managers make informed decisions. In the age of big data, BI technology provides essential support for decision making. Cloud computing also attracts many organizations because of its potential: ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, servers, storage, applications, and services). This paper focuses on the deployment of BI in the cloud, from the vantage point of design science research (DSR). We produce a state of the art of research pertaining to BI in the cloud, following the methodology of systematic literature review. This literature review especially exhibits the different artifacts proposed by design science researchers regarding BI in the cloud. To structure the literature review, we propose a framework composed of two dimensions: artifact type and BI step. In particular, we propose a typology of artifact types, refining the coarse-grained typology commonly used in DSR. We use the two-dimensional framework both to map the current state of DSR regarding BI in the cloud, and to elicit future research avenues in terms of design science artifacts for BI in the cloud. The contribution is threefold: the literature review may help DSR researchers get an overview of this active research domain; the two-dimensional framework facilitates the understanding of different research streams; finally, the proposed future topics may guide researchers in identifying promising research avenues.}
}

@article{rayyan-727967440,
  title={Dealing with noise problem in machine learning data-sets: A systematic review},
  year={2019},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={161},
  pages={466-474},
  author={Gupta, Shivani and Gupta, Atul},
  url={https://www.sciencedirect.com/science/article/pii/S1877050919318575},
  keywords={Classification, Attribute noise, Class noise, Noise, Noise handling techniques, Noise identification techniques, Types of noise},
  abstract={The occurrences of noisy data in data set can significantly impact prediction of any meaningful information. Many empirical studies have shown that noise in data set dramatically led to decreased classification accuracy and poor prediction results. Therefore, the problem of identifying and handling noise in prediction application has drawn considerable attention over past many years. In our study, we performed a systematic literature review of noise identification and handling studies published in various conferences and journals between January 1993 to July 2018. We have identified 79 primary studies are of noise identification and noise handling techniques. After investigating these studies, we found that among the noise identification schemes, the accuracy of identification of noisy instances by using ensemble-based techniques are better than other techniques. But regarding efficiency, usually single based techniques method is better; it is more suitable for noisy data sets. Among noise handling techniques, polishing techniques generally improve classification accuracy than filtering and robust techniques, but it introduced some errors in the data sets.}
}

@article{rayyan-727967442,
  title={Social network data to alleviate cold-start in recommender system: A systematic review},
  year={2018},
  journal={Information Processing & Management},
  issn={0306-4573},
  volume={54},
  number={4},
  pages={529-544},
  author={Gonzalez Camacho, Lesly Alejandra and Alves-Souza, Solange Nice},
  url={https://www.sciencedirect.com/science/article/pii/S0306457317306544},
  keywords={Systematic literature review, Cold start, Collaborative filtering, Recommender system, Social network, Social Support, Cold Temperature},
  abstract={Recommender Systems are currently highly relevant for helping users deal with the information overload they suffer from the large volume of data on the web, and automatically suggest the most appropriate items that meet users needs. However, in cases in which a user is new to Recommender System, the system cannot recommend items that are relevant to her/him because of lack of previous information about the user and/or the user-item rating history that helps to determine the users preferences. This problem is known as cold-start, which remains open because it does not have a final solution. Social networks have been employed as a good source of information to determine users preferences to mitigate the cold-start problem. This paper presents the results of a Systematic Literature Review on Collaborative Filtering-based Recommender System that uses social network data to mitigate the cold-start problem. This Systematic Literature Review compiled the papers published between 2011–2017, to select the most recent studies in the area. Each selected paper was evaluated and classified according to the depth which social networks used to mitigate the cold-start problem. The final results show that there are several publications that use the information of the social networks within the Recommender System; however, few research papers currently use this data to mitigate the cold-start problem.}
}

@article{rayyan-727967443,
  title={The impact of global dispersion on coordination, team performance and software quality – A systematic literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={57},
  pages={277-294},
  author={Nguyen-Duc, Anh and Cruzes, Daniela S and Conradi, Reidar},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001414},
  keywords={Systematic literature review, Software quality, Performance, Global software development, Meta analysis, Global dispersion, Software},
  abstract={Context Global software development (GSD) contains different context setting dimensions, which are essential for effective teamwork and success of projects. Although considerable research effort has been made in this area, as yet, no agreement has been reached about the impact of these dispersion dimensions on team coordination and project outcomes. Objective This paper summarizes empirical evidence on the impact of global dispersion dimensions on coordination, team performance and project outcomes. Method We performed a systematic literature review of 46 publications from 25 journals and 19 conference and workshop proceedings, which were published between 2001 and 2013. Thematic analysis was used to identify global dimensions and their measures. Vote counting was used to decide on the impact trends of dispersion dimensions on team performance and software quality. Results Global dispersion dimensions are consistently conceptualized, but quantified in many different ways. Different dispersion dimensions are associated with a distinct set of coordination challenges. Overall, geographical dispersion tends to have a negative impact on team performance and software quality. Temporal dispersion tends to have a negative impact on software quality, but its impact on team performance is inconsistent and can be explained by type of performance. Conclusion For researchers, we reveal several opportunities for future research, such as coordination challenges in inter-organizational software projects, impact of processes and practices mismatches on project outcomes, evolution of coordination needs and mechanism over time and impact of dispersion dimensions on open source project outcomes. For practitioners, they should consider the tradeoff between cost and benefits while dispersing tasks, alignment impact of dispersion dimensions with individual and organizational objectives, coordination mechanisms as situational approaches and collocation of development activities of high quality demand components in GSD projects.}
}

@article{rayyan-727967444,
  title={Systematic review for network survivability analysis in MANETS},
  year={2015},
  journal={Procedia - Social and Behavioral Sciences},
  issn={1877-0428},
  volume={195},
  pages={1872-1881},
  author={Azni, A H and Ahmad, Rabiah and Noh, Zul Azri Mohamad and Hazwani, Farida and Hayaati, Najwa},
  url={https://www.sciencedirect.com/science/article/pii/S1877042815039038},
  keywords={Systematic Literature Review, MANETS, Network Survivability, Survival Analysis},
  abstract={Network survivability analysis in MANETs was hardly an issue in the early years of wireless technology because there were no critical network system that depended on wireless technology yet. Today, network survivability analysis is an essential aspect of reliable communication especially in MANETs. Although various methods have been proposed to measure network survivability analysis in MANETs, no related review has been published as to date for this topic. Thus, a comprehensive review of this body of work would be beneficial to researchers to have an overview of the current state of research trend in this area. This paper provides a systematic literature review (SLR) of the state of the art approach in network survivability analysis in MANETs. We used studies from a number of relevant article sources, and our results showed the existence of twenty six (26) articles. From this SLR we found that the existing of analysis method is focusing on individual node in which the node is treated as independent event. Furthermore, the analysis also reveals the less popular methods in analyzing network survivability are with statistical methods such as regression analysis and survival analysis. The implication of this study is to give a clear direction to future researchers in this area for a better and accurate analysis in measuring network survivability in MANETs.}
}

@article{rayyan-727967445,
  title={A systematic review of knowledge sharing challenges and practices in global software development},
  year={2016},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={36},
  number={6},
  pages={995-1019},
  author={Zahedi, Mansooreh and Shahin, Mojtaba and Ali Babar, Muhammad},
  url={https://www.sciencedirect.com/science/article/pii/S026840121630384X},
  keywords={Empirical software engineering, Global software development (GSD), Systematic literature review (SLR), Knowledge management (KM), Knowledge sharing, Software},
  abstract={Context Global Software Development (GSD) presents significant challenges to share and understand knowledge required for developing software. Organizations are expected to implement appropriate practices to address knowledge-sharing challenges in GSD. With the growing literature on GSD and its widespread adoption, it is important to build a body of knowledge to support future research and effective knowledge sharing practices. Objective We aimed at systematically identifying and synthesizing knowledge sharing challenges and practices. We also intended to classify the recurrent challenges and most frequently reported practices in different contextual settings. Method We used Systematic Literature Review (SLR) for reviewing 61 primary studies that were selected after searching the GSD literature published over the last 14 years (2000–September 2014). We applied thematic analysis method for analysing the data extracted from the reviewed primary studies. Results Our findings revealed that knowledge sharing challenges and practices in GSD could be classified in 6 main themes: management, team structure, work processes/practices, team cognition, social attributes and technology. In regard to contextual settings, we found empirical studies were mainly conducted in an offshore outsourcing collaboration model distributed between two sites. Most of the studied organizations were large enterprises. Many of the studies did not report any information for several contextual attributes that made it difficult to analyse the reported challenges and practices with respect to their respective contexts. Conclusion We can conclude: (a) there is a higher tendency among researchers to report practices than challenges of knowledge sharing in GSD. (b) Given our analysis, most of the reported knowledge sharing challenges and practices fall under the theme of “work practices”. (c) The technology related knowledge-sharing challenges are the least reported; we discussed the available technologies for supporting knowledge sharing needs in GSD. (d) The organizational contextual information is missing from a large number of studies; hence, it was not possible to investigate the potential relations between knowledge sharing challenges/practices and the contextual attributes of GSD teams. We assert the need of exploring knowledge sharing in the context of small/medium sized organizations to avoid the risk of findings being biased by specific empirical setting (e.g., large enterprises distributed between US and India).}
}

@article{rayyan-727967446,
  title={Software requirements selection and prioritization using SBSE approaches: A systematic review and mapping of the literature},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={103},
  pages={267-280},
  author={Pitangueira, Antônio Mauricio and Maciel, Rita Suzana P and Barros, Márcio},
  url={https://www.sciencedirect.com/science/article/pii/S0164121214002118},
  keywords={Systematic review, Requirements prioritization, Requirements selection, Software},
  abstract={The selection and prioritization of software requirements represents an area of interest in Search-Based Software Engineering (SBSE) and its main focus is finding and selecting a set of requirements that may be part of a software release. This paper presents a systematic review and mapping that investigated, analyzed, categorized and classified the SBSE approaches that have been proposed to address software requirement selection and prioritization problems, reporting quantitative and qualitative assessment. Initially 39 papers returned from our search strategy in this area and they were analyzed by 18 previously established quality criteria. The results of this systematic review show which aspects of the requirements selection and prioritization problems were addressed by researchers, which approaches and search techniques are currently adopted to address these problems, as well as the strengths and weaknesses in this research area highlighted from the quality criteria.}
}

@article{rayyan-727967447,
  title={A systematic literature review: Opinion mining studies from mobile app store user reviews},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={125},
  pages={207-219},
  author={Genc-Nayebi, Necmiye and Abran, Alain},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216302291},
  keywords={Systematic literature review, Requirements engineering, App stores opinion mining, Mobile application},
  abstract={As mobile devices have overtaken fixed Internet access, mobile applications and distribution platforms have gained in importance. App stores enable users to search for, purchase and install mobile applications and then give feedback in the form of reviews and ratings. A review might contain information about the user's experience with the app and opinion of it, feature requests and bug reports. Hence, reviews are valuable not only to users who would like to find out what others think about an app, but also to developers and software companies interested in customer feedback. The rapid increase in the number of applications and total app store revenue has accelerated app store data mining and opinion aggregation studies. While development companies and app store regulators have pursued upfront opinion mining studies for business intelligence and marketing purposes, research interest into app ecosystem and user reviews is relatively new. In addition to studies examining online product reviews, there are now some academic studies focused on mobile app stores and user reviews. The objectives of this systematic literature review are to identify proposed solutions for mining online opinions in app store user reviews, challenges and unsolved problems in the domain, any new contributions to software requirements evolution and future research direction.}
}

@article{rayyan-727967448,
  title={Empirical studies of agile software development: A systematic review},
  year={2008},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={50},
  number={9},
  pages={833-859},
  author={Dybå, Tore and Dingsøyr, Torgeir},
  url={https://www.sciencedirect.com/science/article/pii/S0950584908000256},
  keywords={Evidence-based software engineering, Empirical software engineering, Systematic review, Agile software development, Scrum, Research synthesis, XP, Extreme programming, Software},
  abstract={Agile software development represents a major departure from traditional, plan-based approaches to software engineering. A systematic review of empirical studies of agile software development up to and including 2005 was conducted. The search strategy identified 1996 studies, of which 36 were identified as empirical studies. The studies were grouped into four themes: introduction and adoption, human and social factors, perceptions on agile methods, and comparative studies. The review investigates what is currently known about the benefits and limitations of, and the strength of evidence for, agile methods. Implications for research and practice are presented. The main implication for research is a need for more and better empirical studies of agile software development within a common research agenda. For the industrial readership, the review provides a map of findings, according to topic, that can be compared for relevance to their own settings and situations.}
}

@article{rayyan-727967449,
  title={A systematic literature review of use case specifications research},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={67},
  pages={128-158},
  author={Tiwari, Saurabh and Gupta, Atul},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915001081},
  keywords={Guidelines, Systematic reviews, Quality, Evolution, Use case specifications, Use case templates},
  abstract={Context Use cases have been widely accepted and acknowledged as a specification tool for specifying the functional requirements of a software system. Many variations of use cases exist which tries to address the issues such as their completeness, degree of formalism, automated information extraction, usability, and pertinence. Objective The aim of this systematic review is to examine the existing literature for the evolution of the use cases, their applications, quality assessments, open issues, and the future directions. Method We perform keyword-based extensive search to identify the relevant studies related to use case specifications research reported in journal articles, conference papers, workshop papers, bulletins and book chapters. Results The specified search process resulted 119 papers, which were published between 1992 and February 2014. This included, 54 journal articles, 42 conference papers, 2 ACM/IEEE bulletins, 12 book chapters, 6 workshop papers and 3 white papers. We found that as many as twenty use case templates have been proposed and applied for various software specification problems ranging from informal descriptions with paragraph-style text to more formal keyword-oriented templates. Conclusion Use cases have been evolved from initial plain, semi-formal textual descriptions to a more formal template structure facilitating automated information extraction in various software development life cycle activities such as requirement documentation, requirement analysis, requirement validation, domain modeling, test case generation, planning and estimation, and maintenance. The issues that remain to be sorted out are (1) the right degree of formalism, (2) the efficient change management, (3) the industrial relevance, and (4) assessment of the quality of the specification. Additionally, its synergy with other software models that are used in the development processes is an issue that needs to be addressed.}
}

@article{rayyan-727967451,
  title={Mental health ubiquitous monitoring supported by social situation awareness: A systematic review},
  year={2020},
  journal={Journal of Biomedical Informatics},
  issn={1532-0464},
  volume={107},
  pages={103454},
  author={Moura, Ivan and Teles, Ariel and Silva, Francisco and Viana, Davi and Coutinho, Luciano and Barros, Flávio and Endler, Markus},
  url={https://www.sciencedirect.com/science/article/pii/S1532046420300824},
  keywords={Mental health, Mental states, Sociability, Social behavior, Social situation awareness, Ubiquitous computing, Social Support, Mental Health},
  abstract={Traditionally, the process of monitoring and evaluating social behavior related to mental health has based on self-reported information, which is limited by the subjective character of responses and various cognitive biases. Today, however, there is a growing amount of studies that have provided methods to objectively monitor social behavior through ubiquitous devices and have used this information to support mental health services. In this paper, we present a Systematic Literature Review (SLR) to identify, analyze and characterize the state of the art about the use of ubiquitous devices to monitor users' social behavior focused on mental health. For this purpose, we performed an exhaustive literature search on the six main digital libraries. A screening process was conducted on 160 peer-reviewed publications by applying suitable selection criteria to define the appropriate studies to the scope of this SLR. Next, 20 selected studies were forwarded to the data extraction phase. From an analysis of the selected studies, we recognized the types of social situations identified, the process of transforming contextual data into social situations, the use of social situation awareness to support mental health monitoring, and the methods used to evaluate proposed solutions. Additionally, we identified the main trends presented by this research area, as well as open questions and perspectives for future research. Results of this SLR showed that social situation-aware ubiquitous systems represent promising assistance tools for patients and mental health professionals. However, studies still present limitations in methodological rigor and restrictions in experiments, and solutions proposed by them have limitations to be overcome.}
}

@article{rayyan-727967452,
  title={Towards pragmatic interoperability to support collaboration: A systematic review and mapping of the literature},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={72},
  pages={137-150},
  author={Neiva, Frâncila Weidt and David, José Maria N and Braga, Regina and Campos, Fernanda},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916000021},
  keywords={Collaboration, Collaborative systems, Groupware, Interoperability, Pragmatic interoperability},
  abstract={Context: Many researchers have argued that providing interoperability support only considering the format and meaning (i.e. syntax and semantic) of data exchange is not enough to achieve complete, effective and meaningful collaboration. Pragmatic interoperability has been highlighted as a key requirement to enhance collaboration. However, fulfilling this requirement is not a trivial task and there is a lack of works discussing solutions to achieve this level of interoperability. Objectives: The aim of this study is to present a systematic review and mapping of the literature in order to identify, analyse and classify the published solutions to achieve pragmatic interoperability. Method: To conduct a systematic review and mapping in accordance with the guidelines proposed in the evidence-based software engineering literature. Results: Our study identified 13 papers reporting pragmatic interoperability computational solutions. The first paper in our set of selected papers was published in 2004; the main strategies used to address pragmatic interoperability issues were service discovery, composition and/or selection and ontologies. The application domain of the identified solutions was mainly e-business. In addition, most of the identified solutions were software architectures. Conclusion: Mature proposals addressing pragmatic interoperability are still rare in the literature. Although many works have discussed the importance of pragmatic interoperability, it is necessary that researchers report solutions that implement and evaluate pragmatic interoperability in order to make progress in this area.}
}

@article{rayyan-727967453,
  title={Leveraging Software Product Lines Engineering in the development of external DSLs: A systematic literature review},
  year={2016},
  journal={Computer Languages, Systems & Structures},
  issn={1477-8424},
  volume={46},
  pages={206-235},
  author={Méndez-Acuña, David and Galindo, José A and Degueule, Thomas and Combemale, Benoît and Baudry, Benoît},
  url={https://www.sciencedirect.com/science/article/pii/S1477842416300768},
  keywords={Variability management, Domain-specific languages, Software language engineering, Software Product Lines Engineering, Software},
  abstract={The use of domain-specific languages (DSLs) has become a successful technique in the development of complex systems. Consequently, nowadays we can find a large variety of DSLs for diverse purposes. However, not all these DSLs are completely different; many of them share certain commonalities coming from similar modeling patterns – such as state machines or petri nets – used for several purposes. In this scenario, the challenge for language designers is to take advantage of the commonalities existing among similar DSLs by reusing, as much as possible, formerly defined language constructs. The objective is to leverage previous engineering efforts to minimize implementation from scratch. To this end, recent research in software language engineering proposes the use of product line engineering, thus introducing the notion of language product lines. Nowadays, there are several approaches that result useful in the construction of language product lines. In this article, we report on an effort for organizing the literature on language product line engineering. More precisely, we propose a definition for the life-cycle of language product lines, and we use it to analyze the capabilities of current approaches. In addition, we provide a mapping between each approach and the technological space it supports.}
}

@article{rayyan-727967456,
  title={Equality in cumulative voting: A systematic review with an improvement proposal},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={2},
  pages={267-287},
  author={Riņķevičs, K and Torkar, R},
  url={https://www.sciencedirect.com/science/article/pii/S0950584912001589},
  keywords={Requirements engineering, Prioritization, Compositional data, Cumulative voting, Log-ratio},
  abstract={Context Prioritization is an essential part of requirements engineering, software release planning and many other software engineering disciplines. Cumulative Voting (CV) is known as a relatively simple method for prioritizing requirements on a ratio scale. Historically, CV has been applied in decision-making in government elections, corporate governance, and forestry. However, CV prioritization results are of a special type of data—compositional data. Objectives The purpose of this study is to aid decision-making by collecting knowledge on the empirical use of CV and develop a method for detecting prioritization items with equal priority. Methods We present a systematic literature review of CV and CV analysis methods. The review is based on searching electronic databases and snowball sampling of the found primary studies. Relevant studies are selected based on titles, abstracts, and full text inspection. Additionally, we propose Equality of Cumulative Votes (ECVs)—a CV result analysis method that identifies prioritization items with equal priority. Results CV has been used in not only requirements prioritization and release planning but also in e.g. software process improvement, change impact analysis and model driven software development. The review presents a collection of state of the practice studies and CV result analysis methods. In the end, ECV was applied to 27 prioritization cases from 14 studies and identified nine groups of equal items in three studies. Conclusions We believe that the analysis of the collected studies and the CV result analysis methods can help in the adoption of CV prioritization method. The evaluation of ECV indicates that it is able to detect prioritization items with equal priority and thus provide the practitioner with a more fine-grained analysis.}
}

@article{rayyan-727967457,
  title={Technology acceptance model in m-learning context: A systematic review},
  year={2018},
  journal={Computers & Education},
  issn={0360-1315},
  volume={125},
  pages={389-412},
  author={Al-Emran, Mostafa and Mezhuyev, Vitaliy and Kamaludin, Adzhar},
  url={https://www.sciencedirect.com/science/article/pii/S0360131518301519},
  keywords={Systematic literature review, Technology acceptance model, Mobile learning, Learning},
  abstract={Various review studies were conducted to provide valuable insights into the current research trend of the Technology Acceptance Model (TAM). Nevertheless, this issue still needs to be investigated from further directions. It has been noticed that research overlooks the investigation of TAM with regard to Mobile learning (M-learning) studies from the standpoint of different perspectives. The present study systematically reviews and synthesizes the TAM studies related to M-learning aiming to provide a comprehensive analysis of 87 research articles from 2006 to 2018. The main findings include that most of the TAM studies involving M-learning focused on extending the TAM with external variables, followed by the studies that extended the model by factors from other theories/models. In addition, the main research problem that was frequently tackled among all the analyzed studies was to examine the acceptance of M-learning among students. Moreover, questionnaire surveys were the primarily relied research methods for data collection. Additionally, most of the analyzed studies were undertaken in Taiwan, this is followed by Spain, China, and Malaysia, respectively among the other countries. Besides, most of the analyzed studies were frequently conducted in humanities and educational context, followed by IT and computer science context, respectively among the other contexts. Most of the analyzed studies were carried out in the higher educational settings. To that end, the findings of this review study provide an insight into the current trend of TAM research involving M-learning studies and form an essential reference for scholars in the M-learning context.}
}

@article{rayyan-727967458,
  title={Artificial Immune Systems approaches to secure the internet of things: A systematic review of the literature and recommendations for future research},
  year={2020},
  journal={Journal of Network and Computer Applications},
  issn={1084-8045},
  volume={157},
  pages={102537},
  author={Aldhaheri, Sahar and Alghazzawi, Daniyal and Cheng, Li and Barnawi, Ahmed and Alzahrani, Bandar A},
  url={https://www.sciencedirect.com/science/article/pii/S1084804520300114},
  keywords={Artificial intelligence, Internet of things, IoT, Artificial immune networks, Artificial immune system, Clonal selection, Cyber security, Danger theory, Dendritic cell, Negative selection, Network security, Internet, Immune System},
  abstract={As the Internet of Things (IoT) recently attains tremendous popularity, this promising technology leads to a variety of security challenges. The traditional solutions do not fit the new challenges brought by the IoT ecosystem. Although the development's area of Artificial Immune Systems (AIS) provides an opportunity to improve security issues and create a fertile and exciting environment for further research and experiments, there is not any systematic and comprehensive study about analyzing its importance for IoT environment. Therefore, this work aims to identify, evaluate, and perform a comprehensive study of empirical research on the studies of AIS approaches to secure the IoT environment. The relevant and high-quality studies are addressing using three research questions about the main research motivations, existing solutions, and future gaps and directions. The AIS approaches have been divided into three main categories based on IoT layers, and detailed classifications have also been included based on different parameters. To achieve this aim, the authors use a systematic literature review (SLR) as a powerful method to collect and critically analyze the research papers. Also, the authors discuss the selected studies and their main techniques, as well as their benefits and drawbacks in general. This research process strives to build a knowledge base for AIS solutions under the umbrella of IoT security and suggest directions for future research.}
}

@article{rayyan-727967459,
  title={A systematic review on the code smell effect},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={144},
  pages={450-477},
  author={Santos, José Amancio M and Rocha-Junior, João B and Prates, Luciana Carla Lins and do Nascimento, Rogeres Santos and Freitas, Mydiã Falcão and de Mendonça, Manoel Gomes},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301444},
  keywords={Systematic review, Code smell, Thematic synthesis, Smell},
  abstract={Context: Code smell is a term commonly used to describe potential problems in the design of software. The concept is well accepted by the software engineering community. However, some studies have presented divergent findings about the usefulness of the smell concept as a tool to support software development tasks. The reasons of these divergences have not been considered because the studies are presented independently. Objective: To synthesize current knowledge related to the usefulness of the smell concept. We focused on empirical studies investigating how smells impact the software development, the code smell effect. Method: A systematic review about the smell effect is carried out. We grouped the primary studies findings in a thematic map. Result: The smell concept does not support the evaluation of quality design in practice activities of software development. There is no strong evidence correlating smells and some important software development attributes, such as effort in maintenance. Moreover, the studies point out that human agreement on smell detection is low. Conclusion: In order to improve analysis on the subject, the area needs to better outline: (i) factors affecting human evaluation of smells; and (ii) a classification of types of smells, grouping them according to relevant characteristics.}
}

@article{rayyan-727967460,
  title={Cloud computing service composition: A systematic literature review},
  year={2014},
  journal={Expert Systems with Applications},
  issn={0957-4174},
  volume={41},
  number={8},
  pages={3809-3824},
  author={Jula, Amin and Sundararajan, Elankovan and Othman, Zalinda},
  url={https://www.sciencedirect.com/science/article/pii/S0957417413009925},
  keywords={Systematic literature review, QoS, Cloud computing service composition, Importance percentage of quality of service parameters, Quality of service parameter, Research objectives},
  abstract={The increasing tendency of network service users to use cloud computing encourages web service vendors to supply services that have different functional and nonfunctional (quality of service) features and provide them in a service pool. Based on supply and demand rules and because of the exuberant growth of the services that are offered, cloud service brokers face tough competition against each other in providing quality of service enhancements. Such competition leads to a difficult and complicated process to provide simple service selection and composition in supplying composite services in the cloud, which should be considered an NP-hard problem. How to select appropriate services from the service pool, overcome composition restrictions, determine the importance of different quality of service parameters, focus on the dynamic characteristics of the problem, and address rapid changes in the properties of the services and network appear to be among the most important issues that must be investigated and addressed. In this paper, utilizing a systematic literature review, important questions that can be raised about the research performed in addressing the above-mentioned problem have been extracted and put forth. Then, by dividing the research into four main groups based on the problem-solving approaches and identifying the investigated quality of service parameters, intended objectives, and developing environments, beneficial results and statistics are obtained that can contribute to future research.}
}

@article{rayyan-727967461,
  title={A systematic review of evaluation of variability management approaches in software product lines},
  year={2011},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={53},
  number={4},
  pages={344-362},
  author={Chen, Lianping and Ali Babar, Muhammad},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910002223},
  keywords={Systematic literature reviews, Software product line, Empirical studies, Variability management, Software},
  abstract={Context Variability management (VM) is one of the most important activities of software product-line engineering (SPLE), which intends to develop software-intensive systems using platforms and mass customization. VM encompasses the activities of eliciting and representing variability in software artefacts, establishing and managing dependencies among different variabilities, and supporting the exploitation of the variabilities for building and evolving a family of software systems. Software product line (SPL) community has allocated huge amount of effort to develop various approaches to dealing with variability related challenges during the last two decade. Several dozens of VM approaches have been reported. However, there has been no systematic effort to study how the reported VM approaches have been evaluated. Objective The objectives of this research are to review the status of evaluation of reported VM approaches and to synthesize the available evidence about the effects of the reported approaches. Method We carried out a systematic literature review of the VM approaches in SPLE reported from 1990s until December 2007. Results We selected 97 papers according to our inclusion and exclusion criteria. The selected papers appeared in 56 publication venues. We found that only a small number of the reviewed approaches had been evaluated using rigorous scientific methods. A detailed investigation of the reviewed studies employing empirical research methods revealed significant quality deficiencies in various aspects of the used quality assessment criteria. The synthesis of the available evidence showed that all studies, except one, reported only positive effects. Conclusion The findings from this systematic review show that a large majority of the reported VM approaches have not been sufficiently evaluated using scientifically rigorous methods. The available evidence is sparse and the quality of the presented evidence is quite low. The findings highlight the areas in need of improvement, i.e., rigorous evaluation of VM approaches. However, the reported evidence is quite consistent across different studies. That means the proposed approaches may be very beneficial when they are applied properly in appropriate situations. Hence, it can be concluded that further investigations need to pay more attention to the contexts under which different approaches can be more beneficial.}
}

@article{rayyan-727967462,
  title={Requirements modeling languages for software product lines: A systematic literature review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={69},
  pages={16-36},
  author={Sepúlveda, Samuel and Cravero, Ania and Cachero, Cristina},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915001494},
  keywords={Software product lines, Systematic literature review, Requirements engineering, Modeling languages, Software},
  abstract={Context: Software product lines (SPLs) have reached a considerable level of adoption in the software industry, having demonstrated their cost-effectiveness for developing higher quality products with lower costs. For this reason, in the last years the requirements engineering community has devoted much effort to the development of a myriad of requirements modelling languages for SPLs. Objective: In this paper, we review and synthesize the current state of research of requirements modelling languages used in SPLs with respect to their degree of empirical validation, origin and context of use, level of expressiveness, maturity, and industry adoption. Method: We have conducted a systematic literature review with six research questions that cover the main objective. It includes 54 studies, published from 2000 to 2013. Results: The mean level of maturity of the modelling languages is 2.59 over 5, with 46% of them falling within level 2 or below -no implemented abstract syntax reported-. They show a level of expressiveness of 0.7 over 1.0. Some constructs (feature, mandatory, optional, alternative, exclude and require) are present in all the languages, while others (cardinality, attribute, constraint and label) are less common. Only 6% of the languages have been empirically validated, 41% report some kind of industry adoption and 71% of the languages are independent from any development process. Last but not least, 57% of the languages have been proposed by the academia, while 43% have been the result of a joint effort between academia and industry. Conclusions: Research on requirements modeling languages for SPLs has generated a myriad of languages that differ in the set of constructs provided to express SPL requirements. Their general lack of empirical validation and adoption in industry, together with their differences in maturity, draws the picture of a discipline that still needs to evolve.}
}

@article{rayyan-727967463,
  title={Choreography in the embedded systems domain: A systematic literature review},
  year={2017},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={91},
  pages={82-101},
  author={Taušan, Nebojša and Markkula, Jouni and Kuvaja, Pasi and Oivo, Markku},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917304469},
  keywords={Systematic literature review, Service-oriented architecture, Embedded systems, Choreography},
  abstract={Context Software companies that develop their products on a basis of service-oriented architecture can expect various improvements as a result of choreography. Current choreography practices, however, are not yet used extensively in the embedded systems domain even though service-oriented architecture is increasingly used in this domain. Objective The objective of this study is to identify current features of the use of choreography in the embedded systems domain for practitioners and researchers by systematically analysing current developments in the scientific literature, strategies for choreography adaption, choreography specification and execution types, and implicit assumptions about choreography. Method To fulfil this objective, a systematic literature review of scientific publications that focus on the use of choreography in the embedded systems domain was carried out. After a systematic screening of 6823 publications, 48 were selected as primary studies and analysed using thematic synthesis. Results The main results of the study showed that there are differences in how choreography is used in embedded and non-embedded systems domain. In the embedded systems domain, it is used to capture the service interactions of a single organisation, while, for example, in the enterprise systems domain it captures the service interactions among multiple organisations. Additionally, the results indicate that the use of choreography can lead to improvements in system performance and that the languages that are used for choreography modelling in the embedded systems domain are insufficiently expressive to capture the complexities that are typical in this domain. Conclusion The selection of the key information resources and the identified gaps in the existing literature offer researchers a foundation for further investigations and contribute to the advancement of the use of choreography in the embedded systems domain. The study results facilitate the work of practitioners by allowing them to make informed decisions about the applicability of choreography in their organisations.}
}

@article{rayyan-727967464,
  title={Design criteria for visualization of energy consumption: A systematic literature review},
  year={2015},
  journal={Sustainable Cities and Society},
  issn={2210-6707},
  volume={18},
  pages={1-12},
  author={Murugesan, Latha Karthigaa and Hoda, Rashina and Salcic, Zoran},
  url={https://www.sciencedirect.com/science/article/pii/S2210670715000499},
  keywords={Visualization, Energy, Grounded Theory},
  abstract={Visualizing energy consumption is widely considered an important way to motivate end-users to conserve energy. Designing effective visualizations, however, is a non-trivial software design challenge. In particular, there are no clear criteria for designing visualizations of energy consumption for end-users. This paper presents systematic literature review findings from a total of 22 primary studies selected after applying quality and relevance filters. The results were synthesized using Grounded Theory's open coding and constant comparison procedures and led to the emergence of design criteria for visualization as the central theme across all primary studies. The key categories comprising this central theme include: (a) functional criteria, which include information displayed in the visualization, modes of visualization, and visualization techniques, and (b) non-functional criteria, which include hardware and software considerations such as integrality, extensibility and portability. Together, these criteria provide clear guidelines based on research evidence for software engineers and researchers designing visualizations of energy consumption for end-users.}
}

@article{rayyan-727967465,
  title={Systematic review on machine learning (ML) methods for manufacturing processes – Identifying artificial intelligence (AI) methods for field application},
  year={2020},
  journal={Procedia CIRP},
  issn={2212-8271},
  volume={93},
  pages={413-418},
  author={Fahle, Simon and Prinz, Christopher and Kuhlenkötter, Bernd},
  url={https://www.sciencedirect.com/science/article/pii/S2212827120307435},
  keywords={machine learning, Artificial Intelligence, factory operation, production systems, Intelligence},
  abstract={Artificial Intelligence (AI) and especially machine learning (ML) become increasingly more frequently applicable in factory operations. This paper presents a systematic review of today's applications of ML techniques in the factory environment. The utilization of ML methods related to manufacturing process planning and control, predictive maintenance, quality control, in situ process control and optimization, logistics, robotics, assistance and learning systems for shopfloor employees are being analyzed. Moreover, an overview of ML training concepts in learning factories is given. Furthermore, these concepts will be analyzed regarding the implemented ML method. Finally, research gaps are identified.}
}

@article{rayyan-727967466,
  title={Software test process improvement approaches: A systematic literature review and an industrial case study},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={111},
  pages={1-33},
  author={Afzal, Wasif and Alone, Snehal and Glocksien, Kerstin and Torkar, Richard},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215001910},
  keywords={Systematic literature review, Case study, Software test process improvement, Software},
  abstract={Software test process improvement (STPI) approaches are frameworks that guide software development organizations to improve their software testing process. We have identified existing STPI approaches and their characteristics (such as completeness of development, availability of information and assessment instruments, and domain limitations of the approaches) using a systematic literature review (SLR). Furthermore, two selected approaches (TPI NEXT and TMMi) are evaluated with respect to their content and assessment results in industry. As a result of this study, we have identified 18 STPI approaches and their characteristics. A detailed comparison of the content of TPI NEXT and TMMi is done. We found that many of the STPI approaches do not provide sufficient information or the approaches do not include assessment instruments. This makes it difficult to apply many approaches in industry. Greater similarities were found between TPI NEXT and TMMi and fewer differences. We conclude that numerous STPI approaches are available but not all are generally applicable for industry. One major difference between available approaches is their model representation. Even though the applied approaches generally show strong similarities, differences in the assessment results arise due to their different model representations.}
}

@article{rayyan-727967467,
  title={A systematic review of software architecture visualization techniques},
  year={2014},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={94},
  pages={161-185},
  author={Shahin, Mojtaba and Liang, Peng and Babar, Muhammad Ali},
  url={https://www.sciencedirect.com/science/article/pii/S0164121214000831},
  keywords={Software architecture, Visualization techniques, Software architecture visualization, Software},
  abstract={Context Given the increased interest in using visualization techniques (VTs) to help communicate and understand software architecture (SA) of large scale complex systems, several VTs and tools have been reported to represent architectural elements (such as architecture design, architectural patterns, and architectural design decisions). However, there is no attempt to systematically review and classify the VTs and associated tools reported for SA, and how they have been assessed and applied. Objective This work aimed at systematically reviewing the literature on software architecture visualization to develop a classification of VTs in SA, analyze the level of reported evidence and the use of different VTs for representing SA in different application domains, and identify the gaps for future research in the area. Method We used systematic literature review (SLR) method of the evidence-based software engineering (EBSE) for reviewing the literature on VTs for SA. We used both manual and automatic search strategies for searching the relevant papers published between 1 February 1999 and 1 July 2011. Results We selected 53 papers from the initially retrieved 23,056 articles for data extraction, analysis, and synthesis based on pre-defined inclusion and exclusion criteria. The results from the data analysis enabled us to classify the identified VTs into four types based on the usage popularity: graph-based, notation-based, matrix-based, and metaphor-based VTs. The VTs in SA are mostly used for architecture recovery and architectural evolution activities. We have also identified ten purposes of using VTs in SA. Our results also revealed that VTs in SA have been applied to a wide range of application domains, among which “graphics software” and “distributed system” have received the most attention. Conclusion SA visualization has gained significant importance in understanding and evolving software-intensive systems. However, only a few VTs have been employed in industrial practice. This review has enabled us to identify the following areas for further research and improvement: (i) it is necessary to perform more research on applying visualization techniques in architectural analysis, architectural synthesis, architectural implementation, and architecture reuse activities; (ii) it is essential to pay more attention to use more objective evaluation methods (e.g., controlled experiment) for providing more convincing evidence to support the promised benefits of using VTs in SA; (iii) it is important to conduct industrial surveys for investigating how software architecture practitioners actually employ VTs in architecting process and what are the issues that hinder and prevent them from adopting VTs in SA.}
}

@article{rayyan-727967468,
  title={A systematic review on the functional testing of semantic web services},
  year={2013},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={86},
  number={11},
  pages={2877-2889},
  author={Tahir, Abbas and Tosi, Davide and Morasca, Sandro},
  url={https://www.sciencedirect.com/science/article/pii/S0164121213001659},
  keywords={Systematic literature review, Functional testing, Semantic web services, Testing approach, Semantics},
  abstract={Semantic web services are gaining more attention as an important element of the emerging semantic web. Therefore, testing semantic web services is becoming a key concern as an essential quality assurance measure. The objective of this systematic literature review is to summarize the current state of the art of functional testing of semantic web services by providing answers to a set of research questions. The review follows a predefined procedure that involves automatically searching 5 well-known digital libraries. After applying the selection criteria to the results, a total of 34 studies were identified as relevant. Required information was extracted from the studies and summarized. Our systematic literature review identified some approaches available for deriving test cases from the specifications of semantic web services. However, many of the approaches are either not validated or the validation done lacks credibility. We believe that a substantial amount of work remains to be done to improve the current state of research in the area of testing semantic web services.}
}

@article{rayyan-727967469,
  title={A systematic review of scholar context-aware recommender systems},
  year={2015},
  journal={Expert Systems with Applications},
  issn={0957-4174},
  volume={42},
  number={3},
  pages={1743-1758},
  author={Champiri, Zohreh Dehghani and Shahamiri, Seyed Reza and Salim, Siti Salwah Binti},
  url={https://www.sciencedirect.com/science/article/pii/S0957417414005569},
  keywords={Academic digital library, Context-aware recommender system, Context-awareness, Contextual information, Awareness},
  abstract={Incorporating contextual information in recommender systems is an effective approach to create more accurate and relevant recommendations. This review has been conducted to identify the contextual information and methods used for making recommendations in digital libraries as well as the way researchers understood and used relevant contextual information from the years 2001 to 2013 based on the Kitchenham systematic review methodology. The results indicated that contextual information incorporated into recommendations can be categorised into three contexts, namely users' context, document's context, and environment context. In addition, the classical approaches such as collaborative filtering were employed more than the other approaches. Researchers have understood and exploited relevant contextual information through four ways, including citation of past studies, citation of past definitions, self-definitions, and field-query researches; however, citation of the past studies has been the most popular method. This review highlights the need for more investigations on the concept of context from user viewpoint in scholarly domains. It also discusses the way a context-aware recommender system can be effectively designed and implemented in digital libraries. Additionally, a few recommendations for future investigations on scholarly recommender systems are proposed.}
}

@article{rayyan-727967470,
  title={A systematic literature review of studies on business process modeling quality},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={58},
  pages={187-205},
  author={Moreno-Montes de Oca, Isel and Snoeck, Monique and Reijers, Hajo A and Rodríguez-Morffi, Abel},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001797},
  keywords={Systematic literature review, Business process modeling, Modeling quality},
  abstract={Context Business process modeling is an essential part of understanding and redesigning the activities that a typical enterprise uses to achieve its business goals. The quality of a business process model has a significant impact on the development of any enterprise and IT support for that process. Objective Since the insights on what constitutes modeling quality are constantly evolving, it is unclear whether research on business process modeling quality already covers all major aspects of modeling quality. Therefore, the objective of this research is to determine the state of the art on business process modeling quality: What aspects of process modeling quality have been addressed until now and which gaps remain to be covered? Method We performed a systematic literature review of peer reviewed articles as published between 2000 and August 2013 on business process modeling quality. To analyze the contributions of the papers we use the Formal Concept Analysis technique. Results We found 72 studies addressing quality aspects of business process models. These studies were classified into different dimensions: addressed model quality type, research goal, research method, and type of research result. Our findings suggest that there is no generally accepted framework of model quality types. Most research focuses on empirical and pragmatic quality aspects, specifically with respect to improving the understandability or readability of models. Among the various research methods, experimentation is the most popular one. The results from published research most often take the form of intangible knowledge. Conclusion We believe there is a lack of an encompassing and generally accepted definition of business process modeling quality. This evidences the need for the development of a broader quality framework capable of dealing with the different aspects of business process modeling quality. Different dimensions of business process quality and of the process of modeling still require further research.}
}

@article{rayyan-727967472,
  title={Adoption of open source software in software-intensive organizations – A systematic literature review},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={11},
  pages={1133-1154},
  author={Hauge, Øyvind and Ayala, Claudia and Conradi, Reidar},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910000972},
  keywords={Systematic literature review, Software development, Open source software, Organizations, Software},
  abstract={Context Open source software (OSS) is changing the way organizations develop, acquire, use, and commercialize software. Objective This paper seeks to identify how organizations adopt OSS, classify the literature according to these ways of adopting OSS, and with a focus on software development evaluate the research on adoption of OSS in organizations. Method Based on the systematic literature review method we reviewed publications from 24 journals and seven conference and workshop proceedings, published between 1998 and 2008. From a population of 24,289 papers, we identified 112 papers that provide empirical evidence on how organizations actually adopt OSS. Results We show that adopting OSS involves more than simply using OSS products. We moreover provide a classification framework consisting of six distinctly different ways in which organizations adopt OSS. This framework is used to illustrate some of the opportunities and challenges organizations meet when approaching OSS, to show that OSS can be adopted successfully in different ways, and to organize and review existing research. We find that existing research on OSS adoption does not sufficiently describe the context of the organizations studied, and it fails to benefit fully from related research fields. While existing research covers a large number of topics, it contains very few closely related studies. To aid this situation, we offer directions for future research. Conclusion The implications of our findings are twofold. On the one hand, practitioners should embrace the many opportunities OSS offers, but consciously evaluate the consequences of adopting it in their own context. They may use our framework and the success stories provided by the literature in their own evaluations. On the other hand, researchers should align their work, and perform more empirical research on topics that are important to organizations. Our framework may be used to position this research and to describe the context of the organization they are studying.}
}

@article{rayyan-727967473,
  title={Complexity metrics for process models – A systematic literature review},
  year={2017},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={51},
  pages={104-117},
  author={Polančič, Gregor and Cegnar, Blaž},
  url={https://www.sciencedirect.com/science/article/pii/S0920548916302276},
  keywords={Systematic literature review, Process model, Metrics, Complexity measurement, Process diagram, Metronidazole},
  abstract={Context One of the focal purposes of using ‘visual' process models (i.e. process diagrams) is to ensure easier, universally understood and unambiguous diagrammatic communication. Thus the models should be easy to comprehend and maintain, which is directly related to their complexity. In order to systematically address process models complexity, it has to be measured. Objective The goal of our work was to provide a better overview and understanding in the field of process models complexity and to provide an overview of the corresponding metrics. Method A systematic literature review (SLR) was conducted, being the most suitable method for achieving aforementioned goals. In addition, to answer the stated research questions, different techniques for qualitative and quantitative data analysis and synthesis were used. Results We identified 43 relevant articles which were systematically analyzed according to a pre-defined process and data acquisition form. Out of these articles we collected 66 process models complexity metrics. Conclusion Modelers can use the ‘catalogue' of process complexity metrics to establish and ensure good quality of diagrams, whereas researches can relate to or extend the ‘catalogue' by providing new metrics or new insights to existing ones.}
}

@article{rayyan-727967475,
  title={Systematic literature review on agile practices in global software development},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={96},
  pages={161-180},
  author={Vallon, Raoul and da Silva Estácio, Bernardo José and Prikladnicki, Rafael and Grechenig, Thomas},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917302975},
  keywords={Systematic literature review, Agile software development, Scrum, XP, Global software development, Distributed software development, Global software engineering, Extreme programming, Agile practices, Software},
  abstract={Context Developing software in distributed development environments exhibits coordination, control and communication challenges. Agile practices, which demand frequent communication and self-organization between remote sites, are increasingly found in global software development (GSD) to mitigate said challenges. Objective We aim to provide detailed insight into what is reported on the successful application of agile practices in GSD from 1999 to 2016 and also identify the most frequently applied agile practices and reported distribution scenarios. We further strive to uncover research opportunities and gaps in the field of agile GSD. Method We build our systematic literature review on top of a previous review, which investigated studies published between 1999 and 2009, and extend the review by years 2010–2016, for which we conduct both a quantitative and a qualitative analysis. Results Our results show that the majority of the cases studied is global and involves complex distribution scenarios with Scrum or combined Scrum/Extreme Programming being the most used agile methods. Key results include that in contrast to 1999–2009, where four Extreme Programming practices were among the ten most frequently used agile practices, in 2010–2016 Scrum is in the center of agile GSD implementations with eight Scrum-based practices in the top ten agile practices used in GSD. Conclusion Agile GSD is a maturing research field with higher quality contributions and a greater variety of publication types and methods from 2010 to 2016 than before from 1999 to 2009. However, researchers need to report full empirical contextual details of their studied cases in order to improve the generalizability of results and allow the future creation of stronger frameworks to drive the implementation of agile practices in GSD.}
}

@article{rayyan-727967476,
  title={How games for computing education are evaluated? A systematic literature review},
  year={2017},
  journal={Computers & Education},
  issn={0360-1315},
  volume={107},
  pages={68-90},
  author={Petri, Giani and Gresse von Wangenheim, Christiane},
  url={https://www.sciencedirect.com/science/article/pii/S0360131517300040},
  keywords={Systematic literature review, Evaluation, Computer science, Computing education, Educational game},
  abstract={Educational games are assumed to be an effective and efficient instructional strategy for computing education. However, it is essential to systematically evaluate such games in order to obtain sound evidence of their impact. Thus, the objective of this article is to present the state of the art on how games for computing education are evaluated. Therefore, we performed a systematic literature review of a sample of 3617 articles from which 112 relevant articles have been identified, describing 117 studies on the evaluation of games for computing education. Based on these studies we analyzed how evaluations are defined (the analysis factors evaluated, research designs, evaluation models/methods used, kind of data collection instruments, etc.), how they have been executed (sample size and replications) and analyzed (data analysis methods used). As a result, we can confirm that most evaluations use a simple research design in which, typically, the game is used and afterwards subjective feedback is collected via questionnaires from the learners. The majority of the evaluations are run with small samples, without replication, using mostly qualitative methods for data analysis. We also observed that most studies do not use a well-defined evaluation model or method. This shows that there is a need for more rigorous evaluations as well as methodological support in order to assist game creators and instructors to improve such games as well as to systematically support decisions on when or how to include them within instructional units.}
}

@article{rayyan-727967477,
  title={A systematic literature review of software requirements reuse approaches},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={93},
  pages={223-245},
  author={Irshad, Mohsin and Petersen, Kai and Poulding, Simon},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916303615},
  keywords={Artefact reuse, Relevance, Requirements reuse, Reusability, Rigor, Software requirements, Software},
  abstract={Context Early software reuse is considered as the most beneficial form of software reuse. Hence, previous research has focused on supporting the reuse of software requirements. Objective This study aims to identify and investigate the current state of the art with respect to (a) what requirement reuse approaches have been proposed, (b) the methods used to evaluate the approaches, (c) the characteristics of the approaches, and (d) the quality of empirical studies on requirements reuse with respect to rigor and relevance. Method We conducted a systematic review and a combination of snowball sampling and database search have been used to identify the studies. The rigor and relevance scoring rubric has been used to assess the quality of the empirical studies. Multiple researchers have been involved in each step to increase the reliability of the study. Results Sixty-nine studies were identified that describe requirements reuse approaches. The majority of the approaches used structuring and matching of requirements as a method to support requirements reuse and text-based artefacts were commonly used as an input to these approaches. Further evaluation of the studies revealed that the majority of the approaches are not validated in the industry. The subset of empirical studies (22 in total) was analyzed for rigor and relevance and two studies achieved the maximum score for rigor and relevance based on the rubric. It was found that mostly text-based requirements reuse approaches were validated in the industry. Conclusion From the review, it was found that a number of approaches already exist in literature, but many approaches are not validated in industry. The evaluation of rigor and relevance of empirical studies show that these do not contain details of context, validity threats, and the industrial settings, thus highlighting the need for the industrial evaluation of the approaches.}
}

@article{rayyan-727967478,
  title={Factors influencing the understandability of process models: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={93},
  pages={112-129},
  author={Dikici, Ahmet and Turetken, Oktay and Demirors, Onur},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916302889},
  keywords={Systematic literature review, Understandability, Business process model, Comprehension, Process model understandability, Fibrinogen},
  abstract={Context Process models are key in facilitating communication in organizations and in designing process-aware information systems. Organizations are facing increasingly larger and more complex processes, which pose difficulties to the understandability of process models. The literature reports several factors that are considered to influence the understandability of process models. However, these studies typically focus on testing of a limited set of factors. A work that collects, abstracts and synthesizes an in-depth summary of the current literature will help in developing the research in this field. Objective We conducted a systematic literature review (SLR) focusing on the empirical studies in the existing literature in order to better understand the state of the research on process model understandability, and identify the gaps and opportunities for future research. Method We searched the studies between the years 1995 and 2015 in established electronic libraries. Out of 1066 publications retrieved initially, we selected 45 publications for thorough analysis. We identified, analyzed and categorized factors that are considered to influence the understandability of process models as studied in the literature using empirical methods. We also analyzed the indicators that are used to quantify process model understandability. Results Our analysis identifies several gaps in the field, as well as issues of inconsistent findings regarding the effect of some factors, unbalanced emphasis on certain indicators, and methodological concerns. Conclusions The existing research calls for comprehensive empirical studies to contribute to a better understanding of the factors of process model understandability. Our study is a comprehensive source for researchers working on the understandability of process models and related fields, and a useful guide for practitioners aiming to generate understandable process models.}
}

@article{rayyan-727967479,
  title={Agile methods tailoring – A systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={110},
  pages={85-100},
  author={Campanelli, Amadeu Silveira and Parreiras, Fernando Silva},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215001843},
  keywords={Agile method tailoring, Agile practice selection, Software method tailoring},
  abstract={Background: The software development industry has been adopting agile methods instead of traditional software development methods because they are more flexible and can bring benefits such as handling requirements changes, productivity gains and business alignment. Objective: This study seeks to evaluate, synthesize, and present aspects of research on agile methods tailoring including the method tailoring approaches adopted and the criteria used for agile practice selection. Method: The method adopted was a Systematic Literature Review (SLR) on studies published from 2002 to 2014. Results: 56 out of 783 papers have been identified as describing agile method tailoring approaches. These studies have been identified as case studies regarding the empirical research, as solution proposals regarding the research type, and as evaluation studies regarding the research validation type. Most of the papers used method engineering to implement tailoring and were not specific to any agile method on their scope. Conclusion: Most of agile methods tailoring research papers proposed or improved a technique, were implemented as case studies analyzing one case in details and validated their findings using evaluation. Method engineering was the base for tailoring, the approaches are independent of agile method and the main criteria used are internal environment and objectives variables.}
}

@article{rayyan-727967480,
  title={Risk management in the software life cycle: A systematic literature review},
  year={2020},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={71},
  pages={103431},
  author={Masso, Jhon and Pino, Francisco J and Pardo, César and García, Félix and Piattini, Mario},
  url={https://www.sciencedirect.com/science/article/pii/S0920548919300881},
  keywords={Systematic literature review, ISO 12207, ISO 31000, Risk management activities, Software life cycle processes, Software risk, Risk Management, Software},
  abstract={Risk management (RM) plays a key role in project management, as it allows identification and prompt management of threats that may arise during project execution. Furthermore, project management within the software industry is evolving rapidly nowadays, a fact that implies new challenges, because the emergence and use of fresh approaches has brought a greater degree of complexity to the RM process. The objective of this paper is to carry out a systematic literature review (SLR) in the field of software risk, in an attempt to characterize and present the state of the art of this field, identifying gaps and opportunities for further research. From the analysis of the results of this SLR it could be observed that interest on the part of the scientific community has turned away from the definition of research work that addressed an integrated risk management process, to pay attention to work that concentrates on specific activities of this process. It was also possible to see that there is a clear lack of scientific rigour as regards the process of validation in the different studies, and a deficiency in the use of standards or of de facto models to define these.}
}

@article{rayyan-727967481,
  title={A systematic literature review of techniques and metrics to reduce the cost of mutation testing},
  year={2019},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={157},
  pages={110388},
  author={Pizzoleto, Alessandro Viola and Ferrari, Fabiano Cutigi and Offutt, Jeff and Fernandes, Leo and Ribeiro, Márcio},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219301554},
  keywords={Systematic review, Mutation testing, Cost reduction, Mutation analysis, Mutation, Metronidazole},
  abstract={Historically, researchers have proposed and applied many techniques to reduce the cost of mutation testing. It has become difficult to find all techniques and to understand the cost-benefit tradeoffs among them, which is critical to transitioning this technology to practice. This paper extends a prior workshop paper to summarize and analyze the current knowledge about reducing the cost of mutation testing through a systematic literature review. We selected 175 peer-reviewed studies, from which 153 present either original or updated contributions. Our analysis resulted in six main goals for cost reduction and 21 techniques. In the last decade, a growing number of studies explored techniques such as selective mutation, evolutionary algorithms, control-flow analysis, and higher-order mutation. Furthermore, we characterized 18 metrics, with particular interest in the number of mutants to be executed, test cases required, equivalent mutants generated and detected, and mutant execution speedup. We found that cost reduction for mutation is increasingly becoming interdisciplinary, often combining multiple techniques. Additionally, measurements vary even for studies that use the same techniques. Researchers can use our results to find more detailed information about particular techniques, and to design comparable and reproducible experiments.}
}

@article{rayyan-727967482,
  title={Software process modeling languages: A systematic literature review},
  year={2014},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={56},
  number={2},
  pages={103-116},
  author={García-Borgoñón, L and Barcelona, M A and García-García, J A and Alba, M and Escalona, M J},
  url={https://www.sciencedirect.com/science/article/pii/S0950584913001894},
  keywords={Systematic literature review, Software process language, Software process modeling, Software},
  abstract={Context Organizations working in software development are aware that processes are very important assets as well as they are very conscious of the need to deploy well-defined processes with the goal of improving software product development and, particularly, quality. Software process modeling languages are an important support for describing and managing software processes in software-intensive organizations. Objective This paper seeks to identify what software process modeling languages have been defined in last decade, the relationships and dependencies among them and, starting from the current state, to define directions for future research. Method A systematic literature review was developed. 1929 papers were retrieved by a manual search in 9 databases and 46 primary studies were finally included. Results Since 2000 more than 40 languages have been first reported, each of which with a concrete purpose. We show that different base technologies have been used to define software process modeling languages. We provide a scheme where each language is registered together with the year it was created, the base technology used to define it and whether it is considered a starting point for later languages. This scheme is used to illustrate the trend in software process modeling languages. Finally, we present directions for future research. Conclusion This review presents the different software process modeling languages that have been developed in the last ten years, showing the relevant fact that model-based SPMLs (Software Process Modeling Languages) are being considered as a current trend. Each one of these languages has been designed with a particular motivation, to solve problems which had been detected. However, there are still several problems to face, which have become evident in this review. This let us provide researchers with some guidelines for future research on this topic.}
}

@article{rayyan-727967483,
  title={Application of artificial intelligence methods in vital signs analysis of hospitalized patients: A systematic literature review},
  year={2020},
  journal={Applied Soft Computing},
  issn={1568-4946},
  volume={96},
  pages={106612},
  author={Kaieski, Naira and da Costa, Cristiano André and da Rosa Righi, Rodrigo and Lora, Priscila Schmidt and Eskofier, Björn},
  url={https://www.sciencedirect.com/science/article/pii/S1568494620305500},
  keywords={Artificial intelligence, Machine learning, Health informatics, Vital signs},
  abstract={In a hospital environment, patients are monitored continuously by electronic devices and health professionals. Therefore, a large amount of data is collected and stored in electronic health records systems for each patient. Among such data, vital signs are one of the most common and relevant types of information monitored to assess a patient's health status. Artificial intelligence techniques can be used to analyze and learn useful standards from clinical datasets to provide better evidence to support the decisions of health professionals and thus help to improve patient health outcomes in hospitals. This systematic literature review aims to provide an updated computational perspective of how artificial intelligence has been applied to analyze the vital signs of adult hospitalized patients and the outcomes obtained. To this end, we reviewed 2899 scientific articles published between 2008 and 2018 and selected 78 articles that met our inclusion criteria to answer the research questions. Moreover, we used the information found in the reviewed articles to propose a taxonomy and identified the main concerns, challenges, and opportunities in this field. Our findings demonstrate that many researchers are exploring the use of artificial intelligence methods in tasks related to improving the health outcomes of hospitalized patients in distinct units. Additionally, although vital signs are significant predictors of clinical deterioration, they are not analyzed in isolation to predict or identify a clinical outcome. Our taxonomy and discussion contribute to the achievement of a significant degree of coverage regarding the aspects related to using machine learning to improve health outcomes in hospital environments, while highlighting gaps in the literature for future research.}
}

@article{rayyan-727967484,
  title={Does the technology acceptance model predict actual use? A systematic literature review},
  year={2010},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={52},
  number={5},
  pages={463-479},
  author={Turner, Mark and Kitchenham, Barbara and Brereton, Pearl and Charters, Stuart and Budgen, David},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909002055},
  keywords={Evidence-based software engineering, Systematic literature review, Literature review, Actual usage, Technology acceptance model (TAM)},
  abstract={Context The technology acceptance model (TAM) was proposed in 1989 as a means of predicting technology usage. However, it is usually validated by using a measure of behavioural intention to use (BI) rather than actual usage. Objective This review examines the evidence that the TAM predicts actual usage using both subjective and objective measures of actual usage. Method We performed a systematic literature review based on a search of six digital libraries, along with vote-counting meta-analysis to analyse the overall results. Results The search identified 79 relevant empirical studies in 73 articles. The results show that BI is likely to be correlated with actual usage. However, the TAM variables perceived ease of use (PEU) and perceived usefulness (PU) are less likely to be correlated with actual usage. Conclusion Care should be taken using the TAM outside the context in which it has been validated.}
}

@article{rayyan-727967485,
  title={Agent-based simulation of unmanned aerial vehicles in civilian applications: A systematic literature review and research directions},
  year={2019},
  journal={Future Generation Computer Systems},
  issn={0167-739X},
  volume={100},
  pages={344-364},
  author={Mualla, Yazan and Najjar, Amro and Daoud, Alaa and Galland, Stéphane and Nicolle, Christophe and Yasar, Ansar-Ul-Haque and Shakshuki, Elhadi},
  url={https://www.sciencedirect.com/science/article/pii/S0167739X18328462},
  keywords={Systematic literature review, Agent-based simulation, Civilian applications, Multi-agent systems, Unmanned aerial vehicle},
  abstract={Recently, the civilian applications of Unmanned Aerial Vehicles (UAVs) are gaining more interest in several domains. Due to operational costs, safety concerns, and legal regulations, Agent-Based Simulation (ABS) is commonly used to design models and conduct tests. This has resulted in numerous research works addressing ABS in civilian UAV applications. This paper aims to provide a comprehensive overview of the ABS contribution in civilian UAV applications by conducting a Systematic Literature Review (SLR) on the relevant research in the previous ten years. Following the SLR methodology, this objective is broken down into several research questions aiming to (i) understand the evolution of ABS use in civilian UAV applications and identify the related hot research topics, (ii) identify the underlying artificial intelligence systems used in the literature, (iii) understand how and when ABS is integrated in broader and more complex internet of things & ubiquitous computing environments, and (iv) identity the communication technologies, tools, and evaluation techniques used to design, implement, and test the proposed ABS models. From the SLR results, key research directions are highlighted including problems related to autonomy, explainability, security, flight duration, integration within smart cities, regulations, and validation & verification of the UAV behavior.}
}

@article{rayyan-727967486,
  title={Antecedents to IT personnel's intentions to leave: A systematic literature review},
  year={2011},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={84},
  number={2},
  pages={238-249},
  author={Ghapanchi, Amir Hossein and Aurum, Aybuke},
  url={https://www.sciencedirect.com/science/article/pii/S0164121210002645},
  keywords={Systematic review, Employee retention, Employee turnover, Intention to leave, IT personnel},
  abstract={This paper undertakes a systematic review to gain insight into existing studies on the turnover of information technology (IT) personnel. Our systematic review of 72 studies from 1980 to 2008 examines the background and trend of research into IT personnel's intentions to leave their workplaces, in addition to providing a taxonomy of the determinants of their intentions to quit as captured in IT literature. We note a huge growth in the number of academic papers on the topic since 1998. Moreover, most of the research on IT turnover has been undertaken in North America, followed by Asia. Based on the 72 extracted studies, we found a total of 70 conceptually distinct IT turnover drivers. We classified them into the 5 broad categories of individual, organisational, job-related, psychological, and environmental, each containing three to four sub-categories. Finally, this paper presents insightful recommendations for IT practitioners as well as for the research community.}
}

@article{rayyan-727967487,
  title={A systematic literature review on agile requirements engineering practices and challenges},
  year={2015},
  journal={Computers in Human Behavior},
  issn={0747-5632},
  volume={51},
  pages={915-929},
  author={Inayat, Irum and Salim, Siti Salwah and Marczak, Sabrina and Daneva, Maya and Shamshirband, Shahaboddin},
  url={https://www.sciencedirect.com/science/article/pii/S074756321400569X},
  keywords={Collaboration, Systematic review, Agile requirements engineering, Agile software development methods, Traditional requirements engineering},
  abstract={Unlike traditional software development methods, agile methods are marked by extensive collaboration, i.e. face-to-face communication. Although claimed to be beneficial, the software development community as a whole is still unfamiliar with the role of the requirements engineering practices in agile methods. The term “agile requirements engineering” is used to define the “agile way” of planning, executing and reasoning about requirements engineering activities. Moreover, not much is known about the challenges posed by collaboration-oriented agile way of dealing with requirements engineering activities. Our goal is to map the evidence available about requirements engineering practices adopted and challenges faced by agile teams in order to understand how traditional requirements engineering issues are resolved using agile requirements engineering. We conducted a systematic review of literature published between 2002 and June 2013 and identified 21 papers, that discuss agile requirements engineering. We formulated and applied specific inclusion and exclusion criteria in two distinct rounds to determine the most relevant studies for our research goal. The review identified 17 practices of agile requirements engineering, five challenges traceable to traditional requirements engineering that were overcome by agile requirements engineering, and eight challenges posed by the practice of agile requirements engineering. However, our findings suggest that agile requirements engineering as a research context needs additional attention and more empirical results are required to better understand the impact of agile requirements engineering practices e.g. dealing with non-functional requirements and self-organising teams.}
}

@article{rayyan-727967488,
  title={Software architecture knowledge management approaches and their support for knowledge management activities: A systematic literature review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={80},
  pages={265-286},
  author={Weinreich, Rainer and Groher, Iris},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916301707},
  keywords={Systematic literature review, Software architecture, Software architecture knowledge management, Software architecture knowledge management activities, Software architecture knowledge management approaches, Software},
  abstract={Context: Numerous approaches for Software Architecture Knowledge Management (SAKM) have been developed by the research community over the last decade. Still, these approaches have not yet found widespread use in practice. Objective: This work identifies existing approaches to SAKM and analyzes them in terms of their support for central architecture knowledge management activities, i.e., capturing, using, maintaining, sharing, and reuse of architectural knowledge, along with presenting the evidence provided for this support. Method: A systematic literature review has been conducted for identifying and analyzing SAKM approaches, covering work published between January 2004 and August 2015. We identified 56 different approaches to SAKM based on 115 studies. We analyzed each approach in terms of its focus and support for important architecture knowledge management activities and in terms of the provided level of evidence for each supported activity. Results: Most of the developed approaches focus on using already-captured knowledge. Using is also the best-validated activity. The problem of efficient capturing is still not sufficiently addressed, and only a few approaches specifically address reuse, sharing, and, especially, maintaining. Conclusions: Without adequate support for other core architecture knowledge management activities besides using, the adoption of SAKM in practice will remain an elusive target. The problem of efficient capturing is still unsolved, as is the problem of maintaining captured knowledge over the long term. We also need more case studies and replication studies providing evidence for the usefulness of developed support for SAKM activities, as well as better reporting on these case studies.}
}

@article{rayyan-727967489,
  title={A systematic literature review on the industrial use of software process simulation},
  year={2014},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={97},
  pages={65-85},
  author={Ali, Nauman Bin and Petersen, Kai and Wohlin, Claes},
  url={https://www.sciencedirect.com/science/article/pii/S0164121214001502},
  keywords={Systematic literature review, Evidence based software engineering, Software process simulation, Software},
  abstract={Context Software process simulation modelling (SPSM) captures the dynamic behaviour and uncertainty in the software process. Existing literature has conflicting claims about its practical usefulness: SPSM is useful and has an industrial impact; SPSM is useful and has no industrial impact yet; SPSM is not useful and has little potential for industry. Objective To assess the conflicting standpoints on the usefulness of SPSM. Method A systematic literature review was performed to identify, assess and aggregate empirical evidence on the usefulness of SPSM. Results In the primary studies, to date, the persistent trend is that of proof-of-concept applications of software process simulation for various purposes (e.g. estimation, training, process improvement, etc.). They score poorly on the stated quality criteria. Also only a few studies report some initial evaluation of the simulation models for the intended purposes. Conclusion There is a lack of conclusive evidence to substantiate the claimed usefulness of SPSM for any of the intended purposes. A few studies that report the cost of applying simulation do not support the claim that it is an inexpensive method. Furthermore, there is a paramount need for improvement in conducting and reporting simulation studies with an emphasis on evaluation against the intended purpose.}
}

@article{rayyan-727967490,
  title={Cloud service evaluation method-based Multi-Criteria Decision-Making: A systematic literature review},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={139},
  pages={161-188},
  author={Alabool, Hamzeh and Kamil, Ahmad and Arshad, Noreen and Alarabiat, Deemah},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218300244},
  keywords={Systematic literature review, Cloud computing service, Cloud service evaluation method, Evaluation theory, Multi-Criteria Decision-Making (MCDM), Decision Making},
  abstract={A substantial effort has been made to solve the cloud-service evaluation problem. Different Cloud Service Evaluation Methods (CSEMs) have been developed to address the problem. Cloud services are evaluated against multiple criteria, which leads to a Multi-Criteria Decision-Making (MCDM) problem. Yet, studies that assess, analyse, and summarize the unresolved problems and shortcomings of current CSEM-based MCDM are limited. In the existing review studies, only individual parts of CSEMs, rarely the full solution, are reviewed and examined. To investigate CSEMs comprehensively, we present a systematic literature review based on Evaluation Theory, a theory that generalizes six evaluation components, target, criteria, yardstick, data gathering techniques, synthesis techniques, and evaluation process. These six evaluation components and the CSEMs validation approach are the seven dimensions used to assess and analyse 77 papers published from 2006 to 2016. Sixteen research deficiencies were identified. The results confirm that the majority of the studies of the proposed CSEMs were either incomplete or lacked sufficient evidence. This research not only provides the relative strengths and weaknesses of the different CSEMs but also offers a basis for researchers and decision makers to develop improved CSEMs.}
}

@article{rayyan-727967491,
  title={Identification of personal traits in adaptive learning environment: Systematic literature review},
  year={2019},
  journal={Computers & Education},
  issn={0360-1315},
  volume={130},
  pages={168-190},
  author={Afini Normadhi, Nur Baiti and Shuib, Liyana and Md Nasir, Hairul Nizam and Bimba, Andrew and Idris, Norisma and Balakrishnan, Vimala},
  url={https://www.sciencedirect.com/science/article/pii/S0360131518303026},
  keywords={Interactive learning environments, Cooperative/collaborative learning, Intelligent tutoring systems, Navigation},
  abstract={An adaptive learning environment provides personalised information to the learner through self-directed study. An adaptive learning environment model can be subdivided into a learner model, domain model, instructional model and adaptive engine. Personal traits comprise part of the components in a learner model and can be identified either explicitly or implicitly in an adaptive learning environment. In such an environment, the e-learning system should adapt to a learner's needs. However, even though academic research on adaptive learning environments has increased, the field lacks a comprehensive literature analysis of learners' personal traits in these environments. This study conducts a systematic literature review to identify the most commonly used personal traits in modelling the learner and the existing techniques suitable for identifying personal traits in an adaptive learning environment. A total of 140 articles spanning the years 2010–2017 are initially reviewed, from which 78 are selected based on the inclusion and exclusion criteria relevant to this study. This study provides an overview of learners' personal traits and the techniques used to identify them to provide a basis for improving adaptive learning environments. The findings indicate that most of the previous works used a learning style from the cognition learning domain category to model individual personal traits, while the computer-based detection technique was commonly applied to identify a learner's personal traits in adaptive learning environments. This study reveals the common learner characteristics used to develop learner models and the techniques for implementing such models. The findings of this paper can guide other researchers to recognise various personal traits and the identification technique for further studies, as well as assist developers in the development of the adaptive learning system.}
}

@article{rayyan-727967492,
  title={Software product line evolution: A systematic literature review},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={105},
  pages={190-208},
  author={Marques, Maíra and Simmonds, Jocelyn and Rossel, Pedro O and Bastarrica, María Cecilia},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301848},
  keywords={Systematic literature review, Software product line, Software reuse, Evolution, Software},
  abstract={Context: Software Product Lines (SPL) evolve when there are changes in the requirements, product structure or the technology being used. Different approaches have been proposed for managing SPL assets and some also address how evolution affects these assets. Existing mapping studies have focused on specific aspects of SPL evolution, but there is no cohesive body of work that gives an overview of the area as a whole. Objective: The goals of this work are to review the characteristics of the approaches reported as supporting SPL evolution, and to synthesize the evidence provided by primary studies about the nature of their processes, as well as how they are reported and validated. Method: We conducted a systematic literature review, considering six research questions formulated to evaluate evolution approaches for SPL. We considered journal, conference and workshop papers published up until March 2017 in leading digital libraries for computer science. Results: After a thorough analysis of the papers retrieved from the digital libraries, we ended up with a set of 60 primary studies. Feature models are widely used to represent SPLs, so feature evolution is frequently addressed. Other assets are less frequently addressed. The area has matured over time: papers presenting more rigorous work are becoming more common. The processes used to support SPL evolution are systematic, but with a low level of automation. Conclusions: Our research shows that there is no consensus about SPL formalization, what assets can evolve, nor how and when these evolve. Case studies are quite popular, but few industrial-sized case studies are publicly available. Also, few of the proposed techniques offer tool support. We believe that the SPL community needs to work together to improve the state of the art, creating methods and tools that support SPL evolution in a more comparable manner.}
}

@article{rayyan-727967493,
  title={A systematic literature review of software quality cost research},
  year={2011},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={84},
  number={3},
  pages={415-427},
  author={Karg, Lars M and Grottke, Michael and Beckhaus, Arne},
  url={https://www.sciencedirect.com/science/article/pii/S0164121210003146},
  keywords={Systematic literature review, Software development, Prevention appraisal failure cost scheme, Quality costs, Software},
  abstract={Abstract Software quality costs have not received as much attention from the research community as other economic aspects of software development. Over the last three decades, a number of articles on this topic have appeared in a range of journals, but comprehensive overviews of this body of research are not available. For the detailed review of software quality cost research presented in this article, we collect 87 articles published between 1980 and 2009 in 60 leading computing journals. We study the distribution of these articles across research disciplines and journals as well as over time. Moreover, we identify the predominant researchers in the software quality cost domain and the related research clusters. We also classify the articles according to three properties, namely, research topic, research scope, and research approach. This categorization enables us to identify aspects emphasized by previous research on software quality costs and to point out promising future research directions. Our review shows that prevention costs have gained the least attention, in spite of their big cost impact. It also reveals that only one article has targeted multiple companies. Further, we observe that many articles do not empirically validate their findings. This is especially true for those articles dealing with an entire firm.}
}

@article{rayyan-727967494,
  title={Approaches to strategic alignment of software process improvement: A systematic literature review},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={123},
  pages={45-63},
  author={Vasconcellos, Francisco J S and Landre, Geraldo B and Cunha, José Adson O G and Oliveira, Juliano L and Ferreira, Ronaldo A and Vincenzi, Auri M R},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216301893},
  keywords={Systematic literature review, Software process improvement, Business alignment, Strategic alignment, Software},
  abstract={Context: Software process improvement (SPI) aims to increase the effectiveness of a software organization. Many studies indicate that the strategic alignment is a critical factor for the SPI success. However, little is known about practical approaches to achieving and maintaining such alignment. Objective: The goal of this study is to evaluate the validation evidence of the existing approaches to the strategic alignment of SPI. Method: We develop a search protocol that combines database search and snowballing to perform the systematic literature review and evaluate empirical studies by applying rigor and relevance criteria. To evaluate the efficiency of our protocol, we use a “quasi-gold standard” to compute the sensitivity and precision of the search. Result: We identified 30 studies (18 empirical) and 19 approaches to strategic alignment of SPI from 495 retrieved studies. Only three out of the 18 empirical studies were rated as high in the categories rigor and relevance, suggesting the need for a stronger validation of the approaches. Conclusion: We conclude that the lack of empirical validation indicates that the results of the existing approaches have not been adequately transferred to practitioners yet, calling for more rigorous studies on the subject.}
}

@article{rayyan-727967497,
  title={Systematic literature review of mobile application development and testing effort estimation},
  year={2018},
  journal={Journal of King Saud University - Computer and Information Sciences},
  issn={1319-1578},
  author={Kaur, Anureet and Kaur, Kulwant},
  url={https://www.sciencedirect.com/science/article/pii/S1319157818306074},
  keywords={Systematic literature review, Agile, Estimation, Test effort, Mobile Applications},
  abstract={In the recent years, the advances in mobile technology have brought an exorbitant change in daily lifestyle of individuals. Smartphones/mobile devices are rampant in all aspects of human life. This has led to an extreme demand for developing software that runs on mobile devices. The developers have to keep up with this high demand and deliver high-quality app on time and within budget. For this, estimation of development and testing of apps play a pivotal role. In this paper, a Systematic Literature Review (SLR) is conducted to highlight development and testing estimation process for software/application. The goal of the present literature survey is to identify and compare existing test estimation techniques for traditional software (desktop/laptop) and for mobile software/application. The characteristics that make mobile software/application different from traditional software are identified in this literature survey. Further, the trend for developing the software is towards agile, thus this study also presents and compares estimation techniques used in agile software development for mobile applications. The analysis of literature review suggests filling a research gap to present formal models for estimating mobile application considering specific characteristics of mobile software.}
}

@article{rayyan-727967498,
  title={A business model for commercial open source software: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={103},
  pages={202-214},
  author={Shahrivar, Shahrokh and Elahi, Shaban and Hassanzadeh, Alireza and Montazer, Gholamali},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301277},
  keywords={Systematic literature review, Business model, Commercial open source software (COSS), Software},
  abstract={Context Commercial open source software (COSS) and community open source software (OSS) are two types of open source software. The former is the newer concept with the grounds for research such as business model. However, in the literature of open source software, the revenue model has been studied as a business model, which is one component of the business model. Therefore, there is a need for a more complete review of the COSS business model with all components. Objective The purpose of this research is to describe and present the COSS business model with all its components. Method A systematic literature review of the COSS business model was conducted and 1157 studies were retrieved through search in six academic databases. The result of the process of selecting the primary studies was 21 studies. By backward snowballing, we discovered 10 other studies, and thus a total of 31 studies were found. Then, the grounded theory coding procedures were used to determine the characteristics and components of the COSS business model. Results The COSS business model was presented with value proposition, value creation & delivery, and value capture. This business model includes eight components: COSS products and complementarities, COSS clients and users, COSS competitive strategies, organizational aspects of COSS, position of COSS producers in the value network, resources and capabilities of COSS business, COSS revenue sources, and COSS cost-benefit. Conclusion This study provides a complete illustration of the COSS business model. Identifies COSS generic competitive strategies. By cost-benefit component, we have considered both tangible and intangible components. This business model is especially effective in developing countries. In future research, it is necessary to review the management of the COSS community, the organization, the new revenue models for disruptive ability of open source software, and the localization of open source software.}
}

@article{rayyan-727967499,
  title={A systematic review of statistical power in software engineering experiments},
  year={2006},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={48},
  number={8},
  pages={745-755},
  author={Dybå, Tore and Kampenes, Vigdis By and Sjøberg, Dag I K},
  url={https://www.sciencedirect.com/science/article/pii/S0950584905001333},
  keywords={Empirical software engineering, Systematic review, Controlled experiment, Effect size, Statistical power, Software},
  abstract={Statistical power is an inherent part of empirical studies that employ significance testing and is essential for the planning of studies, for the interpretation of study results, and for the validity of study conclusions. This paper reports a quantitative assessment of the statistical power of empirical software engineering research based on the 103 papers on controlled experiments (of a total of 5,453 papers) published in nine major software engineering journals and three conference proceedings in the decade 1993–2002. The results show that the statistical power of software engineering experiments falls substantially below accepted norms as well as the levels found in the related discipline of information systems research. Given this study's findings, additional attention must be directed to the adequacy of sample sizes and research designs to ensure acceptable levels of statistical power. Furthermore, the current reporting of significance tests should be enhanced by also reporting effect sizes and confidence intervals.}
}

@article{rayyan-727967501,
  title={A systematic literature review on automated log abstraction techniques},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={122},
  pages={106276},
  author={El-Masri, Diana and Petrillo, Fabio and Guéhéneuc, Yann-Gaël and Hamou-Lhadj, Abdelwahab and Bouziane, Anas},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300264},
  keywords={Systematic literature review, Data mining, Systematic survey, AIOps, Log Abstraction Techniques, Log Analysis, Log Management, Log Mining, Log Parsing, Quality Model, Software Analysis, Software Log},
  abstract={Context: Logs are often the first and only information available to software engineers to understand and debug their systems. Automated log-analysis techniques help software engineers gain insights into large log data. These techniques have several steps, among which log abstraction is the most important because it transforms raw log-data into high-level information. Thus, log abstraction allows software engineers to perform further analyses. Existing log-abstraction techniques vary significantly in their designs and performances. To the best of our knowledge, there is no study that examines the performances of these techniques with respect to the following seven quality aspects concurrently: mode, coverage, delimiter independence, efficiency,scalability, system knowledge independence, and parameter tuning effort. Objectives: We want (1) to build a quality model for evaluating automated log-abstraction techniques and (2) to evaluate and recommend existing automated log-abstraction techniques using this quality model. Method: We perform a systematic literature review (SLR) of automated log-abstraction techniques. We review 89 research papers out of 2,864 initial papers. Results: Through this SLR, we (1) identify 17 automated log-abstraction techniques, (2) build a quality model composed of seven desirable aspects: mode, coverage, delimiter independence, efficiency, scalability, system knowledge independence, and parameter tuning effort, and (3) make recommendations for researchers on future research directions. Conclusion: Our quality model and recommendations help researchers learn about the state-of-the-art automated log-abstraction techniques, identify research gaps to enhance existing techniques, and develop new ones. We also support software engineers in understanding the advantages and limitations of existing techniques and in choosing the suitable technique to their unique use cases.}
}

@article{rayyan-727967502,
  title={Software fault prediction metrics: A systematic literature review},
  year={2013},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={55},
  number={8},
  pages={1397-1418},
  author={Radjenović, Danijel and Heričko, Marjan and Torkar, Richard and Živkovič, Aleš},
  url={https://www.sciencedirect.com/science/article/pii/S0950584913000426},
  keywords={Systematic literature review, Software metric, Software fault prediction, Software, Metronidazole},
  abstract={Context Software metrics may be used in fault prediction models to improve software quality by predicting fault location. Objective This paper aims to identify software metrics and to assess their applicability in software fault prediction. We investigated the influence of context on metrics' selection and performance. Method This systematic literature review includes 106 papers published between 1991 and 2011. The selected papers are classified according to metrics and context properties. Results Object-oriented metrics (49%) were used nearly twice as often compared to traditional source code metrics (27%) or process metrics (24%). Chidamber and Kemerer's (CK) object-oriented metrics were most frequently used. According to the selected studies there are significant differences between the metrics used in fault prediction performance. Object-oriented and process metrics have been reported to be more successful in finding faults compared to traditional size and complexity metrics. Process metrics seem to be better at predicting post-release faults compared to any static code metrics. Conclusion More studies should be performed on large industrial software systems to find metrics more relevant for the industry and to answer the question as to which metrics should be used in a given context.}
}

@article{rayyan-727967503,
  title={Systematic literature review of ensemble effort estimation},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={118},
  pages={151-175},
  author={Idri, Ali and Hosni, Mohamed and Abran, Alain},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216300450},
  keywords={Systematic literature review, Software development effort estimation, Ensemble effort estimation},
  abstract={The need to overcome the weaknesses of single estimation techniques for prediction tasks has given rise to ensemble methods in software development effort estimation (SDEE). An ensemble effort estimation (EEE) technique combines several of the single/classical models found in the SDEE literature. However, to the best of our knowledge, no systematic review has yet been performed with a focus on the use of EEE techniques in SDEE. The purpose of this review is to analyze EEE techniques from six viewpoints: single models used to construct ensembles, ensemble estimation accuracy, rules used to combine single estimates, accuracy comparison of EEE techniques with single models, accuracy comparison between EEE techniques and methodologies used to construct ensemble methods. We performed a systematic review of EEE studies published between 2000 and 2016, and we selected 24 of them to address the questions raised in this review. We found that EEE techniques may be separated into two types: homogeneous and heterogeneous, and that the machine learning single models are the most frequently employed in constructing EEE techniques. We also found that EEE techniques usually yield acceptable estimation accuracy, and in fact are more accurate than single models.}
}

@article{rayyan-727967504,
  title={A systematic literature review of iStar extensions},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={137},
  pages={1-33},
  author={Gonçalves, Enyo and Castro, Jaelson and Araújo, João and Heineck, Tiago},
  url={https://www.sciencedirect.com/science/article/pii/S0164121217302741},
  keywords={Systematic Literature Review, Goal modelling, iStar, Modelling language extensions},
  abstract={iStar is a general-purpose goal-based modelling language used to model requirements at early and late phases of software development. It has been used in industrial and academic projects. Often the language is extended to incorporate new constructs related to an application area. The language is currently undergoing standardisation, so several studies have focused on the analysis of iStar variations to identify the similarities and defining a core iStar. However, we believe it will continue to be extended and it is important to understand how iStar is extended. This paper contributes to this purpose through the identification and analysis of the existing extensions and its constructs. A Systematic Literature Review was conducted to guide identification and analysis. The results point to 96 papers and 307 constructs proposed. The extensions and constructs were analysed according to well-defined questions in three dimensions: a general analysis; model-based analysis (to characterise the extensions from semantic and syntactic definitions); and a third dimension related to semiotic clarity. The application area targeted by the iStar extensions and their evolutions are presented as results of our analysis. The results point to the need for more complete, consistent and careful development of iStar extensions. The paper concludes with some discussions and future directions for this research field.}
}

@article{rayyan-727967505,
  title={Threat modeling – A systematic literature review},
  year={2019},
  journal={Computers & Security},
  issn={0167-4048},
  volume={84},
  pages={53-69},
  author={Xiong, Wenjun and Lagerström, Robert},
  url={https://www.sciencedirect.com/science/article/pii/S0167404818307478},
  keywords={Literature review, Risk management, Cyber security, Cyber attacks, Threat modeling},
  abstract={Cyber security is attracting worldwide attention. With attacks being more and more common and often successful, no one is spared today. Threat modeling is proposed as a solution for secure application development and system security evaluations. Its aim is to be more proactive and make it more difficult for attackers to accomplish their malicious intents. However, threat modeling is a domain that lacks common ground. What is threat modeling, and what is the state-of-the-art work in this field? To answer these questions, this article presents a review of threat modeling based on systematic queries in four leading scientific databases. This is the first systematic literature review on threat modeling to the best of our knowledge. 176 articles were assessed, and 54 of them were selected for further analysis. We identified three separate clusters: (1) articles making a contribution to threat modeling, e.g., introducing a new method, (2) articles using an existing threat modeling approach, and (3) introductory articles presenting work related to the threat modeling process. The three clusters were analyzed in terms of a set of criteria, for instance: Is the threat modeling approach graphical or formal? Is it focused on a specific attack type and application? Is the contribution validated empirically or theoretically? We observe from the results that, most threat modeling work remains to be done manually, and there is limited assurance of their validations. The results can be used for researchers and practitioners who want to know the state-of-the-art threat modeling methods, and future research directions are discussed.}
}

@article{rayyan-727967506,
  title={Using metrics in Agile and Lean Software Development – A systematic literature review of industrial studies},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={62},
  pages={143-163},
  author={Kupiainen, Eetu and Mäntylä, Mika V and Itkonen, Juha},
  url={https://www.sciencedirect.com/science/article/pii/S095058491500035X},
  keywords={Systematic literature review, Software engineering, Measurement, Agile, Lean, Metrics, Metronidazole, Software},
  abstract={Context Software industry has widely adopted Agile software development methods. Agile literature proposes a few key metrics but little is known of the actual metrics use in Agile teams. Objective The objective of this paper is to increase knowledge of the reasons for and effects of using metrics in industrial Agile development. We focus on the metrics that Agile teams use, rather than the ones used from outside by software engineering researchers. In addition, we analyse the influence of the used metrics. Method This paper presents a systematic literature review (SLR) on using metrics in industrial Agile software development. We identified 774 papers, which we reduced to 30 primary studies through our paper selection process. Results The results indicate that the reasons for and the effects of using metrics are focused on the following areas: sprint planning, progress tracking, software quality measurement, fixing software process problems, and motivating people. Additionally, we show that although Agile teams use many metrics suggested in the Agile literature, they also use many custom metrics. Finally, the most influential metrics in the primary studies are Velocity and Effort estimate. Conclusion The use of metrics in Agile software development is similar to Traditional software development. Projects and sprints need to be planned and tracked. Quality needs to be measured. Problems in the process need to be identified and fixed. Future work should focus on metrics that had high importance but low prevalence in our study, as they can offer the largest impact to the software industry.}
}

@article{rayyan-727967507,
  title={The role and value of replication in empirical software engineering results},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={99},
  pages={120-132},
  author={Shepperd, Martin and Ajienka, Nemitari and Counsell, Steve},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917304305},
  keywords={Software engineering, Meta-analysis, Reliability, Replication, Experiment, Software},
  abstract={Context Concerns have been raised from many quarters regarding the reliability of empirical research findings and this includes software engineering. Replication has been proposed as an important means of increasing confidence. Objective We aim to better understand the value of replication studies, the level of confirmation between replication and original studies, what confirmation means in a statistical sense and what factors modify this relationship. Method We perform a systematic review to identify relevant replication experimental studies in the areas of (i) software project effort prediction and (ii) pair programming. Where sufficient details are provided we compute prediction intervals. Results Our review locates 28 unique articles that describe replications of 35 original studies that address 75 research questions. Of these 10 are external, 15 internal and 3 internal-same-article replications. The odds ratio of internal to external (conducted by independent researchers) replications of obtaining a ‘confirmatory' result is 8.64. We also found incomplete reporting hampered our ability to extract estimates of effect sizes. Where we are able to compute replication prediction intervals these were surprisingly large. Conclusion We show that there is substantial evidence to suggest that current approaches to empirical replications are highly problematic. There is a consensus that replications are important, but there is a need for better reporting of both original and replicated studies. Given the low power and incomplete reporting of many original studies, it can be unclear the extent to which a replication is confirmatory and to what extent it yields additional knowledge to the software engineering community. We recommend attention is switched from replication research to meta-analysis.}
}

@article{rayyan-727967508,
  title={Twitter as a tool for the management and analysis of emergency situations: A systematic literature review},
  year={2018},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={43},
  pages={196-208},
  author={Martínez-Rojas, María and del Carmen Pardo-Ferreira, María and Rubio-Romero, Juan Carlos},
  url={https://www.sciencedirect.com/science/article/pii/S0268401218303499},
  keywords={Review, Management, Social network, Data, Emergencies, Twitter},
  abstract={The importance of timely, accurate and effective use of available information is essential to the proper management of emergency situations. In recent years, emerging technologies have provided new approaches towards the distribution and acquisition of crowdsourced information to facilitate situational awareness and management during emergencies. In this regard, internet and social networks have shown potential to be an effective tool in disseminating and obtaining up-to-date information. Among the most popular social networks, research has pointed to Twitter as a source of information that offers valuable real-time data for decision-making. The objective of this paper is to conduct a systematic literature review that provides an overview of the current state of research concerning the use of Twitter to emergencies management, as well as presents the challenges and future research directions.}
}

@article{rayyan-727967509,
  title={Re-identification attacks—A systematic literature review},
  year={2016},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={36},
  number={6},
  pages={1184-1192},
  author={Henriksen-Bulmer, Jane and Jeary, Sheridan},
  url={https://www.sciencedirect.com/science/article/pii/S0268401215301262},
  keywords={Systematic literature review, Anonymisation, Anonymization, Re-identification},
  abstract={The publication of increasing amounts of anonymised open source data has resulted in a worryingly rising number of successful re-identification attacks. This has a number of privacy and security implications both on an individual and corporate level. This paper uses a systematic literature review to investigate the depth and extent of this problem as reported in peer reviewed literature. Using a detailed protocol,seven research portals were explored, 10,873 database entries were searched, from which a subset of 220 papers were selected for further review. From this total, 55 papers were selected as being within scope and to be included in the final review. The main review findings are that 72.7% of all successful re-identification attacks have taken place since 2009. Most attacks use multiple datasets. The majority of them have taken place on global datasets such as social networking data, and have been conducted by US based researchers. Furthermore, the number of datasets can be used as an attribute. Because privacy breaches have security, policy and legal implications (e.g. data protection, Safe Harbor etc.), the work highlights the need for new and improved anonymisation techniques or indeed, a fresh approach to open source publishing.}
}

@article{rayyan-727967510,
  title={Understanding Service-Oriented Architecture (SOA): A systematic literature review and directions for further investigation},
  year={2020},
  journal={Information Systems},
  issn={0306-4379},
  volume={91},
  pages={101491},
  author={Niknejad, Naghmeh and Ismail, Waidah and Ghani, Imran and Nazari, Behzad and Bahari, Mahadi and Hussin, Ab Razak Bin Che},
  url={https://www.sciencedirect.com/science/article/pii/S0306437920300028},
  keywords={Systematic literature review, Service-Oriented Architecture, SOA, Information systems, Success factors},
  abstract={Service-Oriented Architecture (SOA) has emerged as an architectural approach that enhances the service delivery performance of existing traditional systems while still retaining their most important features. This approach, due to its flexibility of adoption, has gained the attention of both academic and business entities, especially in the development of world-leading technologies such as Cloud Computing (CC) and the Internet of Things (IoT). Although many studies have listed the success factors of SOA, a few minor failures have also been reported in the literature. Despite the availability of rich material on SOA, there is a lack of systematic reviews covering the different aspects of the SOA concept in Information Systems (IS) research. Therefore, the central objective of this study is to review existing issues of SOA and share the findings with the academia. Hence, a systematic literature review (SLR) was conducted to analyse existing studies related to SOA and the factors that led to SOA success and failure from 2009 to 2019. To completely cover all SOA-related research in the IS field, a two-stage review protocol that included automatic and manual searching was applied, resulting in 103 primary studies. The articles were categorised into four research themes, namely: SOA Adoption, SOA Concepts, SOA Impact, and SOA Practice. The result shows that the academic research interest on SOA increased recently with most of the articles covering SOA Practice followed by SOA Adoption. Moreover, the findings of this review highlighted SOA Governance, SOA Strategy, Financial Issues and Costs, and Education and Training as the most significant factors of SOA adoption and implementation. Consequently, the outcomes will assist professionals and experts in organisations as well as academic researchers to focus more on these factors for successfully adopting and implementing SOA.}
}

@article{rayyan-727967512,
  title={The effect of software engineers' personality traits on team climate and performance: A Systematic Literature Review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={73},
  pages={52-65},
  author={Soomro, Arjumand Bano and Salleh, Norsaremah and Mendes, Emilia and Grundy, John and Burch, Giles and Nordin, Azlin},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916000082},
  keywords={Systematic literature review, Personality and software engineering, Software team climate, Team performance, Software},
  abstract={Context Over the past 50years numerous studies have investigated the possible effect that software engineers' personalities may have upon their individual tasks and teamwork. These have led to an improved understanding of that relationship; however, the analysis of personality traits and their impact on the software development process is still an area under investigation and debate. Further, other than personality traits, “team climate” is also another factor that has also been investigated given its relationship with software teams' performance. Objective The aim of this paper is to investigate how software professionals' personality is associated with team climate and team performance. Method In this paper we detail a Systematic Literature Review (SLR) of the effect of software engineers' personality traits and team climate on software team performance. Results Our main findings include 35 primary studies that have addressed the relationship between personality and team performance without considering team climate. The findings showed that team climate comprises a wide range of factors that fall within the fields of management and behavioral sciences. Most of the studies used undergraduate students as subjects and as surrogates of software professionals. Conclusions The findings from this SLR would be beneficial for understanding the personality assessment of software development team members by revealing the traits of personality taxonomy, along with the measurement of the software development team working environment. These measurements would be useful in examining the success and failure possibilities of software projects in development processes. General terms Human factors, performance.}
}

@article{rayyan-727967513,
  title={Testing scientific software: A systematic literature review},
  year={2014},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={56},
  number={10},
  pages={1219-1232},
  author={Kanewala, Upulee and Bieman, James M},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001232},
  keywords={Software testing, Systematic literature review, Software quality, Scientific software, Software},
  abstract={Context Scientific software plays an important role in critical decision making, for example making weather predictions based on climate models, and computation of evidence for research publications. Recently, scientists have had to retract publications due to errors caused by software faults. Systematic testing can identify such faults in code. Objective This study aims to identify specific challenges, proposed solutions, and unsolved problems faced when testing scientific software. Method We conducted a systematic literature survey to identify and analyze relevant literature. We identified 62 studies that provided relevant information about testing scientific software. Results We found that challenges faced when testing scientific software fall into two main categories: (1) testing challenges that occur due to characteristics of scientific software such as oracle problems and (2) testing challenges that occur due to cultural differences between scientists and the software engineering community such as viewing the code and the model that it implements as inseparable entities. In addition, we identified methods to potentially overcome these challenges and their limitations. Finally we describe unsolved challenges and how software engineering researchers and practitioners can help to overcome them. Conclusions Scientific software presents special challenges for testing. Specifically, cultural differences between scientist developers and software engineers, along with the characteristics of the scientific software make testing more difficult. Existing techniques such as code clone detection can help to improve the testing process. Software engineers should consider special challenges posed by scientific software such as oracle problems when developing testing techniques.}
}

@article{rayyan-727967514,
  title={Two decades of research on business intelligence system adoption, utilization and success – A systematic literature review},
  year={2019},
  journal={Decision Support Systems},
  issn={0167-9236},
  volume={125},
  pages={113113},
  author={Ain, NoorUl and Vaia, Giovanni and DeLone, William H and Waheed, Mehwish},
  url={https://www.sciencedirect.com/science/article/pii/S0167923619301423},
  keywords={Systematic literature review, Adoption, Business intelligence system, Success, Utilization},
  abstract={In the recent era of technological advances and hyper-competition, business intelligence (BI) systems have attracted significant attention from executives and decision makers due to their ability to provide complex and competitive information inputs for the decision process. Following the world of practice, research into the adoption, utilization and success of BI systems has grown substantially over the past two decades. The literature suggests that organizations have largely failed to capture the benefits of BI systems to their full extent and are seeking ways to leverage value from the implemented systems. However, prior studies do not have any comprehensive study that discusses the issues and challenges related to adoption, utilization and success of BI systems. In this study, using a systematic literature review, we present comprehensive knowledge about what has been found in the domain of BI system adoption, utilization and success. A total of 111 peer-reviewed studies, covering three categories – adoption, utilization and success – published between 2000 and 2019, were selected. The findings present the research methods, underpinning theories and key factors employed to study BI system adoption, utilization and success. In addition, the review identified the key issues related to BI adoption, utilization and success and highlighted the areas that have attracted more or less attention. This study also suggests future directions for researchers and practitioners in terms of unexplored themes that may help organizations to obtain value from BI systems.}
}

@article{rayyan-727967515,
  title={A systematic literature review on the semi-automatic configuration of extended product lines},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={144},
  pages={511-532},
  author={Ochoa, Lina and González-Rojas, Oscar and Juliana, Alves Pereira and Castro, Harold and Saake, Gunter},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301511},
  keywords={Systematic literature review, Extended product line, Product configuration},
  abstract={Product line engineering has become essential in mass customisation given its ability to reduce production costs and time to market, and to improve product quality and customer satisfaction. In product line literature, mass customisation is known as product configuration. Currently, there are multiple heterogeneous contributions in the product line configuration domain. However, a secondary study that shows an overview of the progress, trends, and gaps faced by researchers in this domain is still missing. In this context, we provide a comprehensive systematic literature review to discover which approaches exist to support the configuration process of extended product lines and how these approaches perform in practice. Extend product lines consider non-functional properties in the product line modelling. We compare and classify a total of 66 primary studies from 2000 to 2016. Mainly, we give an in-depth view of techniques used by each work, how these techniques are evaluated and their main shortcomings. As main results, our review identified (i) the need to improve the quality of the evaluation of existing approaches, (ii) a lack of hybrid solutions to support multiple configuration constraints, and (iii) a need to improve scalability and performance conditions.}
}

@article{rayyan-727967516,
  title={Empirical studies omit reporting necessary details: A systematic literature review of reporting quality in model based testing},
  year={2018},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={55},
  pages={156-170},
  author={Khan, Muhammad Uzair and Iftikhar, Sidra and Iqbal, Muhammad Zohaib and Sherin, Salman},
  url={https://www.sciencedirect.com/science/article/pii/S0920548916302112},
  keywords={Empirical study, Model based testing, Reporting guidelines, Reporting quality},
  abstract={Context Empirical studies are essential in evaluating the effectiveness of Model-based Testing (MBT) research and should be reported properly to ensure their replication and to highlight the strengths and limitations of the MBT techniques being evaluated. Researchers have proposed guidelines detailing what information should be reported when presenting empirical studies and what should be the structure of such primary studies. There is a need to evaluate the reporting quality of the empirical studies in MBT literature. Objective To evaluate the reporting quality of empirical studies in the model based testing domain; identifying where the reported studies fail to follow the proposed guidelines and finding frequently omitted details. As an auxiliary goal we aim to quantify the percentage of empirical studies conducted in industrial context. Method We evaluate the reporting quality and the execution contexts of MBT empirical studies reported in literature. For our study we consider the MBT papers published in top ten software engineering journals over the last eighteen years. We evaluate the published primary studies using the empirical study reporting guidelines. Results We found 87 empirical in MBT that met our selection criteria. Initial results showed that the existing guidelines were not only too strict (for example they demand presence of specific sections rather than simply having the details present in the paper), they also did not adequately cover MBT specific details. Therefore, we propose modified the guidelines for reporting empirical studies in MBT and re-evaluated the selected studies. Results show that while only a few empirical studies follow the exact structure proposed by the guidelines, approximately half the papers contain at least 50% of the required details. Most of the papers omit details related to process and analysis leading to presented results. We found a positive trend of improving reporting quality of empirical studies in MBT over the last Eighteen years. Another important finding from the review is that few reported studies were conducted in real industrial context. Conclusions Model based testing community needs to be more aware of the reporting guidelines and more effort should be spent on reporting the necessary details. Furthermore, we found that only few studies that are conducted in industrial context and hence more focus should be given to empirical case studies in real industry context. However, the reporting quality of research papers presenting empirical evaluations is gradually improving.}
}

@article{rayyan-727967517,
  title={Supporting the semi-automatic semantic annotation of web services: A systematic literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={61},
  pages={16-32},
  author={Tosi, Davide and Morasca, Sandro},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915000154},
  keywords={Systematic literature review, Ontologies, Semantic web services, Functional and non-functional aspects, Semantics},
  abstract={Context Semantically annotating web services is gaining more attention as an important aspect to support the automatic matchmaking and composition of web services. Therefore, the support of well-known and agreed ontologies and tools for the semantical annotation of web services is becoming a key concern to help the diffusion of semantic web services. Objective The objective of this systematic literature review is to summarize the current state-of-the-art for supporting the semantical annotation of web services by providing answers to a set of research questions. Method The review follows a predefined procedure that involves automatically searching well-known digital libraries. As a result, a total of 35 primary studies were identified as relevant. A manual search led to the identification of 9 additional primary studies that were not reported during the automatic search of the digital libraries. Required information was extracted from these 44 studies against the selected research questions and finally reported. Results Our systematic literature review identified some approaches available for semantically annotating functional and non-functional aspects of web services. However, many of the approaches are either not validated or the validation done lacks credibility. Conclusion We believe that a substantial amount of work remains to be done to improve the current state of research in the area of supporting semantic web services.}
}

@article{rayyan-727967519,
  title={Feature extraction approaches from natural language requirements for reuse in software product lines: A systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={106},
  pages={132-149},
  author={Bakar, Noor Hasrina and Kasirun, Zarinah M and Salleh, Norsaremah},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215001004},
  keywords={Software product lines, Systematic literature review, Requirements reuse, Feature extractions, Natural language requirements, Software},
  abstract={Requirements for implemented system can be extracted and reused for a production of a new similar system. Extraction of common and variable features from requirements leverages the benefits of the software product lines engineering (SPLE). Although various approaches have been proposed in feature extractions from natural language (NL) requirements, no related literature review has been published to date for this topic. This paper provides a systematic literature review (SLR) of the state-of-the-art approaches in feature extractions from NL requirements for reuse in SPLE. We have included 13 studies in our synthesis of evidence and the results showed that hybrid natural language processing approaches were found to be in common for overall feature extraction process. A mixture of automated and semi-automated feature clustering approaches from data mining and information retrieval were also used to group common features, with only some approaches coming with support tools. However, most of the support tools proposed in the selected studies were not made available publicly and thus making it hard for practitioners' adoption. As for the evaluation, this SLR reveals that not all studies employed software metrics as ways to validate experiments and case studies. Finally, the quality assessment conducted confirms that practitioners' guidelines were absent in the selected studies.}
}

@article{rayyan-727967520,
  title={Prognosis of dementia employing machine learning and microsimulation techniques: A systematic literature review},
  year={2016},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={100},
  pages={480-488},
  author={Dallora, Ana Luiza and Eivazzadeh, Shahryar and Mendes, Emilia and Berglund, Johan and Anderberg, Peter},
  url={https://www.sciencedirect.com/science/article/pii/S1877050916323535},
  keywords={machine learning, dementia, microsimulation, prognosis, Prognosis, Dementia},
  abstract={OBJECTIVE: The objective of this paper is to investigate the goals and variables employed in the machine learning and microsimulation studies for the prognosis of dementia. METHOD: According to preset protocols, the Pubmed, Socups and Web of Science databases were searched to find studies that matched the defined inclusion/exclusion criteria, and then its references were checked for new studies. A quality checklist assessed the selected studies, and removed the low quality ones. The remaining ones (included set) had their data extracted and summarized. RESULTS: The summary of the data of the 37 included studies showed that the most common goal of the selected studies was the prediction of the conversion from mild cognitive impairment to Alzheimer's Disease, for studies that used machine learning, and cost estimation for the microsimulation ones. About the variables, neuroimaging was the most frequent used. CONCLUSIONS: The systematic literature review showed clear trends in prognosis of dementia research in what concerns machine learning techniques and microsimulation.}
}

@article{rayyan-727967521,
  title={Current issue on knowledge management system for future research: a systematic literature review},
  year={2017},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={116},
  pages={68-80},
  author={Iskandar, Karto and Jambak, Muhammad Ikhwan and Kosala, Raymondus and Prabowo, Harjanto},
  url={https://www.sciencedirect.com/science/article/pii/S1877050917320483},
  keywords={Systematic Literature Review, Big Data Issue in KMS, Current Issues, KMS, Knowledge Management System},
  abstract={Nowadays, the number of papers on the topic of Knowledge Management and Knowledge Management System is still widely discussed. The study of Knowledge Management System (KMS) issues are based on Systematic Literature Review (SLR). It aims to analyze the state of the art, identify current popular issues on KMS, and offer directions for future research agenda. The methodology used in this paper is based on the systematic literature review to collect, synthesize and analyze numerous papers on a variety of topics that are closely related to knowledge management system issues that published in the last two decades. Based on fifty-four papers reviewed from six electronic databases, the result of this paper obtained fourteen current issues on knowledge management system. Moreover, the top three popular issues consist of the development of capabilities and features of KMS, Big Data issues on KMS, and adoption to new technology issue for KMS respectively. The conclusion of this study emphasized the big data phenomenon as the most contemporary topic for the future research area besides the growing of required KMS capabilities and features development.}
}

@article{rayyan-727967522,
  title={Web application testing: A systematic literature review},
  year={2014},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={91},
  pages={174-201},
  author={Doğan, Serdar and Betin-Can, Aysu and Garousi, Vahid},
  url={https://www.sciencedirect.com/science/article/pii/S0164121214000223},
  keywords={Systematic literature review, Testing, Web application},
  abstract={Context The web has had a significant impact on all aspects of our society. As our society relies more and more on the web, the dependability of web applications has become increasingly important. To make these applications more dependable, for the past decade researchers have proposed various techniques for testing web-based software applications. Our literature search for related studies retrieved 193 papers in the area of web application testing, which have appeared between 2000 and 2013. Objective As this research area matures and the number of related papers increases, it is important to systematically identify, analyze, and classify the publications and provide an overview of the trends and empirical evidence in this specialized field. Methods We systematically review the body of knowledge related to functional testing of web application through a systematic literature review (SLR) study. This SLR is a follow-up and complimentary study to a recent systematic mapping (SM) study that we conducted in this area. As part of this study, we pose three sets of research questions, define selection and exclusion criteria, and synthesize the empirical evidence in this area. Results Our pool of studies includes a set of 95 papers (from the 193 retrieved papers) published in the area of web application testing between 2000 and 2013. The data extracted during our SLR study is available through a publicly-accessible online repository. Among our results are the followings: (1) the list of test tools in this area and their capabilities, (2) the types of test models and fault models proposed in this domain, (3) the way the empirical studies in this area have been designed and reported, and (4) the state of empirical evidence and industrial relevance. Conclusion We discuss the emerging trends in web application testing, and discuss the implications for researchers and practitioners in this area. The results of our SLR can help researchers to obtain an overview of existing web application testing approaches, fault models, tools, metrics and empirical evidence, and subsequently identify areas in the field that require more attention from the research community.}
}

@article{rayyan-727967523,
  title={A systematic literature review to identify and classify software requirement errors},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={7},
  pages={1087-1109},
  author={Walia, Gursimran Singh and Carver, Jeffrey C},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909000111},
  keywords={Systematic literature review, Software quality, Human errors, Software},
  abstract={Most software quality research has focused on identifying faults (i.e., information is incorrectly recorded in an artifact). Because software still exhibits incorrect behavior, a different approach is needed. This paper presents a systematic literature review to develop taxonomy of errors (i.e., the sources of faults) that may occur during the requirements phase of software lifecycle. This taxonomy is designed to aid developers during the requirement inspection process and to improve overall software quality. The review identified 149 papers from the software engineering, psychology and human cognition literature that provide information about the sources of requirements faults. A major result of this paper is a categorization of the sources of faults into a formal taxonomy that provides a starting point for future research into error-based approaches to improving software quality.}
}

@article{rayyan-727967524,
  title={Current state of research on cross-site scripting (XSS) – A systematic literature review},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={58},
  pages={170-186},
  author={Hydara, Isatou and Sultan, Abu Bakar Md. and Zulzalil, Hazura and Admodisastro, Novia},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914001700},
  keywords={Systematic literature review, Security, Web applications, Cross-site scripting},
  abstract={Context Cross-site scripting (XSS) is a security vulnerability that affects web applications. It occurs due to improper or lack of sanitization of user inputs. The security vulnerability caused many problems for users and server applications. Objective To conduct a systematic literature review on the studies done on XSS vulnerabilities and attacks. Method We followed the standard guidelines for systematic literature review as documented by Barbara Kitchenham and reviewed a total of 115 studies related to cross-site scripting from various journals and conference proceedings. Results Research on XSS is still very active with publications across many conference proceedings and journals. Attack prevention and vulnerability detection are the areas focused on by most of the studies. Dynamic analysis techniques form the majority among the solutions proposed by the various studies. The type of XSS addressed the most is reflected XSS. Conclusion XSS still remains a big problem for web applications, despite the bulk of solutions provided so far. There is no single solution that can effectively mitigate XSS attacks. More research is needed in the area of vulnerability removal from the source code of the applications before deployment.}
}

@article{rayyan-727967525,
  title={Enactment of adaptation in data stream processing with latency implications—A systematic literature review},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={111},
  pages={1-21},
  author={Qin, Cui and Eichelberger, Holger and Schmid, Klaus},
  url={https://www.sciencedirect.com/science/article/pii/S0950584919300539},
  keywords={Systematic literature review, Big data, Enactment, Latency, Runtime adaptation, Stream processing},
  abstract={Context Stream processing is a popular paradigm to continuously process huge amounts of data. Runtime adaptation plays a significant role in supporting the optimization of data processing tasks. In recent years runtime adaptation has received significant interest in scientific literature. However, so far no categorization of the enactment approaches for runtime adaptation in stream processing has been established. Objective This paper identifies and characterizes different approaches towards the enactment of runtime adaptation in stream processing with a main focus on latency as quality dimension. Method We performed a systematic literature review (SLR) targeting five main research questions. An automated search, resulting in 244 papers, was conducted. 75 papers published between 2006 and 2018 were finally included. From the selected papers, we extracted data like processing problems, adaptation goals, enactment approaches of adaptation, enactment techniques, evaluation metrics as well as evaluation parameters used to trigger the enactment of adaptation in their evaluation. Results We identified 17 different enactment approaches and categorized them into a taxonomy. For each, we extracted the underlying technique used to implement this enactment approach. Further, we identified 9 categories of processing problems, 6 adaptation goals, 9 evaluation metrics and 12 evaluation parameters according to the extracted data properties. Conclusion We observed that the research interest on enactment approaches to the adaptation of stream processing has significantly increased in recent years. The most commonly applied enactment approaches are parameter adaptation to tune parameters or settings of the processing, load balancing used to re-distribute workloads, and processing scaling to dynamically scale up and down the processing. In addition to latency, most adaptations also address resource fluctuation / bottleneck problems. For presenting a dynamic environment to evaluate enactment approaches, researchers often change input rates or processing workloads.}
}

@article{rayyan-727967526,
  title={The impact of information security events to the stock market: A systematic literature review},
  year={2016},
  journal={Computers & Security},
  issn={0167-4048},
  volume={58},
  pages={216-229},
  author={Spanos, Georgios and Angelis, Lefteris},
  url={https://www.sciencedirect.com/science/article/pii/S0167404816300013},
  keywords={Literature review, Event study, Information security, Security breaches, Stock market},
  abstract={Information security is a highly critical aspect of information systems. Although the literature regarding security assurance is vast, the research on economic consequences of security incidents is quite limited. The purpose of this systematic review is to search, collect and classify event studies related to information security impact on stock prices. In total, 37 related papers conducting 45 studies were found by the systematic search of bibliographic sources. The majority (75.6%) of these studies report statistical significance of the impact of security events to the stock prices of firms.}
}

@article{rayyan-727967527,
  title={Machine learning techniques for code smell detection: A systematic literature review and meta-analysis},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={108},
  pages={115-138},
  author={Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918302623},
  keywords={Systematic literature review, Machine learning, Code smells, Smell},
  abstract={Background: Code smells indicate suboptimal design or implementation choices in the source code that often lead it to be more change- and fault-prone. Researchers defined dozens of code smell detectors, which exploit different sources of information to support developers when diagnosing design flaws. Despite their good accuracy, previous work pointed out three important limitations that might preclude the use of code smell detectors in practice: (i) subjectiveness of developers with respect to code smells detected by such tools, (ii) scarce agreement between different detectors, and (iii) difficulties in finding good thresholds to be used for detection. To overcome these limitations, the use of machine learning techniques represents an ever increasing research area. Objective: While the research community carefully studied the methodologies applied by researchers when defining heuristic-based code smell detectors, there is still a noticeable lack of knowledge on how machine learning approaches have been adopted for code smell detection and whether there are points of improvement to allow a better detection of code smells. Our goal is to provide an overview and discuss the usage of machine learning approaches in the field of code smells. Method: This paper presents a Systematic Literature Review (SLR) on Machine Learning Techniques for Code Smell Detection. Our work considers papers published between 2000 and 2017. Starting from an initial set of 2456 papers, we found that 15 of them actually adopted machine learning approaches. We studied them under four different perspectives: (i) code smells considered, (ii) setup of machine learning approaches, (iii) design of the evaluation strategies, and (iv) a meta-analysis on the performance achieved by the models proposed so far. Results: The analyses performed show that God Class, Long Method, Functional Decomposition, and Spaghetti Code have been heavily considered in the literature. Decision Trees and Support Vector Machines are the most commonly used machine learning algorithms for code smell detection. Models based on a large set of independent variables have performed well. JRip and Random Forest are the most effective classifiers in terms of performance. The analyses also reveal the existence of several open issues and challenges that the research community should focus on in the future. Conclusion: Based on our findings, we argue that there is still room for the improvement of machine learning techniques in the context of code smell detection. The open issues emerged in this study can represent the input for researchers interested in developing more powerful techniques.}
}

@article{rayyan-727967529,
  title={Integration between requirements engineering and safety analysis: A systematic literature review},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={125},
  pages={68-92},
  author={Vilela, Jéssyka and Castro, Jaelson and Martins, Luiz Eduardo G and Gorschek, Tony},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216302333},
  keywords={Systematic literature review, Requirements engineering, Integration, Communication, Safety analysis, Safety-critical systems},
  abstract={Context: Safety-Critical Systems (SCS) require more sophisticated requirements engineering (RE) approaches as inadequate, incomplete or misunderstood requirements have been recognized as a major cause in many accidents and safety-related catastrophes. Objective: In order to cope with the complexity of specifying SCS by RE, we investigate the approaches proposed to improve the communication or integration between RE and safety engineering in SCS development. We analyze the activities that should be performed by RE during safety analysis, the hazard/safety techniques it could use, the relationships between safety information that it should specify, the tools to support safety analysis as well as integration benefits between these areas. Method: We use a Systematic Literature Review (SLR) as the basis for our work. Results: We developed four taxonomies to help RE during specification of SCS that classify: techniques used in (1) hazard analysis; (2) safety analysis; (3) safety-related information and (4) a detailed set of information regarding hazards specification. Conclusions: This paper is a step towards developing a body of knowledge in safety concerns necessary to RE in the specification of SCS that is derived from a large-scale SLR. We believe the results will benefit both researchers and practitioners.}
}

@article{rayyan-727967530,
  title={A systematic literature review on QoS-aware service composition and selection in cloud environment},
  year={2018},
  journal={Journal of Network and Computer Applications},
  issn={1084-8045},
  volume={110},
  pages={52-74},
  author={Hayyolalam, Vahideh and Pourhaji Kazem, Ali Asghar},
  url={https://www.sciencedirect.com/science/article/pii/S1084804518300845},
  keywords={Cloud computing, Quality of service (QoS), QoS-aware service composition, QoS-aware service selection},
  abstract={Generally, cloud computing consists of providing virtualized and scalable resources as services through the Internet dynamically. According to the costumers' requests, various types of services which have the same functionality with different non-functionality features, are delivered in the cloud environment that often should be combined to satisfy the customer's complex requests. Recently, the composition of unique and loosely-coupled services into a preferred system is a prevalent industrial method and a commonly tracked research topic in academia. Service composition deals with generating new value-added services by merging some single existing services to provide an optimal composite service which includes formerly existing single and simple services aims to improve Quality of service (QoS). To the best of our knowledge, in spite of this issue's significance in cloud computing, there is not any comprehensive and systematic single research about this issue with a particular focus on QoS, which takes all metrics inspected in this paper into consideration. The most notable and impact of this paper is that it does not eliminate any paper in this scope, also it investigates more criteria than the current surveys. Hence, the purpose of this paper is to investigate the former mechanisms and techniques in terms of numerous factors. So, it adopts a systematic literature review, vital questions which can be enhanced by the research accomplished to address the stated problem have been extracted and raised. Afterwards, by classifying the researches into two primary groups (centralized and distributed) based on the environment of the problem and identifying the inspected QoS parameters, predefined goals, and developing environments, appropriate outcomes and statistics are attained that can contribute to upcoming works. In other words, this paper focuses to systematically categorize and evaluate the current research approaches and strategies on QoS-aware cloud service composition (published up to August 2017).}
}

@article{rayyan-727967531,
  title={Information technology service management models applied to medium and small organizations: A systematic literature review},
  year={2016},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={47},
  pages={120-127},
  author={Melendez, Karin and Dávila, Abraham and Pessoa, Marcelo},
  url={https://www.sciencedirect.com/science/article/pii/S0920548915001166},
  keywords={ISO/IEC 20000, ITIL, CMMI-SVC, Service process model, Small organization},
  abstract={(ANTECEDENT) The main responsibility of the Information Technology Service Management (ITSM) as an organization is to provide services in high level quality. That implies that the services will be an appropriate service and it will ensure continuity. In this context, the organization needs to adopt the best practices in service management to be more efficient and competitive. Some ITSM models collect the best practices of recognized organizations. These models are mainly applied by large organizations. (OBJECTIVE) The objective of this study is to gather experiences in the application of ITSM models in small organizations. (METHODS) To achieve this objective a systematic literature review was performed. (RESULTS) We found primary studies applied to IT areas from some large and medium companies but there is a few in small companies' context. (CONCLUSION) During the SLR we have identified some improvements and difficulties in many organizations, we have founded when applying ITSM models. The principal difficulty was the lack of knowledge of its personnel and consultants have, for adopting a model. On the other hand, companies who succeeded in the application of an ITSM model, had founded some benefits, such as processes improvement, higher user satisfaction, and service cost and time reduction.}
}

@article{rayyan-727967534,
  title={Enhancing computing studies in high schools: A systematic literature review & UAE case study},
  year={2019},
  journal={Heliyon},
  issn={2405-8440},
  volume={5},
  number={2},
  pages={e01235},
  author={Talib, Manar Abu and Einea, Omar and Nasir, Qassim and Mowakeh, Mohamad Fouzi and Eltawil, Mohamed},
  url={https://www.sciencedirect.com/science/article/pii/S2405844018334807},
  keywords={Education, Computer science},
  abstract={Open source software (OSS) is increasingly being integrated into educational institutions, and many countries require the use of OSS in government departments. However, not much focus is placed on integrating it into the educational sector in a strategic and productive manner. This paper examines the existing literature on the use of OSS in terms of the potential enhancements it can provide for computer science studies in high schools in general, and those in the UAE more specifically. It also details a survey conducted among 400 high school teachers after teaching them about multiple types of OSS that might enhance their teaching experience. After examining more than 69 different research papers and taking the survey findings into account, we drafted a roadmap that can be used by any educational institute—especially high schools—to strategically integrate OSS into the educational system.}
}

@article{rayyan-727967535,
  title={Software ecosystems – A systematic literature review},
  year={2013},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={86},
  number={5},
  pages={1294-1306},
  author={Manikas, Konstantinos and Hansen, Klaus Marius},
  url={https://www.sciencedirect.com/science/article/pii/S016412121200338X},
  keywords={Systematic literature review, Software ecosystem, Software ecosystems, Software},
  abstract={A software ecosystem is the interaction of a set of actors on top of a common technological platform that results in a number of software solutions or services. Arguably, software ecosystems are gaining importance with the advent of, e.g., the Google Android, Apache, and Salesforce.com ecosystems. However, there exists no systematic overview of the research done on software ecosystems from a software engineering perspective. We performed a systematic literature review of software ecosystem research, analyzing 90 papers on the subject taken from a gross collection of 420. Our main conclusions are that while research on software ecosystems is increasing (a) there is little consensus on what constitutes a software ecosystem, (b) few analytical models of software ecosystems exist, and (c) little research is done in the context of real-world ecosystems. This work provides an overview of the field, while identifying areas for future research.}
}

@article{rayyan-727967536,
  title={Port sustainability and performance: A systematic literature review},
  year={2019},
  journal={Transportation Research Part D: Transport and Environment},
  issn={1361-9209},
  volume={72},
  pages={47-64},
  author={Lim, Sehwa and Pettit, Stephen and Abouarghoub, Wessam and Beresford, Anthony},
  url={https://www.sciencedirect.com/science/article/pii/S1361920918311520},
  abstract={Motivated by a lack of research on port sustainability performance and assessment, this paper uses a systematic literature review to identify trends, measurement methods, and mechanisms for the implementation of strategy and policy in this area. The paper provides a comprehensive and critical evaluation of port operational sustainability, focusing on ascertaining the impact of its implementation. The study analysed and synthesised established characteristics in the current literature regarding the performance of port sustainability and its evaluation in terms of operations and management. Successful performance measurement in port sustainability is driven by the dependence on establishing accurate indicators as the basis for measurement. Our clustering of analytical sustainability indicators reveals that environmental research is focused on pollution, social research is mainly focused on human resource management, while economic research is mainly on port management and borderline investment. Findings are discussed in four key areas of port sustainability performance and assessment: existing trends, implementation of measures, mechanisms for implementation, and assessment gaps and challenges. For existing trends, attempts to evaluate the applicability and practicality of green operations have improved the awareness and promotion of governmental green policies. Implementation measures relate to the utilisation of techniques that reveal optimal practices for practical sustainable operations while mechanisms largely relate to establishing indicators which increase understanding of performance. Finally, challenges in this field include achieving consistency among ports in how sustainability is measured. Future research should incentivise improvements in port operational practice and encourage self-examination in order to reprioritise activity.}
}

@article{rayyan-727967537,
  title={A systematic review on the engineering of software for ubiquitous systems},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={118},
  pages={251-276},
  author={Sánchez Guinea, Alejandro and Nain, Grégory and Le Traon, Yves},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216300553},
  keywords={Evidence-based software engineering, Empirical software engineering, Systematic review, Research synthesis, Development methods, Pervasive systems, Software development cycle, Ubiquitous systems, Software},
  abstract={Context: Software engineering for ubiquitous systems has experienced an important and rapid growth, however the vast research corpus makes it difficult to obtain valuable information from it. Objective: To identify, evaluate, and synthesize research about the most relevant approaches addressing the different phases of the software development life cycle for ubiquitous systems. Method: We conducted a systematic literature review of papers presenting and evaluating approaches for the different phases of the software development life cycle for ubiquitous systems. Approaches were classified according to the phase of the development cycle they addressed, identifying their main concerns and limitations. Results: We identified 128 papers reporting 132 approaches addressing issues related to different phases of the software development cycle for ubiquitous systems. Most approaches have been aimed at addressing the implementation, evolution/maintenance, and feedback phases, while others phases such as testing need more attention from researchers. Conclusion: We recommend to follow existing guidelines when conducting case studies to make the studies more reproducible and closer to real life cases. While some phases of the development cycle have been extensively explored, there is still room for research in other phases, toward a more agile and integrated cycle, from requirements to testing and feedback.}
}

@article{rayyan-727967538,
  title={Agile, web engineering and capability maturity model integration: A systematic literature review.},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={71},
  pages={92-107},
  author={Torrecilla-Salinas, C J and Sedeño, J and Escalona, M J and Mejías, M},
  url={https://www.sciencedirect.com/science/article/pii/S095058491500186X},
  keywords={Software Engineering, Scrum, Agile, CMMI, Web Engineering},
  abstract={Context Agile approaches are an alternative for organizations developing software, particularly for those who develop Web applications. Besides, CMMI (Capability Maturity Model Integration) models are well-established approaches focused on assessing the maturity of an organization that develops software. Web Engineering is the field of Software Engineering responsible for analyzing and studying the specific characteristics of the Web. The suitability of an Agile approach to help organizations reach a certain CMMI maturity level in Web environments will be very interesting, as they will be able to keep the ability to quickly react and adapt to changes as long as their development processes get mature. Objective This paper responds to whether it is feasible or not, for an organization developing Web systems, to achieve a certain maturity level of the CMMI-DEV model using Agile methods. Method The proposal is analyzed by means of a systematic literature review of the relevant approaches in the field, defining a characterization schema in order to compare them to introduce the current state-of-the-art. Results The results achieved after the systematic literature review are presented, analyzed and compared against the defined schema, extracting relevant conclusions for the different dimensions of the problem: compatibility, compliance, experience, maturity and Web. Conclusion It is concluded that although the definition of an Agile approach to meet the different CMMI maturity levels goals could be possible for an organization developing Web systems, there is still a lack of detailed studies and analysis on the field.}
}

@article{rayyan-727967540,
  title={IT service management process improvement based on ISO/IEC 15504: A systematic review},
  year={2012},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={54},
  number={3},
  pages={239-247},
  author={Mesquida, Antoni Lluís and Mas, Antonia and Amengual, Esperança and Calvo-Manzano, Jose A},
  url={https://www.sciencedirect.com/science/article/pii/S0950584911002266},
  keywords={Systematic review, ISO/IEC 15504 (SPICE), IT Service Management (ITSM), Software Process Improvement (SPI)},
  abstract={Context In recent years, many software companies have considered Software Process Improvement (SPI) as essential for successful software development. These companies have also shown special interest in IT Service Management (ITSM). SPI standards have evolved to incorporate ITSM best practices. Objective This paper presents a systematic literature review of ITSM Process Improvement initiatives based on the ISO/IEC 15504 standard for process assessment and improvement. Method A systematic literature review based on the guidelines proposed by Kitchenham and the review protocol template developed by Biolchini et al. is performed. Results Twenty-eight relevant studies related to ITSM Process Improvement have been found. From the analysis of these studies, nine different ITSM Process Improvement initiatives have been detected. Seven of these initiatives use ISO/IEC 15504 conformant process assessment methods. Conclusion During the last decade, in order to satisfy the on-going demand of mature software development companies for assessing and improving ITSM processes, different models which use the measurement framework of ISO/IEC 15504 have been developed. However, it is still necessary to define a method with the necessary guidelines to implement both software development processes and ITSM processes reducing the amount of effort, especially because some processes of both categories are overlapped.}
}

@article{rayyan-727967541,
  title={Challenges and success factors for large-scale agile transformations: A systematic literature review},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={119},
  pages={87-108},
  author={Dikert, Kim and Paasivaara, Maria and Lassenius, Casper},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216300826},
  keywords={Systematic literature review, Agile software development, Challenges, Success factors, Adopting agile software development, Large-scale agile, Organizational transformation},
  abstract={Agile methods have become an appealing alternative for companies striving to improve their performance, but the methods were originally designed for small and individual teams. This creates unique challenges when introducing agile at scale, when development teams must synchronize their activities, and there might be a need to interface with other organizational units. In this paper we present a systematic literature review on how agile methods and lean software development has been adopted at scale, focusing on reported challenges and success factors in the transformation. We conducted a systematic literature review of industrial large-scale agile transformations. Our keyword search found 1875 papers. We included 52 publications describing 42 industrial cases presenting the process of taking large-scale agile development into use. Almost 90% of the included papers were experience reports, indicating a lack of sound academic research on the topic. We identified 35 reported challenges grouped into nine categories, and 29 success factors, grouped into eleven categories. The most salient success factor categories were management support, choosing and customizing the agile model, training and coaching, and mindset and alignment.}
}

@article{rayyan-727967542,
  title={A systematic literature review of blockchain cyber security},
  year={2020},
  journal={Digital Communications and Networks},
  issn={2352-8648},
  volume={6},
  number={2},
  pages={147-156},
  author={Taylor, Paul J and Dargahi, Tooska and Dehghantanha, Ali and Parizi, Reza M and Choo, Kim-Kwang Raymond},
  url={https://www.sciencedirect.com/science/article/pii/S2352864818301536},
  keywords={Blockchain, Smart contracts, IoT, Cryptocurrency, Cyber security, Bitcoin, Distributed ledger technology},
  abstract={Since the publication of Satoshi Nakamoto's white paper on Bitcoin in 2008, blockchain has (slowly) become one of the most frequently discussed methods for securing data storage and transfer through decentralized, trustless, peer-to-peer systems. This research identifies peer-reviewed literature that seeks to utilize blockchain for cyber security purposes and presents a systematic analysis of the most frequently adopted blockchain security applications. Our findings show that the Internet of Things (IoT) lends itself well to novel blockchain applications, as do networks and machine visualization, public-key cryptography, web applications, certification schemes and the secure storage of Personally Identifiable Information (PII). This timely systematic review also sheds light on future directions of research, education and practices in the blockchain and cyber security space, such as security of blockchain in IoT, security of blockchain for AI data, and sidechain security.}
}

@article{rayyan-727967543,
  title={Systematic literature review of industry 4.0 maturity model for manufacturing and logistics sectors},
  year={2020},
  journal={Procedia Manufacturing},
  issn={2351-9789},
  volume={52},
  pages={337-343},
  author={Angreani, Linda Salma and Vijaya, Annas and Wicaksono, Hendro},
  url={https://www.sciencedirect.com/science/article/pii/S2351978920322010},
  keywords={Systematic Literature Review, Production, Industry 4.0 Maturity Model, Industry 4.0 Readiness, Logistics},
  abstract={A maturity model is a wide technique to measure several aspects and identify the current state of processes in an organization, which can be used as a starting point for business improvement. In the Industry 4.0 context, several terms are used to express the model, such as readiness assessment model, roadmap, framework, and maturity index. They have the same purpose of measuring how the current state of an organization unit is capable of adopting and implementing the concept of industry 4.0 in the future. Many researchers had proposed maturity models for assessing Industry 4.0 readiness and maturity since 2011 when Industry 4.0 was commenced. However, there has been no attempt to analyze empirical evidence systematically. This paper aims to analyze currently available maturity models related to Industry 4.0 and provide a synthesis on those maturity models. This paper describes a systematic literature review (SLR) of empirical studies implemented on the maturity model published in several reputable and relevant sources. It focuses on the manufacturing and logistics sectors since the processes in both sectors can be highly improved through the introduction of technologies such as cyber-physical systems, internet of things, and artificial intelligence. In general, the primary purpose of the review is to address the following questions: (1) Based on what dimensions do researchers develop Industry 4.0 maturity models, and what are the most used and influencing parameters in those dimensions? (2) How do those maturity models compare to each other in terms of dimension complexity, techniques, maturity leveling, and kind of application sectors of the model? In conclusion, the maturity model in the context of Industry 4.0 is promising to guide the adoption of industry 4.0 technologies at the organization level. However, just having a maturity model is not enough. More efforts are needed to facilitate the application of it.}
}

@article{rayyan-727967544,
  title={Test case prioritization approaches in regression testing: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={93},
  pages={74-93},
  author={Khatibsyarbini, Muhammad and Isa, Mohd Adham and Jawawi, Dayang N A and Tumeng, Rooster},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916304888},
  keywords={Software testing, Systematic literature review, Regression testing, Test case prioritization},
  abstract={Context Software quality can be assured by going through software testing process. However, software testing phase is an expensive process as it consumes a longer time. By scheduling test cases execution order through a prioritization approach, software testing efficiency can be improved especially during regression testing. Objective It is a notable step to be taken in constructing important software testing environment so that a system's commercial value can increase. The main idea of this review is to examine and classify the current test case prioritization approaches based on the articulated research questions. Method Set of search keywords with appropriate repositories were utilized to extract most important studies that fulfill all the criteria defined and classified under journal, conference paper, symposiums and workshops categories. 69 primary studies were nominated from the review strategy. Results There were 40 journal articles, 21 conference papers, three workshop articles, and five symposium articles collected from the primary studies. As for the result, it can be said that TCP approaches are still broadly open for improvements. Each approach in TCP has specified potential values, advantages, and limitation. Additionally, we found that variations in the starting point of TCP process among the approaches provide a different timeline and benefit to project manager to choose which approaches suite with the project schedule and available resources. Conclusion Test case prioritization has already been considerably discussed in the software testing domain. However, it is commonly learned that there are quite a number of existing prioritization techniques that can still be improved especially in data used and execution process for each approach.}
}

@article{rayyan-727967545,
  title={An overview of software functionality service: A systematic literature review},
  year={2017},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={124},
  pages={337-344},
  author={Salleh, Masrina A and Bahari, Mahadi and Zakaria, Nor Hidayati},
  url={https://www.sciencedirect.com/science/article/pii/S1877050917329319},
  keywords={Systematic Literature Review, Functionality Service, Okoli Guideline, Software Functionality Quality, Software},
  abstract={This study focuses in contributing a literature on software functionality service area. We aim to provide an overview of software functionality service related to its research activity, investigated the major themes and identiﬁed the focus on its sub-characteristics addressed. In doing this, we employed a Systematic Literature Review (SLR) approach by reviewing all relevant articles from four online databases (i.e., IEEE, Springer, ScienceDirect and EmaraldInsight) and finally identified only 79 relevant articles to our research questions. We categorized the articles into its major themes discussed and its sub-characteristics addressed. It is found that there are increased of researched related to software functionality service for the last five years mainly in functionality service development while there is still lack of research coverage on functional compliance sub-characteristics. Future work should be included of reviewing a greater number of articles from more various types of journal and workshop.}
}

@article{rayyan-727967546,
  title={Model-Driven Engineering as a new landscape for traceability management: A systematic literature review},
  year={2012},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={54},
  number={12},
  pages={1340-1356},
  author={Santiago, Iván and Jiménez, Álvaro and Vara, Juan Manuel and De Castro, Valeria and Bollati, Verónica A and Marcos, Esperanza},
  url={https://www.sciencedirect.com/science/article/pii/S0950584912001346},
  keywords={Systematic literature review, Model-Driven Engineering, Traceability},
  abstract={Context Model-Driven Engineering provides a new landscape for dealing with traceability in software development. Objective Our goal is to analyze the current state of the art in traceability management in the context of Model-Driven Engineering. Method We use the systematic literature review based on the guidelines proposed by Kitchenham. We propose five research questions and six quality assessments. Results Of the 157 relevant studies identified, 29 have been considered primary studies. These studies have resulted in 17 proposals. Conclusion The evaluation shows that the most addressed operations are storage, CRUD and visualization, while the most immature operations are exchange and analysis traceability information.}
}

@article{rayyan-727967547,
  title={Software component decision-making: In-house, OSS, COTS or outsourcing - A systematic literature review},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={121},
  pages={105-124},
  author={Badampudi, Deepika and Wohlin, Claes and Petersen, Kai},
  url={https://www.sciencedirect.com/science/article/pii/S0164121216301212},
  keywords={OSS, Component-based software engineering, Outsourcing, COTS, Decision-making, In-house development, Decision Making, Software},
  abstract={Context: Component-based software systems require decisions on component origins for acquiring components. A component origin is an alternative of where to get a component from. Objective: To identify factors that could influence the decision to choose among different component origins and solutions for decision-making (For example, optimization) in the literature. Method: A systematic review study of peer-reviewed literature has been conducted. Results: In total we included 24 primary studies. The component origins compared were mainly focused on in-house vs. COTS and COTS vs. OSS. We identified 11 factors affecting or influencing the decision to select a component origin. When component origins were compared, there was little evidence on the relative (either positive or negative) effect of a component origin on the factor. Most of the solutions were proposed for in-house vs. COTS selection and time, cost and reliability were the most considered factors in the solutions. Optimization models were the most commonly proposed technique used in the solutions. Conclusion: The topic of choosing component origins is a green field for research, and in great need of empirical comparisons between the component origins, as well of how to decide between different combinations of them.}
}

@article{rayyan-727967548,
  title={Metrics for analyzing variability and its implementation in software product lines: A systematic literature review},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={106},
  pages={1-30},
  author={El-Sharkawy, Sascha and Yamagishi-Eichler, Nozomi and Schmid, Klaus},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301873},
  keywords={Software product lines, Systematic literature review, Metrics, Implementation, SPL, Metronidazole, Software},
  abstract={Context: Software Product Line (SPL) development requires at least concepts for variability implementation and variability modeling for deriving products from a product line. These variability implementation concepts are not required for the development of single systems and, thus, are not considered in traditional software engineering. Metrics are well established in traditional software engineering, but existing metrics are typically not applicable to SPLs as they do not address variability management. Over time, various specialized product line metrics have been described in literature, but no systematic description of these metrics and their characteristics is currently available. Objective: This paper describes and analyzes variability-aware metrics, designed for the needs of software product lines. More precisely we restrict the scope of our study explicitly to metrics designed for variability models, code artifacts, and metrics taking both kinds of artifacts into account. Further, we categorize the purpose for which these metrics were developed. We also analyze to what extent these metrics were evaluated to provide a basis for researchers for selecting adequate metrics. Method: We conducted a systematic literature review to identify variability-aware implementation metrics. We discovered 42 relevant papers reporting metrics intended to measure aspects of variability models or code artifacts. Results: We identified 57 variability model metrics, 34 annotation-based code metrics, 46 code metrics specific to composition-based implementation techniques, and 10 metrics integrating information from variability model and code artifacts. For only 31 metrics, an evaluation was performed assessing their suitability to draw any qualitative conclusions. Conclusions: We observed several problematic issues regarding the definition and the use of the metrics. Researchers and practitioners benefit from the catalog of variability-aware metrics, which is the first of its kind. Also, the research community benefits from the identified observations in order to avoid those problems when defining new metrics.}
}

@article{rayyan-727967549,
  title={A systematic literature review on serious games evaluation: An application to software project management},
  year={2015},
  journal={Computers & Education},
  issn={0360-1315},
  volume={87},
  pages={396-422},
  author={Calderón, Alejandro and Ruiz, Mercedes},
  url={https://www.sciencedirect.com/science/article/pii/S0360131515300166},
  keywords={Systematic literature review, Software project management, Evaluation, Serious game, Software},
  abstract={Training that future practitioners receive in software project management is a topic of great importance. The objective of this systematic literature review is to summarize the current state of the art of the different methods and procedures used to assess serious games. The review follows a predefined procedure that involves automatically searching well-known digital databases. 1199 papers were found by the automatic searches in the digital databases and 102 papers were selected as primary studies. The process was complemented with manual searches using author and backward snowballing techniques. Our systematic literature review identified the main methods followed to assess serious games, the application domains in which the assessments took place, the categories of serious games assessed, the main features considered to assess the educational effectiveness of serious games, the procedures followed for the assessments and the size of the population that participated in the assessments. The results are useful to researchers and practitioners willing to assess serious games in different fields, but specially to those interested in assessing serious games in the area of software project management.}
}

@article{rayyan-727967550,
  title={Formal verification approaches for distributed algorithms: A systematic literature review},
  year={2018},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={126},
  pages={1551-1560},
  author={Fakhfakh, Faten and Tounsi, Mohamed and Mosbah, Mohamed and Kacem, Ahmed Hadj},
  url={https://www.sciencedirect.com/science/article/pii/S1877050918314066},
  keywords={formal verification, challenges, Distributed algorithms, dynamic networks, static, taxonomy, Algorithms},
  abstract={Distributed algorithms have become a rapidly growing field of research due to the advances of the network technologies. However, they are very difficult to implement correctly because they must meet many requirements. In this paper, we follow the guidelines of systematic literature reviews to provide a survey of the existing works ensuring the formal verification of distributed algorithms in static and dynamic networks. Then, we develop a taxonomy of these solutions based on some criteria. Also, a discussion on each criterion is shown with a focus on constraints, requirements and challenges. Finally, we identify some recommendations and open research areas which can motivate the development of more efficient solutions. So, throughout this present paper, we provide information for researchers and developers to understand the contributions and challenges of the existing solutions to pave the way for enhancing their reliability.}
}

@article{rayyan-727967551,
  title={Knowledge-based approaches in software documentation: A systematic literature review},
  year={2014},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={56},
  number={6},
  pages={545-567},
  author={Ding, Wei and Liang, Peng and Tang, Antony and van Vliet, Hans},
  url={https://www.sciencedirect.com/science/article/pii/S0950584914000196},
  keywords={Systematic literature review, Software documentation, Knowledge activity, Knowledge-based approach, Software architecture design, Software},
  abstract={Context Software documents are core artifacts produced and consumed in documentation activity in the software lifecycle. Meanwhile, knowledge-based approaches have been extensively used in software development for decades, however, the software engineering community lacks a comprehensive understanding on how knowledge-based approaches are used in software documentation, especially documentation of software architecture design. Objective The objective of this work is to explore how knowledge-based approaches are employed in software documentation, their influences to the quality of software documentation, and the costs and benefits of using these approaches. Method We use a systematic literature review method to identify the primary studies on knowledge-based approaches in software documentation, following a pre-defined review protocol. Results Sixty studies are finally selected, in which twelve quality attributes of software documents, four cost categories, and nine benefit categories of using knowledge-based approaches in software documentation are identified. Architecture understanding is the top benefit of using knowledge-based approaches in software documentation. The cost of retrieving information from documents is the major concern when using knowledge-based approaches in software documentation. Conclusions The findings of this review suggest several future research directions that are critical and promising but underexplored in current research and practice: (1) there is a need to use knowledge-based approaches to improve the quality attributes of software documents that receive less attention, especially credibility, conciseness, and unambiguity; (2) using knowledge-based approaches with the knowledge content in software documents which gets less attention in current applications of knowledge-based approaches in software documentation, to further improve the practice of software documentation activity; (3) putting more focus on the application of software documents using the knowledge-based approaches (knowledge reuse, retrieval, reasoning, and sharing) in order to make the most use of software documents; and (4) evaluating the costs and benefits of using knowledge-based approaches in software documentation qualitatively and quantitatively.}
}

@article{rayyan-727967555,
  title={An investigation into the best practices for the successful design and implementation of lightweight software process assessment methods: A systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={101},
  pages={180-192},
  author={Zarour, Mohammad and Abran, Alain and Desharnais, Jean-Marc and Alarifi, Abdulrahman},
  url={https://www.sciencedirect.com/science/article/pii/S0164121214002726},
  keywords={systematic literature review, assessment method design, software process assessment, Process Assessment (Health Care), Software},
  abstract={Software process assessment (SPA) is an effective tool to understand an organization's process quality and to explore improvement opportunities. However, the knowledge that underlies the best practices required to develop assessment methods, either lightweight or heavyweight methods, is unfortunately scattered throughout the literature. This paper presents the results of a systematic literature review to organize those recognized as the best practices in a way that helps SPA researchers and practitioners in designing and implementing their assessment methods. Such practices are presented in the literature as assessment requirements, success factors, observations, and lessons learned. Consequently, a set of 38 best practices has been collected and classified into five main categories, namely practices related to SPA methods, support tools, procedures, documentation, and users. While this collected set of best practices is important for designing lightweight as well as heavyweight assessment methods, it is of utmost importance in designing lightweight assessment methods, as the design of which depends on individual experience.}
}

@article{rayyan-727967557,
  title={Process models for service-based applications: A systematic literature review},
  year={2011},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={53},
  number={5},
  pages={424-439},
  author={Lane, Stephen and Richardson, Ita},
  url={https://www.sciencedirect.com/science/article/pii/S0950584910002211},
  keywords={Systematic literature review, SOA, Software process, Service-based application},
  abstract={Context Service-Oriented Computing (SOC) is a promising computing paradigm which facilitates the development of adaptive and loosely coupled service-based applications (SBAs). Many of the technical challenges pertaining to the development of SBAs have been addressed, however, there are still outstanding questions relating to the processes required to develop them. Objective The objective of this study is to systematically identify process models for developing service-based applications (SBAs) and review the processes within them. This will provide a useful starting point for any further research in the area. A secondary objective of the study is to identify process models which facilitate the adaptation of SBAs. Method In order to achieve this objective a systematic literature review (SLR) of the existing software engineering literature is conducted. Results During this research 722 studies were identified using a predefined search strategy, this number was narrowed down to 57 studies based on a set of strict inclusion and exclusion criteria. The results are reported both quantitatively in the form of a mapping study, as well as qualitatively in the form of a narrative summary of the key processes identified. Conclusion There are many process models reported for the development of SBAs varying in detail and maturity, this review has identified and categorised the processes within those process models. The review has also identified and evaluated process models which facilitate the adaptation of SBAs.}
}

@article{rayyan-727967558,
  title={Peer to peer (P2P) lending problems and potential solutions: A systematic literature review},
  year={2019},
  journal={Procedia Computer Science},
  issn={1877-0509},
  volume={161},
  pages={204-214},
  author={Suryono, Ryan Randy and Purwandari, Betty and Budi, Indra},
  url={https://www.sciencedirect.com/science/article/pii/S1877050919318265},
  keywords={Systematic Literature Review, Fintech, P2P Lending},
  abstract={There is a growing Financial Technology (Fintech) business model, such as Peer to Peer (P2P) Lending. P2P Lending allows individuals and businesses to borrow and lend money to each other. In its development, China has become the market with the most P2P lending platforms. However, there is a moral hazard that makes this business need to be monitored. This threat begins with verification of the borrower's data that is not appropriate. Whereas in Indonesia Fintech P2P Lending has received special attention, because its regulations and policies have not matured yet. Besides, P2P Lending is considered as a new business to flourish. Consequently, it requires investigation on problems from the implementation of the P2P Lending. This study aims to identify problems in P2P Lending and present alternative technical and non-technical solutions to the problems. By implementing the Kitchenham Systematic Literature Review (SLR) approach from the ACM, AIS, IEEE, SCOPUS, and Science Direct databases, this research finds a rich picture, creates a table of problem identification and alternative solutions.}
}

@article{rayyan-727967559,
  title={A systematic literature review of stakeholder identification methods in requirements elicitation},
  year={2012},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={85},
  number={9},
  pages={2171-2181},
  author={Pacheco, Carla and Garcia, Ivan},
  url={https://www.sciencedirect.com/science/article/pii/S0164121212001288},
  keywords={Software engineering, Systematic review, Requirements engineering, Requirements elicitation, Stakeholder identification},
  abstract={This paper presents a systematic review of relevant published studies related to topics in Requirements Engineering, specifically, concerning stakeholder identification methods in requirements elicitation, dated from 1984 to 2011. Addressing four specific research questions, this systematic literature review shows the following evidence gathered from these studies: current status of stakeholder identification in software requirement elicitation, the best practices recommended for its performance, consequences of incorrect identification in requirements quality, and, aspects which need to be improved. Our findings suggest that the analyzed approaches still have serious limitations in terms of covering all aspects of stakeholder identification as an important part of requirements elicitation. However, through correctly identifying and understanding the stakeholders, it is possible to develop high quality software.}
}

@article{rayyan-727967560,
  title={Model-driven architecture based testing: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={102},
  pages={30-48},
  author={Uzun, Burak and Tekinerdogan, Bedir},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918300880},
  keywords={Systematic review, Software architecture, Model-based testing},
  abstract={Context Model-driven architecture based testing (MDABT) adopts architectural models of a system under test and/or its environment to derive test artifacts. In the literature, different MDABT approaches have been provided together with the corresponding lessons results and lessons learned. Objective The overall objective of this paper is to identify the published concerns for applying MDABT, identify the proposed solutions, and describe the current research directions for MDABT. Method To this end we have provided a systematic literature review (SLR) that is conducted by a multi-phase study selection process using the published literature in major software engineering journals and conference proceedings. Results We reviewed 739 papers that are discovered using a well-planned review protocol, and 31 of them were assessed as primary studies related to our research questions. Based on the analysis of the data extraction process, we discuss the primary trends and approaches and present the identified obstacles. Conclusion This study shows that although a generic process the approaches different in various ways with different goals, modeling abstractions and results. Further, based on the synthesis process in the SLR we can state that the potential of MDABT has not been fully exploited yet.}
}

@article{rayyan-727967561,
  title={Behavioral software engineering: A definition and systematic literature review},
  year={2015},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={107},
  pages={15-37},
  author={Lenberg, Per and Feldt, Robert and Wallgren, Lars Göran},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215000989},
  keywords={Software engineering, Human aspects, Psychology, Software},
  abstract={Throughout the history of software engineering, the human aspects have repeatedly been recognized as important. Even though research that investigates them has been growing in the past decade, these aspects should be more generally considered. The main objective of this study is to clarify the research area concerned with human aspects of software engineering and to create a common platform for future research. In order to meet the objective, we propose a definition of the research area behavioral software engineering (BSE) and present results from a systematic literature review based on the definition. The result indicates that there are knowledge gaps in the research area of behavioral software engineering and that earlier research has been focused on a few concepts, which have been applied to a limited number of software engineering areas. The individual studies have typically had a narrow perspective focusing on few concepts from a single unit of analysis. Further, the research has rarely been conducted in collaboration by researchers from both software engineering and social science. Altogether, this review can help put a broader set of human aspects higher on the agenda for future software engineering research and practice.}
}

@article{rayyan-727967562,
  title={Taking the emotional pulse of software engineering — A systematic literature review of empirical studies},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={115},
  pages={23-43},
  author={Sánchez-Gordón, Mary and Colomo-Palacios, Ricardo},
  url={https://www.sciencedirect.com/science/article/pii/S0950584919301661},
  keywords={Systematic literature review, Affect, Behavioral software engineering, Emotion, Mood, Social aspects of software development, Software, Pulse},
  abstract={Context Over the past 50 years of Software Engineering, numerous studies have acknowledged the importance of human factors. However, software developers' emotions are still an area under investigation and debate that is gaining relevance in the software industry. Objective In this study, a systematic literature review (SLR) was carried out to identify, evaluate, and synthesize research published concerning software developers' emotions as well as the measures used to assess its existence. Method By searching five major bibliographic databases, authors identified 7172 articles related to emotions in Software Engineering. We selected 66 of these papers as primary studies. Then, they were analyzed in order to find empirical evidence of the intersection of emotions and software engineering. Results Studies report a total of 40 discrete emotions but the most frequent were: anger, fear, disgust, sadness, joy, love, and happiness. There are also 2 different dimensional approaches and 10 datasets related to this topic which are publicly available on the Web. The findings also showed that self-reported mood instruments (e.g., SAM, PANAS), physiological measures (e.g., heart rate, perspiration) or behavioral measures (e.g., keyboard use) are the least reported tools, although, there is a recognized intrinsic problem with the accuracy of current state of the art sentiment analysis tools. Moreover, most of the studies used software practitioners and/or datasets from industrial context as subjects. Conclusions The study of emotions has received a growing attention from the research community in the recent years, but the management of emotions has always been challenging in practice. Although it can be said that this field is not mature enough yet, our results provide a holistic view that will benefit researchers by providing the latest trends in this area and identifying the corresponding research gaps.}
}

@article{rayyan-727967563,
  title={Multiple fault localization of software programs: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={124},
  pages={106312},
  author={Zakari, Abubakar and Lee, Sai Peck and Abreu, Rui and Ahmed, Babiker Hussien and Rasheed, Rasheed Abubakar},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300641},
  keywords={Fault localization, Multiple faults, One-bug-at-a-time (OBA), Parallel debugging, Program debugging, Software},
  abstract={Context Multiple fault localization (MFL) is the act of identifying the locations of multiple faults (more than one fault) in a faulty software program. This is known to be more complicated, tedious, and costly in comparison to the traditional practice of presuming that a software contains a single fault. Due to the increasing interest in MFL by the research community, a broad spectrum of MFL debugging approaches and solutions have been proposed and developed. Objective The aim of this study is to systematically review existing research on MFL in the software fault localization (SFL) domain. This study also aims to identify, categorize, and synthesize relevant studies in the research domain. Method Consequently, using an evidence-based systematic methodology, we identified 55 studies relevant to four research questions. The methodology provides a systematic selection and evaluation process with rigorous and repeatable evidence-based studies selection process. Result The result of the systematic review shows that research on MFL is gaining momentum with stable growth in the last 5 years. Three prominent MFL debugging approaches were identified, i.e. One-bug-at-a-time debugging approach (OBA), parallel debugging approach, and multiple-bug-at-a-time debugging approach (MBA), with OBA debugging approach being utilized the most. Conclusion The study concludes with some identified research challenges and suggestions for future research. Although MFL is becoming of grave concern, existing solutions in the field are less mature. Studies utilizing real faults in their experiments are scarce. Concrete solutions to reduce MFL debugging time and cost by adopting an approach such as MBA debugging approach are also less, which require more attention from the research community.}
}

@article{rayyan-727967568,
  title={Leveraging creativity in requirements elicitation within agile software development: A systematic literature review},
  year={2019},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={157},
  pages={110396},
  author={Aldave, Ainhoa and Vara, Juan M and Granada, David and Marcos, Esperanza},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219301712},
  keywords={Systematic review, Software development, Software project management, Requirements elicitation, Agile methodologies, Creative thinking, Software},
  abstract={Agile approaches tend to focus solely on scoping and simplicity rather than on problem solving and discovery. This hampers the development of innovative solutions. Additionally, little has been said about how to capture and represent the real user needs. To fill this gap, some authors argue in favor of the application of “Creative thinking” for requirements elicitation within agile software development. This synergy between creativeness and agility has arisen as a new means of bringing innovation and flexibility to increasingly demanding software. The aim of the present study is therefore to employ a systematic review to investigate the state-of-the-art of those approaches that leverage creativity in requirements elicitation within Agile Software Development, as well as the benefits, limitations and strength of evidence of these approaches. The review was carried out by following the guidelines proposed by Dr. Kitchenham. The search strategy identified 1451 studies, 17 of which were eventually classified as primary studies. The selected studies contained 13 different and unique proposals. These approaches provide evidence that enhanced creativity in requirements elicitation can be successfully implemented in real software projects. We specifically observed that projects related to user interface development, such as those for mobile or web applications, are good candidates for the use of these approaches. We have also found that agile methodologies such as Scrum, Extreme Programming or methodologies based on rapid modelling are preferred when introducing creativity into requirements elicitation. Despite this being a new research field, there is a mixture of techniques, tools and processes that have already been and are currently being successfully tested in industry. Finally, we have found that, although creativity is an important ingredient with which to bring about innovation, it is not always sufficient to generate new requirements because this needs to be followed by user engagement and a specific context in which proper conditions, such as flexibility, time or resources, have to be met.}
}

@article{rayyan-727967569,
  title={Software process simulation modeling: Systematic literature review},
  year={2020},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={70},
  pages={103425},
  author={García-García, J A and Enríquez, J G and Ruiz, M and Arévalo, C and Jiménez-Ramírez, A},
  url={https://www.sciencedirect.com/science/article/pii/S0920548919303095},
  keywords={Systematic literature review, Software engineering, Software process, Software Process Simulation Modeling, SPSM, Software},
  abstract={Changes and continuous progress in logistics and productive systems make the realization of improvements in decision making necessary. Simulation is a good support tool for this type of decisions because it allows reproducing processes virtually to study their behavior, to analyze the impact of possible changes or to compare different design alternatives without the high cost of scale experiments. Although process simulation is usually focused on industrial processes, over the last two decades, new proposals have emerged to bring simulation techniques into software engineering. This paper describes a Systematic Literature Review (SLR) which returned 8070 papers (published from 2013 to 2019) by a systematic search in 4 digital libraries. After conducting this SLR, 36 Software Process Simulation Modeling (SPSM) works were selected as primary studies and were documented following a specific characterization scheme. This scheme allows characterizing each proposal according to the paradigm used and its technology base as well as its future line of work. Our purpose is to identify trends and directions for future research on SPSM after identifying and studying which proposals in this topic have been defined and the relationships and dependencies between these proposals in the last five years. After finishing this review, it is possible to conclude that SPSM continues to be a topic that is very much addressed by the scientific community, but each contribution has been proposed with particular goals. This review also concludes that Agent-Based Simulation and System Dynamics paradigm is increasing and decreasing, respectively, its trend among SPSM proposals in the last five years. Regarding Discrete-Event Simulation paradigm, it seems that it is strengthening its position among research community in recent years to design new approaches.}
}

@article{rayyan-727967572,
  title={Testing and verification of neural-network-based safety-critical control software: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={123},
  pages={106296},
  author={Zhang, Jin and Li, Jingyue},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300471},
  keywords={Systematic literature review, Neural network, Safety-critical control software, Software testing and verification, Neural Networks (Computer), Nerve Net, Software},
  abstract={Context: Neural Network (NN) algorithms have been successfully adopted in a number of Safety-Critical Cyber-Physical Systems (SCCPSs). Testing and Verification (T&V) of NN-based control software in safety-critical domains are gaining interest and attention from both software engineering and safety engineering researchers and practitioners. Objective: With the increase in studies on the T&V of NN-based control software in safety-critical domains, it is important to systematically review the state-of-the-art T&V methodologies, to classify approaches and tools that are invented, and to identify challenges and gaps for future studies. Method: By searching the six most relevant digital libraries, we retrieved 950 papers on the T&V of NN-based Safety-Critical Control Software (SCCS). Then we filtered the papers based on the predefined inclusion and exclusion criteria and applied snowballing to identify new relevant papers. Results: To reach our result, we selected 83 primary papers published between 2011 and 2018, applied the thematic analysis approach for analyzing the data extracted from the selected papers, presented the classification of approaches, and identified challenges. Conclusion: The approaches were categorized into five high-order themes, namely, assuring robustness of NNs, improving the failure resilience of NNs, measuring and ensuring test completeness, assuring safety properties of NN-based control software, and improving the interpretability of NNs. From the industry perspective, improving the interpretability of NNs is a crucial need in safety-critical applications. We also investigated nine safety integrity properties within four major safety lifecycle phases to investigate the achievement level of T&V goals in IEC 61508-3. Results show that correctness, completeness, freedom from intrinsic faults, and fault tolerance have drawn most attention from the research community. However, little effort has been invested in achieving repeatability, and no reviewed study focused on precisely defined testing configuration or defense against common cause failure.}
}

@article{rayyan-727967574,
  title={Analyzing the software architectures supporting HCI/HMI processes through a systematic review of the literature},
  year={2019},
  journal={Telematics and Informatics},
  issn={0736-5853},
  volume={38},
  pages={118-132},
  author={Cruz-Benito, Juan and García-Peñalvo, Francisco J and Therón, Roberto},
  url={https://www.sciencedirect.com/science/article/pii/S0736585318305392},
  keywords={Systematic Literature Review, Human-Computer Interaction, Human-Machine Interaction, Software Architectures, Software},
  abstract={Many researchers have dealt with Human-Computer Interaction or Human-Machine Interaction by building or designing software architectures that facilitate the users' interaction or recognize users' inputs to the generate proper responses. Many studies include these approaches in different research areas: from research in healthcare to mobile environments, robotics, etc. Interaction is seen as a critical concept, and the work for its improvement is a crucial factor for many platforms, systems, and business domains. The goal of this manuscript is to present a systematic review of the literature to identify, analyze and classify the published approaches to support or enhance Human-Computer Interaction or Human-Machine Interaction from the perspective of software architectures. The method followed is the systematic review following the guidelines related to Systematic Literature Reviews methods such as the one proposed by Kitchenham and other authors in the field of software engineering. As results, this study identified 39 papers that included software architectures to improve or analyze Human-Computer Interaction or Human-Machine Interaction. Three main approaches were found on software architectures: layered architectures, modular architectures, and architectures based on software agents, but they lacked standardization and were mainly ad-hoc solutions. The primary interfaces covered were those related to Graphical User Interfaces (GUIs) and multimodal/natural ones. The primary application domain detected were in multimodal systems. The main purpose of most of the papers was to support multimodal interaction. Some conclusions achieved are that the generic solutions to support or analyze HCI/HMI processes are still rare in the literature. Despite many works dealing with this topic and its issues and challenges, it is necessary to keep on improving the research in this area through the application of standard techniques and solutions, exploring new ways of analyzing and interpreting interaction, escaping from ad-hoc solutions or evaluating the solutions proposed.}
}

@article{rayyan-727967575,
  title={Software engineering process models for mobile app development: A systematic literature review},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={145},
  pages={98-111},
  author={Jabangwe, Ronald and Edison, Henry and Duc, Anh Nguyen},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301638},
  keywords={Systematic literature review, Hybrid apps, Mobile application development, Mobile apps, Native apps, Software engineering process models, Software},
  abstract={Context: An effective development model can help improve competitive advantage and shorten release cycles, which is vital in the fast paced environment of mobile app development. Objective: The aim with this paper is to provide an extensive review of existing mobile app development models. Method: The review is done by following a systematic literature review process. Also presented is an assessment of the usefulness and relevance to industry of the models based on a rigor and relevance framework. Results: 20 primary studies were identified, each with distinct models. Agile methods or state-based principles are commonly adopted across the models. Relatively little effort focuses on deployment, maintenance, project evaluation activities. Conclusion: The review reveals that the contexts in which the identified models are intended to be used vary. This benefits practitioners as they are able to select a model that suits their contexts. However, the usefulness in industry of most of the models, based on the contexts in which the models were evaluated, is questionable. There is a need for evaluating mobile app models in contexts that resemble realistic contexts. The review also calls for further research addressing special constraints of mobile apps, e.g., testing apps on multiple-platforms, user involvement in release planning and continuous deployment.}
}

@article{rayyan-727967577,
  title={Ontology-based solutions for interoperability among product lifecycle management systems: A systematic literature review},
  year={2020},
  journal={Journal of Industrial Information Integration},
  issn={2452-414X},
  volume={20},
  pages={100176},
  author={Fraga, Alvaro Luis and Vegetti, Marcela and Leone, Horacio Pascual},
  url={https://www.sciencedirect.com/science/article/pii/S2452414X20300510},
  keywords={Ontology, Review, Interoperability, Product lifecycle management, Roles of ontology},
  abstract={During recent years, globalization has had an impact on the competitive capacity of industries, forcing them to integrate their productive processes with other, geographically distributed, facilities. This requires the information systems that support such processes to interoperate. Significant attention has been paid to the development of ontology-based solutions, which are meant to tackle issues from inconsistency to semantic interoperability and knowledge reusability. This paper looks into how the available technology, models and ontology-based solutions might interact within the manufacturing industry environment to achieve semantic interoperability among industrial information systems. Through a systematic literature review, this paper has aimed to identify the most relevant elements to consider in the development of an ontology-based solution and how these solutions are being deployed in industry. The research analyzed 54 studies in alignment with the specific requirements of our research questions. The most relevant results show that ontology-based solutions can be set up using OWL as the ontology language, Protégé as the ontology modeling tool, Jena as the application programming interface to interact with the built ontology, and different standards from the International Organization for Standardization Technical Committee 184, Subcommittee 4 or 5, to get the foundational concepts, axioms, and relationships to develop the knowledge base. We believe that the findings of this study make an important contribution to practitioners and researchers as they provide useful information about different projects and choices involved in undertaking projects in the field of industrial ontology application.}
}

@article{rayyan-727967579,
  title={On the generation of requirements specifications from software engineering models: A systematic literature review},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={9},
  pages={1291-1307},
  author={Nicolás, Joaquín and Toval, Ambrosio},
  url={https://www.sciencedirect.com/science/article/pii/S0950584909000378},
  keywords={Systematic literature review, Requirements document generation from software engineering model, Specification generation from software engineering model, Textual requirements generation from software engineering model, Software},
  abstract={System and software requirements documents play a crucial role in software engineering in that they must both communicate requirements to clients in an understandable manner and define requirements in precise detail for system developers. The benefits of both lists of textual requirements (usually written in natural language) and software engineering models (usually specified in graphical form) can be brought together by combining the two approaches in the specification of system and software requirements documents. If, moreover, textual requirements are generated from models in an automatic or closely monitored form, the effort of specifying those requirements is reduced and the completeness of the specification and the management of the requirements traceability are improved. This paper presents a systematic review of the literature related to the generation of textual requirements specifications from software engineering models.}
}

@article{rayyan-727967581,
  title={Challenges and best practices in industry-academia collaborations in software engineering: A systematic literature review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={79},
  pages={106-127},
  author={Garousi, Vahid and Petersen, Kai and Ozkan, Baris},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916301203},
  keywords={Systematic literature review, Software engineering, Challenges, Industry, Best practices, Industry-academia collaborations, Success patterns, Universities, Software},
  abstract={Context: The global software industry and the software engineering (SE) academia are two large communities. However, unfortunately, the level of joint industry-academia collaborations in SE is still relatively very low, compared to the amount of activity in each of the two communities. It seems that the two 'camps' show only limited interest/motivation to collaborate with one other. Many researchers and practitioners have written about the challenges, success patterns (what to do, i.e., how to collaborate) and anti-patterns (what not do do) for industry-academia collaborations. Objective: To identify (a) the challenges to avoid risks to the collaboration by being aware of the challenges, (b) the best practices to provide an inventory of practices (patterns) allowing for an informed choice of practices to use when planning and conducting collaborative projects. Method: A systematic review has been conducted. Synthesis has been done using grounded-theory based coding procedures. Results: Through thematic analysis we identified 10 challenge themes and 17 best practice themes. A key outcome was the inventory of best practices, the most common ones recommended in different contexts were to hold regular workshops and seminars with industry, assure continuous learning from industry and academic sides, ensure management engagement, the need for a champion, basing research on real-world problems, showing explicit benefits to the industry partner, be agile during the collaboration, and the co-location of the researcher on the industry side. Conclusion: Given the importance of industry-academia collaboration to conduct research of high practical relevance we provide a synthesis of challenges and best practices, which can be used by researchers and practitioners to make informed decisions on how to structure their collaborations.}
}

@article{rayyan-727967583,
  title={Similarity-based analyses on software applications: A systematic literature review},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={168},
  pages={110669},
  author={Auch, Maximilian and Weber, Manuel and Mandl, Peter and Wolff, Christian},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220301278},
  keywords={Machine learning, Secondary study, Software similarity, Software},
  abstract={In empirical studies on processes, practices, and techniques of software engineering, automation and machine learning are gaining popularity. In order to extract knowledge from existing software projects, a sort of similarity analysis is often performed using different methodologies, data and metadata. This systematic literature review focuses therefore on existing approaches of similarity-, categorization- and relevance-based analysis on software applications. In total, 136 relevant publications and patents were identified between 2002 and 2019 according to the established inclusion and exclusion criteria, which perform a calculation of software similarity in general or to support certain software engineering phases.}
}

@article{rayyan-727967584,
  title={Motivation in software engineering: A systematic literature review},
  year={2008},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={50},
  number={9},
  pages={860-878},
  author={Beecham, Sarah and Baddoo, Nathan and Hall, Tracy and Robinson, Hugh and Sharp, Helen},
  url={https://www.sciencedirect.com/science/article/pii/S0950584907001097},
  keywords={Software Engineering, Systematic literature review, Motivation, Characteristics, Personality, Software Engineer, Software},
  abstract={Objective In this paper, we present a systematic literature review of motivation in Software Engineering. The objective of this review is to plot the landscape of current reported knowledge in terms of what motivates developers, what de-motivates them and how existing models address motivation. Methods We perform a systematic literature review of peer reviewed published studies that focus on motivation in Software Engineering. Systematic reviews are well established in medical research and are used to systematically analyse the literature addressing specific research questions. Results We found 92 papers related to motivation in Software Engineering. Fifty-six percent of the studies reported that Software Engineers are distinguishable from other occupational groups. Our findings suggest that Software Engineers are likely to be motivated according to three related factors: their ‘characteristics' (for example, their need for variety); internal ‘controls' (for example, their personality) and external ‘moderators' (for example, their career stage). The literature indicates that de-motivated engineers may leave the organisation or take more sick-leave, while motivated engineers will increase their productivity and remain longer in the organisation. Aspects of the job that motivate Software Engineers include problem solving, working to benefit others and technical challenge. Our key finding is that the published models of motivation in Software Engineering are disparate and do not reflect the complex needs of Software Engineers in their career stages, cultural and environmental settings. Conclusions The literature on motivation in Software Engineering presents a conflicting and partial picture of the area. It is clear that motivation is context dependent and varies from one engineer to another. The most commonly cited motivator is the job itself, yet we found very little work on what it is about that job that Software Engineers find motivating. Furthermore, surveys are often aimed at how Software Engineers feel about ‘the organisation', rather than ‘the profession'. Although models of motivation in Software Engineering are reported in the literature, they do not account for the changing roles and environment in which Software Engineers operate. Overall, our findings indicate that there is no clear understanding of the Software Engineers' job, what motivates Software Engineers, how they are motivated, or the outcome and benefits of motivating Software Engineers.}
}

@article{rayyan-727967585,
  title={On the application of search-based techniques for software engineering predictive modeling: A systematic review and future directions},
  year={2017},
  journal={Swarm and Evolutionary Computation},
  issn={2210-6502},
  volume={32},
  pages={85-109},
  author={Malhotra, Ruchika and Khanna, Megha and Raje, Rajeev R},
  url={https://www.sciencedirect.com/science/article/pii/S2210650216303418},
  keywords={Effort estimation, Software quality, Search-based techniques, Change prediction, Defect prediction, Maintainability prediction, Software},
  abstract={Software engineering predictive modeling involves construction of models, with the help of software metrics, for estimating quality attributes. Recently, the use of search-based techniques have gained importance as they help the developers and project-managers in the identification of optimal solutions for developing effective prediction models. In this paper, we perform a systematic review of 78 primary studies from January 1992 to December 2015 which analyze the predictive capability of search-based techniques for ascertaining four predominant software quality attributes, i.e., effort, defect proneness, maintainability and change proneness. The review analyses the effective use and application of search-based techniques by evaluating appropriate specifications of fitness functions, parameter settings, validation methods, accounting for their stochastic natures and the evaluation of developmental models with the use of well-known statistical tests. Furthermore, we compare the effectiveness of different models, developed using the various search-based techniques amongst themselves, and also with the prevalent machine learning techniques used in literature. Although there are very few studies which use search-based techniques for predicting maintainability and change proneness, we found that the results of the application of search-based techniques for effort estimation and defect prediction are encouraging. Hence, this comprehensive study and the associated results will provide guidelines to practitioners and researchers and will enable them to make proper choices for applying the search-based techniques to their specific situations.}
}

@article{rayyan-727967586,
  title={Reproducibility and credibility in empirical software engineering: A case study based on a systematic literature review of the use of the SZZ algorithm},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={99},
  pages={164-176},
  author={Rodríguez-Pérez, Gema and Robles, Gregorio and González-Barahona, Jesús M},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917304275},
  keywords={Systematic literature review, Reproducibility, Credibility, SZZ Algorithm, Case-Control Studies, Software, Algorithms},
  abstract={Context Reproducibility of Empirical Software Engineering (ESE) studies is an essential part for improving their credibility, as it offers the opportunity to the research community to verify, evaluate and improve their research outcomes. Objective We aim to study reproducibility and credibility in ESE with a case study, by investigating how they have been addressed in studies where SZZ, a widely-used algorithm by Śliwerski, Zimmermann and Zeller to detect the origin of a bug, has been applied. Methodology We have performed a systematic literature review to evaluate publications that use SZZ. In total, 187 papers have been analyzed for reproducibility, reporting of limitations and use of improved versions of the algorithm. Results We have found a situation with a lot of room for improvement in ESE as reproducibility is not commonly found; factors that undermine the credibility of results are common. We offer some lessons learned and guidelines for researchers and reviewers to address this problem. Conclusion Reproducibility and other related aspects that ensure a high quality scientific process should be taken more into consideration by the ESE community in order to increase the credibility of the research results.}
}

@article{rayyan-727967587,
  title={A systematic literature review of machine learning techniques for software maintainability prediction},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={119},
  pages={106214},
  author={Alsolai, Hadeel and Roper, Marc},
  url={https://www.sciencedirect.com/science/article/pii/S0950584919302228},
  keywords={Systematic literature review, Machine learning, Dataset, Metric, Software maintainability prediction, Software},
  abstract={Context Software maintainability is one of the fundamental quality attributes of software engineering. The accurate prediction of software maintainability is a significant challenge for the effective management of the software maintenance process. Objective The major aim of this paper is to present a systematic review of studies related to the prediction of maintainability of object-oriented software systems using machine learning techniques. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software maintainability measurements, metrics, datasets, evaluation measures, individual models and ensemble models. Method The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018. Results We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other software quality attributes. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level product metrics as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on regression problems and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely. Conclusion Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results.}
}

@article{rayyan-727967588,
  title={A systematic review of quasi-experiments in software engineering},
  year={2009},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={51},
  number={1},
  pages={71-82},
  author={Kampenes, Vigdis By and Dybå, Tore and Hannay, Jo E and K. Sjøberg, Dag I},
  url={https://www.sciencedirect.com/science/article/pii/S0950584908000670},
  keywords={Empirical software engineering, Effect size, Field experiments, Quasi-experiments, Randomization, Selection bias, Software},
  abstract={Background: Experiments in which study units are assigned to experimental groups nonrandomly are called quasi-experiments. They allow investigations of cause–effect relations in settings in which randomization is inappropriate, impractical, or too costly. Problem outline: The procedure by which the nonrandom assignments are made might result in selection bias and other related internal validity problems. Selection bias is a systematic (not happening by chance) pre-experimental difference between the groups that could influence the results. By detecting the cause of the selection bias, and designing and analyzing the experiments accordingly, the effect of the bias may be reduced or eliminated. Research method: To investigate how quasi-experiments are performed in software engineering (SE), we conducted a systematic review of the experiments published in nine major SE journals and three conference proceedings in the decade 1993–2002. Results: Among the 113 experiments detected, 35% were quasi-experiments. In addition to field experiments, we found several applications for quasi-experiments in SE. However, there seems to be little awareness of the precise nature of quasi-experiments and the potential for selection bias in them. The term “quasi-experiment” was used in only 10% of the articles reporting quasi-experiments; only half of the quasi-experiments measured a pretest score to control for selection bias, and only 8% reported a threat of selection bias. On average, larger effect sizes were seen in randomized than in quasi-experiments, which might be due to selection bias in the quasi-experiments. Conclusion: We conclude that quasi-experimentation is useful in many settings in SE, but their design and analysis must be improved (in ways described in this paper), to ensure that inferences made from this kind of experiment are valid.}
}

@article{rayyan-727967589,
  title={Investigation on test effort estimation of mobile applications: Systematic literature review and survey},
  year={2019},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={110},
  pages={56-77},
  author={Kaur, Anureet and Kaur, Kulwant},
  url={https://www.sciencedirect.com/science/article/pii/S095058491930031X},
  keywords={Software engineering, Mobile applications, Survey, Systematic literature review (SLR), Test effort estimation},
  abstract={Context In the last few years, the exigency of mobile devices has proliferated to prodigious heights. The process of developing the mobile software/application proceeds amidst testing phase to verify the correctness of the mobile app. The estimation of testing plays a vital role in the effective completion of testing. Objective To identify how estimation of test effort for mobile applications is distinct from other software via published literature and from mobile software organizations. Second is to recognize different issues in adapting traditional test estimation methods to the mobile domain and if suggestions from survey results could be helpful in providing an improved test estimation model for mobile applications. Method A systematic literature review is conducted followed by a survey through an online questionnaire filled from experienced mobile application developers and testers. Results The results from SLR cover identification of mobile app specific characteristics and reports test effort estimation techniques in the mobile domain. Findings from survey corroborate that a) Function Point/Test Point Analysis is highly adapted traditional test estimation technique to mobile domain; b) Challenges like uncertain requirements, no tool support for test estimation, complexity in testing, client miscommunication etc. are reported; c)Suggestions to improve test estimation process include proper test planning, adoption of agile methodology, healthier communication among client, developer, and tester etc.; d) On the basis of responses, Analytical Hierarchical Process (AHP) identifies “Diverse Devices and OS” along with “Type of App” as highly influential mobile app characteristic on the test estimation process. Conclusion Results conclude that the importance of identified mobile app characteristics from SLR cannot be ignored in the estimation process of mobile software testing. There might be a possibility to improve existing test estimation techniques for mobile apps by giving weight to mobile app specific characteristics and by considering suggestions from experienced developers and testers.}
}

@article{rayyan-727967590,
  title={Aligning software engineering education with industrial needs: A meta-analysis},
  year={2019},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={156},
  pages={65-83},
  author={Garousi, Vahid and Giray, Görkem and Tüzün, Eray and Catal, Cagatay and Felderer, Michael},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219301347},
  keywords={Meta-analysis, Systematic literature review (SLR), Important skills, Industry needs, Knowledge gap, Software engineering education, Software},
  abstract={Context According to various reports, many software engineering (SE) graduates often face difficulties when beginning their careers, which is mainly due to misalignment of the skills learned in university education with what is needed in the software industry. Objective Our objective is to perform a meta-analysis to aggregate the results of the studies published in this area to provide a consolidated view on how to align SE education with industry needs, to identify the most important skills and also existing knowledge gaps. Method To synthesize the body of knowledge, we performed a systematic literature review (SLR), in which we systematically selected a pool of 35 studies and then conducted a meta-analysis using data extracted from those studies. Results Via a meta-analysis and using data from 13 countries and over 4,000 data points, highlights of the SLR include: (1) software requirements, design, and testing are the most important skills; and (2) the greatest knowledge gaps are in configuration management, SE models and methods, SE process, design (and architecture), as well as in testing. Conclusion This paper provides implications for both educators and hiring managers by listing the most important SE skills and the knowledge gaps in the industry.}
}

@article{rayyan-727967591,
  title={Intelligent software engineering in the context of agile software development: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={119},
  pages={106241},
  author={Perkusich, Mirko and Chaves e Silva, Lenardo and Costa, Alexandre and Ramos, Felipe and Saraiva, Renata and Freire, Arthur and Dilorenzo, Ednaldo and Dantas, Emanuel and Santos, Danilo and Gorgônio, Kyller and Almeida, Hyggo and Perkusich, Angelo},
  url={https://www.sciencedirect.com/science/article/pii/S0950584919302587},
  keywords={Artificial intelligence, Machine learning, Agile software development, Search-based software engineering, Bayesian networks, Intelligent software engineering, Software, Intelligence},
  abstract={CONTEXT: Intelligent Software Engineering (ISE) refers to the application of intelligent techniques to software engineering. We define an “intelligent technique” as a technique that explores data (from digital artifacts or domain experts) for knowledge discovery, reasoning, learning, planning, natural language processing, perception or supporting decision-making. OBJECTIVE: The purpose of this study is to synthesize and analyze the state of the art of the field of applying intelligent techniques to Agile Software Development (ASD). Furthermore, we assess its maturity and identify adoption risks. METHOD: Using a systematic literature review, we identified 104 primary studies, resulting in 93 unique studies. RESULTS: We identified that there is a positive trend in the number of studies applying intelligent techniques to ASD. Also, we determined that reasoning under uncertainty (mainly, Bayesian network), search-based solutions, and machine learning are the most popular intelligent techniques in the context of ASD. In terms of purposes, the most popular ones are effort estimation, requirements prioritization, resource allocation, requirements selection, and requirements management. Furthermore, we discovered that the primary goal of applying intelligent techniques is to support decision making. As a consequence, the adoption risks in terms of the safety of the current solutions are low. Finally, we highlight the trend of using explainable intelligent techniques. CONCLUSION: Overall, although the topic area is up-and-coming, for many areas of application, it is still in its infancy. So, this means that there is a need for more empirical studies, and there are a plethora of new opportunities for researchers.}
}

@article{rayyan-727967592,
  title={A systematic literature review on crowdsourcing in software engineering},
  year={2019},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={153},
  pages={200-219},
  author={Sarı, Aslı and Tosun, Ayşe and Alptekin, Gülfem Işıklar},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219300779},
  keywords={Systematic literature review, Empirical software engineering, Crowdsourcing, Crowdsourcing in software engineering, Software},
  abstract={Background Crowdsourcing outsources a task to large groups of people by open call format, and it recently plays significant role for software practitioners. Aim The purpose of this study is to conduct a comprehensive overview on crowdsourcing in software engineering (CSE), concerning business models, tools, platforms, software development processes, and software economics. Method We conducted a systematic literature review on CSE. We identified 158 relevant studies and 6 secondary studies. We further reviewed 67 primary studies that passed our quality assessment criteria. We defined 10 research questions and synthesized different approaches used in primary studies regarding each question. Results Majority of studies report the application of crowdsourcing for coding and testing tasks. Crowdsourcing follows a unique methodology in which project planning, task specification and deployment have more emphasis. There is not enough literature on effort estimation approaches in CSE and associated cost factors. Complexity of the task and its expected duration play significant role in estimation. Conclusions Future studies should focus more on economic models, experience reports, specific software development methodologies, and strategic pricing mechanism for CSE.}
}

@article{rayyan-727967593,
  title={Solutions in global software engineering: A systematic literature review},
  year={2013},
  journal={International Journal of Information Management},
  issn={0268-4012},
  volume={33},
  number={1},
  pages={119-132},
  author={Schneider, Stefan and Torkar, Richard and Gorschek, Tony},
  url={https://www.sciencedirect.com/science/article/pii/S0268401212000989},
  keywords={Systematic literature review, Process model, Solutions, Global software engineering, Distributed development, Solution, Software},
  abstract={Global software engineering (GSE) has received increased attention, as globalization enables and encourages increased distribution of product development. Many empirical studies and systematic literature reviews (SLRs) focus on the identification of challenges, this paper however presents the first SLR collecting and analyzing solutions associated with GSE, while also evaluating the level of empirical validation of said solutions. As a starting point the paper presents a GSE model, designed to categorize solutions into process areas, useful for the analysis of the research community's contributions to state-of-the-art and identifying fundamental gaps in research. In addition, the model categorizing the solutions is populated with references and good-examples, useful for practitioners, which can use the model to find solutions to overall challenges in various process areas. The overall results of the systematic review revealed more than 330 papers containing 127 solutions that were then identified and mapped to the model. The process areas of project management are highly populated, while other areas like product integration have received surprisingly little attention. In addition, selected process area is elaborated upon in terms of contents and deficiencies.}
}

@article{rayyan-727967595,
  title={What recommendation systems for software engineering recommend: A systematic literature review},
  year={2016},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={113},
  pages={101-113},
  author={Gasparic, Marko and Janes, Andrea},
  url={https://www.sciencedirect.com/science/article/pii/S0164121215002605},
  keywords={Systematic literature review, Recommendation system for software engineering, Software},
  abstract={A recommendation system for software engineering (RSSE) is a software application that provides information items estimated to be valuable for a software engineering task in a given context. Present the results of a systematic literature review to reveal the typical functionality offered by existing RSSEs, research gaps, and possible research directions. We evaluated 46 papers studying the benefits, the data requirements, the information and recommendation types, and the effort requirements of RSSE systems. We include papers describing tools that support source code related development published between 2003 and 2013. The results show that RSSEs typically visualize source code artifacts. They aim to improve system quality, make the development process more efficient and less expensive, lower developer's cognitive load, and help developers to make better decisions. They mainly support reuse actions and debugging, implementation, and maintenance phases. The majority of the systems are reactive. Unexploited opportunities lie in the development of recommender systems outside the source code domain. Furthermore, current RSSE systems use very limited context information and rely on simple models. Context-adapted and proactive behavior could improve the acceptance of RSSE systems in practice.}
}

@article{rayyan-727967596,
  title={Time pressure in software engineering: A systematic review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={121},
  pages={106257},
  author={Kuutila, Miikka and Mäntylä, Mika and Farooq, Umar and Claes, Maëlick},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300045},
  keywords={Software},
  abstract={Context Large project overruns and overtime work have been reported in the software industry, resulting in additional expense for companies and personal issues for developers. Experiments and case studies have investigated the relationship between time pressure and software quality and productivity. Objective The present work aims to provide an overview of studies related to time pressure in software engineering; specifically, existing definitions, possible causes, and metrics relevant to time pressure were collected, and a mapping of the studies to software processes and approaches was performed. Moreover, we synthesize results of existing quantitative studies on the effects of time pressure on software development, and offer practical takeaways for practitioners and researchers, based on empirical evidence. Method Our search strategy examined 5414 sources, found through repository searches and snowballing. Applying inclusion and exclusion criteria resulted in the selection of 102 papers, which made relevant contributions related to time pressure in software engineering. Results The majority of high quality studies report increased productivity and decreased quality under time pressure. The most frequent categories of studies focus on quality assurance, cost estimation, and process simulation. It appears that time pressure is usually caused by errors in cost estimation. The effect of time pressure is most often identified during software quality assurance. Conclusions The majority of empirical studies report increased productivity under time pressure, while the most cost estimation and process simulation models assume that compressing the schedule increases the total needed hours. We also find evidence of the mediating effect of knowledge on the effects of time pressure, and that tight deadlines impact tasks with an algorithmic nature more severely. Future research should better contextualize quantitative studies to account for the existing conflicting results and to provide an understanding of situations when time pressure is either beneficial or harmful.}
}

@article{rayyan-727967597,
  title={Threat analysis of software systems: A systematic literature review},
  year={2018},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={144},
  pages={275-294},
  author={Tuma, K and Calikli, G and Scandariato, R},
  url={https://www.sciencedirect.com/science/article/pii/S0164121218301304},
  keywords={Systematic literature review (SLR), Risk assessment, Security-by-design, Software systems, Threat analysis (modeling), Software},
  abstract={Architectural threat analysis has become an important cornerstone for organizations concerned with developing secure software. Due to the large number of existing techniques it is becoming more challenging for practitioners to select an appropriate threat analysis technique. Therefore, we conducted a systematic literature review (SLR) of the existing techniques for threat analysis. In our study we compare 26 methodologies for what concerns their applicability, characteristics of the required input for analysis, characteristics of analysis procedure, characteristics of analysis outcomes and ease of adoption. We also provide insight into the obstacles for adopting the existing approaches and discuss the current state of their adoption in software engineering trends (e.g. Agile, DevOps, etc.). As a summary of our findings we have observed that: the analysis procedure is not precisely defined, there is a lack of quality assurance of analysis outcomes and tool support and validation are limited.}
}

@article{rayyan-727967599,
  title={A systematic literature review on the usage of eye-tracking in software engineering},
  year={2015},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={67},
  pages={79-107},
  author={Sharafi, Zohreh and Soh, Zéphyrin and Guéhéneuc, Yann-Gaël},
  url={https://www.sciencedirect.com/science/article/pii/S0950584915001196},
  keywords={Software engineering, Experiment, Eye-tracking, Software},
  abstract={Context Eye-tracking is a mean to collect evidence regarding some participants' cognitive processes. Eye-trackers monitor participants' visual attention by collecting eye-movement data. These data are useful to get insights into participants' cognitive processes during reasoning tasks. Objective The Evidence-based Software Engineering (EBSE) paradigm has been proposed in 2004 and, since then, has been used to provide detailed insights regarding different topics in software engineering research and practice. Systematic Literature Reviews (SLR) are also useful in the context of EBSE by bringing together all existing evidence of research and results about a particular topic. This SLR evaluates the current state of the art of using eye-trackers in software engineering and provides evidence on the uses and contributions of eye-trackers to empirical studies in software engineering. Method We perform a SLR covering eye-tracking studies in software engineering published from 1990 up to the end of 2014. To search all recognised resources, instead of applying manual search, we perform an extensive automated search using Engineering Village. We identify 36 relevant publications, including nine journal papers, two workshop papers, and 25 conference papers. Results The software engineering community started using eye-trackers in the 1990s and they have become increasingly recognised as useful tools to conduct empirical studies from 2006. We observe that researchers use eye-trackers to study model comprehension, code comprehension, debugging, collaborative interaction, and traceability. Moreover, we find that studies use different metrics based on eye-movement data to obtain quantitative measures. We also report the limitations of current eye-tracking technology, which threaten the validity of previous studies, along with suggestions to mitigate these limitations. Conclusion However, not withstanding these limitations and threats, we conclude that the advent of new eye-trackers makes the use of these tools easier and less obtrusive and that the software engineering community could benefit more from this technology.}
}

@article{rayyan-727967600,
  title={Task scheduling in big data platforms: A systematic literature review},
  year={2017},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={134},
  pages={170-189},
  author={Soualhia, Mbarka and Khomh, Foutse and Tahar, Sofiène},
  url={https://www.sciencedirect.com/science/article/pii/S0164121217301954},
  keywords={Systematic Literature Review, Hadoop, Mesos, Spark, Storm, Task Scheduling},
  abstract={Context: Hadoop, Spark, Storm, and Mesos are very well known frameworks in both research and industrial communities that allow expressing and processing distributed computations on massive amounts of data. Multiple scheduling algorithms have been proposed to ensure that short interactive jobs, large batch jobs, and guaranteed-capacity production jobs running on these frameworks can deliver results quickly while maintaining a high throughput. However, only a few works have examined the effectiveness of these algorithms. Objective: The Evidence-based Software Engineering (EBSE) paradigm and its core tool, i.e., the Systematic Literature Review (SLR), have been introduced to the Software Engineering community in 2004 to help researchers systematically and objectively gather and aggregate research evidences about different topics. In this paper, we conduct a SLR of task scheduling algorithms that have been proposed for big data platforms. Method: We analyse the design decisions of different scheduling models proposed in the literature for Hadoop, Spark, Storm, and Mesos over the period between 2005 and 2016. We provide a research taxonomy for succinct classification of these scheduling models. We also compare the algorithms in terms of performance, resources utilization, and failure recovery mechanisms. Results: Our searches identifies 586 studies from journals, conferences and workshops having the highest quality in this field. This SLR reports about different types of scheduling models (dynamic, constrained, and adaptive) and the main motivations behind them (including data locality, workload balancing, resources utilization, and energy efficiency). A discussion of some open issues and future challenges pertaining to improving the current studies is provided.}
}

@article{rayyan-727967601,
  title={Stakeholder quantification and prioritisation research: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={102},
  pages={85-99},
  author={Hujainah, Fadhl and Abu Bakar, Rohani Binti and Al-haimi, Basheer and Abdulgabber, Mansoor Abdullateef},
  url={https://www.sciencedirect.com/science/article/pii/S0950584917302422},
  keywords={Systematic review, Stakeholders prioritisation, Stakeholders quantification},
  abstract={Context Stakeholder quantification and prioritisation (SQP) is executed to quantify and prioritise stakeholders of the system based on their impacts. Selecting and involving the appropriate stakeholders are considered one of the major factors for producing a successful system. Objective The objectives of this paper is to provide precise investigation regarding the SQP domain with respect to its impact on prioritising requirements, identifying SQP attributes, critically investigating the existing techniques, and presenting the challenges and recommended future works. Method The systematic literature review (SLR) guidelines proposed by Kitchenham are adopted to guide the review process. The identified related studies underwent a rigorous study selection process. Thus, 31 out of 210 identified studies were selected as primary studies to address adequately the formulated research questions. Results Findings demonstrate that SQP is a crucial process in requirement prioritisation (RP) because of its ability to identify stakeholders' impact on the systems requirements that lead to the production of a correctly prioritised list of requirements. Seventeen SQP attributes are revealed along with their description, usage impact, and degree of importance. Furthermore, nine techniques that focus on quantification and prioritisation of the stakeholders are identified and critically analysed in terms of their description, SQP process involved, SQP attributes used, types, and limitations. The findings reveal that these techniques face some challenges with respect to the lack of low-level implementation details, lack of automation and intelligence level, and heavy reliance on the involvement of experts. Conclusion SQP has been extensively discussed in stakeholder analysis and requirement prioritisation domains. Based on the findings, a new intelligent solution is suggested to minimise the need for expert participation in conducting the SQP process along with proposing measurement criteria for the attributes used to evaluate the stakeholders. The deficiency of research works regarding the selection of SQP techniques is also observed.}
}

@article{rayyan-727967602,
  title={Profiling of pornography addiction among children using EEG signals: A systematic literature review},
  year={2020},
  journal={Computers in Biology and Medicine},
  issn={0010-4825},
  volume={125},
  pages={103970},
  author={Kang, Xiaoxi and Handayani, Dini Oktarina Dwi and Chong, Pei Pei and Acharya, U Rajendra},
  url={https://www.sciencedirect.com/science/article/pii/S0010482520303024},
  keywords={Systematic literature review, Addiction, EEG, Pornography, Erotica, Only Child, Child, Electroencephalography},
  abstract={Nowadays human behavior has been affected with the advent of new digital technologies. Due to the rampant use of the Internet by children, many have been addicted to pornography. This addiction has negatively affected the behaviors of children including increased impulsiveness, learning ability to attention, poor decision-making, memory problems, and deficit in emotion regulation. The children with porn addiction can be identified by parents and medical practitioners as third-party observers. This systematic literature review (SLR) is conducted to increase the understanding of porn addiction using electroencephalogram (EEG) signals. We have searched five different databases namely IEEE, ACM, Science Direct, Springer and National Center for Biotechnology Information (NCBI) using addiction, porn, and EEG as keywords along with ‘OR ‘operation in between the expressions. We have selected 46 studies in this work by screening 815,554 papers from five databases. Our results show that it is possible to identify children with porn addiction using EEG signals.}
}

@article{rayyan-727967604,
  title={On the application of genetic programming for software engineering predictive modeling: A systematic review},
  year={2011},
  journal={Expert Systems with Applications},
  issn={0957-4174},
  volume={38},
  number={9},
  pages={11984-11997},
  author={Afzal, Wasif and Torkar, Richard},
  url={https://www.sciencedirect.com/science/article/pii/S0957417411004490},
  keywords={Systematic review, Modeling, Genetic programming, Symbolic regression, Software},
  abstract={The objective of this paper is to investigate the evidence for symbolic regression using genetic programming (GP) being an effective method for prediction and estimation in software engineering, when compared with regression/machine learning models and other comparison groups (including comparisons with different improvements over the standard GP algorithm). We performed a systematic review of literature that compared genetic programming models with comparative techniques based on different independent project variables. A total of 23 primary studies were obtained after searching different information sources in the time span 1995–2008. The results of the review show that symbolic regression using genetic programming has been applied in three domains within software engineering predictive modeling: (i) Software quality classification (eight primary studies). (ii) Software cost/effort/size estimation (seven primary studies). (iii) Software fault prediction/software reliability growth modeling (eight primary studies). While there is evidence in support of using genetic programming for software quality classification, software fault prediction and software reliability growth modeling; the results are inconclusive for software cost/effort/size estimation.}
}

@article{rayyan-727967605,
  title={Software product line applied to the internet of things: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={124},
  pages={106293},
  author={Geraldi, Ricardo Theis and Reinehr, Sheila and Malucelli, Andreia},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300434},
  keywords={Software product line, Internet of things, Variability management, Families of systems, Product family engineering, Internet, Software},
  abstract={Context Internet of Things (IoT) is a promising paradigm due to the growing number of devices that may be connected, defined as “things”. Managing these “things” is still considered a challenge. One way to overcome this challenge may be by adopting the software product line (SPL) paradigm and the variability management (VM) activity. SPL engineering consists of mechanisms that provide identification, representation, and traceability, which may be helpful to “things” management supported by VM organizational and technical activities. Objective This research aims to investigate how SPL engineering has been applied along with the IoT paradigm, as well as how VM is being carried out. Method A systematic literature review (SLR) was conducted considering papers available until March 2019. This systematic review identified 1039 papers. After eliminating the duplicated titles and the ones not related to the review, 112 papers remained. The number of papers was narrowed to 56 after applying the exclusion criteria. Results The results provide evidence on the diversity of proposed SPLs used to specify approaches for managing IoT systems. However, most SPLs and research developed for IoT lack a systematic and detailed specification to ensure their quality, as well as tailoring guidelines for further use.}
}

@article{rayyan-727967606,
  title={Software project scheduling problem in the context of search-based software engineering: A systematic review},
  year={2019},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={155},
  pages={43-56},
  author={Rezende, Allan Vinicius and Silva, Leila and Britto, André and Amaral, Rodrigo},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219301086},
  keywords={Systematic review, Search-based software engineering, Software project scheduling problem, Software},
  abstract={This work provides a systematic literature review of the software project scheduling problem, in the context of search-based software engineering, and summarizes the main models, techniques, search algorithms and evaluation criteria applied to solve this problem. We also discuss trends and research opportunities. Our keyword search found 438 papers, published in the last 20 years. After considering the inclusion and exclusion criteria and performing the snowballing procedure, we have analyzed 37 primary studies. The results show the predominance of the use of evolutionary algorithms. The static model, in which the scheduling is performed once during the project, is considered in the majority of the papers. Synthetic instances are commonly used to validate the heuristic and hypervolume and execution time are the mostly applied evaluating criteria.}
}

@article{rayyan-727967607,
  title={Software architectures of the convergence of cloud computing and the Internet of Things: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={122},
  pages={106271},
  author={Banijamali, Ahmad and Pakanen, Olli-Pekka and Kuvaja, Pasi and Oivo, Markku},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300215},
  keywords={Cloud computing, Fog computing, Software architecture, Edge computing, Complex systems, Internet of Things (IoT), Internet, Software},
  abstract={Context Over the last few years, there has been an increasing interest in the convergence of cloud computing and the Internet of Things (IoT). Although software systems in this domain have attracted researchers to develop a large body of knowledge on software architecture designs, there is no systematic analysis of this knowledge. Objective This study aims to identify and synthesise state-of-the-art architectural elements including the design patterns, styles, views, quality attributes, and evaluation methodologies in the convergence of cloud computing and IoT. Method We used systematic literature review (SLR) methodology for a detailed analysis of 82 primary studies of a total of 1618 studies. Results We extracted six architectural design patterns in this domain; among them, edge connectivity patterns stand out as the most popular choice. The service-oriented architecture is the most frequently applied style in this context. Among all applicable quality attributes, scalability, timeliness, and security were the most investigated quality attributes. In addition, we included nine cross analyses to address the relationship between architectural patterns, styles, views, and evaluation methodologies with respect to different quality attributes and application areas. Conclusions Our findings indicate that research on software architectures in this domain is increasing. Although few studies were found in which industrial evaluations were presented, industry requires more scientific and empirically validated design frameworks to guide software engineering in this domain. This work provides an overview of the field while identifying areas for future research.}
}

@article{rayyan-727967609,
  title={Requirements engineering for safety-critical systems: A systematic literature review},
  year={2016},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={75},
  pages={71-89},
  author={Martins, Luiz Eduardo G and Gorschek, Tony},
  url={https://www.sciencedirect.com/science/article/pii/S0950584916300568},
  keywords={Systematic literature review, Requirements engineering, Safety-critical systems, Accident, Hazard, Safety requirements},
  abstract={Context Safety-Critical Systems (SCS) are becoming increasingly present in our society. A considerable amount of research effort has been invested into improving the SCS requirements engineering process as it is critical to the successful development of SCS and, in particular, the engineering of safety aspects. Objective This article aims to investigate which approaches have been proposed to elicit, model, specify and validate safety requirements in the context of SCS, as well as to what extent such approaches have been validated in industrial settings. The paper will also investigate how the usability and usefulness of the reported approaches have been explored, and to what extent they enable requirements communication among the development project/team actors in the development of SCS. Method We conducted a systematic literature review by selecting 151 papers published between 1983 and 2014. The research methodology to conduct the SLR was based on the guidelines proposed by Kitchenham and Biolchini. Results The results of this systematic review should encourage further research into the design of studies to improve the requirements engineering for SCS, particularly to enable the communication of the safety requirements among the project team actors, and the adoption of other models for hazard and accident models. The presented results point to the need for more industry-oriented studies, particularly with more participation of practitioners in the validation of new approaches. Conclusion The most relevant findings from this review and their implications for further research are as follows: integration between requirements engineering and safety engineering areas; dominance of the traditional approaches; early mortality of new approaches; need for industry validation; lack of evidence for the usefulness and usability of most approaches; and the lack of studies that investigate how to improve the communication process throughout the lifecycle. Based on the findings, we suggest a research agenda to the community of researchers and advices to SCS practitioners.}
}

@article{rayyan-727967610,
  title={A systematic literature review on requirement prioritization techniques and their empirical evaluation},
  year={2020},
  journal={Computer Standards & Interfaces},
  issn={0920-5489},
  volume={69},
  pages={103389},
  author={Bukhsh, Faiza Allah and Bukhsh, Zaharah Allah and Daneva, Maya},
  url={https://www.sciencedirect.com/science/article/pii/S0920548919300789},
  keywords={Systematic literature review, Requirements engineering, Empirical study, Requirements prioritization, Empirical research method},
  abstract={[Context and Motivation] Many requirements prioritization approaches have been proposed, however not all of them have been investigated empirically in real-life settings. As a result, our knowledge of their applicability and actual use is incomplete. [Question/problem] A 2007 systematic review on requirements prioritization mapped out the landscape of proposed prioritization approaches and their prioritization criteria. To understand how this sub-field of requirements engineering has developed since 2007 and what evidence has been accumulated through empirical evaluations, we carried out a literature review that takes as input publications published between 2007 and 2019. [Principle ideas/results] We evaluated 102 papers that proposed and/or evaluated requirements prioritization methods. Our results show that the newly proposed requirements prioritization methods tend to use as basis fuzzy logic and machine learning algorithms. We also concluded that the Analytical Hierarchy Process is the most accurate and extensively used requirement prioritization method in industry. However, scalability is still its major limitation when requirements are large in number. We have found that machine learning has shown potential to deal with this limitation. Last, we found that experiments were the most used research method to evaluate the various aspects of the proposed prioritization approaches. [Contribution] This paper identified and evaluated requirements prioritization techniques proposed between 2007 and 2019, and derived some trends. Limitations of the proposals and implications for research and practice are identified as well.}
}

@article{rayyan-727967611,
  title={Attack surface definitions: A systematic literature review},
  year={2018},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={104},
  pages={94-103},
  author={Theisen, Christopher and Munaiah, Nuthan and Al-Zyoud, Mahran and Carver, Jeffrey C and Meneely, Andrew and Williams, Laurie},
  url={https://www.sciencedirect.com/science/article/pii/S0950584918301514},
  keywords={Systematic literature review, Software engineering, Attack surface, Vulnerabilities},
  abstract={Context Michael Howard conceptualized the attack surface of a software system as a metaphor for risk assessment during the development and maintenance of software. While the phrase attack surface is used in a variety of contexts in cybersecurity, professionals have different conceptions of what the phrase means. Objective The goal of this systematic literature review is to aid researchers and practitioners in reasoning about security in terms of attack surface by exploring various definitions of the phrase attack surface. Method We reviewed 644 works from prior literature, including research papers, magazine articles, and technical reports, that use the phrase attack surface and categorized them into those that provided their own definition; cited another definition; or expected the reader to intuitively understand the phrase. Results In our study, 71% of the papers used the phrase without defining it or citing another paper. Additionally, we found six themes of definitions for the phrase attack surface. Conclusion Based on our analysis, we recommend practitioners choose a definition of attack surface appropriate for their domain based on the six themes we identified in our study.}
}

@article{rayyan-727967612,
  title={Crowdsourced software testing: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={127},
  pages={106363},
  author={Alyahya, Sultan},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920301312},
  keywords={Software testing, Systematic literature review, Empirical software engineering, Crowdsourcing, Crowdsourced software testing, Software},
  abstract={Context Crowdsourced software testing (CST) refers to the use of crowdsourcing techniques in the domain of software testing. CST is an emerging area with its applications rapidly increasing in the last decade. Objective A comprehensive review on CST has been conducted to determine the current studies aiming to improve and assess the value of using CST as well as the challenges identified by these evaluation studies. Method We conducted a systematic literature review on CST by searching six popular databases. We identified 50 primary studies that passed our quality assessment criteria and defined two research questions covering the aim of the study. Results There are three main process activities that the current literature aims to improve, namely selection of suitable testers, reporting of defects, and validation of submitted defects. In addition, there are 23 CST evaluation studies and most of them involve a large group and real crowd. These studies have identified 27 different challenges encountered during the application of crowdsourcing in software testing. Conclusions The improvements achieved for the specific process activities in CST help explore other unexplored process activities. Similarly, knowing the characteristics of the evaluation studies can direct us on what other studies are worth investigating. Additionally, many of the challenges identified by the evaluation studies represent research problems that need better understanding and alternative solutions. This research also offers opportunities for practitioners to understand and apply new solutions proposed in the literature and the variations between them. Moreover, it provides awareness to the related parties regarding the challenges reported in the literature, which they may encounter during CST tasks.}
}

@article{rayyan-727967613,
  title={Empirical software product line engineering: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={128},
  pages={106389},
  author={Chacón-Luna, Ana Eva and Gutiérrez, Antonio Manuel and Galindo, José A and Benavides, David},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920301555},
  keywords={Software product lines, Systematic literature review, Case study, Experiment, Empirical strategies, Software},
  abstract={Context: The adoption of Software Product Line Engineering (SPLE) is usually only based on its theoretical benefits instead of empirical evidences. In fact, there is no work that synthesizes the empirical studies on SPLE. This makes it difficult for researchers to base their contributions on previous works validated with an empirical strategy. Objective: The objective of this work is to discover and summarize the studies that have used empirical evidences in SPLE limited to those ones with the intervention of humans. This will allow evaluating the quality and to know the scope of these studies over time. Doing so, research opportunities can arise Methods: A systematic literature review was conducted. The scope of the work focuses on those studies in which there is human intervention and were published between 2000 and 2018. We considered peer-reviewed papers from journals and top software engineering conferences. Results: Out of a total of 1880 studies in the initial set, a total of 62 primary studies were selected after applying a series of inclusion and exclusion criteria. We found that, approximately 56% of the studies used the empirical case study strategy while the rest used experimental strategies. Around 86% of the case studies were performed in an industrial environment showing the penetration of SPLE in industry. Conclusion: The interest of empirical studies has been growing since 2008. Around 95.16% of the studies address aspects related to domain engineering while application engineering received less attention. Most of the experiments and case study evaluated showed an acceptable level of quality. The first study found dates from 2005 and since then, the interest in the empirical SPLE has increased.}
}

@article{rayyan-727967614,
  title={A systematic literature review of model-driven security engineering for cyber–physical systems},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={169},
  pages={110697},
  author={Geismann, Johannes and Bodden, Eric},
  url={https://www.sciencedirect.com/science/article/pii/S0164121220301461},
  keywords={Systematic literature review, Cyber–physical systems, Literature survey, Model-driven security, Platform-specific, Security modeling},
  abstract={The last years have elevated the importance of cyber–physical systems like IoT applications, smart cars, or industrial control systems, and, therefore, these systems have also come into the focus of attackers. In contrast to software products running on PCs or smartphones, updating and maintaining cyber–physical systems presents a major challenge. This challenge, combined with the often decades-long lifetime of cyber–physical systems, and with their deployment in often safety-critical contexts, makes it particularly important to consider their security already at design time. When aiming to obtain a provably secure design, model-driven security approaches are key, as they allow to identify and mitigate threats in early phases of the development. As attacks may exploit both code-level as well as physical vulnerabilities, such approaches must consider not just the cyber layer but the physical layer as well. To find out which model-driven security approaches for cyber–physical systems exist considering both layers, we conducted a systematic literature review. From a set of 1160 initial papers, we extracted 69 relevant publications describing 17 candidate approaches. We found seven approaches specifically developed for cyber–physical systems. We provide a comprehensive description of these approaches, discuss them in particular detail, and determine their limitations. We found out that model-driven security is a relevant research area but most approaches focus only on specific security properties and even for CPS-specific approaches the platform is only rarely taken into account.}
}

@article{rayyan-727967615,
  title={Model composition in model driven engineering: A systematic literature review},
  year={2020},
  journal={Information and Software Technology},
  issn={0950-5849},
  volume={125},
  pages={106316},
  author={Abouzahra, Anas and Sabraoui, Ayoub and Afdel, Karim},
  url={https://www.sciencedirect.com/science/article/pii/S0950584920300689},
  keywords={Systematic literature review, Model composition, Model Driven Engineering},
  abstract={Context Model Driven Engineering (MDE) aims to alleviate complexity and improve reusability in software development. The development of complex software implies to divide it into independent parts before then assembled. This is how the problem of model composition has become an interesting and stills an emerging topic in MDE. Objective Our goal is to analyze the current state of the art in model composition in the context of Model Driven Engineering. Method We use the systematic literature review based on the guidelines proposed by Biolchini et al., Brereton et al., and Kitchenham and Charters. We propose five research questions and six quality assessments. Results Of the 9270 search results, 56 have been considered relevant studies. These studies have resulted in 36 primary studies. Conclusion The evaluation shows that most of approaches allow more than two models as inputs of the composition, allow composing heterogeneous models and enable the tuning of the composition schema, while the important limitations are about the maturity of implementations and the lack on the management of future evolutions or backwards compatibility.}
}

@article{rayyan-727967617,
  title={Obstacles and features of farm management information systems: A systematic literature review},
  year={2019},
  journal={Computers and Electronics in Agriculture},
  issn={0168-1699},
  volume={157},
  pages={189-204},
  author={Tummers, J and Kassahun, A and Tekinerdogan, B},
  url={https://www.sciencedirect.com/science/article/pii/S0168169918307944},
  keywords={Systematic literature review, Farm Management Information System, Features of FMIS, Obstacles to FMIS, Information Systems},
  abstract={Various Farm Management Information Systems (FMISs) have been developed to support the management of the farm businesses. These FMISs typically support the different domains of the agricultural sector, such as arable and dairy farming; and include different set of features, such as crop, field, and financial management. These FMISs also have to deal with diverse obstacles during their development and adoption, such as lack of standardized data, cost and usability. Though several papers have been published in the past several years on this topic, there has been no explicit attempt to systematically review these papers to identify and characterize the features and obstacles. The objective of this study is to identify and describe the state-of-the-art of FMISs and as such pave the way for further research and development of FMISs. We applied a systematic literature review protocol in which we included the literature published from 2008 to 2018. We found 1048 papers of which 38 papers were selected as primary studies that we analyzed further in detail. From the detailed analysis, we identified 81 unique FMIS features and 51 unique obstacles of FMISs. We have systematically ranked the identified features and obstacles and describe the key associated aspects. These aspects include the agricultural domains, modeling approaches, delivery models, and identified stakeholders.}
}

@article{rayyan-727967618,
  title={A systematic literature review on semantic web enabled software testing},
  year={2020},
  journal={Journal of Systems and Software},
  issn={0164-1212},
  volume={162},
  pages={110485},
  author={Dadkhah, Mahboubeh and Araban, Saeed and Paydar, Samad},
  url={https://www.sciencedirect.com/science/article/pii/S0164121219302596},
  keywords={Software testing, Systematic literature review, Ontology, Semantic web, Test generation, Software, Semantics},
  abstract={Software testing, as a major verification and validation activity which revolves around quality tests, is a knowledge-intensive activity. Hence, it is reasonable to expect that it can be improved by effective application of semantic web technologies, e.g., ontologies, which have been frequently used in knowledge engineering activities. The objective of this work is to investigate and provide a better understanding of how semantic web enabled techniques, i.e., the techniques that are based on the effective application of the semantic web technologies, have been used to support software testing activities. For this purpose, a Systematic Literature Review based on a predefined procedure is conducted. A total of 52 primary studies were identified as relevant, which have undergone a thorough meta-analysis with regards to our posed research questions. This study indicates the benefits of semantic web enabled software testing in both industry and academia. It also identifies main software testing activities that can benefit from the semantic web enabled techniques. Furthermore, contributions of such techniques to the testing process are thoroughly examined. Finally, potentials and difficulties of applying these techniques to software testing, along with the promising research directions are discussed.}
}

@article{rayyan-727967619,
  title={Data preprocessing for heart disease classification: A systematic literature review},
  year={2020},
  journal={Computer Methods and Programs in Biomedicine},
  issn={0169-2607},
  volume={195},
  pages={105635},
  author={Benhar, H and Idri, A and Fernández-Alemán, J L},
  url={https://www.sciencedirect.com/science/article/pii/S0169260720314681},
  keywords={Literature review, Data preprocessing, Cardiac datasets, Cardiology, Datamining},
  abstract={Context Early detection of heart disease is an important challenge since 17.3 million people yearly lose their lives due to heart diseases. Besides, any error in diagnosis of cardiac disease can be dangerous and risks an individual's life. Accurate diagnosis is therefore critical in cardiology. Data Mining (DM) classification techniques have been used to diagnosis heart diseases but still limited by some challenges of data quality such as inconsistencies, noise, missing data, outliers, high dimensionality and imbalanced data. Data preprocessing (DP) techniques were therefore used to prepare data with the goal of improving the performance of heart disease DM based prediction systems. Objective The purpose of this study is to review and summarize the current evidence on the use of preprocessing techniques in heart disease classification as regards: (1) the DP tasks and techniques most frequently used, (2) the impact of DP tasks and techniques on the performance of classification in cardiology, (3) the overall performance of classifiers when using DP techniques, and (4) comparisons of different combinations classifier-preprocessing in terms of accuracy rate. Method A systematic literature review is carried out, by identifying and analyzing empirical studies on the application of data preprocessing in heart disease classification published in the period between January 2000 and June 2019. A total of 49 studies were therefore selected and analyzed according to the aforementioned criteria. Results The review results show that data reduction is the most used preprocessing task in cardiology, followed by data cleaning. In general, preprocessing either maintained or improved the performance of heart disease classifiers. Some combinations such as (ANN + PCA), (ANN + CHI) and (SVM + PCA) are promising terms of accuracy. However the deployment of these models in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of interpretation.}
}

@article{rayyan-727967627,
  title={The use of empirical methods in open source software research: Facts, trends and future directions},
  year={2009},
  issn={978-1-4244-3720-7},
  pages={19-24},
  author={Stol, Klaas-Jan and Babar, Muhammad Ali and Russo, Barbara and Fitzgerald, Brian},
  url={https://doi.org/10.1109/FLOSS.2009.5071355},
  publisher={IEEE Computer Society},
  series={FLOSS '09},
  keywords={Software},
  abstract={Open Source Software (OSS) is a field of study with increasing interest of researchers. By its nature, OSS is especially suitable for empirical research. A great number of OSS related empirical studies have been conducted, but no effort has been made to systematically review the published evidence. This paper presents the results of a systematic review to investigate research topics and used methods in OSS related research. We present our results as facts and trends in this field and provide directions for future research.}
}

@article{rayyan-727967637,
  title={Social aspects and how they influence MSECO developers},
  year={2019},
  pages={99-106},
  author={Steglich, Caio and Marczak, Sabrina and de Souza, Cleidson R B and Guerra, Luiz Pedro and Mosmann, Luiz Henrique and Filho, Fernando Figueira and Perin, Marcelo},
  url={https://doi.org/10.1109/CHASE.2019.00032},
  publisher={IEEE Press},
  series={CHASE '19},
  keywords={developer's collaboration, mobile software ecosystem, social aspects},
  abstract={Mobile software ecosystem (MSECO) is a new software development paradigm for mobile technologies, having three main dimensions, namely: Technical, Business and Social. The literature has a considerable number of studies on technical and business dimensions, but only a few studies focus on the social aspects of MSECOs. However, the literature has enough to provide evidence that the actors involved, such as developers, are crucial to an MSECO. This study aims to complement earlies studies by describing new social factors that influence developers to work in a MSECO. We conducted a systematic literature review in order to identify these new factors, and a field study in which 20 developers were interviewed to understand how these factors can influence them to join or keep participating in a MSECO. We found that developer become more rigorous to continue participating then to adopt a MSECO.}
}

@article{rayyan-727967638,
  title={Reference framework for digital twins within cyber-physical systems},
  year={2019},
  pages={25-31},
  author={Josifovska, Klementina and Yigitbas, Enes and Engels, Gregor},
  url={https://doi.org/10.1109/SEsCPS.2019.00012},
  publisher={IEEE Press},
  series={SEsCPS '19},
  keywords={cyber-physical system, digital twin, reference framework, Twins},
  abstract={Cyber-Physical Systems (CPSs) represent systems which integrate physical units and processes with computational entities over Internet and allow ubiquitous access of information and services. Although the application of CPSs promise to positively transform many application fields, there are still many open questions and challenges on how to design and realize a CPS. As indicated in the third level of the 5-level CPS architecture, the so-called cyber level, one of the challenges addresses the need for digital twins as high-fidelity mirroring images of CPSs entities. This is a prerequisite to realize the upper levels of the 5-level CPS architecture - the cognition and configuration level. In the scientific literature, the concept of a Digital Twin is introduced as a concrete realization for mirroring physical entities in the virtual world. However, a reference framework for the main building blocks of a Digital Twin framework is missing. This hinders a reuse of best practices and proven solutions for concrete realizations of a Digital Twin. In order to tackle this problem, we have established a reference framework for Digital Twins within a CPS. Our framework specifies the main building blocks of a Digital Twin in terms of structure and interrelations. To achieve this goal, we performed a systematic literature review, where we evaluated existing Digital Twin realizations used in different application domains of CPSs and we applied Grounded Theory and Framework Analysis as underlying methodologies. This reference framework serves a blueprint for developing Digital Twins of physical entities which are part of a CPS.}
}

@article{rayyan-727967641,
  title={Analyzing forty years of software maintenance models},
  year={2017},
  issn={978-1-5386-1589-8},
  pages={146-148},
  author={Lenarduzzi, Valentina and Sillitti, Alberto and Taibi, Davide},
  url={https://doi.org/10.1109/ICSE-C.2017.122},
  publisher={IEEE Press},
  series={ICSE-C '17},
  keywords={systematic literature review, component, software maintenance, Software},
  abstract={Software maintenance has dramatically evolved in the last four decades, to cope with the continuously changing software development models and programming languages and adopting increasingly advanced prediction models. In this work, we present the initial results of a Systematic Literature Review (SLR), highlighting the evolution of the metrics and models adopted in the last forty years.}
}

@article{rayyan-727967643,
  title={Challenges for static analysis of java reflection: Literature review and empirical study},
  year={2017},
  issn={978-1-5386-3868-2},
  pages={507-518},
  author={Landman, Davy and Serebrenik, Alexander and Vinju, Jurgen J},
  url={https://doi.org/10.1109/ICSE.2017.53},
  publisher={IEEE Press},
  series={ICSE '17},
  keywords={systematic literature review, empirical study, Java, reflection, static analysis},
  abstract={The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-the-art static analysis.Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available.We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code.}
}

@article{rayyan-727967650,
  title={Is scrum fit for global software engineering?},
  year={2017},
  issn={978-1-5386-1587-4},
  pages={1-10},
  author={Lous, Pernille and Kuhrmann, Marco and Tell, Paolo},
  url={https://doi.org/10.1109/ICGSE.2017.13},
  publisher={IEEE Press},
  series={ICGSE '17},
  keywords={systematic literature review, systematic mapping study, global software engineering, agile software development, Software},
  abstract={Distributed software engineering and agility are strongly pushing on today's software industry. Due to inherent incompatibilities, for years, studying Scrum and its application in distributed setups has been subject to theoretical and applied research, and an increasing body of knowledge reports insights into this combination. Through a systematic literature review, this paper contributes a collection of experiences on the application of Scrum to global software engineering (GSE). In total, we identified 40 challenges in 19 categories practitioners face when using Scrum in GSE. Among the challenges, scaling Scrum to GSE and adopting practices accordingly are the most frequently named. Our findings also show that most solution proposals aim at modifying elements of the Scrum core processes. We thus conclude that, even though Scrum allows for extensive modification, Scrum itself represents a barrier for global software engineering, and development teams have to customize Scrum properly to benefit from agile software development in GSE.}
}

@article{rayyan-727967651,
  title={Software analytics to software practice: A systematic literature review},
  year={2015},
  pages={30-36},
  author={Abdellatif, Tamer Mohamed and Capretz, Luiz Fernando and Ho, Danny},
  publisher={IEEE Press},
  series={BIGDSE '15},
  keywords={⛔ No DOI found, systematic literature review, big data analytics, software analytics, software development analytics, Software},
  abstract={Software Analytics (SA) is a new branch of big data analytics that has recently emerged (2011). What distinguishes SA from direct software analysis is that it links data mined from many different software artifacts to obtain valuable insights. These insights are useful for the decision-making process throughout the different phases of the software lifecycle. Since SA is currently a hot and promising topic, we have conducted a systematic literature review, presented in this paper, to identify gaps in knowledge and open research areas in SA. Because many researchers are still confused about the true potential of SA, we had to filter out available research papers to obtain the most SA-relevant work for our review. This filtration yielded 19 studies out of 135. We have based our systematic review on four main factors: which software practitioners SA targets, which domains are covered by SA, which artifacts are extracted by SA, and whether these artifacts are linked or not. The results of our review have shown that much of the available SA research only serves the needs of developers. Also, much of the available research uses only one artifact which, in turn, means fewer links between artifacts and fewer insights. This shows that the available SA research work is still embryonic leaving plenty of room for future research in the SA field.}
}

@article{rayyan-727967655,
  title={The impacts of software process improvement on developers: A systematic review},
  year={2012},
  issn={978-1-4673-1067-3},
  pages={113-122},
  author={Lavallée, Mathieu and Robillard, Pierre N},
  publisher={IEEE Press},
  series={ICSE '12},
  keywords={Software},
  abstract={This paper presents the results of a systematic review on the impacts of Software Process Improvement (SPI) on developers. This review selected 26 studies from the highest quality journals, conferences, and workshop in the field. The results were compiled and organized following the grounded theory approach. Results from the grounded theory were further categorized using the Ishikawa (or fishbone) diagram. The Ishikawa Diagram models all the factors potentially impacting software developers, and shows both the positive and negative impacts. Positive impacts include a reduction in the number of crises, and an increase in team communications and morale, as well as better requirements and documentation. Negative impacts include increased overhead on developers through the need to collect data and compile documentation, an undue focus on technical approaches, and the fact that SPI is oriented toward management and process quality, and not towards developers and product quality. This systematic review should support future practice through the identification of important obstacles and opportunities for achieving SPI success. Future research should also benefit from the problems and advantages of SPI identified by developers.}
}

@article{rayyan-727967656,
  title={Software industry experiments: A systematic literature review},
  year={2013},
  issn={978-1-4673-6286-3},
  pages={2-8},
  author={Dieste, Oscar and Juristo, Natalia and Martínez, Mauro Danilo},
  publisher={IEEE Press},
  series={CESI '14},
  keywords={industry, experiment, scoping study, Software},
  abstract={Background: There is no specialized survey of experiments conducted in the software industry. Goal: Identify the major features of software industry experiments, such as time distribution, independent and dependent variables, subject types, design types and challenges. Method: Systematic literature review, taking the form of a scoping study. Results: We have identified 10 experiments and five quasi-experiments up to July 2012. Most were run as of 2003. The main features of these studies are that they test technologies related to quality and management and analyse outcomes related to effectiveness and effort. Most experiments have a factorial design. The major challenges faced by experimenters are to minimize the cost of running the experiment for the company and to schedule the experiment so as not to interfere with production processes. Conclusion: Companies appear to be disinclined to run experiments because they are not perceived to have direct benefits. We believe that researchers staging a field experiment in a company should adopt a business-aligned stance and plan an experiment that clearly benefits managers and professionals.}
}

@article{rayyan-727967657,
  title={Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics},
  year={2015},
  issn={978-1-4503-3470-9},
  pages={83-92},
  author={Lehrig, Sebastian and Eikerling, Hendrik and Becker, Steffen},
  url={https://doi.org/10.1145/2737182.2737185},
  publisher={Association for Computing Machinery},
  series={QoSA '15},
  keywords={systematic literature review, cloud computing, cloud, definitions, efficiency, elasticity, metrics, scalability, Metronidazole, Elasticity},
  abstract={Context: In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives: Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods: We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies metrics, and considers typical cloud characteristics and cloud roles. Results: Our SLR yields 418 initial results from which we select 20 for in-depth evaluation based on our quality selection criteria. In our evaluation, we recommend concepts, definitions, and metrics for each property. Conclusions: Software architects can use our recommendations to analyze the quality of cloud computing applications. Cloud providers and cloud consumers can specify service level objectives based on our metric suggestions.}
}

@article{rayyan-727967658,
  title={Trade-off decisions across time in technical debt management: A systematic literature review},
  year={2018},
  issn={978-1-4503-5713-5},
  pages={85-94},
  author={Becker, Christoph and Chitchyan, Ruzanna and Betz, Stefanie and McCord, Curtis},
  url={https://doi.org/10.1145/3194164.3194171},
  publisher={Association for Computing Machinery},
  series={TechDebt '18},
  keywords={behavioral software engineering, decision making, intertemporal choice, naturalistic, rationalistic, technical debt, time},
  abstract={Technical Debt arises from decisions that favour short-term outcomes at the cost of longer-term disadvantages. They may be taken knowingly or based on missing or incomplete awareness of the costs; they are taken in different roles, situations, stages and ways. Whatever technical or business factor motivate such decisions, they always imply a trade-off in time, a 'now vs. later'. How exactly are such decisions made, and how have they been studied?This paper analyzes how decisions on technical debt are studied in software engineering via a systematic literature review. It examines the presently published Software Engineering research on Technical Debt, with a particular focus on decisions involving time. The findings reveal surprising gaps in published work on empirical research in decision making. We observe that research has rarely studied how decisions are made, even in papers that focus on the decision process. Instead, most attention is focused on engineering measures and feeding them into an idealized decision making process. These findings lead to a set of recommendations for future empirical research on Technical Debt.}
}

@article{rayyan-727967659,
  title={Dispersion, coordination and performance in global software teams: A systematic review},
  year={2012},
  issn={978-1-4503-1056-7},
  pages={129-138},
  author={Anh, Nguyen-Duc and Cruzes, Daniela S and Conradi, Reidar},
  url={https://doi.org/10.1145/2372251.2372274},
  publisher={Association for Computing Machinery},
  series={ESEM '12},
  keywords={systematic literature review, global software development, communication, distribution, performance, team coordination, Software},
  abstract={Effective team coordination is crucial for successful global software projects. Although considerable research effort has been made in this area, no agreement has been reached on the influence of dispersion on team coordination and performance. The objective of this paper is to summarize the evidence on the relationship among context dispersion, team coordination and performance in global software projects. We have performed a Systematic literature review (SLR) to collect relevant studies and a thematic analysis to synthesize the extracted data. We found 28 primary studies reporting the impact of five dispersion dimensions on team performance. Previously, only two primary studies considered and distinguished all of these dispersion dimensions in studying dispersed team performance. The dispersion dimensions affect team outcomes indirectly through influencing organic and mechanistic coordination processes. Empirical evidence show that geographical dispersion impacts negatively and temporal dispersion has a mixed effect on team performance. While studies with teams working across different time zones shows a tendency that the team performance is pessimistically perceived, studies that use direct measure on task performance shows a positive association to temporal dispersion. The paper provides implications for future research and practitioners in establishing effective distributed team coordination.}
}

@article{rayyan-727967660,
  title={Software evolution visualization techniques and methods - a systematic review},
  year={2016},
  pages={1-6},
  author={Salameh, Hani Bani and Ahmad, Ayat and Aljammal, Ashraf},
  keywords={Software, Systematics, Visualization, Tools, Evolution, Unified modeling language, Data visualization, Systematic Literature Review (SLR), CVS, History, Object oriented modeling, Repository, SEV},
  abstract={Background: Software is an important asset for organizations and development teams. It must evolve over time in order to meet different changes in its environment, satisfy the developers' needs, and adapt to new requirements. Software developers and team members face difficulties tracking the changes others made to their software. Software visualization is one of the effective techniques that help stakeholders to better understand how software evolves, and which parts of the software are most affected by the change. Many visualization tools and techniques have been introduced by researchers and organizations to facilitate such understanding. Method: This article presents a systematic literature review (SLR) on software evolution visualization (SEV) tools. The SLR's main focus is to: (1) explore the main target of SEV, (2) analyze the classifications and taxonomies that are used to represent SEV tools, and (3) find out what are the main sources of information used to visualize software's evolution. Result: 29 papers were analyzed out of 55 papers. The result showed that SEV tools can be classified into five different groups: graph-based, notation-based, matrix-based, and metaphor-based and others. Graph-based are most popular while Notation-based are the least. SEVs focus can be either Artifact-centric visualization, Metric-centric visualization, Feature-centric visualization, or Architecture-centric visualization. The main source of information used to ex-tract information are the software repositories. Conclusion: This work can help developer, maintainer, researcher to get good knowledge about the state of software evolution and visualization as a whole.}
}

@article{rayyan-727967662,
  title={Requirements management techniques and tools in small and medium enterprises (SMEs): a systematic review},
  year={2019},
  pages={1-7},
  author={García, Yolanda-Meredith and Montes, Ángel and Lira, Jairo and Martínez, Juan},
  keywords={Software, Software engineering, Systematics, Visualization, Tools, Unified modeling language, requirements management, Requirements management, SME's, software engineering systematic review, techniques, tools},
  abstract={Currently, software is an important element used in different areas, both in the personal or professional. Therefore, it is required that the software be of quality, that is, that it fulfills the purpose for which it was created and satisfies the client. That's why to develop software, you must follow an engineering approach as well as a discipline, being of special importance the Requirements Management (REQM). In such a way that this work considers the REQM as one of the basic areas of project management, it starts with the requirements to define the "what to build" for the product and the project. This paper presents a software engineering systematic review process, the phases followed, the description of each one of them, as well as its implementation applied to the subject of the techniques and tools of the REQM area in software development Small and Medium Enterprises (SME's).}
}

@article{rayyan-727967663,
  title={Non-functional requirements prioritization: A systematic literature review},
  year={2019},
  pages={379-386},
  author={Ijaz, Khush Bakht and Inayat, Irum and Allah Bukhsh, Faiza},
  keywords={systematic literature review, Software engineering, Systematics, Bibliographies, Data mining, Search problems, Quality assessment, non-functional requirements, quality attributes, quality requirements},
  abstract={Continuous delivery and rapidly changing requirements in agile environments force the developers to put non-functional requirements (NFRs) on halt till maintenance phase. However, neglecting NFRs during prioritization phase may lead to inaccurate estimations for software projects resulting in high maintenance cost and failures. The subjective and uncertain nature of non-functional requirements makes them unfit to be prioritized using conventional prioritization methods. Although the existing literature reports on inadequate consideration given to NFRs prioritization, still no comprehensive systematic effort has been done to report the limitations and evaluation mechanisms of existing NFRs prioritization approaches. Requirements engineering society lacks a broad understanding of NFRs prioritization approaches and the challenges which need to be overcome. Therefore, we aim to investigate (i) the existing NFR prioritization techniques and their validation mechanisms, (ii) the role of Artificial Intelligence (AI) in NFRs prioritization, and (iii) the limitations of existing NFRs prioritization techniques. For this, we reviewed the literature published from 2008 till present and extracted 30 studies. The results reveal twenty-five NFRs prioritization techniques out of which only three are AI based. The major limitations we have come across are that most of the NFRs prioritization techniques are not scalable to large datasets, inter-dependencies between functional requirements (FRs) and NFRs are ignored, and the uncertainties associated with NFRs are not considered at all. However, the literature suggests that AI-based techniques and Fuzzy logic may be used to solve issues such as uncertainties i.e. ambiguities, vagueness, and subjective opinions of stakeholders. This review adds to the existing body of knowledge on NFRs and motivates the practitioners to focus on the NFR prioritization by highlighting the limitations of the existing methods.}
}

@article{rayyan-727967664,
  title={Multi-objective optimization techniques for software refactoring: A systematic literature review},
  year={2019},
  pages={1-7},
  author={Rafique, Muhammad Zaid and Alam, Khubaib Amjab and Iqbal, Umer},
  keywords={Software, Software Engineering, Systematics, Systematic Literature Review, Bibliographies, Tools, Optimization, Databases, Automated Software Refactoring, Complexity theory, Multi-Objective Software Refactoring, Search-Based Software Engineering, Search-Based Software Refactoring, Software refactoring},
  abstract={Software Refactoring is an essential activity of software maintenance. It aims at improving the internal structure of the program without affecting its external functionalities which not only aids in improving maintainability and readability but also helps in reducing overall software complexity. Many different manuals and automated software refactoring tools are available but most of these tools focus single objective refactoring i.e. improving the quality or reducing the code lines. Software refactoring involves many factors so different authors have proposed different multi-objective software refactoring approaches. We have performed systematic literature to classify and analyzed the studies published in the field of multi-objective software refactoring. The main objectives of our research are to categorize the studies on multi-objective software refactoring according to 4 criteria. We have considered studies from electronics databases from 2014 to 2019. A total of 19 studies were finalized based on our inclusion-exclusion and quality assessment criteria. The results of our research show that NSGA-II is a widely popular technique in the domain of multi-objective software refactoring whereas NSGA-III is popular when many objectives were considered. Furthermore, 11 most widely uses open source and industrial projects are identified which are used to evaluate the multi-objective software refactoring approaches. It was also observed that Precision, Recall and Inverse Generation Distance are commonly used evaluation metrics. The chronological distribution of studies shows that 2016 was the most productive research year in this field. Our results show that 76% of studies are ranked high based on our predefined quality assessment criteria. Based on our results we have concluded that multiobjective software refactoring is still an emerging field and there is a need to apply the latest state-of-the-art multi-objective approaches to get better results.}
}

@article{rayyan-727967666,
  title={Overcoming the equivalent mutant problem: A systematic literature review and a comparative experiment of second order mutation},
  year={2014},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={40},
  number={1},
  pages={23-42},
  author={Madeyski, Lech and Orzeszyna, Wojciech and Torkar, Richard and Józala, Mariusz},
  keywords={Systematics, Testing, Databases, Mutation testing, Java, Educational institutions, equivalent mutant problem, higher order mutation, Informatics, Libraries, second order mutation, Mutation},
  abstract={Context. The equivalent mutant problem (EMP) is one of the crucial problems in mutation testing widely studied over decades. Objectives. The objectives are: to present a systematic literature review (SLR) in the field of EMP; to identify, classify and improve the existing, or implement new, methods which try to overcome EMP and evaluate them. Method. We performed SLR based on the search of digital libraries. We implemented four second order mutation (SOM) strategies, in addition to first order mutation (FOM), and compared them from different perspectives. Results. Our SLR identified 17 relevant techniques (in 22 articles) and three categories of techniques: detecting (DEM); suggesting (SEM); and avoiding equivalent mutant generation (AEMG). The experiment indicated that SOM in general and JudyDiffOp strategy in particular provide the best results in the following areas: total number of mutants generated; the association between the type of mutation strategy and whether the generated mutants were equivalent or not; the number of not killed mutants; mutation testing time; time needed for manual classification. Conclusions . The results in the DEM category are still far from perfect. Thus, the SEM and AEMG categories have been developed. The JudyDiffOp algorithm achieved good results in many areas.}
}

@article{rayyan-727967667,
  title={Software configuration engineering in practice interviews, survey, and systematic literature review},
  year={2020},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={46},
  number={6},
  pages={646-673},
  author={SAYAGH, Mohammed and Kerzazi, Noureddine and Adams, Bram and Petrillo, Fabio},
  keywords={Systematic literature review, Systematics, survey, Bibliographies, Empirical study, Interviews, Software systems, configuration, configuration engineering, Facebook, interviews, Software algorithms, Software},
  abstract={Modern software applications are adapted to different situations (e.g., memory limits, enabling/disabling features, database credentials) by changing the values of configuration options, without any source code modifications. According to several studies, this flexibility is expensive as configuration failures represent one of the most common types of software failures. They are also hard to debug and resolve as they require a lot of effort to detect which options are misconfigured among a large number of configuration options and values, while comprehension of the code also is hampered by sprinkling conditional checks of the values of configuration options. Although researchers have proposed various approaches to help debug or prevent configuration failures, especially from the end users' perspective, this paper takes a step back to understand the process required by practitioners to engineer the run-time configuration options in their source code, the challenges they experience as well as best practices that they have or could adopt. By interviewing 14 software engineering experts, followed by a large survey on 229 Java software engineers, we identified 9 major activities related to configuration engineering, 22 challenges faced by developers, and 24 expert recommendations to improve software configuration quality. We complemented this study by a systematic literature review to enrich the experts' recommendations, and to identify possible solutions discussed and evaluated by the research community for the developers' problems and challenges. We find that developers face a variety of challenges for all nine configuration engineering activities, starting from the creation of options, which generally is not planned beforehand and increases the complexity of a software system, to the non-trivial comprehension and debugging of configurations, and ending with the risky maintenance of configuration options, since developers avoid touching and changing configuration options in a mature system. We also find that researchers thus far focus primarily on testing and debugging configuration failures, leaving a large range of opportunities for future work.}
}

@article{rayyan-727967669,
  title={Kanban in software development: A systematic literature review},
  year={2013},
  pages={9-16},
  author={Ahmad, Muhammad Ovais and Markkula, Jouni and Oivo, Markku},
  keywords={systematic literature review, Systematics, Visualization, Bibliographies, Context, kanban, lean approach, Manufacturing industries, software development, Software development management, Software},
  abstract={Using of Kanban in software development is an emerging topic. This systematic literature review was conducted in order to analyze the current trend of Kanban usage in software development and to identify the obtained benefits and involved challenges. The search strategy resulted in 492 papers, of which 19 were identified as primary studies relevant to our research. The main reported benefits of using the Kanban method were improved lead time to deliver software, improved quality of software, improved communication and coordination, increased consistency of delivery, and decreased customer reported defects. The reported challenges included lack of knowledge and specialized training as well as various organizational issues. Additionally, suggested practices were extracted from the primary studies and summarized for guiding the practitioners interested in adopting Kanban. The findings of this literature review are intended for helping researchers and practitioners to gain a better understanding of the current state of Kanban usage in software development.}
}

@article{rayyan-727967670,
  title={Tacit knowledge in software testing: A systematic review},
  year={2019},
  pages={1-6},
  author={Idrus, Hariaty Mohd and Ali, Nor'ashikin},
  keywords={Software, Software testing, systematic literature review, Systematics, Bibliographies, Knowledge management, software testing, Knowledge engineering, competency, knowledge management, software testers, tacit knowledge},
  abstract={This paper presents a systematic review of tacit knowledge in software testing. The main objectives of conducting this systematic review is to identify and synthesize issues and challenges regarding tacit knowledge in software testing, its influential factors that affect the tacit knowledge creation, sharing, use and transfer among software testers, its impacts on software testing, and the research methods being undertaken by the selected reviewed studies. Systematic Literature Review (SLR) is used for reviewing 14 primary studies that focus specifically on tacit knowledge in software testing. This paper provides significant evidences on the importance of tacit knowledge in software testing that will direct further directions for knowledge management (KM) and software testing practitioners and researchers.}
}

@article{rayyan-727967671,
  title={Change Impact analysis and propagation in service based business process management systems preliminary results from a systematic review},
  year={2014},
  pages={7-12},
  author={Amjad Alam, Khubaib and Ahmad, Rodina Binti and Akhtar, Maria},
  keywords={Systematics, SOA, Service-oriented architecture, Context, systematic literature review (SLR), BPM, Organizations, Analytical models, Change Propagation, CIA, Dependency Analysis, Web Services},
  abstract={Change Impact analysis and propagation have widely been studied in Software engineering research, but most studies are related to monolithic software applications, and very few studies have focused on distributed environments. Newer technologies like SOA, BPM and Cloud demand different perspectives and newer tools and techniques to support impact analysis and propagation in distributed environments. SOA adoption is fairly recent and major concern is now shifting towards maintenance and evolution of the service based business Process management systems. Change impact analysis and propagation have been identified as a potential research area in this context. This study is part of a larger study to systematically review all available research on impact analysis and propagation in context of Business process management (BPM) and Service Oriented Architecture (SOA). Preliminary results have been reported by answering 2 selected research Questions. 43 studies were selected out of initial set of 182 research articles. Studies answering selected research questions have been included in this report. BPM is considered at Business Level for Business operations and Process Models, while SOA is considered as a Deployment Architecture at service level. We have extended the scope of our study to Inter-Process and inter-service change analysis in addition to Top-Down, Bottom-Up analysis. This study revealed that although evolution of service based systems is getting significant attention, very few approaches and tools exist to support impact analysis and propagation activities.}
}

@article{rayyan-727967672,
  title={Using scrum in global software development: A systematic literature review},
  year={2009},
  pages={175-184},
  author={Hossain, Emam and Babar, Muhammad Ali and Paik, Hye-young},
  keywords={Software engineering, systematic literature reviews, Data mining, Project management, Scrum, Programming, Global software development, Australia, agile approaches, Computer architecture, Computer industry, Meeting planning, Time to market, Variable speed drives, Software},
  abstract={There is a growing interest in applying agile practices in global software development (GSD) projects. The literature on using Scrum, one of the most popular agile approaches, in distributed development projects has steadily been growing. However, there has not been any effort to systematically select, review, and synthesize the literature on this topic. We have conducted a systematic literature review of the primary studies that report using Scrum practices in GSD projects. Our search strategy identified 366 papers, of which 20 were identified as primary papers relevant to our research. We extracted data from these papers to identify various challenges of using Scrum in GSD. Current strategies to deal with the identified challenges have also been extracted. This paper presents the reviewpsilas findings that are expected to help researchers and practitioners to understand the challenges involved in using Scrum for GSD projects and the strategies available to deal with them.}
}

@article{rayyan-727967673,
  title={A systematic literature review of best practices and challenges in follow-the-sun software development},
  year={2013},
  pages={18-23},
  author={Kroll, Josiane and Hashmi, Sajid Ibrahim and Richardson, Ita and Audy, Jorge L N},
  keywords={Software, Software engineering, Testing, Global software development, challenges, Best practices, best practice, Cultural differences, Electronic mail, Follow-the-sun (FTS), Global communication},
  abstract={Follow-the-sun (FTS) software development is a strategy used to reduce the length of software projects that are developed across globally distributed locations. However, due to communication and collaboration challenges, software companies find it difficult to adopt this development strategy during task allocation and daily project handovers. In this study, we present results from a Systematic Literature Review (SLR) performed on papers published between 1990 and 2012. Our goal was to identify best practices and challenges for FTS implementation. We found 36 best practices and 17 challenges for FTS. These results are discussed in this paper in order to indicate opportunities for future research and make our results useful for the project managers.}
}

@article{rayyan-727967674,
  title={Requirements engineering visualization: A systematic literature review},
  year={2016},
  pages={6-15},
  author={Abad, Zahra Shakeri Hossein and Noaeen, Mohammad and Ruhe, Guenther},
  keywords={Software, Visualization, Manuals, Requirements engineering, Unified modeling language, Data visualization, Stakeholders},
  abstract={Requirements Engineering (RE) is a decision-centric activity which is highly data-intensive. The results of this process are known to have key impact on the results of the project. As known from the experience in other fields and disciplines, visualization can potentially provide more insights into data, information and knowledge studied. While research in the area of information visualization and its application to software engineering has rapidly increased over the last decade, there is only a limited amount of studies addressing the usage and impact of visualization techniques for RE activities. In this paper, we report on the results of a Systematic Literature Review (SLR) related to RE visualization. Extending the established SLR process by the usage of grounded theory for the encoding of papers, we synthesize 18 usage patterns. Even though there are punctual applications, there is a clear deficit on a holistic perspective across the different RE activities. As another conclusion, we derive the clear need for more research on visualization support in particular for tackling requirements uncertainty, requirements verification, and modeling, as well as non-functional requirements (NFRs).}
}

@article{rayyan-727967676,
  title={Continuous practices and technical debt: a systematic literature review},
  year={2020},
  pages={40-44},
  author={Lunde, Bj⊘rn Arild and Colomo-Palacios, Ricardo},
  keywords={Software, Software engineering, Systematics, Bibliographies, Tools, Technical debt, Databases, continuous delivery, continuous deployment, Complexity theory, continuous integration, continuous refactoring, continuous release},
  abstract={Technical debt in software development is a common problem that is overlooked by many development teams. This debt can be generated from a variety of reasons, including time pressure and complexity in software. Technical debt in simple terms is when a simple and less optimized solution is carried out in order to gain short term benefits, which leads to refactoring and reworking code later on, costing both time and money. The issue is present in both big, established companies and small startups, and is the reason why many of these small startups never get enough economic grip before debt catch up and they go bankrupt. This paper aims to address this problem by exploring how continuous practices including DevOps could help resolve this issue by adopting the right approaches into the software development cycle and workflow. So as to collect information about these topics, a systematic literature review has been conducted, covering both positive and negative impacts these practices can have on technical debt. The findings will present the current practices used to manage and reduce the accumulation of technical debt, if and how these approaches can be used to reduce already existing technical debt and which of these practices that have the biggest impact on technical debt. The paper concludes that there's potential for continuous practices including DevOps to possibly reduce technical debt if applied appropriately.}
}

@article{rayyan-727967678,
  title={HTTPS contribution in web application security: A systematic literature review},
  year={2020},
  pages={347-356},
  author={Wijitrisnanto, Fajar and Suhardi and Yustianto, Purnomo},
  keywords={systematic literature review, Systematics, Data mining, Search problems, Databases, Protocols, Application security, cookie, csp, hpkp, hsts, https, security, Servers, tls, web application},
  abstract={A Web application is one of the most used technology nowadays due to its flexibility in delivering services to society. It also plays a good portion in enhancing our daily life since it could provide almost any kind of services through an application served from the internet. Thus, many users' private information runs the risk of being exposed to an unauthorized party. Standard browser connection uses HTTPS protocol, while both TLS over HTTP and Web application are known for several of vulnerabilities. This paper presents the results of an SLR study on web application security of HTTPS implementation. The study selects 45 qualified papers related to the topic and analyzed 24 of the documents. The findings are categorized into three labels: threats, threats impact, and defense mechanisms. This work also classifies the attack and threats based on the impact produced. In this study, the lack of understanding about security-related mechanism in TLS, session management, and web application still become the culprit of most attack and vulnerability. Based on this work, a researcher could better prioritize and prepare security mechanism to overcome the threats.}
}

@article{rayyan-727967679,
  title={Software architecture optimization methods: A systematic literature review},
  year={2013},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={39},
  number={5},
  pages={658-683},
  author={Aleti, Aldeida and Buhnova, Barbora and Grunske, Lars and Koziolek, Anne and Meedeniya, Indika},
  keywords={Software, systematic literature review, Systematics, Software architecture, Taxonomy, Computer architecture, optimization methods, Optimization methods, problem overview, Software architecture optimization},
  abstract={Due to significant industrial demands toward software systems with increasing complexity and challenging quality requirements, software architecture design has become an important development activity and the research domain is rapidly evolving. In the last decades, software architecture optimization methods, which aim to automate the search for an optimal architecture design with respect to a (set of) quality attribute(s), have proliferated. However, the reported results are fragmented over different research communities, multiple system domains, and multiple quality attributes. To integrate the existing research results, we have performed a systematic literature review and analyzed the results of 188 research papers from the different research communities. Based on this survey, a taxonomy has been created which is used to classify the existing research. Furthermore, the systematic analysis of the research literature provided in this review aims to help the research community in consolidating the existing research efforts and deriving a research agenda for future developments.}
}

@article{rayyan-727967680,
  title={Evaluation and measurement of software process Improvement—A systematic literature review},
  year={2012},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={38},
  number={2},
  pages={398-424},
  author={Unterkalmsteiner, Michael and Gorschek, Tony and Islam, A K M Moinul and Cheng, Chow Kian and Permadi, Rahadian Bayu and Feldt, Robert},
  keywords={Software, Software measurement, Systematics, Data mining, Organizations, Current measurement, metrics/measurement, Process implementation and change, process measurement, systematic literature review.},
  abstract={BACKGROUND-Software Process Improvement (SPI) is a systematic approach to increase the efficiency and effectiveness of a software development organization and to enhance software products. OBJECTIVE-This paper aims to identify and characterize evaluation strategies and measurements used to assess the impact of different SPI initiatives. METHOD-The systematic literature review includes 148 papers published between 1991 and 2008. The selected papers were classified according to SPI initiative, applied evaluation strategies, and measurement perspectives. Potential confounding factors interfering with the evaluation of the improvement effort were assessed. RESULTS-Seven distinct evaluation strategies were identified, wherein the most common one, “Pre-Post Comparison,” was applied in 49 percent of the inspected papers. Quality was the most measured attribute (62 percent), followed by Cost (41 percent), and Schedule (18 percent). Looking at measurement perspectives, “Project” represents the majority with 66 percent. CONCLUSION-The evaluation validity of SPI initiatives is challenged by the scarce consideration of potential confounding factors, particularly given that “Pre-Post Comparison” was identified as the most common evaluation strategy, and the inaccurate descriptions of the evaluation context. Measurements to assess the short and mid-term impact of SPI initiatives prevail, whereas long-term measurements in terms of customer satisfaction and return on investment tend to be less used.}
}

@article{rayyan-727967681,
  title={Using bio-inspired features selection algorithms in software effort estimation: A systematic literature review},
  year={2019},
  pages={220-227},
  author={Ali, Asad and Gravino, Carmine},
  keywords={Software, Systematic literature review, Effort estimation, Quality assessment, Estimation, Software algorithms, Bio inspired algorithms, Feature extraction, Feature selection algorithms, Genetic algorithms, Prediction algorithms, Algorithms, Tocopherols},
  abstract={Feature selection algorithms select the best and relevant set of features of the datasets which leads to an increase in the accuracy of predictions when employed with the machine learning techniques. Different feature selection algorithms are used in the domain of Software Development Effort Estimations (SDEE) and recently the use of bio-inspired feature selection algorithms got the attention of the researchers, which provided the best results in terms of the accuracy measures. In this paper, we manage to systematically evaluate and assess different bio-inspired feature selection algorithms which have been employed and investigated in the studies related to SDEE with the aim of increasing the accuracy of estimations. To the best of our knowledge, there is no Systematic Literature Review (SLR) which investigated the use of bio-inspired algorithms in SDEE. Since, the use of bio-inspired algorithms in the area of SDEE started in the late 2000, we have considered the studies published between 2007-2018. We have selected about 30 different studies from five digital libraries, i.e., IEEE explore, Springer, ScienceDirect, ACM digital library, and Google Scholar, after the filtering of inclusion/exclusion and quality assessment criteria. The main findings of our SLR are that Genetic Algorithms (GA) and Particle Swarm Optimizations (PSO) are widely used bio-inspired algorithms. Moreover, GA and PSO are the algorithms which outperform baseline estimation techniques (estimation techniques employed without any feature selection algorithms) in more number of experiments, in terms of prediction accuracy.}
}

@article{rayyan-727967683,
  title={Programmer eXperience: A systematic literature review},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={71079-71094},
  author={Morales, Jenny and Rusu, Cristian and Botella, Federico and Quiñones, Daniela},
  keywords={systematic literature review, Systematics, Bibliographies, Programming, Usability, Heuristic evaluation, Programmer eXperience, Programming environments, usability, User experience, User eXperience},
  abstract={Programmers use various software development artifacts in their work, such as programming environments, design documents, and programming codes. These software artifacts can be studied and improved based on usability and User eXperience (UX) factors. In this paper, we consider programmers to be a specific case of users and analyze different elements that influence their experience in this specific context. We conducted a systematic literature review of papers published over the last ten years related to 1) the definition of the Programmer eXperience (PX); 2) the PX, UX, and usability factors regarding the programming environments, design documents, and programming codes; and 3) sets of heuristics to evaluate the software development artifacts mentioned before. We analyzed 73 articles, and the results obtained show that: 1) the important elements that influence the PX are the motivation of programmers and the choice of tools they use in their work, such as programming environments; 2) most of the identified studies (59%) aimed to evaluate the influence of the PX, UX, and usability on programming environments; 3) the majority of the studies (70%) used methods such as usability tests and/or heuristic evaluation methods; and 4) four sets of heuristics are used to evaluate software development artifacts in relation to programming environments, programming languages, and application programming interfaces. The results suggest that further research in this area is necessary to better understand and evaluate the concept of the PX.}
}

@article{rayyan-727967684,
  title={Software stability: A systematic literature review},
  year={2018},
  pages={109-115},
  author={Ramirez, Saul Melchor and Cortes, Karen and Ocharan-Hernandez, Jorge Octavio and Sanchez Garcia, Angel Juan},
  keywords={Software, Measurement, Software architecture, Computer architecture, design stability, evolvability, Proposals, software architecture design, software eolution, software stability, Stability criteria, stability metric},
  abstract={Evolvability is the capability of a software product to be evolved to continue to serve its customers in a cost effective way. The term software evolution is closely related to maintenance, and evolvability is often used to mean maintainability or modifiability. When developing software architectures, evolvability is a desired quality attribute. It must be remembered that software architecture design is related to the proper consideration of quality attributes. Architectural decisions are made in order to fulfill, not only functional requirements, but also quality attributes. In order to design a software architecture that properly considers evolvability, Maccari and Galal have proposed an evolvability view which considers components stability. However, there is no guidance on how to obtain components stability. In order to propose a stability metric for architectural components, a systematic literature review (SLR) was performed. The intention of such a systematic literature review was to identify and evaluate available research about software stability. The results of the SRL are presented along with some proposals for further research.}
}

@article{rayyan-727967686,
  title={What do affect customers to use mobile payment continually? A systematic literature review},
  year={2020},
  pages={1-6},
  author={Putri, Mutia Fadhila and Purwandari, Betty and Hidayanto, Achmad Nizar},
  keywords={Systematics, Bibliographies, Databases, Business, Informatics, Customer Relationship Management, intention to use, Mobile Payment, Online banking, Reliability theory},
  abstract={The intention to use mobile payment (M-Payment) has been growing, in line with digital economy growth. This phenomenon contributes to the emergence of M-Payment research lately. Several theories can be applied to those researches. In general, the research tends to adopt any particular theory to explore the factors that affect the use of M-Payment. A comprehensive and succinct review is needed to continually help scholars and practitioners understand what affects customers' use of M-Payment, the marketing strategy applied in the M - Payment business, and the theories implemented in current M-Payment research. This study aims to categorize the findings and assess M-Payment research's state of the art to facilitate future research. Data retrieved from IEEE, ACM, Science Direct, Scopus, EBSCOhost, and SpringerLink databases were published between 2017 and 2020. The data is analyzed by following the Kitchenham systematic literature review approach. As a result, this study establishes a table of theoretical used in M-Payment research, the marketing strategy applied in the M - Payment business, and factors affecting M-Payment's use classified into three main groups: technological factors, behavioral factors, and personal factors.}
}

@article{rayyan-727967687,
  title={Usability heuristics: A systematic review},
  year={2016},
  pages={1-8},
  author={Jimenez, Cristhy and Lozada, Pablo and Rosas, Pablo},
  keywords={Systematics, Systematic Literature Review, Bibliographies, Data mining, Usability, Software systems, Proposals, Heuristic Evaluation, Software Evaluation, Usability Heuristics},
  abstract={Heuristic evaluation is one of the most commonly used usability inspection methods. The set of usability heuristics plays a key role in the performance of this method. Traditionally, the ten Nielsen's usability heuristics have been widely applied. However, nowadays, new sets of specific usability heuristics are been developed in order to improve the results of usability evaluations. This paper presents a preliminar systematic literature review (SLR) conducted in order to analyze the progress in the development and use of usability heuristics. The main goal was to identify new sets of usability heuristics but also justify the need to formalize a process for developing specific usability heuristics.}
}

@article{rayyan-727967688,
  title={The role of project manager in agile software teams: A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={117109-117121},
  author={Gandomani, Taghi Javdani and Tavakoli, Zeinab and Zulzalil, Hazura and Farsani, Hadi Khosravi},
  keywords={Software, systematic literature review, Systematics, Bibliographies, Agile software development, Project management, Scrum, Databases, Agile project management, Agile project manager, Companies, Planning, project manager},
  abstract={The use of Agile methodologies in software development has grown steadily over recent years. One of the main emphases of these methods is employing cross-functional and self-organized teams and highly skilled developers in software projects. In such a condition, project management would be a serious concern. Indeed, it would be confusing whether Agile teams are really in need of the role of the project manager. While Agile methodologies do not explicitly define the role of the project manager, many reports mention the existence of this role in Agile projects in real environments. So, it seems that the existence of this role is debated. Conducting a Systematic Literature Review, this study tried to find out answers to the ambiguities and questions regarding the role of Agile project management, the role of the project manager, and related issues. Focusing on the primary studies, the results show that there is no independent job called project manager in Agile methodologies. However, there is a need for it. Moreover, in the absence of this role in Agile methodologies and the need for it, it seems that this role would be structurally different from the traditional role of the project manager in terms of responsibilities and duties. Finally, the results show that pre-defined roles in Agile methodologies are often responsible for the project manager duties in software teams with no project manager.}
}

@article{rayyan-727967691,
  title={A systematic literature review of interoperable architecture for e-government portals},
  year={2011},
  pages={82-87},
  author={Sedek, Khairul Anwar and Sulaiman, Shahida and Omar, Mohd Adib},
  keywords={Systematic literature review, Security, Reliability, Interoperability, Computer architecture, E-government Portal, Electronic government, Portals, Service oriented architecture, Software Architecture},
  abstract={One of the roles of e-government portals is to provide a one-stop service to users. In order to fulfill this role, it requires collaboration with other government agencies and businesses to provide an effective one-stop center for users to access and perform various services. Current e-government portals are mostly lack of interoperability whereby users still need to access government services from various portals or websites. Interoperability is a technical requirement to achieve government services collaboration and integration. There are many challenges and approaches to achieve better interoperability in e-government portals. Architecture-based and model-based approaches are essential research areas that can improve interoperability starting from the planning stages. Architecture provides overall overview of e-government components and relationship between components. This paper systematically reviews current architecture-based approaches to find a suitable approach and its requirements to produce a better architecture for e-government portal based on the lessons learned from the previous works.}
}

@article{rayyan-727967693,
  title={Taxonomy for complexity estimation in agile methodologies: A systematic literature review},
  year={2019},
  pages={87-96},
  author={Durán, Mayra and Juárez-Ramírez, Reyes and Jiménez, Samantha and Tona, Claudia},
  keywords={Scrum, complexity, estimation, User Story},
  abstract={Currently, software development teams use different methods to estimate their projects, in Scrum, there are different methods to estimate the value and complexity of a user story. However, these methods are not accurate and most of them depend on many attributes that sometimes are not contemplated or are unknown by the development team. Although Planning Poker has many benefits, it has been found that this method is efficient mostly for experience teams, since the estimation will always depend on the observation of an expert and his experience. On the other hand, without a standard set of attributes for describing complexity, subjectivity problems remain when estimating user stories. This study presents a systematic literature review in which identifies the attributes that influence the complexity estimation in user stories.}
}

@article{rayyan-727967694,
  title={Usability of mobile applications: A systematic literature study},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={55563-55577},
  author={Weichbroth, Paweł},
  keywords={systematic literature review, Systematics, Bibliographies, Mobile applications, Usability, usability, attributes, ISO Standards, measures, Smart phones, usability evaluation methods},
  abstract={Since the release of the first mobile devices, the usability of on-board applications has been the concern not only of software vendors but hardware manufacturers as well. The academia community later willingly joined the discussion on usability in terms of theory and empirical measurement, having experience and knowledge in desktop settings. At first sight, such a background should guarantee a solid foundation to conduct research on software usability in a new setting. However, a preliminary study on the subject matter revealed methodological disorder in contemporary literature. As a matter of fact, a need emerged to review existing usability definitions, attributes and measures to recognize all associated aspects. In order to fill this void, we conducted a systematic literature review on usability studies indexed by the Scopus database and devoted to mobile applications. The input volume covers 790 documents from 2001 to 2018. The data analysis shows that the ISO 9241-11 usability definition has been adopted in an unchanged form and popularized as the standard by the HCI community. Secondly, in total, 75 attributes were identified and analysed. The most frequent are efficiency (70%), satisfaction (66%) and effectiveness (58%), which directly originate from the above definition. Subsequently, the less frequent are learnability (45%), memorability (23%), cognitive load (19%) and errors (17%). The last two concern simplicity (13%) and ease of use (9%). Thirdly, in the evaluation of usability, controlled observation and surveys are two major research methods applied, while eye-tracking, thinking aloud and interview are hardly used and serve as complementary to collect additional data. Moreover, usability evaluations are often confused with user experience dimensions, covering not only application quality characteristics, but also user beliefs, emotions and preferences. All these results indicate the need for further research on the usability of mobile applications, aiming to establish a consensus in the theory and practice among all interested parties.}
}

@article{rayyan-727967695,
  title={A simplified systematic literature review: Improving Software Requirements Specification quality with boilerplates},
  year={2015},
  pages={99-105},
  author={Anuar, Umairah and Ahmad, Sabrina and Emran, Nurul A},
  keywords={Software, Systematics, Bibliographies, Data mining, Requirements engineering, Stakeholders, Protocols, boilerplates, software requirements specification, SRS quality},
  abstract={The quality of Software Requirements Specification (SRS) is crucial in order to ensure successful project completion. SRS of poor quality usually lacks of quality attributes such as completeness, accuracy and disambiguity. Boilerplate is a technique used to deal with problems in SRS. However, study on the coverage of boilerplate contribution especially in improving SRS quality is limited. This paper presents Systematic Literature Review (SLR) on problems in SRS and boilerplates. The review that covers literature from 1997 to 2015 reveals that 1) poor quality SRS is the most popular problem among the other five SRS problems discovered, 2) Boilerplate technique has been applied to cope with SRS of poor quality, where disambiguity has been found the most popular quality attribute.}
}

@article{rayyan-727967696,
  title={Evolution of the web of social machines: A systematic review and research challenges},
  year={2020},
  journal={IEEE Transactions on Computational Social Systems},
  issn={2329-924X},
  volume={7},
  number={2},
  pages={373-388},
  author={Brito, Kellyton dos Santos and de Lima, Alysson Alves and Ferreira, Sérgio Endrigo and de Arruda Burégio, Vanilson and Garcia, Vinicius Cardoso and de Lemos Meira, Silvio Romero},
  keywords={systematic review, Software, Software engineering, Systematics, Bibliographies, Quality assessment, Taxonomy, Conferences, Human???machine interaction, social computing, social machines (SMs), web 2.0},
  abstract={Social machines (SMs) are the term used to define processes in which the people do the creative work and the machine does the administration. The concept was scarcely studied until 2013, when the series of workshops on SMs was created, and the topic began to receive more attention. However, it is not clear how research has evolved since then. This article aims to investigate and summarize how the research field of SM has evolved since 2013, to outline the state of the art and practice, and identify research opportunities within this field. We performed a systematic literature review analyzing the quantity and quality of publications, the main topics addressed, the current classifications of SMs, the context in which the concepts are used, and the main perceived challenges. We identified and analyzed 56 relevant studies addressing 12 topics, representing the current practical landscape of research regarding SM. Our findings suggest that: 1) research interest in SM is increasing, but is still concentrated into two research clusters; 2) topics are grouped under two main headings: a) human behavior and b) software development; 3) there is still a need for a common taxonomy to define and classify SM; 4) the main contexts are crowdsourcing and social networks, and the majority of studies are small-scale studies in an academic setup; and 5) more empirical rigor and evidence is needed regarding their use, benefits and challenges, despite some evidence regarding challenges related to user engagement, trust, scalability, and a better human-machine collaboration. Finally, a vision of the future of SMs, with the integration of web of people, artificial intelligence, and things, is also presented and discussed.}
}

@article{rayyan-727967697,
  title={The relationship between requirements engineering and virtual reality systems: A systematic literature review},
  year={2013},
  pages={53-62},
  author={dos Santos, Alinne C Corrêa and Delamaro, Márcio Eduardo and Nunes, Fátima L S},
  keywords={Software, Systematics, Data mining, Manuals, Databases, Conferences, requirements engineering, systematic literature revie, virtual reality, Virtual reality},
  abstract={The development of Virtual Reality (VR) is a difficult task, requiring knowledge and understanding of different areas. Furthermore, the Requirements Engineering (RE) has a key role in the development of VR systems, because the requirements of these systems are imposed directly by human senses and abstracted by the ability of the developers to represent the physical and kinematic models of these environments. The aim of this paper is to present the results of a Systematic Literature Review to consolidate existing evidence regarding the use of RE for VR systems and VR contributions to the RE process. We have analyzed 12 primary studies published between 1998 and 2011. The results indicate mainly the deficiency of studies that show the use of the RE process for VR systems, because it is necessary that this process occur in accordance with the technological peculiarities of VR systems.}
}

@article{rayyan-727967699,
  title={Systematic literature review: Success, failure, risks, benefits and barriers factors in the adoption of open source software},
  year={2018},
  pages={328-336},
  author={Carvallo Vega, Juan Pablo and Crespo Martinez, Paul Esteban and Carvajal Vargas, Fabian Marcelo and Vintimilla Guzman, Rosalva Natali},
  keywords={Systematics, SLR, Systematic Literature Review, Bibliographies, Open source software, OSS, Open Source Software, Information systems, Information and communication technology, IT, Silicon compounds, Software},
  abstract={The paradigm of Open Source Software (OSS) has revolutionized the way in which the software is used, marketed and distributed. Due to its strategic importance, in recent years, public administrations have defined plans for the promotion and strengthening of Information and Communication Technologies (ICT) based on the use of OSS. These strategies have been recognized benefits and a wide social repercussion, given that the open and collaborative paradigm of the OSS phenomenon allows the use and diffusion of ICTs at all social levels. However, it limits the exploitation of the benefits of adopting OSS in the public, private industry and in the Ecuadorian society in general, due to shortcomings in the identification, assessment and risk management, in addition to good practices and adoption, the motive this project is to make a systematic literature review of the OSS adoption, based on Kitchenham and Charters methodological guide; this guide consists in a technique based on empirical research, which requires following a protocol to collect the literature on existing research, related to the free software adoption by organizations, for obtaining relevant references of success, failure, risk, benefits and barriers factors of adoption, in order to determinate the current situation of the OSS use in Ecuador.}
}

@article{rayyan-727967700,
  title={Predicting infections using computational intelligence – a systematic review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={31083-31102},
  author={Baldominos, Alejandro and Puello, Adráan and Oğul, Hasan and Aşuroğlu, Tunç and Colomo-Palacios, Ricardo},
  keywords={machine learning, systematic literature review, Systematics, Bibliographies, Machine learning, Computational intelligence, Diseases, expert systems, infection prediction, Medical diagnostic imaging, physiological signals, Physiology, Intelligence},
  abstract={Infections encompass a set of medical conditions of very diverse kinds that can pose a significant risk to health, and even death. As with many other diseases, early diagnosis can help to provide patients with proper care to minimize the damage produced by the disease, or to isolate them to avoid the risk of spread. In this context, computational intelligence can be useful to predict the risk of infection in patients, raising early alarms that can aid medical teams to respond as quick as possible. In this paper, we survey the state of the art on infection prediction using computer science by means of a systematic literature review. The objective is to find papers where computational intelligence is used to predict infections in patients using physiological data as features. We have posed one major research question along with nine specific subquestions. The whole review process is thoroughly described, and eight databases are considered which index most of the literature published in different scholarly formats. A total of 101 relevant documents have been found in the period comprised between 2003 and 2019, and a detailed study of these documents is carried out to classify the works and answer the research questions posed, resulting to our best knowledge in the most comprehensive study of its kind. We conclude that the most widely addressed infection is by far sepsis, followed by Clostridium difficile infection and surgical site infections. Most works use machine learning techniques, from which logistic regression, support vector machines, random forest and naive Bayes are the most common. Some machine learning works provide some ideas on the problems of small data and class imbalance, which can be of interest. The current systematic literature review shows that automatic diagnosis of infectious diseases using computational intelligence is well documented in the medical literature.}
}

@article{rayyan-727967701,
  title={An evaluation framework for communication and coordination processes in offshore software development outsourcing relationship: Using fuzzy methods},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={112879-112906},
  author={Khan, Rafiq Ahmad and Idris, Mohd Yazid and Khan, Siffat Ullah and Ilyas, Muhammad and Ali, Sikandar and Ud Din, Aziz and Murtaza, Ghulam and Khan, Abdul Wahid and Jan, Saeed Ullah},
  keywords={Software, systematic literature review, Collaboration, survey, Outsourcing, Computer science, challenges, Cultural differences, Companies, case study, fuzzy multi-attribute decision-making, practices and mitigation levels, Software outsourcing},
  abstract={Offshore software development outsourcing (OSDO) is a modern business strategy for producing high-quality software at a low cost. The OSDO refers to the practice of contracting to an offshore (extrinsic) organization to perform some or all software development work of a product. For the benefit of the OSDO vendors, this paper aims to develop a “communication and coordination challenges mitigation model” (CCCMM) that provides solutions for unambiguously defined communication and coordination processes in global software development (GSD) environment. Our proposed model is based on the fuzzy multi-attribute decision-making (FMADM) approach incorporating the capability of group decision-making. The FMADM approach is used both in the ranking of survey and assessment of case studies. First, the authors undertook a systematic literature review (SLR) that identified all cited challenges from a set of 101 articles. We identified 18 problem areas faced by the GSD vendors in OSDO relationships. Of these, six were ranked as critical. For the purpose of identifying corrective interventions, a second SLR was conducted that revealed 75 remedial measures extracted from 63 chosen articles. To validate our SLR findings, we surveyed 42 outsourcing experts from six countries. We also categorized six critical challenges and 75 corrective practices into four mitigation levels based on CMMI, SOVRM, and SOPM. In addition, two case studies were conducted to evaluate CCCMM outcomes in OSDO companies. The assessment results of the first case study do not recommend Company-A for the successful implementation of level-2 of the CCCMM, so Company-A stands at level-1. We have observed from the second case study that Company-B has implemented all the critical challenges of the level-2 only; therefore, Company-B is at level-2 “success” of the proposed assessment model.}
}

@article{rayyan-727967704,
  title={The role of software process simulation modeling in software risk management: A systematic review},
  year={2009},
  pages={302-311},
  author={Liu, Dapeng and Wang, Qing and Xiao, Junchao},
  keywords={Software engineering, Project management, Risk management, Software development management, Analytical models, Application software, Discrete event simulation, Process planning, Risk analysis, Software tools, Risk Management, Software},
  abstract={Nowadays software projects are still suffering from many problems due to various kinds of software risks. Software risk management is a crucial part of successful project management, but it is often not well implemented in real-world software projects. One reason is that project managers lack effective and practical tools to manage software risks. Software process simulation modeling (SPSM) has been emerging as a promising approach to address a variety of issues in software engineering area, including risk management. However, the current state of how SPSM supports software risk management is not yet clear. This paper presents a systematic literature review which purpose is to obtain the state of the art of the applications of SPSM in software risk management. We drew the following conclusions from the review results: (1) The number of SPSM studies on software risk management is relatively small, but increasing gradually in recent years. (2) SPSM is mainly applied in risk analysis and risk management planning activities. (3) Software risks related to requirements, development process and management process are the ones most studied by SPSM. (4) Discrete-event simulation and system dynamics are two most popular simulation paradigms, while Hybrid simulation methods are more and more widely used. (5) Extend, iThink and Vensim are the most popular simulation tools in SPSM. (6) Most of SPSM approaches and models have not been well applied into real-world risk management practices.}
}

@article{rayyan-727967706,
  title={Handwritten optical character recognition (OCR): A comprehensive systematic literature review (SLR)},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={142642-142668},
  author={Memon, Jamshed and Sami, Maira and Khan, Rizwan Ahmed and Uddin, Mueen},
  keywords={Systematics, Bibliographies, Databases, Protocols, Character recognition, classification, deep learning, feature extraction, languages, Optical character recognition, Optical character recognition software, Optical imaging},
  abstract={Given the ubiquity of handwritten documents in human transactions, Optical Character Recognition (OCR) of documents have invaluable practical worth. Optical character recognition is a science that enables to translate various types of documents or images into analyzable, editable and searchable data. During last decade, researchers have used artificial intelligence/machine learning tools to automatically analyze handwritten and printed documents in order to convert them into electronic format. The objective of this review paper is to summarize research that has been conducted on character recognition of handwritten documents and to provide research directions. In this Systematic Literature Review (SLR) we collected, synthesized and analyzed research articles on the topic of handwritten OCR (and closely related topics) which were published between year 2000 to 2019. We followed widely used electronic databases by following pre-defined review protocol. Articles were searched using keywords, forward reference searching and backward reference searching in order to search all the articles related to the topic. After carefully following study selection process 176 articles were selected for this SLR. This review article serves the purpose of presenting state of the art results and techniques on OCR and also provide research directions by highlighting research gaps.}
}

@article{rayyan-727967707,
  title={Process mining of duplicate tasks: A systematic literature review},
  year={2020},
  pages={778-784},
  author={Duan, Chenchen and Wei, Qingjie},
  keywords={Systematics, Bibliographies, Data mining, Tools, Task analysis, Measurement, Databases, conformance checking, duplicate tasks, process discovery, process mining, systematic literature reviewe},
  abstract={Process mining improves and provides insights for business processes, which are information related to process execution. In general, process mining can be separated into three classes: process discovery, conformance checking and process enhancement. In order to simplify the process model, we make an assumption that both events in the log and tasks in the model have an injective relation in process mining, i.e., do not allow two tasks to share the same label (thus duplicates task). In addition, Duplicate tasks have some issues concerning the quality of process model discovered and the potential indeterminism in conformance checking. In this paper, we perform a systematic literature review of process discovery and conformance checking metrics for duplicate tasks. This review can: (1) provide a comprehensive review of the current work of duplicate tasks in process discovery and conformance checking; (2) help researchers choose proper process mining approach, tools, and metrics; (3) identify research opportunities in duplicate tasks.}
}

@article{rayyan-727967708,
  title={Bio-inspired algorithms in software fault prediction: A systematic literature review},
  year={2020},
  pages={1-8},
  author={Ali, Asad and Gravino, Carmine},
  keywords={Systematic Literature Review, Bibliographies, Optimization, Estimation, Fault prediction, Software algorithms, Feature extraction, Genetic algorithms, Prediction algorithms, Bio-inspired algorithms, Feature selection, Parameter tuning, Algorithms, Software, Tocopherols},
  abstract={Bio-inspired (and meta-heuristic) algorithms are successfully employed in different domains and the research is going on to accommodate them in all the contexts where optimization is required. In software engineering, and especially Software Fault Prediction (SFP), they are investigated in various forms, e.g., to extract the most relevant features in a dataset or to select the most appropriate set of parameter values in the application of estimation techniques. In SFP, feature selection and optimization/tuning of estimation technique's parameters are an active research area, where recently various bio-inspired algorithms have been employed for both strategies. In this work, we present a Systematic Literature Review (SLR) about the use of bio-inspired algorithms for feature selection and parameter optimization aiming at increasing fault prediction accuracy of the models built with various estimation techniques. To the best of our knowledge, there is no SLR in SFP which covers the use of bioinspired algorithms, both for feature selection and parameter optimization. Since, the use of bio-inspired algorithms in the area of SFP started to be investigated in the late 2000, we have considered studies published between 2007 and 2019. As result, we have selected about 19 studies related to parameter optimization and 15 dealing with feature selection (in total 34 studies), extracted from five well-known digital libraries (ACM digital library, IEEE explore, Springer, ScienceDirect, and Scopus). Genetic Algorithms (GA) and Particle Swarm Optimization (PSO) are the widely used bio-inspired algorithms, both for parameter optimization and feature selection. Among them, GA is the better performed algorithm when evaluating its performance against the baseline (i.e., estimation techniques without any algorithm for feature selection or parameter optimization and trained with their default values). The SLR results also suggests that bio-inspired algorithms seem to provide more accurate predictions for feature selection than for parameter optimization.}
}

@article{rayyan-727967709,
  title={A systematic literature review on autonomous agile teams},
  year={2019},
  pages={146-151},
  author={Acharya, Bibek and Colomo-Palacios, Ricardo},
  keywords={Software, Software engineering, Systematics, Bibliographies, Task analysis, Databases, Organizations, agile teams, autonomous, autonomy, self-managed, self-organizing},
  abstract={Organizations are needed of flexible structures to achieve their aims. In the software arena, Self-organization is the one of the principles of the agile methodologies as defined in the agile manifesto. Autonomous agile teams are a way to conform self-organization. The main objective of this paper is to know about the how autonomous agile teams organize themselves and what are the benefits and the challenges faced by these teams. A systematic literature review was conducted to find answers to these questions. 23 relevant papers were identified as primary sources to define and study autonomous and self-organized agile team. From the review, it was found that there are many benefits and challenges of autonomous agile teams and the various strategies to overcome the challenges.}
}

@article{rayyan-727967712,
  title={Software process simulation modeling: Facts, trends and directions},
  year={2008},
  pages={59-66},
  author={Zhang, He and Kitchenham, Barbara and Pfahl, Dietmar},
  keywords={systematic literature review, Software engineering, Information systems, Computer science, Mathematics, Software tools, Computational modeling, Computer simulation, Helium, Mathematical model, software process simulation modeling, Software reusability, Software},
  abstract={Software process simulation modeling (SPSM) research has increased since the first ProSim workshop held in 1998 and Kellner, Madachy and Raffo (KMR) discussed the "why, what and how" of process simulation. This paper aims to assess how SPSM has evolved during the past 10 years in particular whether the reasons for SPSM, the simulation paradigms, tools, problem domains, and model scopes have changed. We performed a systematic literature review of software process simulation papers from the ProSim series publications in the last decade. We identified 96 studies from the sources and included them in this review. The papers were categorized into four major types and data needed to address each research question was extracted. We found a need for refining the reasons and the classification scheme for SPSM introduced by KMR. More emerging SPSM paradigms and model scopes were added to enhance KMR's discussion. Trends over time showed that interest in continuous modeling was decreasing and interest in micro-processes was increasing. Hybrid models were based primarily on system dynamics and discrete event simulation and were all implemented by vertical integration. We recommend SPSM research concentrate more on recent software processes and on making SPSM more reusable and thus easier to build.}
}

@article{rayyan-727967713,
  title={A systematic review of feature selection techniques in software quality prediction},
  year={2019},
  pages={1-5},
  author={Alsolai, Hadeel and Roper, Marc},
  keywords={Systematic literature review, feature selection, prediction, software defect, software maintainability, Software},
  abstract={Background: Feature selection techniques are important factors for improving machine learning models because they increase prediction accuracy and decrease the time to create a model. Recently, feature selection techniques have been employed on software quality prediction problems with different results and no clear indication of which techniques are frequently used.Objective: This study aims to conduct a systematic review of the application of feature selection techniques in software quality prediction and answers eight research questions.Method: The review evaluates 15 papers in 9 journals and 6 conference proceedings from 2007 to 2017 using the standard systematic literature review method.Results: The results obtained from this study reveal that the filter feature selection method was the most commonly used in the studies (60%) and RELIEF was the most employed among this method, and a limited number of studies employed an ensemble method. Several studies used public datasets available in the PROMISE software project repository (60%). Most studies focused on software defect prediction (classification problem) using area under curve (AUC) as a primary evaluation measure, whereas only two studies focused on software maintainability prediction (regression problem) using mean magnitude of relative error (MMRE) as a primary evaluation measure. All selected studies performed k-fold cross-validation to evaluate model accuracy. Individual prediction models were mostly employed and ensemble models appeared only in three studies. Naive Bayes was the most investigated among individual models, whereas Random forest was the most investigated among ensemble models.Conclusion: Feature selection techniques used by selected primary studies have a positive impact on the performance of the prediction models. Further, both ensemble feature selection method and ensemble models have the ability for increasing prediction accuracy over single methods or individual models and have reported improvement in the prediction accuracy; however, the application of these techniques in software quality prediction is still limited.}
}

@article{rayyan-727967715,
  title={Tools and practices to software quality assurance: A systematic literature review},
  year={2018},
  pages={1-6},
  author={Munoz, Mirna and Mejia, Jezreel and Ibarra, Saúl},
  keywords={Systematics, Tools, Quality assurance, Software quality, software, tools, ISO Standards, development, IEC Standards, practices, quality assurance, quality management, Software},
  abstract={In the last few years the software industry has become relevant, 4 of the 5 most valuable companies in the world are developing software, and in the same way, the budget dedicated to Information Technology (IT) in companies have grown in a 49%. Therefore, currently doesn't exist a market without being related to software. In parallel, there has been developed a set of models and standards for quality assurance. This is the reason why in the software industry the resources focused on software quality assurance have been increased, this is reflected in the large number of quality models such as: CMMI, ISO/IEC standards among others, which contain practices that help organizations to achieve better levels in quality assurance. Besides, this has generated the development of tools to support the quality assurance. This paper presents a systematic review to identify the tools and practices that are implemented to ensure quality in the development of software products and services. Moreover, an analysis of defect types with higher value in the software products is performed.}
}

@article{rayyan-727967716,
  title={A systematic review on code clone detection},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={86121-86144},
  author={Ain, Qurat Ul and Butt, Wasi Haider and Anwar, Muhammad Waseem and Azam, Farooque and Maqbool, Bilal},
  keywords={Software, SLR, Tools, Databases, CCD, CCD tools, Charge coupled devices, Cloning, code clone detection, code clone types, Computer bugs, Semantics},
  abstract={Code cloning refers to the duplication of source code. It is the most common way of reusing source code in software development. If a bug is identified in one segment of code, all the similar segments need to be checked for the same bug. Consequently, this cloning process may lead to bug propagation that significantly affects the maintenance cost. By considering this problem, code clone detection (CCD) appears as an active area of research. Consequently, there is a strong need to investigate the latest techniques, trends, and tools in the domain of CCD. Therefore, in this paper, we comprehensively inspect the latest tools and techniques utilized for the detection of code clones. Particularly, a systematic literature review (SLR) is performed to select and investigate 54 studies pertaining to CCD. Consequently, six categories are defined to incorporate the selected studies as per relevance, i.e., textual approaches (12), lexical approaches (8), tree-based approaches (3), metric-based approaches (7), semantic approaches (7), and hybrid approaches (17). We identified and analyzed 26 CCD tools, i.e., 13 existing and 13 proposed/developed. Moreover, 62 open-source subject systems whose source code is utilized for the CCD are presented. It is concluded that there exist several studies to detect type1, type2, type3, and type4 clones individually. However, there is a need to develop novel approaches with complete tool support in order to detect all four types of clones collectively. Furthermore, it is also required to introduce more approaches to simplify the development of a program dependency graph (PDG) while dealing with the detection of the type4 clones.}
}

@article{rayyan-727967717,
  title={The mHealth applications usability evaluation review},
  year={2020},
  pages={70-73},
  author={Ansaar, Muhammad Zaki and Hussain, Jamil and Bang, Jaehun and Lee, Sungyoung and Shin, Kim Young and Young Woo, Kim},
  keywords={Systematic literature review, Systematics, Bibliographies, Reliability, Usability, Computer science, usability, applications, Medical services, mHealth, Operating systems, smartphones},
  abstract={Smartphones are contributing to the improvement of healthcare information and services with the help of mHealth apps. Commercially available mHealth apps have drawn prominent public attention by providing improved medication adherence and efficient results, but some of the studies exist to support their use. Usability has become the main factor for the success or adoption of smartphone apps since it helps to organize the consistency for the users to achieve their goal in an easy and efficient way. This study aims to investigate the usability evaluation process of mHealth applications with the help of a Systematic Literature Review (SLR). Our findings show that the usability evaluation process can be more reliable and satisfactory by applying the mix-method approach. This study will encourage developers and researchers to design more effortless and usable applications for users, especially for older adults and novice users.}
}

@article{rayyan-727967718,
  title={Formalizing a systematic review updating process},
  year={2008},
  pages={143-150},
  author={Dieste, Oscar and López, Marta and Ramos, Felicidad},
  keywords={Data mining, Systematic review, Terminology, Interviews, Protocols, Proposals, Book reviews, process, Strontium},
  abstract={The objective of a systematic review is to obtain empirical evidence about the topic under review and to allow moving forward the body of knowledge of a discipline. Therefore, systematic reviewing is a tool we can apply in Software Engineering to develop well founded guidelines with the final goal of improving the quality of the software systems. However, we still do not have as much experience in performing systematic reviews as in other disciplines like medicine, and therefore we need detailed guidance. This paper presents a proposal of a improved process to perform systematic reviews in software engineering. This process is the result of the tasks carried out in a first review and a subsequent update concerning the effectiveness of elicitation techniques.}
}

@article{rayyan-727967719,
  title={A systematic literature review on attractiveness and learnability factors in Web applications},
  year={2015},
  pages={22-27},
  author={Ngadiman, Norzila and Sulaiman, Shahida and Mohd Nasir Wan Kadir, Wan},
  keywords={Systematic literature review, Systematics, Bibliographies, Guidelines, Web applications, Quality, Usability, Navigation, Conferences, Attractiveness, Learnability, Operability},
  abstract={User interface design is an essential element for consideration in Web application development. Usability (ISO/IEC 9126-1:2001) or operability (ISO/IEC 25010:2011) is one of non-functional requirements which must be taken into consideration when designing a user interface. Attractiveness and learnability are among the sub criteria under the operability factor. Analysis of these criteria may be used to evaluate user interface design. This study has adopted a systematic literature review method to study existing works concerning the two factors of operability. The outcome of the review provides insight into existing works on attractiveness and learnability factors in software applications generally and Web applications specifically.}
}

@article{rayyan-727967720,
  title={A systematic literature review on knowledge representation approaches for systems-of-systems},
  year={2015},
  pages={70-79},
  author={Abdalla, Gabriel and Damasceno, Carlos Diego N and Guessi, Milena and Oquendo, Flavio and Nakagawa, Elisa Yumi},
  keywords={Systematic Literature Review, Ontology, Ontologies, Modeling, Taxonomy, Terminology, Interoperability, Knowledge Representation, System of systems, Systems-of-Systems},
  abstract={Systems-of-Systems are a class of systems composed of diverse, independent constituent systems. Together, these constituents can accomplish missions that otherwise could not be performed by any of them separately. In another perspective, knowledge representation approaches can assist in the establishment of a common understanding in this field by formalizing and standardizing the main terms and concepts adopted. In spite of the relevance of SoS, a consolidated terminology which could support the community working with such systems is still missing. Furthermore, the multiplicity of stakeholders, technologies, and expertise involved in an SoS makes the need of a common understanding even more imperative. In this study, we report on the main findings of a systematic literature review covering knowledge representation approaches in the SoS field. With this study, we are able to present a comprehensive panorama of the knowledge representation approaches that are currently adopted. Even though a consolidated terminology is not available yet, such panorama can be helpful for devising a common, comprehensive terminology for the SoS field. Therefore, we conclude this paper with directions for future work.}
}

@article{rayyan-727967721,
  title={Does the adoption of ERP systems help improving decision-making? A systematic literature review},
  year={2018},
  pages={61-66},
  author={OUIDDAD, Ahmed and OKAR, Chafik and CHROQUI, Razane and HASSANI, Imane BEQQALI},
  keywords={Systematics, Systematic Literature Review, Bibliographies, Data mining, Decision making, Planning, Art, Decision-Making, Enterprise resource planning, ERP, Decision Making},
  abstract={Enterprise Resource Planning (ERP) systems have significantly grown and evolved in the last decades. As a result, they have become highly important for operational data analysis and subsequently to create decision support and analytical applications. The majority of studies on ERP systems have aimed to evaluate their transactional and operational impacts, without taking into consideration their importance in the decision-making aspects. Based on a systematic literature review methodology, this article intended to analyze previous research works on the role of ERP in improving the decision-making. The research was conducted based on four scientific search engines: Emerald Insight, IEEE Xplore, ProQuest and ScienceDirect. After screening more than 386 articles, 27 of them were selected, categorized and then synthesized. The study provides useful information on the way these systems contribute to improving the decisional aspect in the enterprise.}
}

@article{rayyan-727967722,
  title={Challenges of migrating legacies web to mobile: A systematic literature review},
  year={2020},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={18},
  number={5},
  pages={861-873},
  author={Cajas, Viviana and Urbieta, Matías and Rossi, Gustavo and Domínguez Mayo, Francisco},
  keywords={systematic literature review, Systematics, Bibliographies, Legacy application, Web 2.0, Business, Adaptation models, evolution, IEEE transactions, migration, mobile applications, Mobile handsets},
  abstract={The multi-device era comes thanks to mobile computing which gives remote access to resources from anywhere changing the people's life and opening new business opportunities. However, the legacy systems do not render the content properly in mobile devices because they were thought to be only compliant with Web browsers. Economic availability is often the reason why these have not been modernized. This work proposes a systematic literature review about the approaches used for the portabilization or modernization of web 1.0 business applications to mobile devices in the period 2006-2017, from SCOPUS, IEEE, and ACM. The search obtained 824 articles, 44 were selected and classified with respect to focus, scope, type of research and type of contribution. The results obtained allowed us to reach conclusions about the state of the subject and to determine the research gaps, such as the need for better use of the mobile characteristics because the adaptations are mostly basic. In addition, an approach is proposed and compared with the aforementioned them.}
}

@article{rayyan-727967723,
  title={Identification of key success factors and challenges for ERP systems — A systematic literature review},
  year={2017},
  pages={1-6},
  author={Wijaya, Santo F and Prabowo, Harjanto and Meyliana and Kosala, Raymond},
  keywords={Systematic literature review, Challenges, Critical success factors, ERP systems},
  abstract={Organizations need information system as a tool for decision making. Enterprise Resource Planning (ERP) systems are a tool of information systems to achieve work efficiency. ERP systems are the best solution to maintain a competitive advantage for most organizations. Successful implementations of ERP systems have a lot of benefits for the organizations. But the fact that many organizations have failed in implementing ERP systems, but also many organizations have succeeded in implementation of ERP systems. It is the challenge for the organizations to implementation of ERP systems success. The purpose of this study is to propose identify key success factors and challenges for ERP systems. This study employs Systematic. Literature Review approach for review and summary about the key success factors of ERP implementation.}
}

@article{rayyan-727967724,
  title={Critical success factors for big data: A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={118940-118956},
  author={Al-Sai, Zaher Ali and Abdullah, Rosni and Husin, Mohd Heikal},
  keywords={Systematics, Bibliographies, critical success factors (CSFs), systematic literature review (SLR), Big Data, Organizations, Planning, Big data (BD), big data analytics (BDA), big data challenges, big data implementation, information system success, Investment, maturity, readiness},
  abstract={During the last few decades, many organizations have started recognizing the benefits of Big Data (BD) to drive their digital transformation and to gain faster insights from faster data. Making smart data-driven decisions will help the organizations to ride the waves toward invaluable investments. The successful implementation of Big Data projects depends on their alignment with the current organizational, technological, and analytical aspects. Identifying the Critical Success Factors (CSFs) for Big Data is fundamental to overcome the challenges surrounding Big Data Analytics (BDA) and implementation. In recent years, the investigations related to identifying the CSFs of Big Data and Big Data Analytics expanded on a large scale trying to address the limitations in existing publications and contribute to the body of knowledge. This paper aims to provide more understanding about the existing CSFs for Big Data Analytics and implementation and contributes to the body of knowledge by answering three research questions: 1) How many studies have investigated on Big Data CSFs for analytics and implementation?, 2) What are the existing CSFs for Big Data Analytics, and 3) What are the categories of Big Data Analytics CSFs?. By conducting a Systematic Literature Review (SLR) for the available studies related to Big Data CSFs in the last twelve years (2007-2019), a final list of sixteen (16) related articles was extracted and analyzed to identify the Big Data Analytics CSFs and their categories. Based on the descriptive qualitative content analysis method for the selected literature, this SLR paper identifies 74 CSFs for Big Data and proposes a classification schema and framework in terms of 5 categories, namely Organization, Technology, People, Data Management, and Governance. The findings of this paper could be used as a referential framework for a successful strategy and implementation of Big Data by formulating more effective data-driven decisions. Future work will investigate the priority of the Big Data CSFs and their categories toward developing a conceptual framework for assessing the success of Big Data projects.}
}

@article{rayyan-727967725,
  title={Open source software development process: A systematic review},
  year={2020},
  pages={135-144},
  author={Napoleão, Bianca M and Petrillo, Fabio and Hallé, Sylvain},
  keywords={Software, systematic literature review, Software engineering, Systematics, Bibliographies, Data mining, Libraries, Conferences, open source, software development process},
  abstract={Open Source Software (OSS) has been recognized by the software development community as an effective way to deliver software. Unlike traditional software development, OSS development is driven by collaboration among developers spread geographically and motivated by common goals and interests. Besides this fact, it is recognized by the OSS community the need to understand OSS development process and its activities. Our goal is to investigate the state-of-art about OSS process through conducting a systematic literature review providing an overview of how the OSS community has been investigating OSS process over past years. We identified and summarized OSS process activities and their characteristics and translated them into an OSS macro process using BPMN notation. As a result, we systematically analyzed 33 studies presenting an overview of the OSS process research and a generalized OSS development macro process represented by BPMN notation with a detailed description of each OSS process activity and roles in OSS environment. We conclude that OSS process can be in practice further investigated by researchers. In addition, the presented OSS process can be used as a guide for OSS projects and be adapted according to each OSS project reality. It provides insights to managers and developers who want to improve their development process even in OSS and traditional environments. Finally, recommendations for OSS community regarding OSS process activities are provided.}
}

@article{rayyan-727967726,
  title={A systematic review on creativity techniques for requirements engineering},
  year={2012},
  pages={34-39},
  author={Saha, Shishir Kumar and Selvi, Mehmet and Büyükcan, Güral and Mohymen, Mirza},
  keywords={Requirements Engineering, Databases, Creativity Techniques, IEEE Xplore, Innovation Candidate, RE},
  abstract={Now-a-days Creativity is very much important for requirements analysis. The practice of systematic creativity technique is needed to generate inventive ideas and to achieve better outcome in requirements engineering. Creativity techniques are used to discover creative and innovative requirements and to understand client's expectation. In the paper we performed systematic review on articles those are related to creativity, creativity techniques, requirements engineering and empirical evaluation on creativity techniques for requirements engineering. In the systematic literature review, different sources are used (e.g. IEEE Xplore, ACM, Compendex, Inspec, Springerlink, Science Direct). Then preformed search with relevant search terms. We minimized search result combining creativity and requirements engineering and then go through the title and abstract and selected articles for review using inclusion and exclusion criteria. From the systematic review we determined the roles of creativity and identified the impact of creativity techniques in requirements engineering area. Also, we explored ideas on future impact and trend of creativity in requirements engineering.}
}

@article{rayyan-727967727,
  title={A systematic review of Web engineering research},
  year={2005},
  pages={10-pp.–},
  author={Mendes, E},
  keywords={Software engineering, Software measurement, Testing, Computer science, Physics, Engineering management, Maintenance engineering, Manufacturing processes, Quality management, Reliability engineering},
  abstract={This paper uses a systematic literature review as means of investigating the rigor of claims arising from Web engineering research. Rigor is measured using criteria combined from software engineering research. We reviewed 173 papers and results have shown that only 5% would be considered rigorous methodologically. In addition to presenting our results, we also provide suggestions for improvement of Web engineering research based on lessons learnt by the software engineering community.}
}

@article{rayyan-727967730,
  title={Network survivability analysis modeling approach for MANETS: A systematic review},
  year={2014},
  pages={74-79},
  author={Azni, A H and Ahmad, Rabiah and Mohamad Noh, Zul Azri and Hazwani, Farida and Hayaati, Najwa},
  keywords={Systematic Literature Review, Measurement, Reliability, Mobile computing, Analytical models, Mathematical model, Ad hoc networks, MANETs, Network survivability, Network topology, Survival Analysis},
  abstract={Network survivability analysis modeling in MANETs was hardly an issue in the early years of wireless technology because there was no critical network system that depended on wireless technology yet. Today, network survivability analysis is an essential aspect of reliable communication especially in MANETs. Although various methods have been proposed to model network survivability analysis in MANETs, no related review has been published as to date for this topic. Thus, a comprehensive review of this body of work would be beneficial to researchers to have an overview of the current state of research trend in this area. This paper provides a systematic literature review (SLR) of the state of the art approach in modeling network survivability analysis in MANETs. We used studies from a number of relevant article sources, and our results showed the existence of twenty six articles. From this SLR we found that the existing of modeling method is focusing on individual node in which the node is treated as independent event. Furthermore, the analysis also reveals the less popular methods in modeling network survivability analysis are with statistical methods such as regression analysis and survival analysis. The implication of this study is to give a clear direction to future researchers in this area for a better and accurate analysis in measuring network survivability in MANETs.}
}

@article{rayyan-727967733,
  title={Automated software testing on mobile applications: A review with special focus on android platform},
  year={2020},
  pages={292-293},
  author={Musthafa, Fathima Naja and Mansur, Syeda and Wibawanto, Adika},
  keywords={Software, Software testing, Software engineering, Tools, Automation, Software Testing, Mobile applications, Automated testing techniques, Graphical user interfaces, Mobile application testing tools, Quality Assurance, Methyltestosterone},
  abstract={Development of mobile applications and hence testing them with automated tools are rapidly achieving grounds on the technology market with the explosive evolution, demand and use of mobile technology. Although automated software testing has been a topic of research for many years, automation testing on mobile application is being a key topic in the software engineering industry and hence the development and introduction of new automated tools have gained attention in the recent years. This research aims at identifying, analyzing, and synthesizing the current state-of-the-art of automated testing on mobile application with special focus on to the popular mobile application platform "Android". A systematic literature review was conducted on studies retrieved from electronic search space. Various literature reviewed and referred there in, as a conclusion, its obvious that none of the techniques used in automated testing is alone inadequate and a combination of them works well as an effective testing strategy. Also, the challenges thus faced by the practitioners of automated testing could be still mitigated with an efficient selection of testing tool.}
}

@article{rayyan-727967734,
  title={A systematic review of the effects of team climate on software team productivity},
  year={2014},
  pages={1-7},
  author={Soomro, Arjumand Bano and Salleh, Norsaremah},
  keywords={systematic review, Software, Software engineering, Software measurement, Systematics, Data mining, Productivity, Meteorology, personality, team climate, team productivity},
  abstract={The term team-work has been a significant topic in software engineering over the past 50 years. The team climate is the exchange of ideas and perceptions among team members in favor to promote the innovation in work processes. In this paper, we presented our work on a systematic review on the effect of team climate on the software productivity or performance. The summarized results from this research would be useful for achieving effectiveness in software engineering work teams.}
}

@article{rayyan-727967735,
  title={A systematic literature review of methodology of learning evaluation based on item response theory in the context of programming teaching},
  year={2020},
  pages={1-9},
  author={Santos, Jucelio S and Andrade, Wilkerson L and Brunet, João and Araujo Melo, Monilly Ramos},
  keywords={Search problems, Tools, Programming, Education, Libraries, Instruments, Real-time systems},
  abstract={This Research Full Paper presents a Systematic Literature Review (SLR) that investigates state-of-the-art methods, processes, approaches, and instruments based on Item Response Theory (IRT) in the programming teaching context. Various studies support professors and students to improve the evaluation process in teaching programming. Among the different techniques and theories associated with these studies, the IRT gained prominence because of its effectiveness. Due to the lack of an overview in the area, we present a SLR with the objective of identity studies that use IRT as a methodology of evaluation of learning in the context of Programming Teaching; studies which present real-time feedback; and experimental studies that have been carried out to validate them. To achieve these goals, we planned an SLR following the guidelines proposed by Kitchenham (2004). Our main findings are a) There is a limited number of studies that explore IRT in evaluation methodologies in the teaching programming context. Among these studies, the main focus was the development on of instruments to measure programming skills; b) Most instruments are multiple-choice, adopt the 3PL model, and do not show evidence of real-time feedback except SIETTE and CodeWorkout and are also the only instruments that evaluate the coding capacity of individuals; c) The studies showed scientific evidence on the use of IRT in the evaluation methodology in the programming teaching context. The studies presented experiments that indicate a significant gain in the measurement of programming abilities when compared to the traditional evaluation method.}
}

@article{rayyan-727967739,
  title={A preliminary analysis of various testing techniques in Agile development - a systematic literature review},
  year={2016},
  pages={600-605},
  author={Thangiah, Murugan and Basri, Shuib},
  keywords={Software, Software testing, Software engineering, Systematics, Bibliographies, Agile development, SME's, Computers, Exploratory software Testing},
  abstract={There are numerous software development and testing methods, tools and techniques have emerged over the past few decades with the main objective are to enhance the software quality. In Small and Medium size Enterprises (SME's), Agile methods have been gaining acceptance but quality of the product it produced is remains as the major concern because the tesing methods and standards are not improved. In Agile development process, though there are many testing techniques are exists, SME's cannot afford to follow the traditional methods of testing process, because of high cost and it is a time consuming process. In this research paper, only the issues surfaced in Regression Testing and Automated Testing are analysed and proposed that exploratory testing (ET) methods either can be used as an alternative or can be integrate along with the existing testing methods. However, there is not enough research work is conducted on Exploratory testing and emphasized the importance to focus more research work to be carried out in ET.}
}

@article{rayyan-727967740,
  title={Personality requirements in requirement engineering of web development: A systematic literature review},
  year={2016},
  pages={183-188},
  author={Askarinejadamiri, Zahra},
  keywords={Software, Software engineering, Systematics, Bibliographies, Requirements engineering, Software development, Human factors, Education, Personality, requirement engineering, web development},
  abstract={Personality requirement is a key factor for the success of software development. In order to doing requirement engineering for web development, some human personality should be considered. In fact, Personality represents some human factors such as human, ability human behavior and human capital which will be discussed in this paper. Therefore, these factors were distinguished and presented as an effective element of software development and subsequently web development in this research. Knowing these components assist the developer to have a better view on the project. This paper review some selected paper in research are of requirement engineering and human personality. A major result of this paper is a categorization of Personality of human that usually ignored in the project and they cause the problem in project to improving the success of web development.}
}

@article{rayyan-727967741,
  title={Maintainability prediction of relational database-driven applications: A systematic review},
  year={2012},
  pages={263-272},
  author={Riaz, Mehwish},
  keywords={Measures, Systematic Review, Prediction, Relational Database-Driven Sofwtare Applications, Software Maintainability},
  abstract={Background: Maintainability is an important quality attribute. Its prediction for relational database-driven applications can help organizations improve the maintainability of these applications. Aims: The aim of this paper is to present the results of a Systematic Literature Review - also known as Systematic Review (SR) - with an up-to-date account of the state of art on maintainability prediction and measures for relational database-driven applications, to compare these results with those from a previously conducted SR [19], and to provide a baseline for conducting further research in this area. Method: A SR on maintainability prediction for relational databasedriven applications was carried out using Kitchenham's guidelines for conducting SRs in Software Engineering. Results: The results show little evidence on maintainability prediction for relational database-driven applications with expert judgment as the most common prediction technique, coupling related measures as the most common predictors, and subjective assessment as most common maintainability measure. Conclusions: The presented results suggest a strong need for further investigating the area of maintainability prediction for relational database-driven applications.}
}

@article{rayyan-727967742,
  title={Systematic literature review: Model refactoring},
  year={2017},
  pages={1-5},
  author={Dharmawan, Tio and Rochimah, Siti},
  keywords={Software, Systematics, Systematic Literature Review, Unified modeling language, Organizations, Object oriented modeling, Filtering, Model Driven Refactoring, Observers, Pattern Based Model Refactoring, Refactoring Model, Software Evolution},
  abstract={Refactoring is the method to detecting and fixing bad smells in software. Refactoring techniques that have developed is a refactoring technique that is done on the source code. Along with the development of model driven software engineering (MDSE), it also developed the method of refactoring on the model. Refactoring method in the model is considered more effective and efficient because the detection and repair of bad smell is done at the design phase. The method of refactoring on the model evolves into a variety of techniques. Due to this, the systematic literature review is done to get the development of refactoring method on the developing model.}
}

@article{rayyan-727967743,
  title={Situational requirement engineering: A systematic literature review protocol},
  year={2013},
  pages={123-126},
  author={Khan, Huma Hayat and bin Mahrin, Mohd. Naz'ri and bt Chuprat, Suriayati},
  keywords={Software, systematic literature review, Software engineering, Systematics, Data mining, Quality assessment, Conferences, Protocols, situational requirement engineering},
  abstract={Requirements Engineering (RE) is known to be one of the critical phases in software development. Lots of work related to RE is already published. Field of RE is maturing day by day, leading to exploration at its deeper level. It is argued that RE is subject to situational characteristics. This exposure becomes even more when RE is performed in global software development environment. There is a need to identify these situational characteristics based on RE literature. We plan to systematically explore situational RE based studies to distinguish and account state of the art in situational RE based reported research. This paper objective is to provide the systematic literature review (SLR) protocol to illustrate a process for combining the situational RE work that will ultimately present a state of the art of the field in global software development environment. This SLR aims to not only summarize the data related to situational RE in form of situational characteristics but will also be useful for RE practitioners specifically working in global software development environment by providing a check list base upon situational characteristics. It will also assist RE researchers to discover knowledge gaps to distinguish needs and probability for future research directions in the field of situational RE in global software development environment.}
}

@article{rayyan-727967744,
  title={Variability in software Systems—A systematic literature review},
  year={2014},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={40},
  number={3},
  pages={282-306},
  author={Galster, Matthias and Weyns, Danny and Tofan, Dan and Michalik, Bartosz and Avgeriou, Paris},
  keywords={systematic review, software engineering, Software engineering, Systematics, Manuals, Variability, Context, Software systems, Data collection, Decision support systems, Software},
  abstract={Context: Variability (i.e., the ability of software systems or artifacts to be adjusted for different contexts) became a key property of many systems. Objective: We analyze existing research on variability in software systems. We investigate variability handling in major software engineering phases (e.g., requirements engineering, architecting). Method: We performed a systematic literature review. A manual search covered 13 premium software engineering journals and 18 premium conferences, resulting in 15,430 papers searched and 196 papers considered for analysis. To improve reliability and to increase reproducibility, we complemented the manual search with a targeted automated search. Results: Software quality attributes have not received much attention in the context of variability. Variability is studied in all software engineering phases, but testing is underrepresented. Data to motivate the applicability of current approaches are often insufficient; research designs are vaguely described. Conclusions: Based on our findings we propose dimensions of variability in software engineering. This empirically grounded classification provides a step towards a unifying, integrated perspective of variability in software systems, spanning across disparate or loosely coupled research themes in the software engineering community. Finally, we provide recommendations to bridge the gap between research and practice and point to opportunities for future research.}
}

@article{rayyan-727967745,
  title={Requirements prioritization techniques and different aspects for prioritization a systematic literature review protocol},
  year={2014},
  pages={31-36},
  author={Sher, Falak and Jawawi, Dayang N A and Mohamad, Radziah and Babar, Muhammad Imran},
  keywords={Software, Software engineering, Systematics, Bibliographies, Decision making, Requirements prioritization, Protocols, business aspects, client aspects, systematic review protocol, technical aspects},
  abstract={Requirements prioritization (RP) is considered as an important part of software requirements engineering in which requirements are ranked to develop high-quality software. Success of quality software depends on the selection of well-prioritized requirements. Different techniques are proposed and used to prioritize the software requirements. Requirements are assigned weights or ranked according to their importance and are placed in a priority list for implementation in successive releases. These techniques depend on many aspects that need to be addressed while prioritizing requirements. Requirements prioritization aspects are categorized into three major groups' technical aspects, business aspects and client aspects. Most of the existing techniques are unable to support these aspects, and it affects the quality of decision-making in the requirements prioritization process. Hence, there is a need to explore the different techniques and their support for different aspects. A comparison of the existing techniques is performed. The requirements prioritization aspects are selected to determine the current trends in the software requirements prioritization process. The issue of scalability and the business/client related aspects are the key focal points of this research paper. This paper describes the review protocol, as per guidelines of the Barbara Kitchenham, in order to conduct a systematic literature review.}
}

@article{rayyan-727967746,
  title={Gamification in software engineering teamworks: A systematic literature review},
  year={2016},
  pages={1-8},
  author={Hernández, Luis and Muñoz, Mirna and Mejia, Jezreel and Peña, Adriana},
  keywords={Software, systematic literature review, software engineering, Software engineering, Systematics, Bibliographies, Teamwork, Collaborative work, Silicon compounds, collaborative work, gamification, gamification elements, teamwork},
  abstract={Nowadays, software development is done by teams where there are several factors involved in their performance. One of the most important factors is the collaborative work, fundamental skill that every professional should have, especially in the area of software engineering. Based on the above mentioned, the adequate integration of a teamwork influences its performance. Therefore, the skills, knowledge and interactive styles for each member it should be complemented, in order to get a high effective teams. In this context, one of the techniques currently being used for achieving activities related to collaborative work is the gamification, which aims to guide the improvement of the collaborative work. This study presents a comparison among the different gamification elements that can be applied to create a teamwork, reducing its integration time, and therefore, improve its performance.}
}

@article{rayyan-727967747,
  title={Trends in software engineering processes using deep learning: A systematic literature review},
  year={2020},
  pages={445-454},
  author={Del Carpio, Alvaro Fernández and Angarita, Leonardo Bermón},
  keywords={Software, Software engineering, Systematics, Machine Learning, Systematic Review, Deep learning, Maintenance engineering, Biological system modeling, Deep Learning, Predictive models, Software Processes},
  abstract={In recent years, several researchers have applied machine learning techniques to several knowledge areas achieving acceptable results. Thus, a considerable number of deep learning models are focused on a wide range of software processes. This systematic review investigates the software processes supported by deep learning models, determining relevant results for the software community. This research identified that the most extensively investigated sub-processes are software testing and maintenance. In such sub-processes, deep learning models such as CNN, RNN, and LSTM are widely used to process bug reports, malware classification, libraries and commits recommendations generation. Some solutions are oriented to effort estimation, classify software requirements, identify GUI visual elements, identification of code authors, the similarity of source codes, predict and classify defects, and analyze bug reports in testing and maintenance processes.}
}

@article{rayyan-727967748,
  title={Ontologies supporting the distributed software development: A systematic literature review},
  year={2012},
  pages={55-59},
  author={Junior, Alex Nery B and de Azevedo, Ryan R and da Silva, Fabio Q B and Rocha, Rodrigo G C and Costa, Catarina},
  keywords={systematic literature review, Software engineering, ontology, Conferences, distributed software development, Software},
  abstract={In the past decade, there was a notably significant raise in the adoption of the Distributed Software Development approach. This so-called approach has brought a lot of competitive advantages, as well as new challenges, such as communication and sharing of information among distributed teams. In this scenario, the use of the ontology concept simplifies and normalizes the teams' understanding of shared information and eases the communication between them. This research's purpose is to make a systematic literature review in order to identify which tools, models, techniques and satisfactory practices that utilize ontology as an aid to DSD.}
}

@article{rayyan-727967749,
  title={Knowledge sharing management in offshore software development outsourcing relationships from vendors' perspective: A systematic literature review protocol},
  year={2011},
  pages={469-474},
  author={Alam, Asad Ullah and Khan, Siffat Ullah},
  keywords={Software, Systematic Literature Review, Programming, Outsourcing, Knowledge transfer, Organizations, Client-Vendor Relationships, Knowledge Sharing Management, Software Development Outsourcing},
  abstract={Offshore software development outsourcing (OSDO) is a well known business strategy adopted by many organizations in developed countries by outsourcing their software development work to low-wages countries. Developing software at offshore locations offers many benefits including access to skilled human resource and high quality software development at low cost. However outsourcing is not a risk free business for both vendor and client organizations. Vendor organizations need to address a number of factors for successful outcomes of the outsourcing relationships. Likewise knowledge sharing management (KSM) plays an important role in OSDO relationships. This research seeks to explore KSM in the context of OSDO relationships from vendors' perspective. The objective is to identify the factors that can play a positive or negative role in KSM by reviewing the literature in a systematic way. Systematic Literature Review (SLR) is based on a structured protocol, and is therefore, different from ordinary literature review. SLR provides in-depth, more thorough and comparatively unbiased results than ordinary literature review. We have developed a SLR protocol for the KSM, and are in the process of implementing the protocol. The expected outcomes of this review will be the identification of critical success factors and critical barriers to be addressed by vendor organizations for enhancing KSM in the context of OSDO relationships.}
}

@article{rayyan-727967750,
  title={Intercultural challenges in offshore software development outsourcing relationships: A systematic literature review protocol},
  year={2011},
  pages={475-480},
  author={Azeem, Muhammad Ilyas and Khan, Siffat Ullah},
  keywords={Software, systematic literature review, Systematics, Programming, Outsourcing, Cultural differences, Global communication, Protocols, Intercultural challenges, outsourcing relationships, SLR protocol},
  abstract={Offshore software development outsourcing (OSDO) is an emerging business approach adopted by many software development organizations in developed countries. Developing software at offshore locations has many benefits including access to large labor pool, low development cost and round-the-clock development. However, inspite of these benefits OSDO presents a variety of challenges to the software development organizations including temporal, geographical and intercultural differences. Intercultural differences cause many problems to vendors in OSDO relationships. This research seeks to identify the potential intercultural challenges faced by vendors in OSDO relationships by reviewing the literature in a systematic way. We have developed a systematic literature review (SLR) protocol, and are in the process of implementing the protocol. SLR is based on a structured protocol, and is therefore, different from ordinary literature review. SLR provides in-depth and more thorough results than ordinary literature review. The expected outcomes of this review will be the identification of intercultural challenges or barriers faced by vendor organisations in the establishment and maintenance of OSDO relationships.}
}

@article{rayyan-727967751,
  title={Definitions, features, and technologies on classroom response systems: A systematic literature review},
  year={2020},
  pages={221-225},
  author={Natanael, Yosua and Rosmansyah, Yusep},
  keywords={Software, systematic literature review, Systematics, SLR, Bibliographies, Education, audience response systems, classroom response systems, clickers, Communications technology, CRS, Input devices, Receivers},
  abstract={Classroom Response System (CRS) is a learning technology that supports face-to-face learning sessions by gathering responses to questions given by teachers in classroom which provides feedback to teacher during learning process using electronic devices. This paper described the definition of CRS and also its features and technologies with Systematic Literature Review (SLR) method. SLR was conducted to trace related studies trough three reputable journal database; IEEE Xplore, ACM Digital Library, and Sciencedirect. From 17,809 articles gathered, only 20 articles are eligible for synthesizing. The results are: CRS can be defined as a system used to support interaction and engagement between teachers and students in the classroom. CRS adopts an electronic voting system where the teacher displays questions via projector screen and students respond to them by answering through input device; the types of questions that can be accommodated by CRS can be grouped into three features, namely simple type interaction, text based interaction, and freeform based interaction; CRS takes the advantages of existing hardware and no longer used proprietary hardware.}
}

@article{rayyan-727967753,
  title={A study of computing undergraduates undertaking a systematic literature review},
  year={2011},
  journal={IEEE Transactions on Education},
  issn={1557-9638},
  volume={54},
  number={4},
  pages={558-563},
  author={Brereton, Pearl},
  keywords={Software engineering, Systematics, Data mining, Case study, systematic literature review (SLR), Education, Protocols, Planning, Book reviews, computing education, evidence-based software engineering (EBSE), group projects},
  abstract={Teaching computing students about the importance of evidence and about the use of empirical methods for evaluating computing technologies can be difficult, especially within dual honors undergraduate degree programs. The aims of this study were to explore the effectiveness of second-year undergraduate computing students in carrying out a systematic literature review and to identify the elements of the process that the students found most difficult. A multicase case study of students carrying out an assignment to perform a systematic literature review (SLR) was undertaken. Students worked in groups and were studying across a range of computing programs. Data was collected from three sources: student grades, the comments made by the teaching staff on the submitted reports, and a debriefing questionnaire. All of the groups successfully completed the assignment. Results on which parts of the process were the most difficult were mixed, although much of the evidence suggests that the students found the conduct phase more problematic than the planning phase. It can be concluded that undergraduates can do SLRs, but the task is clearly quite challenging and time-consuming. SLRs are well suited to being undertaken by groups.}
}

@article{rayyan-727967754,
  title={Poster: A systematic literature review to support the selection of user acceptance testing techniques},
  year={2018},
  pages={418-419},
  author={Dos Santos, Ernani César and Vilain, Patrícia and Hiura Longo, Douglas},
  keywords={Software, Software engineering, Systematics, Bibliographies, Tools, Testing, techniques, classification, features, Natural languages, User acceptance testing},
  abstract={User Acceptance Testing (UAT) aims to determine whether or not a software satisfies users acceptance criteria. Although some studies have used acceptance tests as software requirements, no previous study has collected information about available UAT techniques and established a comparison of them, to support an organization in the selection of one over another. This work presents a Systematic Literature Review on UAT to find out available techniques and compare their main features. We selected 80 studies and found out 21 UAT techniques. As result, we created a comparative table summarizing these techniques and their features.}
}

@article{rayyan-727967756,
  title={A systematic literature review on fault prediction performance in software engineering},
  year={2012},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={38},
  number={6},
  pages={1276-1304},
  author={Hall, Tracy and Beecham, Sarah and Bowes, David and Gray, David and Counsell, Steve},
  keywords={Software testing, Systematic literature review, Systematics, Context modeling, Analytical models, Predictive models, Data models, Fault diagnosis, software fault prediction, Software},
  abstract={Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs, and improve the quality of software. Objective: We investigate how the context of models, the independent variables used, and the modeling techniques applied influence the performance of fault prediction models. Method: We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesize the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modeling techniques such as Naive Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology, and performance comprehensively.}
}

@article{rayyan-727967757,
  title={Model-based software design and testing in blockchain smart contracts: A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={164556-164569},
  author={Sánchez-Gómez, Nicolás and Torres-Valderrama, Jesus and García-García, J A and Gutiérrez, Javier J and Escalona, M J},
  keywords={Software, systematic literature review, Software engineering, Systematics, Testing, software testing, Proposals, blockchain, Contracts, model-based software engineering, smart contract, software development life cycle, Software Design},
  abstract={Blockchain technology promises to spark a real revolution. One of most important concepts associated with this technology is smart contracts, which enable the automatic execution of agreements and augur a world without intermediaries. The conditions and rules of “contracts” are established in a computer codes and trust is enforced by consensus among the participants. One relevant feature associated with smart contract is the immutability property, which establishes the non-alteration of blockchain network data after the clauses of the contract are been approved by all parties or entities involved. For this reason, smart contract development requires more effort and care than the development of other common programs. They require systematic mechanisms to collect requirements and functional specifications. In addition, it is necessary to verify and validate the agreed functionality and the implemented code before they are deployed in the blockchain platform. This article presents a systematic literature review of primary studies in the field of Software Development Life Cycle, focusing on model-based software design and testing in the blockchain domain of smart contracts. This research aims to identify gaps and/or opportunities for further research. After carried out this review, it was observed that no clear methodology exists for evaluating and validating the quality either of this software or the overall development process. This means that software developers may implement smart contract code in which bugs and serious security vulnerabilities appear when the software is delivered to their customers.}
}

@article{rayyan-727967758,
  title={Causes of requirement change - A systematic literature review},
  year={2012},
  pages={22-31},
  author={Bano, Muneera and Imtiaz, Salma and Ikram, Naveed and Niazi, Mahmood and Usman, Muhammad},
  keywords={systematic literature review, requirements engineering, causes, requirements change},
  abstract={Context: Research shows that one of the main reasons of project failure is changing requirements. The success or failure of software projects largely depends upon how we respond to changing requirements. The knowledge about the causes of requirements change can improve our ability to make better decisions and manage changing requirements effectively. Objective: In this paper we present findings from an empirical study that was aimed at identifying the causes of requirement change and the frequency of these causes in different software development phases. Methods: We performed a systematic literature review and went through all the stages required by the process. Although our search strings yielded a large amount of papers but after careful filtration we were left with only five papers (six studies) which reported empirical knowledge about the causes of requirement change. Results: We have identified different causes and their frequency in software development phases. We have classified the extracted causes of requirements change into two major types i.e., essential and accidental causes. Conclusions: It is surprising to find little empirical evidence on the causes of requirements change as requirements change has been widely quoted as one of the major challenges faced by requirements engineers. With this small number of evidences, it is hard to generalize the research results. There is a need for further empirical research to identify and fully understand the causes of requirement change.}
}

@article{rayyan-727967759,
  title={Using the 5W+1H model in reporting systematic literature review: A case study on software testing for cloud computing},
  year={2013},
  pages={222-229},
  author={Jia, Changjiang and Yu, Yuen Tak},
  keywords={Software testing, systematic literature review, Systematics, Cloud computing, software testing, Computational modeling, 5W+1H, cloud-based application, Software as a service, Software},
  abstract={This paper documents a case study of using the 5W+1H model for reporting systematic literature review on software testing for cloud computing. To our knowledge, this is the first systematic literature review that applies the 5W+1H model, which is widely used in the journalism domain, to report the full picture of the research area in both software engineering and services computing. Existing guidelines on systematic literature review heavily rely on the researcher to pose the right research questions, and the review results are tightly focused on these research questions. For researchers new to a field, defining the right research questions that are effective in revealing the critical issues in the field can be challenging. Our case study demonstrates that the 5W+1H model provides an easy aid for the researcher to get over such initial challenges. As the researcher becomes more familiar with the field, he/she may then refine the research questions by adding more topic-specific contexts. In this way, the 5W+1H model serves to provide an exploratory framework to shape a systematic literature review. Applying to software testing for cloud computing, we are able to synthesize a comprehensive picture of recent researches on the field, including publication pattern, article citation immediacy, research topic diversity, research ideas for addressing testing challenges at different cloud service architectural layers. Based on the case study, we summarize the lessons learned on using the 5W+1H model in reporting systematic literature review.}
}

@article{rayyan-727967760,
  title={Software requirements prioritisation: A systematic literature review on significance, stakeholders, techniques and challenges},
  year={2018},
  journal={IEEE Access},
  issn={2169-3536},
  volume={6},
  pages={71497-71523},
  author={Hujainah, Fadhl and Bakar, Rohani Binti Abu and Abdulgabber, Mansoor Abdullateef and Zamli, Kamal Z},
  keywords={systematic literature review, Software engineering, Systematics, Bibliographies, Requirements prioritization, challenges, Software systems, techniques, Complexity theory, Stakeholders, requirements prioritization criteria, stakeholders, Software},
  abstract={As one of the gatekeepers of quality software systems, requirements' prioritization (RP) is often used to select the most important requirements as perceived by system stakeholders. To date, many RP techniques that adopt various approaches have been proposed in the literature. To identify the strengths, opportunities, and limitations of these existing approaches, this paper studied and analyzed the RP field in terms of its significance in the software development process based on the standard review guidelines by Kitchenham. By a rigorous study selection strategy, 122 relevant studies were selected to address the defined research questions. Findings indicated that RP plays a vital role in ensuring the development of a quality system with defined constraints. The stakeholders involved in RP were reported, and new categories of the participating stakeholders were proposed. Additionally, 108 RP techniques were identified and analyzed with respect to their benefits, prioritization criteria, size of requirements, types in terms of automation level, and their limitations; 84 prioritization criteria were disclosed with their frequency usages in prioritizing the requirements. The study revealed that the existing techniques suffer from serious limitations in terms of scalability, the lack of quantification, and the prioritization of the participating stakeholders, time consumption, requirement interdependences, and the need for highly professional human intervention. These findings are useful for researchers and practitioners in improving the current state of the art and state of practices.}
}

@article{rayyan-727967761,
  title={A systematic review of logging practice in software engineering},
  year={2017},
  pages={534-539},
  author={Rong, Guoping and Zhang, Qiuping and Liu, Xinbei and Gu, Shenghiu},
  keywords={Software Engineering, Software engineering, Systematics, Systematic Literature Review, Tools, Software systems, Fault tolerance, Fault tolerant systems, Logging Practice, Software},
  abstract={Background: Logging practice is a critical activity in software development, which aims to offer significant information to understand the runtime behavior of software systems and support better software maintenance. There have been many relevant studies dedicated to logging practice in software engineering recently, yet it lacks a systematic understanding to the adoption state of logging practice in industry and research progress in academia. Objective: This study aims to synthesize relevant studies on the logging practice and portray a big picture of logging practice in software engineering so as to understand current adoption status and identify research opportunities. Method: We carried out a systematic review on the relevant studies on logging practice in software engineering. Results: Our study identified 41 primary studies relevant to logging practice. Typical findings are: (1) Logging practice attracts broad interests among researchers in many concrete research areas. (2) Logging practice occurred in many development types, among which the development of fault tolerance systems is the most adopted type. (3) Many challenges exist in current logging practice in software engineering, e.g., tradeoff between logging overhead and analysis cost, where and what to log, balance between enough logging and system performance, etc. Conclusion: Results show that logging practice plays a vital role in various applications for diverse purposes. However, there are many challenges and problems to be solved. Therefore, various novel techniques are necessary to guide developers conducting logging practice and improve the performance and efficiency of logging practice.}
}

@article{rayyan-727967762,
  title={Sustainability in software engineering: A systematic literature review},
  year={2012},
  pages={32-41},
  author={Penzenstadler, Birgit and Bauer, Veronika and Calero, Coral and Franch, Xavier},
  keywords={Software},
  abstract={Background: Supporting sustainability in software engineering is becoming an active area of research. We want to contribute the first Systematic Literature Review(SLR) in this field to aid researchers who are motivated to contribute to that topic by providing a body of knowledge as starting point, because we know from own experience, this search can be tedious and time consuming. Aim: We aim to provide an overview of different aspects of sustainability in software engineering research with regard to research activity, investigated topics, identified limitations, proposed approaches, used methods, available studies, and considered domains. Method: The applied method is a SLR in five reliable and commonly-used databases according to the (quasi-standard) protocol by Kitchenham et al. [1]. We assessed the 100 first results of each database ordered by relevance with respect to the search query. Results: Of 500 classified publications, we regard 96 as relevant for our research questions. We sketch a taxonomy of their topics and domains, and provide lists of used methods and proposed approaches. Most of the excluded publications were ruled out because of an unfitting usage of terms within the search query. Conclusions: Currently, there is little research coverage on the different aspects of sustainability in software engineering while other disciplines are already more active. Future work includes extending the study by reviewing a higher number of publications, including dedicated journal and workshop searches, and snowballing.}
}

@article{rayyan-727967763,
  title={Empirical research in software process modeling: A systematic literature review},
  year={2011},
  pages={339-342},
  author={Bai, Xu and Zhang, He and Huang, LiGuo},
  keywords={Software, systematic literature review, Software engineering, Systematics, Data mining, Guidelines, empirical research, Educational institutions, Data analysis, Software process modeling and simulation},
  abstract={Recognized as one of the powerful technologies in software process engineering, Software Process Modeling (SPM) has received significant attention over the last three decades. Although empirical research plays a critical role in software engineering, the state-of-the-practice of empirical research in SPM has not been systematically reviewed. This paper serves as a status report of the assessment of empirical research in SPM by analyzing all refereed studies that were published in relevant venues from 1987 to 2008 using systematic review methodology. The primary findings indicate that in current SPM-related empirical studies, (1) software process management and improvement (SPI) was not yet the most popular primary research objectives, (2) exploratory empirical research methods, e.g., case study and action research, were dominantly used, (3) there were common issues in empirical research reports in terms of following rigorous reporting guidelines. Based on the review results, we also suggest the future needs for empirical research in SPM, in terms of research topics, SPM techniques, the strengths of research methodology and the rigors of empirical studies.}
}

@article{rayyan-727967764,
  title={Improvements to the function point analysis method: A systematic literature review},
  year={2015},
  journal={IEEE Transactions on Engineering Management},
  issn={1558-0040},
  volume={62},
  number={4},
  pages={495-506},
  author={de Freitas Junior, Marcos and Fantinato, Marcelo and Sun, Violeta},
  keywords={Software, Artificial intelligence, Software measurement, systematic literature review (SLR), Complexity theory, ISO Standards, Accuracy, Accuracy improvement, function point analysis (FPA)},
  abstract={Function point analysis (FPA) is a standardized method to systematically measure the functional size of software. This method is proposed by an international organization and it is currently recommended by governments and organizations as a standard method to be adopted for this type of measurement. This paper presents a compilation of improvements, focused on increasing the accuracy of the FPA method, which have been proposed over the past 13 years. The methodology used was a systematic literature review (SLR), which was conducted with four research questions aligned with the objectives of this study. As a result of the SLR, of the 1600 results returned by the search engines, 454 primary studies were preselected according to the criteria established for the SLR. Among these studies, only 18 specifically referred to accuracy improvements for FPA, which was the goal of this study. The low number of studies that propose FPA improvements might demonstrate the maturity of the method in the current scenario of software metrics. Specifically in terms of found issues, it was found that the step for calculating the functional size exhibited the highest number of problems, indicating the need to revise FPA in order to encompass the possible improvements suggested by the researchers.}
}

@article{rayyan-727967765,
  title={Quality factors enhancement of requirement engineering: A systematic literature review},
  year={2019},
  pages={13-135},
  author={Abbas, Syed Manzar and Alam, Khubaib Amjad and Iqbal, Umer and Ajmal, Sahar},
  keywords={Systematic literature review, Quality Enhancement, RE Phases, Requirement Engineering},
  abstract={Software requirement engineering is among the most important issues for starting any software project. The most-reported problem in requirement engineering (RE) is the difficulty to identify quality requirements. Sometime analysts may face incorrect and incomplete requirements, which may become the reason for project failures from the perspective of dissatisfaction of stakeholders. Hence, the quality in each phase of RE is important. The main focus of this article is to categorizing, Identifying, and synthesizing the existing researches on quality enhancement of the RE process. The systematically reviewing the relevant studies based on the Kitchenham systematic review methodology is the main objective of this study. This review identifies the methods which are used for enhancing the quality of RE by improving requirement elicitation, requirement analysis and specification, and requirement validation process. In this research, we are not specific to any phase of RE. Hence, the techniques obtained for quality enhancement purpose can target different phases as we are going to deal with the overall quality of requirements to enhance different quality factors as defined by IEEE standards. In general, 3 defined research questions have been invested for the sake of discussion on explored results. Likewise, 44 articles were selected from an initial set of 101 research papers. In particular, research articles answering formulated question have been included in this SLR.}
}

@article{rayyan-727967766,
  title={Requirements prioritization techniques in the last decade: A systematic literature review},
  year={2020},
  pages={11-20},
  author={Somohano-Murrieta, Juan Carlos B and Ocharán-Hernández, Jorge Octavio and Sánchez-García, Angel J and de los Ángeles Arenas-Valdés, Maria},
  keywords={Software, Systematics, Systematic Literature Review, Bibliographies, Data mining, Guidelines, Requirements engineering, Quality assessment, Requirements Prioritization, Requirements Analysis, Requirements Prioritization Techniques},
  abstract={Requirements Prioritization is an activity, part of Requirements Engineering, whose purpose is to determine the relevance that each requirement has within a software system to be developed. In order to conduct this activity, several requirements prioritization techniques have been proposed. However, companies and software developers do not know which techniques can give the best results possible or when to apply them. Choosing the wrong technique might lead the prioritization process to an inappropriate approach. This systematic literature review aims to know the state of the art of the prioritization techniques which have been used in software projects developed during the last decade, as well as knowing the benefits provided by their implementation. Our results show that AHP, Cumulative Voting, Cost-Value Approach, and Numerical Assignment were the most documented techniques. According to the studies reviewed, these techniques have specific advantages, for example, accuracy and effort reduction benefits. They also have disadvantages such as scalability issues and time consumption problems. However, the use of Requirements Prioritization Techniques, in general terms, generate cost and effort benefits as well as a considerable reduction in the time needed to conduct the Prioritization Process.}
}

@article{rayyan-727967767,
  title={Systematic literature review on effort estimation for Open Sources (OSS) web application development},
  year={2016},
  pages={1158-1167},
  author={Lee, Tseu Kwan and Wei, Koh Tieng and Abd Ghani, Abdul Azim},
  keywords={systematic literature review, Systematics, Bibliographies, Effort estimation, Measurement, Estimation, Databases, Complexity theory, Libraries, open sources, web application development},
  abstract={The development of Web applications has a crucial role as most organizations have their own corporate Web applications to meet the needs of their respective businesses. Different needs create different complexities which represent a new challenge to Web application development. In order to ensure the timely delivery of a project, software providers offering this service choose to use Open Sources (OSS) as an alternative. Since OSS consist of an existing framework that can be implemented directly into the application, how far does this affect the complexity of the effort estimation? A number of research papers have outlined the efforts made to refine the complexity of this field. However, to our best knowledge a systematic overview of the research done on Web application development that involves OSS usage does not appear to exist. Hence, the aim of this paper is to conduct a systematic literature review (SLR) of OSS Web application development. For this purpose, 34 papers from a total of 67 papers were identified and studied. The findings of this study indicate that (a) no research has been carried out on the field mentioned; (b) there is no early effort estimation model for Web projects that involve the usage of OSS. Therefore, this work provides an overview of the field besides identifying future research possibilities.}
}

@article{rayyan-727967769,
  title={Understanding institutional repository in higher learning institutions: A systematic literature review and directions for future research},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={35242-35263},
  author={Asadi, Shahla and Abdullah, Rusli and Yah, Yusmadi and Nazir, Shah},
  keywords={Software, systematic literature review, Systematics, Bibliographies, Data mining, Education, Protocols, Institutional repositories, IRs, Open Access, university},
  abstract={Institutional repositories (IRs) have received considerable attention from researchers across disciplines and around the globe. They have potentially increased the public value, ranking, prestige, and visibility of researchers, and relevant universities. However, despite the important and rapid growth of research in this area, few efforts have been made to systematically review and integrate the findings from previous research studies or to examine the current state of study regarding IRs. The primary goal of this paper is to provide a better understanding and an in-depth review of the current state of study regarding IRs. This research uses a systematic literature review (SLR) and followed a protocol to properly organize the work related to institutional repositories. The data were collected from primary studies published from 2007 to 2018 from the six major databases (ScienceDirect, IEEE Explorer, Springer, ACM, Taylor and Francis, and Emerald insight). Several papers regarding IRs were reviewed, applying inclusion and exclusion criteria, and a total of 115 studies were included as the main part of this research. The results obtained from these studies indicated that the absence of knowledge of open access IRs among scholars and institutions and inadequate information and communication technology infrastructure were significant challenges behind the development of open access IRs. Meanwhile, enhanced visibility of the academic institution, increased local and global rankings, increased prestige and public value, and improved teaching, learning, and research development by the scholars of the institution were found to be the main benefits of institutional repositories. This paper also highlighted that most of the studies in this research area were focused on the ”deployment, implementation, and adoption” and ”benefits and challenges” of institutional repositories. The outcomes of this paper can assist future researchers by providing a roadmap of institutional repositories and highlighting guidelines for successful implementation of IRs in higher learning institutions.}
}

@article{rayyan-727967770,
  title={A systematic literature review and a unified model of ATD},
  year={2016},
  pages={189-197},
  author={Besker, Terese and Martini, Antonio and Bosch, Jan},
  keywords={Systematic literature review, Software engineering, Software Architecture, Architectural Technical Debt, Software Maintenance},
  abstract={Fast software deliveries are hindered by high maintenance efforts due to internal quality issues and Technical Debt (TD) and specifically, Architectural Technical Debt (ATD) has received increased attention in the last few years. ATD has a significant influence and impact on system success and, left unchecked, it can cause expensive repercussions, it is, therefore, of maintenance and evolutionary importance to understand the basic underlying factors of ATD. Thus, with this as background, there is a need for a descriptive model to illustrate and explain the different ATD issues. The aim of this study is to synthesize and compile research efforts with the goal of creating new knowledge with a specific interest in the ATD field. The contribution of this paper is the presentation of a novel descriptive model, providing a comprehensive interpretation of the ATD phenomenon. This model categorizes the main characteristics of ATD and reveals their corresponding relations. The model is based on a systematic literature review (SLR) of currently recognized knowledge concerning ATD.}
}

@article{rayyan-727967771,
  title={A ranking-based approach for supporting the initial selection of primary studies in a Systematic Literature Review},
  year={2019},
  pages={1-10},
  author={González-Toral, Santiago and Freire, Renán and Gualán, Ronald and Saquicela, Víctor},
  keywords={automation, text mining, Systematic literature review, Systematics, Text mining, Bibliographies, data mining, Tools, Ontologies, Semantics, knowledge graphs, machinelearning, NLP, PCA, ranking indexing},
  abstract={Traditionally most of the steps involved in a Systematic Literature Review (SLR) process are manually executed, causing inconvenience of time and effort, given the massive amount of primary studies available online. This has motivated a lot of research focused on automating the process. Current state-of-the-art methods combine active learning methods and manual selection of primary studies from a smaller set so they can maximize the finding of relevant papers while at the same time minimizing the number of manually reviewed papers. In this work, we propose a novel strategy to further improve these methods whose early success heavily depends on an effective selection of initial papers to be read by researchers using a PCAbased method which combines different document representation and similarity metric approaches to cluster and rank the content within the corpus related to an enriched representation of research questions within the SLR protocol. Validation was carried out over four publicly available data sets corresponding to SLR studies from the Software Engineering domain. The proposed model proved to be more efficient than a BM25 baseline model as a mechanism to select the initial set of relevant primary studies within the top 100 rank, which makes it a promising method to bootstrap an active learning cycle.}
}

@article{rayyan-727967772,
  title={A systematic literature review on machine learning for automated requirements classification},
  year={2020},
  pages={21-28},
  author={Pérez-Verdejo, J Manuel and Sánchez-García, Angel J and Ocharán-Hernández, Jorge Octavio},
  keywords={Software, Software engineering, Systematics, Systematic Literature Review, Machine learning, Machine Learning, Requirements Engineering, Classification, Databases, Machine learning algorithms, Software algorithms, Requirements Classification},
  abstract={The development of quality software begins with the correct identification of the system needs. These requirements represent the basis of the subsequent activities in the software life cycle. The correct identification of these requirements in their different categories impacts on the actions taken to meet them. However, this classification can be often time-consuming or error-prone when it comes to large-scale systems, so different proposals have been made to assist in this process automatically. This systematic literature review identifies those applications of Machine Learning techniques in the classification of software requirements. In this regard, 13 articles were identified, from which relevant information on the applied algorithms, their training process, and their evaluation metrics are analyzed. From the results obtained, it is identified that the most recurrent classification algorithms featured on the identified studies are Naive Bayes, Decision Trees, and Natural Language Processing algorithms. The most frequent training datasets are academic databases and collected user reviews.}
}

@article{rayyan-727967773,
  title={Methodology for systematic literature review applied to engineering and education},
  year={2018},
  pages={1364-1373},
  author={Torres-Carrión, Pablo Vicente and González-González, Carina Soledad and Aciar, Silvana and Rodríguez-Morales, Germania},
  keywords={systematic literature review, Systematics, Bibliographies, Databases, Computer science, Proposals, Planning, educational enginering, methodology, Thesauri},
  abstract={A systematic review of the scientific literature in a specific area is important for identifying research questions, as well as for justifying future research in said area. This process is complex for beginners in scientific research, especially if you have not developed skills for searching and filtering information, and do not know which high-level databases are relevant in their field of study. The method proposed leads the researcher from "My" to "The" current state of the problem; we propose an adaptation of the method by Kitchenham and Bacca, which divides the process into three sub-parts: planning, conducting and reporting results. From the approach of the research problem in the preliminary phase research questions (recommended between 3 to 5) and "mentefacto conceptual" is drawn; this last one gives originality to the method and facilitates the development of the thesaurus for searches and inclusion and exclusion criteria. Early research requires doing a basic systematic study to identify work done to review the literature in the area and, if any is found, to verify if those results yield an answer to our research questions. As part of planning the search process, general and specific inclusion and exclusion criteria were defined, along with some complementary inclusion and exclusion parameters. The method followed with rigor, returns to the researcher a list of impact journals in the study area, and a detail of articles that are related to each category of the research questions. A study case has been considered as a guide to expose each of the phases of the methodology in a practical way, with results that support the proposal.}
}

@article{rayyan-727967774,
  title={What software engineering “Best practices” are we teaching students - a systematic literature review},
  year={2018},
  pages={1-8},
  author={Marques, Maíra and Robledo, Javier},
  keywords={Software, Software engineering, Bibliographies, Guidelines, Education, Best practices, Libraries},
  abstract={This research presents that teaching software engineering can be a demanding challenge for instructors, considering that the software industry grows rapidly and there are new development technologies being released constantly. Some of the methodologies being used in industry with time are converted in “best practices”. This systematic literature review (SLR) focuses on finding what are the software engineering best practices being taught to students in academia. It is expected to show with this SLR what are the best practices being taught and how, so other instructors and the teaching staff can evaluate what to choose and level up their courses to the extent of what is being used and is already tested. To perform this SLR, a well-known protocol was used with the search string: “software engineering education” and “best practices” (variations and synonyms of the words were also used), the search was performed in six well-known databases. It is surprising that the amount of primary studies found in this SLR was not what was expected, seventeen primary studies were identified. These studies mentioned a total of seventy best practices that are being used in academia to teach software engineering, some of them are mentioned in more than one paper. But the granularity of the primary studies was quite different some of the best practices are really software engineering best practices and others are instructional best practices. It was also evaluated how the use of these practices was validated and reported, and the results are very diverse, some of them did not have a validation, others have qualitative data, and a few qualitative and quantitative data.}
}

@article{rayyan-727967776,
  title={Systematic literature review on global software development risks in agile methodology},
  year={2020},
  pages={231-236},
  author={Podari, Zuriyaninatasa and Arbain, Adila Firdaus and Ibrahim, Noraini and Abang Jawawi, Dayang Norhayati and Nasir Wan Kadir, Wan Mohd and Fahmi, Azim Muhammad},
  keywords={Software, Software engineering, Systematics, Bibliographies, Risk management, Agile methodology, challenges, global software development, Standards, Focusing, risks},
  abstract={Background: The word “Global Software Development” can be described as the development of software, with development teams spread across different geographical locations. Problem statement: The issues arise when there are gaps in information, workflows or processes, policies and others in the world. Objective: This paper aims to build an understanding of the risk in Global Software Development. Then, to identify category risk in Global Software Development and how Agile can reduce or mitigate their challenges. Method: This review paper using the standard systematic literature review method by Kitchehamm by reviewing and analyzing the relevant state-of -art techniques and approaches in the journal libraries based on the research questions. Results: The findings show that communication in Agile Global Software development is the main risk challenge. Contribution: The contributions of this paper may support the academician to propose and validate an enhanced approach to solve the issues if risk management in Agile GSD environment and assist the practitioners in choosing the most suitable and relevant method based on the requirement of Agile GSD project. This review paper is also focusing on the contribution to the Software Engineering Management and Software Engineering Models and Methods Knowledge Area.}
}

@article{rayyan-727967777,
  title={Software architecture and requirements: A systematic literature review},
  year={2015},
  pages={1-5},
  author={Batool, Dur-e-Benish and Molta, Yasir Hafeez and Sarwar, Amber and Abbasi, Mateen Ahmed and Jabeen, Javeria},
  keywords={Systematic literature review, Systematics, Bibliographies, Data mining, Ontology, Service-oriented architecture, Computer architecture, Architecture description languages, software architecture, Software},
  abstract={Research in software architecture (SA) can be seen in two perspectives: a traditional and modern one. Software architecture is represented using graphical diagrams (Models, Frameworks) of the system, Architecture Description Languages, Ontology. The main focus of this paper is to know about the software architecture and to find out the strength of evidence in empirical work reported within literature. The outcome of this systematic literature review will be useful for researchers and practitioners and this SLR also includes widely used tools, models, and techniques used in SA; software architecture challenges/Issues widely reported; the SA areas which are under major consideration; the SA areas that require sufficient attention. In the end we also provide information model regarding requirements and architecture, which handles portability and contextual issues regarding platform dependency. Main purpose of information model is to facilitate practitioners for achieving traceability between requirements and architecture.}
}

@article{rayyan-727967779,
  title={Software requirements modeling: A systematic literature review},
  year={2020},
  pages={194-200},
  author={Arif, Mohd. and Mohammad, Chaudhary Wali and Sadiq, Mohd.},
  keywords={systematic literature review, Requirements engineering, notations, requirements modeling, Software},
  abstract={Software requirements modeling (SRM) is a subprocess of requirements engineering (RE) which is used to elicit and represent the need of the stakeholders. Different systematic literature reviews (SLR) have been performed in different areas of RE like requirements elicitation, stakeholder identification, requirements prioritization, use case models, etc. Despite the availability of different SRM techniques, less attention is given to synthesize the existing SRM techniques in the context of the unified modeling language (UML) and goal oriented techniques like “Knowledge Acquisition for Automated Specifications” (KAOS), I* framework, non-functional requirements (NFR) framework, and Tropos, etc. Therefore, to address this issue, in this paper we present the SLR by analysing the existing SRM techniques based on the following formulated research questions (RQs): (a) how UML and goal oriented techniques were evolved? (b) which modeling techniques are appropriate for modeling the NFRs? (c) what are the tools available for modeling the different types of the software requirements, i.e., functional and nonfunctional requirements? Search items were extracted from the RQs to identify the primary studies from the Journals, Conferences, Workshops, and Symposium. Our SLR has identified 56 distinct studies which have been published from 2008 to 2019. Selected studies were assessed according to the formulated RQs for their quality and coverage to specific SRM technique thus identifying some gaps in the literature. We observed that there is need to develop the SRM techniques for representing the different types of the NFRs; and also to strengthen the UML by integrating the NFRs and multi-criteria decision making techniques.}
}

@article{rayyan-727967781,
  title={Understanding quality attributes in microservice architecture},
  year={2017},
  pages={9-10},
  author={Li, Shanshan},
  keywords={Software, systematic literature review, Software engineering, Systematics, Bibliographies, quality attributes, Conferences, Computer architecture, IEEE Press, microservices, monolith},
  abstract={As a prevalent architectural style, microservice architecture overcomes the challenges of monolithic architecture and achieves better quality by implementing small-scale microservice, rather than binding all functions into one monolith. Welldesigned microservice architecture with better quality relies on clear understanding of related quality attributes. However, current understanding of quality attributes in microservice architecture is deficient and not comprehensive. In this study, we aim to construct knowledge of quality attributes in architecture through a Systematic Literature Review (SLR), the exploratory case study and the explanatory survey. By analyzing the influential factors and the corresponding tactics of related quality attributes, our research is aimed at providing a comprehensive guide on quality improvement in microservice architecture.}
}

@article{rayyan-727967783,
  title={Empirical evaluation of the impact of object-oriented code refactoring on quality attributes: A systematic literature review},
  year={2018},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={44},
  number={1},
  pages={44-69},
  author={Al Dallal, Jehad and Abdin, Anas},
  keywords={systematic literature review, Systematics, Bibliographies, Software quality, Unified modeling language, Object oriented modeling, Libraries, quality attribute, quality measure, refactoring scenario},
  abstract={Software refactoring is a maintenance task that addresses code restructuring to improve its quality. Many studies have addressed the impact of different refactoring scenarios on software quality. This study presents a systematic literature review that aggregates, summarizes, and discusses the results of 76 relevant primary studies (PSs) concerning the impact of refactoring on several internal and external quality attributes. The included PSs were selected using inclusion and exclusion criteria applied to relevant articles published before the end of 2015. We analyzed the PSs based on a set of classification criteria, including software quality attributes and measures, refactoring scenarios, evaluation approaches, datasets, and impact results. We followed the vote-counting approach to determine the level of consistency among the PS reported results concerning the relationship between refactoring and software quality. The results indicated that different refactoring scenarios sometimes have opposite impacts on different quality attributes. Therefore, it is false that refactoring always improves all software quality aspects. The vote-counting study provided a clear view of the impacts of some individual refactoring scenarios on some internal quality attributes such as cohesion, coupling, complexity, inheritance, and size, but failed to identify their impacts on external and other internal quality attributes due to insufficient findings.}
}

@article{rayyan-727967784,
  title={A systematic literature review of applications of the physics of notations},
  year={2019},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={45},
  number={8},
  pages={736-759},
  author={van der Linden, Dirk and Hadar, Irit},
  keywords={Systematic literature review, Visualization, Unified modeling language, Complexity theory, Physics, Semantics, cognitive effectiveness, design rationale, physics of notations, visual notations},
  abstract={INTRODUCTION: The Physics of Notations (PoN) is a theory for the design of cognitively effective visual notations, emphasizing the need for design grounded in objective and verifiable rationale. Although increasingly applied, no systematic analysis of PoN applications has yet been performed to assess the theory's efficacy in practice. OBJECTIVES: Our primary objective was to assess the scope and verifiability of PoN applications. METHOD: We performed a systematic literature review (SLR) of peer-reviewed PoN applications. We analyzed what visual notations have been evaluated and designed using the PoN, for what reasons, to what degree applications consider requirements of their notation's users, and how verifiable these applications are. RESULTS: Seventy PoN applications were analyzed. We found major differences between applications evaluating existing notations and applications designing new notations. Particularly, in the case of new notations, we found that most applications adopted the PoN with little critical thought towards it, rarely considered its suitability for a particular context, and typically treated and discussed the PoN with few, if any, verifiable details and data. CONCLUSION: The results warrant consideration for those applying the PoN to do so carefully, and show the need for additional means to guide designers in systematically applying the PoN.}
}

@article{rayyan-727967785,
  title={A systematic literature review and meta-analysis on cross project defect prediction},
  year={2019},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={45},
  number={2},
  pages={111-147},
  author={Hosseini, Seyedrebvar and Turhan, Burak and Gunarathna, Dimuthu},
  keywords={meta-analysis, systematic literature review, Systematics, Bibliographies, Measurement, Context modeling, Defect prediction, Object oriented modeling, Predictive models, Data models, cross project, fault prediction, within project},
  abstract={Background: Cross project defect prediction (CPDP) recently gained considerable attention, yet there are no systematic efforts to analyse existing empirical evidence. Objective: To synthesise literature to understand the state-of-the-art in CPDP with respect to metrics, models, data approaches, datasets and associated performances. Further, we aim to assess the performance of CPDP versus within project DP models. Method: We conducted a systematic literature review. Results from primary studies are synthesised (thematic, meta-analysis) to answer research questions. Results: We identified 30 primary studies passing quality assessment. Performance measures, except precision, vary with the choice of metrics. Recall, precision, f-measure, and AUC are the most common measures. Models based on Nearest-Neighbour and Decision Tree tend to perform well in CPDP, whereas the popular naïve Bayes yields average performance. Performance of ensembles varies greatly across f-measure and AUC. Data approaches address CPDP challenges using row/column processing, which improve CPDP in terms of recall at the cost of precision. This is observed in multiple occasions including the meta-analysis of CPDP versus WPDP. NASA and Jureczko datasets seem to favour CPDP over WPDP more frequently. Conclusion: CPDP is still a challenge and requires more research before trustworthy applications can take place. We provide guidelines for further research.}
}

@article{rayyan-727967786,
  title={Problems in the adoption of agile-scrum methodologies: A systematic literature review},
  year={2016},
  pages={141-148},
  author={López-Martínez, Janeth and Juárez-Ramírez, Reyes and Huertas, Carlos and Jiménez, Samantha and Guerra-García, Cesar},
  keywords={Software, systematic literature review, Systematics, Bibliographies, Scrum, Companies, adoption problems, agile methodologies, Scrum (Software development)},
  abstract={Agile methodologies are focused on the people and functional product delivery in short periods of time. There are methodologies that change considerably the work habits of software developers. Scrum is an agile methodology that involves an iterative, incremental, and empiric process. Besides it is designed to add value, focus, clarity and transparency to the activities and products of a project. Nowadays, most companies are interested in the adoption of agile methodologies. Although Scrum is a light process and easy to understand, its adoption sometimes is difficult. Agile methodologies are not obvious by themselves, so they are difficult to introduce in the culture of a company. In order to identify the problems presented during the adoption, a Systematic Literature Review is performed focusing in Scrum. We found several problems, these are categorized in four groups: people, process, project, and company (organization). The results represent a basis to propose a framework to support the agile adoption.}
}

@article{rayyan-727967787,
  title={Testability and software robustness: A systematic literature review},
  year={2015},
  pages={341-348},
  author={Hassan, Mohammad Mahdi and Afzal, Wasif and Blom, Martin and Lindström, Birgitta and Andler, Sten F and Eldh, Sigrid},
  keywords={Software, Systematic literature review, Testing, Robustness, Software robustness, Contracts, Fault tolerance, Fault tolerant systems, Observability, Software testability},
  abstract={The concept of software testability has been researched in several different dimensions, however the relation of this important concept with other quality attributes is a grey area where existing evidence is scattered. The objective of this study is to present a state-of-the-art with respect to issues of importance concerning software testability and an important quality attribute: software robustness. The objective is achieved by conducting a systematic literature review (SLR) on the topic. Our results show that a variety of testability issues are in focus with observability and controllability issues being most researched. Fault tolerance, exception handling and handling external influence are prominent robustness issues in focus.}
}

@article{rayyan-727967788,
  title={Systematic literature review: Teaching novices programming using robots},
  year={2011},
  pages={21-30},
  author={Major, L and Kyriacou, T and Brereton, O P},
  keywords={systematic literature review, SLR, innovative, learning, novices, programming, robotics, robots, teaching, Robotics},
  abstract={Background: Teaching programming to novices is a difficult task due to the complex nature of the subject, as negative stereotypes are associated with programming and because introductory programming courses often fail to encourage student understanding. Aim: This study investigates the effectiveness of using robots as tools to aid the process of teaching programming and to determine whether such technology can help to overcome the current barriers for learners in this context. Method: The Systematic Literature Review (SLR) methodology has been selected to discover how effective the use of robotics has been in the teaching of introductory programming concepts. Nine electronic databases, the proceedings from six conferences and two journals have been searched for literature relevant to the study. Results: After applying inclusion and exclusion criteria 34 articles have been accepted in the SLR. 74% of included literature report robots to be an effective teaching tool and one that can help novice programmers in their studies. Conclusion: Robots can be a powerful and effective tool when used in an introductory programming course but the potential remains to further investigate methods for their implementation. Thoughts on the use of the SLR methodology from the perspective of a PhD student are also given.}
}

@article{rayyan-727967789,
  title={Reporting usability defects: A systematic literature review},
  year={2017},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={43},
  number={9},
  pages={848-867},
  author={Yusop, Nor Shahida Mohamad and Grundy, John and Vasa, Rajesh},
  keywords={Software engineering, Systematics, Bibliographies, Systematic review, Testing, Usability, Human computer interaction, test management, usability defect reporting, usability testing, user interface},
  abstract={Usability defects can be found either by formal usability evaluation methods or indirectly during system testing or usage. No matter how they are discovered, these defects must be tracked and reported. However, empirical studies indicate that usability defects are often not clearly and fully described. This study aims to identify the state of the art in reporting of usability defects in the software engineering and usability engineering literature. We conducted a systematic literature review of usability defect reporting drawing from both the usability and software engineering literature from January 2000 until March 2016. As a result, a total of 57 studies were identified, in which we classified the studies into three categories: reporting usability defect information, analysing usability defect data and key challenges. Out of these, 20 were software engineering studies and 37 were usability studies. The results of this systematic literature review show that usability defect reporting processes suffer from a number of limitations, including: mixed data, inconsistency of terms and values of usability defect data, and insufficient attributes to classify usability defects. We make a number of recommendations to improve usability defect reporting and management in software engineering.}
}

@article{rayyan-727967791,
  title={Towards a set of factors to identify the success in scrum project delivery: A systematic literature review},
  year={2019},
  pages={97-106},
  author={Tona, Claudia and Juárez-Ramírez, Reyes and Jiménez, Samantha and Durán, Mayra and Guerra-García, César},
  keywords={systematic literature review, Scrum, component, software development, Scrum management, Sprint, Sprint management, success},
  abstract={Agile-based software development is increasingly being adopted by software professionals, as it guarantees the early development of high-quality software and software products. One of the most popular agile methods is Scrum, which is a methodology that involves an iterative, incremental and empirical process. In addition, it is designed to add value, focus, clarity, and transparency to the activities and products of a project. Agile methods have been criticized and defended, and research has shown that accommodating change can be a factor in both success and failure. Although Scrum is a light and easy to understand process, its adoption is sometimes difficult. To gather a set of factors to identify success during a Sprint implementation, a systematic review of the literature is carried out in which we find several factors that help to achieve the success of a Sprint; these are classified into four groups: personnel, project, product, and organization. The results represent a basis for companies seeking to improve the implementation of Scrum.}
}

@article{rayyan-727967792,
  title={Software architecture degradation in open source software: A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={173681-173709},
  author={Baabad, Ahmed and Zulzalil, Hazura Binti and Hassan, Sa'adah and Baharom, Salmi Binti},
  keywords={systematic literature review, Systematics, Bibliographies, Software architecture, Open source software, OSS, Computer architecture, architectural degradation, architectural erosion, Degradation, open-source, Software},
  abstract={Software architecture (SA) has a prominent role in all stages of system development. Given the persistent evolution of software systems over time, SA tends to be eroded or degraded. Such phenomenon is called architectural degradation. In light of this phenomenon, the current study focuses on problems of architectural erosion in the open-source software (OSS). There has been a significant research activity on the OSS over the last decade. Nonetheless, the architectural degradation problems in the OSS are still scattered and disorganized. In addition, there has been no systematic attempt made on existing studies to provide evidence, insight and better understanding for researchers and practitioners. The main objective of the present study is to provide a profound understanding and to review the existing studies on the architectural erosion of the OSS. In this study, we conduct a systematic literature review (SLR) to gather, organize, classify, and analyze the architectural degradation of previous papers published until the year 2020. The data for this study were collected from eight major online databases (ACM, Springer, ScienceDirect, Taylor, IEEE Explorer, Scopus, Web of Science, and Wiley). A total of 74 primary studies were identified as the final samples of this research. The results indicated that rapid software evolution, frequent changes, and the lack of developers' awareness are the most common causes occurred in architecture degradation. Meanwhile, the prominent key indicators of architectural erosion symptoms are code smells and architectural smells. Additionally, the results indicated the most commonly used of the proposed solution for addressing architectural erosion is the metrics-based strategy. Acknowledging the limitations of the current study, more studies are needed that focus on determining other causes that are still ambiguous and improving the other solutions to provide better results in the precision and effectiveness of addressing architectural erosion.}
}

@article{rayyan-727967793,
  title={Information dashboards and tailoring capabilities - a systematic literature review},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={109673-109688},
  author={Vázquez-Ingelmo, Andrea and Garcia-Peñalvo, Francísco J and Therón, Roberto},
  keywords={Artificial intelligence, systematic literature review, Systematics, Visualization, SLR, Bibliographies, Tools, User experience, Planning, adaptive, custom, information dashboards, personalized, tailoring},
  abstract={The design and development of information dashboards are not trivial. Several factors must be accounted; from the data to be displayed to the audience that will use the dashboard. However, the increase in popularity of these tools has extended their use in several and very different contexts among very different user profiles. This popularization has increased the necessity of building tailored displays focused on specific requirements, goals, user roles, situations, domains, etc. Requirements are more sophisticated and varying; thus, dashboards need to match them to enhance knowledge generation and support more complex decision-making processes. This sophistication has led to the proposal of new approaches to address personal requirements and foster individualization regarding dashboards without involving high quantities of resources and long development processes. The goal of this work is to present a systematic review of the literature to analyze and classify the existing dashboard solutions that support tailoring capabilities and the methodologies used to achieve them. The methodology follows the guidelines proposed by Kitchenham and other authors in the field of software engineering. As results, 23 papers about tailored dashboards were retrieved. Three main approaches were identified regarding tailored solutions: customization, personalization, and adaptation. However, there is a wide variety of employed paradigms and features to develop tailored dashboards. The present systematic literature review analyzes challenges and issues regarding the existing solutions. It also identifies new research paths to enhance tailoring capabilities and thus, to improve user experience and insight delivery when it comes to visual analysis.}
}

@article{rayyan-727967794,
  title={A systematic literature review and quality analysis of javascript malware detection},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={190539-190552},
  author={Sohan, Md. Fahimuzzman and Basalamah, Anas},
  keywords={systematic literature review, Systematics, Bibliographies, Data mining, Quality assessment, Databases, Cybersecurity, javascript attacks, javascript malware detection, malicious code detection, Malware},
  abstract={Context: JavaScript (JS) is an often-used programming language by millions of web pages and is also affected by thousands of malicious attacks. Objective: In this investigation, we provided a general view and a quick understanding of JavaScript Malware Detection (JSMD) research reported in the scientific literature from several perspectives. Method: We performed a Systematic Literature Review (SLR) and quality analysis of published research articles on the topic. We investigated 32 articles published between the year 2009 to the year 2019. Results: Selected 32 papers explained in this article reflect the outline of what was published so far. One of our key findings is the performance of Machine Learning (ML) based detection models were relatively higher than others. We also found that only a few papers were able to achieve high scores according to the quality assessment criteria. Conclusion: In this SLR, we summarized and synthesized the existing JSMD studies to identify the previous research practices and also to shed light on future guidelines in the malware detection space. This study will guide and help future researchers to investigate the previous literature efficiently and effectively.}
}

@article{rayyan-727967796,
  title={An investigation into software product innovation: A systematic literature review},
  year={2016},
  pages={1-9},
  author={Edison, Henry and Duc, Anh Nguyen and Jabangwe, Ronald and Wang, Xiaofeng and Abrahamsson, Pekka},
  keywords={Software, systematic literature review, Software engineering, Systematics, Bibliographies, Data mining, Databases, empirical evidence, software product innovation, Technological innovation},
  abstract={New products enable firms not only to accrue high profits but also to leapfrog competition. Different key activities and processes have been proposed to increase the likelihood of successful product innovation. Software products have different characteristics, which need different treatment than products in other domains. Current research on software innovation is still scattered among different areas. This study accumulates the current knowledge and empirical evidences of software product innovation using a systematic literature review approach, and builds the path for future research in this area. Among others, our findings highlight research gaps, as well as best practices and determinants for software product innovation from the reviewed empirical studies.}
}

@article{rayyan-727967797,
  title={Knowledge mapping system implementation in knowledge management: A systematic literature review},
  year={2018},
  pages={131-136},
  author={Hakim, Shidiq Al and Sensuse, Dana Indra},
  keywords={systematic literature review, Systematics, Bibliographies, Search problems, Knowledge management, Databases, Conferences, Protocols, knowledge map system, knowledge mapping, knowledge mapping system},
  abstract={Knowledge mapping has been studied widely in knowledge management context, but the terminology of knowledge map system (KMSs) is not been much studied and it needs to identify state the art KMSs topic from a literature review to propose the future research. The method refers to the systematic literature review as guidelines from Kitchenham, this research gathers, synthesizes, and analyses some paper based on keyword “knowledge map system” or “knowledge mapping system” and “knowledge management”, where it published from 2008 until 2017 on four international electronic databases and using predefined review protocol. We obtained 9 articles used in this study and find that most design systems use customized with some computational technics. The scope is still a lot of focus on enterprise and virtual community, accordingly it needs to be developed further system for the country as public services and also validation method that combines elements of content and software.}
}

@article{rayyan-727967799,
  title={Ludic practices to support the development of software engineering educational games: A systematic review},
  year={2018},
  pages={794-802},
  author={Zambon, Cláudia and Thiry, Marcello},
  keywords={Software, Software Engineering, Software engineering, Systematics, Information services, Games, catalog, Earth, educational games, Electronic publishing, learning objectives, play activity},
  abstract={In this paper we presente a systematic review of the literature with the objective of identifying playful practices used in educational games. From this result, began the construction of a catalog of playful practices to support the development of educational games. Our research is focused initially on the area of Software Engineering. However, the structure of the systematic review and the catalog under development can be extended to other areas. With a traceable structure among the key elements of the catalog (play practices, levels of knowledge and contents), we try to present a practical reference material for developers of educational games or even for teachers who want to apply recreational activities in the classroom. The catalog under construction is available on a wiki in order to enable it to grow collaboratively. In addition to the results of the systematic review, this article also presents an initial version of the catalog of playful practices.}
}

@article{rayyan-727967800,
  title={Quality metrics in software design: A systematic review},
  year={2019},
  pages={80-86},
  author={Hernandez-Gonzalez, Esmeralda Yamileth and Sanchez-Garcia, Angel Juan and Cortes-Verdin, Maria Karen and Perez-Arriaga, Juan Carlos},
  keywords={Systematic Literature Review, Metrics, software quality, object-oriented software design, Metronidazole, Software Design, Software},
  abstract={This paper presents the results of a systematic literature review, which aimed to identify metrics for the quality of software that are applied in the design stage. Fifteen papers from different electronic databases were selected to answer three questions. The analysis allowed us to provide an overview of the metrics used to design artifacts. These metrics will serve as the basis for generating models based on artificial intelligence techniques (Neuronal Networks, Regression, or some other), that help to estimate quality in the early stages of the software development process. It is concluded that most of the design metrics are object oriented. In addition, the design metrics are applied to class diagrams, package diagrams and sequence diagrams.}
}

@article{rayyan-727967802,
  title={Preparing students and engineers for global software development: A systematic review},
  year={2010},
  pages={177-186},
  author={Monasor, Miguel J and Vizcaíno, Aurora and Piattini, Mario and Caballero, Ismael},
  keywords={Software, systematic literature review, Programming, global software development, education, Proposals, Companies, Book reviews, distributed software development, learning, teaching, training, Training},
  abstract={In recent years, the evolution of Global Software Development (GSD) has grown both rapidly and significantly, and although the efficiency of this new type of development has been proven, some challenging issues must still be confronted. Of all these, our research line is focused on designing the specific training that members of virtual teams must receive. Universities and companies therefore need to design training schemas to deal with the specifics of GSD, which are principally related to communication difficulties and time and cultural differences. In this work we present the findings of a Systematic Literature Review in the field of GSD training and teaching. Our intention is twofold: on the one hand we wish to discover the existing strategies and proposals available up to the present day, and on the other hand we wish to identify the open challenges, that will be helpful for practitioners and researchers in the future.}
}

@article{rayyan-727967803,
  title={Software process improvement: A systematic literature review},
  year={2012},
  pages={459-464},
  author={Zil-e-Huma and Bano, Muneera and Ikram, Naveed},
  keywords={Systematic Literature Review, Empirical, Software Process Improvement, Software},
  abstract={CONTEXT - Software Process Improvement (SPI) initiatives create new and improve existing processes to increase productivity, customer satisfaction, quality of product while reducing cost, and time to market thus maximizing Return on investments. OBJECTIVE - The main focus of this paper is to know about the state of art in SPI and to find out the strength of evidence in empirical work reported within SPI literature. METHOD - Methodology of systematic literature review (SLR) is used. A protocol has been developed and executed. Search strings developed and mentioned in the protocol were applied to the databases to extract relevant papers. A set of papers were identified after reading abstracts of papers extracted after application of search string. A quality criterion was applied on this set to finally select the studies for data extraction. Currently, we are at the data extraction phase of SLR. EXPECTED OUTCOME - The anticipated outcome of this systematic review will be state of art in SPI including widely used tools, models, and techniques; reasons to initiate SPI; SPI challenges/Issues widely reported; the SPI areas which are under more consideration; the SPI areas that lack of attention; frequencies of empirical studies in each of the SPI sub-areas.}
}

@article{rayyan-727967805,
  title={Comparison of software process models. A systematic literature review},
  year={2015},
  pages={1-6},
  author={Cano, Christian and Melgar, Andrés and Dávila, Abraham and Pessoa, Marcelo},
  keywords={Software, Systematics, Systematic Literature Review, Comparison, Analytical models, ISO Standards, Computational modeling, IEC Standards, Software Process Model},
  abstract={Nowadays, there are several software process models, which fulfill different purposes, approaches and requirements. However, this proliferation causes some confusion in the industry about the benefits or advantages of each proposal. In this context, studies have been conducted to determine the existing equivalence or the extent of coverage between these models having used different approaches to the comparisons. This work aims to present a study of techniques and experiences on comparison of software process models. For this study, a systematic literature review was conducted in relevant databases and available documents finding that there are few works or experiences in this area and it represents an aspect in software engineering the requires a higher level of research and development. Five different methods to compare process models were found and it was identified that the CCT - Comparison Composition Tree method is the unique that have a graphic representation.}
}

@article{rayyan-727967807,
  title={Empirical studies of pair programming for CS/SE teaching in higher education: A systematic literature review},
  year={2011},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={37},
  number={4},
  pages={509-525},
  author={Salleh, Norsaremah and Mendes, Emilia and Grundy, John},
  keywords={Testing, Software design, Empirical studies, Education, systematic review., Computer science, Collaborative work, pair programming, Algorithm design and analysis, Educational programs, Performance evaluation, Programming profession, Time measurement},
  abstract={The objective of this paper is to present the current evidence relative to the effectiveness of pair programming (PP) as a pedagogical tool in higher education CS/SE courses. We performed a systematic literature review (SLR) of empirical studies that investigated factors affecting the effectiveness of PP for CS/SE students and studies that measured the effectiveness of PP for CS/SE students. Seventy-four papers were used in our synthesis of evidence, and 14 compatibility factors that can potentially affect PP's effectiveness as a pedagogical tool were identified. Results showed that students' skill level was the factor that affected PP's effectiveness the most. The most common measure used to gauge PP's effectiveness was time spent on programming. In addition, students' satisfaction when using PP was overall higher than when working solo. Our meta-analyses showed that PP was effective in improving students' grades on assignments. Finally, in the studies that used quality as a measure of effectiveness, the number of test cases succeeded, academic performance, and expert opinion were the quality measures mostly applied. The results of this SLR show two clear gaps in this research field: 1) a lack of studies focusing on pair compatibility factors aimed at making PP an effective pedagogical tool and 2) a lack of studies investigating PP for software design/modeling tasks in conjunction with programming tasks.}
}

@article{rayyan-727967808,
  title={Systematic review of success factors for scaling agile methods in global software development environment: A client-vendor perspective},
  year={2017},
  pages={17-24},
  author={Shameem, Mohammad and Kumar, Chiranjeev and Chandra, Bibhas and Khan, Arif Ali},
  keywords={Software, systematic literature review, Software engineering, Systematics, Data mining, Quality assessment, Global software development, Organizations, Standards organizations, distributed agile process},
  abstract={Presently, global software development(GSD) is gaining a much attention from the softwaredevelopment organizations. In GSD, the agile developmentbecomes more challenging due to the geographically,socio-cultural and temporal boundaries.Several frameworks have been developed to managethe agile development programs in large scale softwaredevelopment organizations e.g. scaled agile framework(SAFe), large-scale scrum (LeSS) and disciplined agiledelivery (DAD). However, these frameworks arelacking to provide the detail information about theagile development programs in GSD environment. Inthis study, the mentioned research gap has been triedto fill by conducting a systematic literature review(SLR) study to identify the key factors that couldpositively impact the agile development activities inGSD environment. Using SLR approach, a total of 15success factors were identified that could positivelyaffect the agile development in GSD environment.The identified success factors were further categorizedinto two broad categories of client and vendor GSDorganizations. Client-vendor classification was used toprovide a broad picture of agile programs, and theirrespective success factors. Moreover, the identifiedfactors were also mapped into six different categoriesbased on a model of process improvement.}
}

@article{rayyan-727967809,
  title={A systematic literature review of the pain management mobile applications: Toward building a conceptual model},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={131512-131526},
  author={Shah, Umm E Mariya and Chiew, Thiam Kian},
  keywords={systematic literature review, Systematics, Bibliographies, Mobile applications, Databases, Usability, Conceptual model, mobile applications, m-health, pain, Pain, self-management, Pain Management},
  abstract={In healthcare, mobile-based interventions support the improvement of clinical process and result in a positive behavioral change and improve the patients' health condition. This study aims at reviewing mobile applications documented for pain management in the scientific databases, to identify the key factors that are vital for pain management. In this research, a systematic literature review was conducted on the selected studies collected from five scientific databases: Medline, PubMed, EMBASE, Web of Science and Scopus. After applying the inclusion and exclusion criteria and performing the quality assessment, twenty-five studies were finalized. It has been observed that the apps were not all-inclusive in features to provide an effective pain self-management solution. As found from the review, the general features of the pain management mobile applications are pain information, pain coping strategy, social support, sub-goals and achievements, self-reporting, feedback, and patient report. Some apps involved psychological interventions. A prominent technique found was cognitive behavior therapy. This study has contributed to the body of knowledge by proposing a conceptual model in guiding the development of pain management mobile applications. The conceptual model was evaluated by a panel of experts to evaluate comprehensiveness, accuracy, and dependencies among the elements of the model, and the appropriateness of the proposed model. Experts recognized the importance of pain management and provided positive feedback to the proposed model.}
}

@article{rayyan-727967810,
  title={Developers' coordination issues and its impact on software quality: A systematic review},
  year={2017},
  pages={659-663},
  author={Suali, A J and Fauzi, S S M and Sobri, W A W M and Nasir, M.H.N.M.},
  keywords={Software engineering, Knowledge management, Software quality, Organizations, Information technology, Coordination, Software Quality, Systematic Literature Review (STC), Software},
  abstract={Complex projects require involvement from many experts to fulfill the requirements. Complexity arises as working in distributed projects indeed requires expertise to overcome the gaps. Coordination among developers increases the likelihood of delivering high quality software. However, working in isolation impedes coordination and causes issues during development. Coordination issues impact the software quality in software engineering projects. This paper aims to investigate issues relating to coordination and its impact on software quality in software engineering projects. Systematic Literature Review (SLR) is applied to perform this study. Among the coordination issues uncovered are language barriers, intercultural, inefficient communication, lack of trust, lack of project flow understanding, different time zones, dependency issues, strategic issues, knowledge management, geographical distance, awareness, and organizational boundaries. As for the finding of this study, all these obstacles significantly impact software quality.}
}

@article{rayyan-727967811,
  title={Arabic text classification methods: Systematic literature review of primary studies},
  year={2016},
  pages={361-367},
  author={Alabbas, Waleed and Al-Khateeb, Haider M and Mansour, Ali},
  keywords={systematic literature review, Systematics, Bibliographies, data mining, Text categorization, Databases, big data, Analytical models, Data models, Arabic text classification, Text corpus, Arabs},
  abstract={Recent research on Big Data proposed and evaluated a number of advanced techniques to gain meaningful information from the complex and large volume of data available on the World Wide Web. To achieve accurate text analysis, a process is usually initiated with a Text Classification (TC) method. Reviewing the very recent literature in this area shows that most studies are focused on English (and other scripts) while attempts on classifying Arabic texts remain relatively very limited. Hence, we intend to contribute the first Systematic Literature Review (SLR) utilizing a search protocol strictly to summarize key characteristics of the different TC techniques and methods used to classify Arabic text, this work also aims to identify and share a scientific evidence of the gap in current literature to help suggesting areas for further research. Our SLR explicitly investigates empirical evidence as a decision factor to include studies, then conclude which classifier produced more accurate results. Further, our findings identify the lack of standardized corpuses for Arabic text; authors compile their own, and most of the work is focused on Modern Arabic with very little done on Colloquial Arabic despite its wide use in Social Media Networks such as Twitter. In total, 1464 papers were surveyed from which 48 primary studies were included and analyzed.}
}

@article{rayyan-727967812,
  title={An update on effort estimation in agile software development: A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={166768-166800},
  author={Fernández-Diego, Marta and Méndez, Erwin R and González-Ladrón-De-Guevara, Fernando and Abrahão, Silvia and Insfran, Emilio},
  keywords={Software, Systematics, Bibliographies, Effort estimation, Agile software development, Estimation, systematic literature review (SLR), Variable speed drives, Planning, agile methods, agile software development (ASD)},
  abstract={Software developers require effective effort estimation models to facilitate project planning. Although Usman et al. systematically reviewed and synthesized the effort estimation models and practices for Agile Software Development (ASD) in 2014, new evidence may provide new perspectives for researchers and practitioners. This article presents a systematic literature review that updates the Usman et al. study from 2014 to 2020 by analyzing the data extracted from 73 new papers. This analysis allowed us to identify six agile methods: Scrum, Xtreme Programming and four others, in all of which expert-based estimation methods continue to play an important role. This is particularly the case of Planning Poker, which is very closely related to the most frequently used size metric (story points) and the way in which software requirements are specified in ASD. There is also a remarkable trend toward studying techniques based on the intensive use of data. In this respect, although most of the data originate from single-company datasets, there is a significant increase in the use of cross-company data. With regard to cost factors, we applied the thematic analysis method. The use of team and project factors appears to be more frequent than the consideration of more technical factors, in accordance with agile principles. Finally, although accuracy is still a challenge, we identified that improvements have been made. On the one hand, an increasing number of papers showed acceptable accuracy values, although many continued to report inadequate results. On the other, almost 29% of the papers that reported the accuracy metric used reflected aspects concerning the validation of the models and 18% reported the effect size when comparing models.}
}

@article{rayyan-727967813,
  title={A systematic literature review to identify human related challenges in globally distributed agile software development: towards a hypothetical model for scaling agile methodologies},
  year={2018},
  pages={1-7},
  author={Shameem, Mohammad and Chandra, Bibhas and Kumar, Rakesh Ranjan and Kumar, Chiranjeev},
  keywords={Software, Systematic literature review, Systematics, Bibliographies, Quality assessment, Databases, Agile development, Global software development, Organizations, Standards organizations, Human related challenges, Scaling, Humanities, Humanism, Humans},
  abstract={Currently, software organizations are implementing agile methodologies in global software development (GSD) because of low development cost, schedule and high quality product. However, GSD project is complex undertaken because of it distributed dimensions especially when the agile methodologies are concerned. The objective of this study is to identify the human related factors that can negatively influence agile practices in GSD organizations, and proposed a hypothetical model of the identified challenges related to the scaling agile methodologies. A Systematic Literature Review (SLR) method was used to identify the challenges. In the findings, a total of eleven challenges were identified using SLR. This study also reported the Critical Challenges (CChs) for scaling agile methodologies using a criterion of the challenges having a frequency ≥ 50 %. Findings reported the six out of eleven challenges as critical challenges in scaling agile methods. Based on the identified challenges, a hypothetical model was presented that is highlighted a relationship between identified challenges and the implementation of agile methodologies in GSD environment.}
}

@article{rayyan-727967815,
  title={Model management tools for models of different domains: A systematic literature review},
  year={2019},
  pages={1-8},
  author={Torres, Weslley and van den Brand, Mark and Serebrenik, Alexander},
  keywords={Systematics, Systematic Literature Review, Bibliographies, Tools, Modeling, Product lifecycle management, Google, Model Management, Model-Based Systems Engineering, Systems Engineering},
  abstract={Objective: The goal of this study is to present an overview of industrial and academic approaches to cross-domain model management. We aim at identifying industrial and academic tools for cross-domain model management and describing the inconsistency types addressed by them as well as strategies the users of the tools employ to keep consistency between models of different domains. Method: We conducted a systematic literature review. Using the keyword-based search on Google Scholar we analyzed 515 potentially relevant studies; after applying inclusion and exclusion criteria 88 papers were selected for further analysis. Results: The main findings/contributions are: (i) a list of available tools used to support model management; (ii) approximately 31% of the tools can provide consistency model checking on models of different domains and approximately 24% on the same domain; (iii) available strategies to keep the consistency between models of different domains are not mature enough; (iv) explicit modeling dependencies between models is not common in the industry. However, it is considered as a requirement by academia if one wishes to manage inconsistency between models of different domains. Conclusion: This study presents an overview of industrial practices and academic approaches about the cross-domain model management. The results presented in this study can be used as a starting point for future research on model management topics, and also for further improvement of actual model management tools.}
}

@article{rayyan-727967816,
  title={Using blockchain to improve collaborative business process management: Systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={142312-142336},
  author={Garcia-Garcia, Julian Alberto and Sánchez-Gómez, Nicolás and Lizcano, David and Escalona, M J and Wojdyński, Tomás},
  keywords={Systematic literature review, Systematics, Collaboration, BPM, Business process management, Computer architecture, Companies, blockchain technology, business process management, collaborative business processes, inter-organizational process management},
  abstract={BlockChain Technology (BCT) has appeared with strength and promises an authentic revolution on business, management, and organizational strategies related to utilization of advanced software systems. In fact, BCT promotes a decentralized architecture to process management and the collaborative work between entities when these ones are working together in a business process. This paper aims to know what proposals exist to improve any stage of business process management using BCT because this technology could provide benefits in this management. For this purpose, this paper presents a systematic literature review in area of Collaborative Business Processes (CBP) in BCT domain to identify opportunities and gaps for further research. This paper concludes there is a rapid and growing interest of public bodies, scientific community and software industries to know opportunities that BCT offers to improve CBP management in a decentralized manner. However, although the topic is in early stages, there are very promising lines of research and relevant open issues, but there also is lack of scientific rigor in validation process into the different studies.}
}

@article{rayyan-727967817,
  title={A systematic literature review of machine learning applications for port's operations},
  year={2020},
  pages={1-5},
  author={Mekkaoui, Sara E and Benabbou, Loubna and Berrado, Abdelaziz},
  keywords={machine learning, systematic literature review, Data mining, Machine learning, Optimization, analytics, Libraries, Planning, Biological system modeling, ports, shipping, Transportation, Learning},
  abstract={In transportation systems, there is a need of Machine Learning (ML) to create intelligent solutions for many issues. In port's studies, there has been a long focus on optimization and simulation modeling, but still, ML served in building more complex decision support systems for better management of port operations. To evaluate the contributions in the application of ML for port operations, we conducted this Systematic Literature Review (SLR) in order to select and characterize the most relevant papers. This paper, reports the applied research protocol and its results, and highlights the gaps that could be addressed in future works.}
}

@article{rayyan-727967818,
  title={Reference architectures for self-managed software systems: A systematic literature review},
  year={2014},
  pages={21-31},
  author={Affonso, Frank J and Scannavino, Katia R F and Oliveira, Lucas B R and Nakagawa, Elisa Y},
  keywords={Systematic literature review, Software architecture, Databases, Reference architecture, Software systems, Computer architecture, Computational modeling, Self-managed software systems, Software},
  abstract={Self-Managed Software Systems (SMSS) have emerged as an important type of software systems. However, the development of such systems is not a trivial task, as they constantly deal with adaptations at runtime so as to fulfill new needs of both users and execution environment. From another perspective, Reference Architectures (RAs) have been used for the aggregation of knowledge on specific domains, promoting the reuse of design expertise and facilitating the development, standardization, and evolution of software systems. Considering the relevance of such architectures, RAs for SMSS (RA4SMSS) have also been proposed. On the other hand, to the best of our knowledge, no study on a panorama or comparison on RA4SMSS has been published. This paper reports the results of a systematic literature review on RA4SMSS. They show that although relevant initiatives have been found, the SMSS area needs a broader contribution to boost the development of such systems. Moreover, research lines that must further investigated were also identified.}
}

@article{rayyan-727967819,
  title={Research on proposals and trends in the architectures of semantic search engines: A systematic literature review},
  year={2017},
  pages={271-280},
  author={Morales, Jorge and Melgar, Andrés},
  keywords={systematic literature review, Systematics, Bibliographies, Quality assessment, Semantic web, Computer architecture, Protocols, software architecture, Engines, knowledge, knowledge representation, ontologies, semantic search engines, Research Design, Semantics},
  abstract={Semantic web technologies have gained some spot-light in recent years, mostly explained by the spread of mobile devices and broadband Internet access. As once envisioned by Tim Berners-Lee, semantic web technologies have fostered the development of standards that enable, in turn, the emergence of semantic search engines that give users the information they are looking for. This paper presents the results of a systematic literature review that focuses on understanding the proposals on the semantic search engines from an architectural point of view. From the results it is possible to say that most of the studies propose an integral solution for their users where their requirements, the context and the modules that comprise the search engine have a great role to play. Ontologies and knowledge also play an important role in these architectures as they evolve, enabling a great myriad of solutions that respond in a better way to the users' expectations.}
}

@article{rayyan-727967822,
  title={Global software development and capability maturity model integration: A systematic literature review},
  year={2018},
  pages={1-6},
  author={Hidayati, Anita and Purwandari, Betty and Budiardjo, Eko K and Solichah, Iis},
  keywords={Software, Outsourcing, Systematic Literature Review (SLR), Companies, Standards organizations, software process improvement, Capability maturity model, Capability Maturity Model Integration (CMMI), Global Software Development (GSD), Process Area (PA)},
  abstract={Global Software Development (GSD) offers many benefits. On the other hand, it also has several challenges such as its impact on software quality. The implementation of software processes improvement, such as the Capability Maturity Model Integration (CMMI), can improve quality of software products. However, CMMI as a process improvement model has been rarely discussed in GSD context. To fill this gap a systematic literature study was conducted by using Kitchenham's method. It investigated GSD research from several databases between 2013-2018. At the end there are 12 selected papers. The findings indicate that CMMI is essential for the success of GSD projects. However, it requires multiple customizations and combinations with other standards. Concept Process Areas (PAs) and maturity level from CMMI are used in new standards Software Process Improvement (SPI) with different approaches. The results of this study are potential as a reference to develop customized CMMI to increase success rate in GSD projects.}
}

@article{rayyan-727967823,
  title={A systematic literature review in multi-agent systems: Patterns and trends},
  year={2019},
  pages={1-10},
  author={Falco, Mariana and Robiolo, Gabriela},
  keywords={systematic literature review, Systematics, Bibliographies, Guidelines, Multi-agent systems, Analytical models, Market research, AOSE, Integrated circuit modeling, multi-agent systems},
  abstract={Multi-Agent Systems became a powerful solution to model and solve problems in complex and dynamic environments. While research in this area grew exponentially before 2009, there is a need to understand the status quo of the field from 2009 to June 2017 in order to comprehend the general evolution. The results of a SLR related to Multi-Agent Systems, its applications and research gaps, following Kitchenham and Wholin guidelines are presented in this paper. From the analysis of279 papers (out of3522 candidates), our findings suggest that: a) there is a general decreasing trend of publications (but it is increasing for specific domains), b) only 15% of the papers portrayed a real case study, c) the top 20 were formed by 67 authors, d) the papers were mostly published in journals and conferences, e) there is no unified methodology or framework, f) the top 3 application domains were transport/traffic, healthcare/biology, and logistics/manufacturing, g) MAS interact with different disciplines like machine learning. Finally, the MAS community should work together to close the gaps and unify the field, bridging with other disciplines and industry.}
}

@article{rayyan-727967824,
  title={On the security aspects of Internet of Things: A systematic literature review},
  year={2019},
  journal={Journal of Communications and Networks},
  issn={1976-5541},
  volume={21},
  number={5},
  pages={444-457},
  author={Macedo, Evandro L C and de Oliveira, Egberto A R and Silva, Fabio H and Mello, Rui R and França, Felipe M G and Delicato, Flavia C and de Rezende, José F and de Moraes, Luís F M},
  keywords={trust, Internet of Things, IoT, techniques, Protocols, security, Market research, Access control, architecture, authentication, Authentication, data protection, Data protection, internet of things, Internet},
  abstract={Internet of Things (IoT) has gained increasing visibility among emerging technologies and undoubtedly changing our daily life. Its adoption is strengthened by the growth of connected devices (things) as shown in recent statistics. However, as the number of connected things grows, responsibility related to security aspects also needs to increase. For instance, cyberattacks might happen if simple authentication mechanisms are not implemented on IoT applications, or if access control mechanisms are weakly defined. Considering the relevance of the subject, we performed a systematic literature review (SLR) to identify and synthesize security issues in IoT discussed in scientific papers published within a period of 8 years. Our literature review focused on four main security aspects, namely authentication, access control, data protection, and trust. We believe that a study considering these topics has the potential to reveal important opportunities and trends related to IoT security. In particular, we aim to identify open issues and technological trends that might guide future studies in this field, thus providing useful material both to researchers and to managers and developers of IoT systems. In this paper, we describe the protocol adopted to perform the SLR and present the state-of-the-art on the field by describing the main techniques reported in the retrieved studies. To the best of our knowledge, ours is the first study to compile information on a comprehensive set of security aspects in IoT. Moreover, we discuss the placement, in terms of architectural tiers, for deploying security techniques, in an attempt to provide guidelines to help design decisions of security solution developers. We summarize our results showing security trends and research gaps that can be explored in future studies.}
}

@article{rayyan-727967825,
  title={Using a systematic literature review to strengthen the evidence supporting a simulation model of distributed software projects},
  year={2019},
  pages={371-378},
  author={Lima, Adailton M and Quites Reis, Rodrigo and de Souza, Cleidson R B},
  keywords={Software engineering, Distributed Software Development, Literature Review, In Silico Studies, Process Simulation, Software},
  abstract={In silico studies allow the use of computer models to simulate the environment, object, and subject behavior of an experiment. They are valuable tools to support the quantitative analysis of the behavior of different types of projects because they allow the use of different techniques such as stochastic and analytical methods to evaluate the impact of project decisions without the real execution costs. Recently, in silico studies have been used to study distributed software development projects. In this paper, we present a simulation model defined by a set of variables that describe the dynamics of Distributed Software Development (DSD) projects. The assessment of our simulation model is based on a Systematic Literature Review (SLR) where we seek evidence, from primary studies published until October 2018, that the variables and relationships in our model do exist in actual DSD projects. We use a SLR as a validation mechanism. Our results are twofold. First, there is a gap of studies on some variables including knowledge expertise and task allocation strategy in distributed software development projects. And, second, there still is a lack of data to support results related to productivity, especially testing activities, on DSD projects. Despite the problem of lack of common terminology for reporting the results on DSD studies, we argue that we need more studies to be able to clearly infer the dynamics of the relationship between variables on distributed software development. Our study brings one step closer to fulfill this gap.}
}

@article{rayyan-727967826,
  title={Parallelization, modeling, and performance prediction in the multi-/many core area: A systematic literature review},
  year={2017},
  pages={48-55},
  author={Frank, Markus and Hilbrich, Marcus and Lehrig, Sebastian and Becker, Steffen},
  keywords={Software, Unified modeling language, Computational modeling, Predictive models, Hardware, Multicore processing, Parallel programming, Software Performance Engineering Performance Prediction Modelling Multicore Many Core Parallel Programming},
  abstract={Context: Software developers face complex, connected, and large software projects. The development of such systems involves design decisions that directly impact the quality of the software. For an early decision making, software developers can use model-based prediction approaches for (non-)functional quality properties. Unfortunately, the accuracy of these approaches is challenged by newly introduced hardware features like multiple cores within a single CPU (multicores) and their dependence on shared memory and other shared resources. Objectives: Our goal is to understand whether and how existing model-based performance prediction approaches face this challenge. We plan to use gained insights as foundation for enriching existing prediction approaches with capabilities to predict systems running on multicores. Methods: We perform a Systematic Literature Review (SLR) to identify current model-based prediction approaches in the context of multicores. Results: Our SLR covers the software engineering, embedded systems, High Performance Computing, and Software Performance Engineering domains for which we examined 34 sources in detail. We found various performance prediction approaches which tries to increase prediction accuracy for multicore systems by including shared memory designs to the prediction models. Conclusion: However, our results show that the memory designs models are only in an initial phase. Further research has to be done to improve cache, memory, and memory bandwidth model as well as to include auto tuner support.}
}

@article{rayyan-727967827,
  title={Cloud computing security requirements: A systematic review},
  year={2012},
  pages={1-7},
  author={Iankoulova, Iliana and Daneva, Maya},
  keywords={systematic literature review, Cloud computing, Data privacy, Privacy, cloud computing, empirical study, Access control, Fires, sequirity requirements engineering, Software-as-a-Service},
  abstract={Many publications have dealt with various types of security requirements in cloud computing but not all types have been explored in sufficient depth. It is also hard to understand which types of requirements have been under-researched and which are most investigated. This paper's goal is to provide a comprehensive and structured overview of cloud computing security requirements and solutions. We carried out a systematic review and identified security requirements from previous publications that we classified in nine sub-areas: Access Control, Attack/Harm Detection, Non-repudiation, Integrity, Security Auditing, Physical Protection, Privacy, Recovery, and Prosecution. We found that (i) the least researched sub-areas are non-repudiation, physical protection, recovery and prosecution, and that (ii) access control, integrity and auditability are the most researched sub-areas.}
}

@article{rayyan-727967829,
  title={A systematic review on the use of ontologies in requirements engineering},
  year={2014},
  pages={1-10},
  author={Dermeval, Diego and Vilela, Jéssyka and Bittencourt, Ig Ibert and Castro, Jaelson and Isotani, Seiji and Brito, Patrick},
  keywords={Software, Software engineering, Systematics, Data mining, Quality assessment, Ontologies, Industries},
  abstract={Requirements Engineering (RE) discipline deals with elicitation, analysis, specification, validation and management of requirements. Several ontology-driven approaches have been proposed to improve these RE activities. However, the requirements engineering community still lacks a comprehensive understanding on how ontologies are used in RE process. The objective of this work is to explore how ontologies are employed in requirements engineering, aiming to identify the main phases addressed, the languages that have been used, the types of existing contributions, as well as the requirements modeling styles have been used and the benefits of using ontology in RE. We conducted a systematic literature review to identify the primary studies on the use of ontologies in RE, following a pre-defined review protocol. Sixty-six papers were selected, covering the five main RE process phases. Moreover, we have identified thirteen ontology-related languages. Furthermore, twenty-six empirical studies have been identified which provided evidence of five group of benefits. The main findings of this review are: (1) there are empirical evidences to state that ontologies benefit RE activities in both academy and industry settings, helping to reduce ambiguity, inconsistency and incompleteness of requirements; (2) the vast majority of papers do not meet all RE phases; (3) nearly half of the papers use W3C recommended languages; (4) the majority of contributions are supported by a tool; and (5) there is a great diversity of requirements modeling styles supported by ontologies.}
}

@article{rayyan-727967830,
  title={Cultural factors influencing international collaborative software engineering education in china},
  year={2017},
  pages={31-40},
  author={Wang, Yuqing and Markkula, Jouni and Jiang, Jing},
  keywords={Software, Systematics, Collaboration, Guidelines, Education, Interviews, software engineering education, Cultural differences, Chinese culture, cross-cultural education, international collaborative education},
  abstract={Software engineering (SE) is a rapidly developing international discipline that requires up-to-date knowledge and skills. The need for well-educated professional software engineers is increasing globally. In China, universities are opening opportunities for collaboration and building cooperative relationships with Western universities in technology fields, including SE, to offer Chinese students possibilities for international education in China instead of studying abroad. Designing high-quality SE education in international collaborative programs faces challenges introduced by cultural factors that affect learning practices. In this study, we addressed these challenges in the context of international collaborative SE education in China. In the first step, we synthesized existing knowledge of Chinese cultural factors affecting learning by conducting a systematic literature review (SLR). In the second step, we conducted interviews with SE students and teachers in a Chinese university that is preparing an international collaborative SE program, in order to see whether the identified cultural factors are valid in the current learning contexts of SE education. The results revealed that many of the identified factors are still valid, but some of them present differently in the current context because of the novelty of the SE discipline and the changing educational environment in China.}
}

@article{rayyan-727967831,
  title={Agile to lean software development transformation: A systematic literature review},
  year={2018},
  pages={969-973},
  author={Kišš, Filip and Rossi, Bruno},
  keywords={Software, Systematics, Bibliographies, Measurement, Quality assessment, Companies},
  abstract={Context: Lean development has been often proposed as an adaptation to agile for scaling-up to larger contexts. Goals: we wanted to better understand the “agile-to-lean” transformation, in terms of: i) reported benefits, ii) challenges faced, iii) metrics used. Method: we performed a Systematic Literature Review (SLR) about “agile-to-lean” transformations. Results: reduced lead time, improved flow, continuous improvement, and improved defect fix rate were the main reported benefits. Adaptation to lean thinking, teaching the lean mindset, identification of the concept of waste, and scaling flexibility were the main challenges. Lead time was the most reported metric.}
}

@article{rayyan-727967832,
  title={The dynamic aspects of product derivation in DSPL: A systematic literature review},
  year={2013},
  pages={466-473},
  author={da Silva, Jackson Raniel F and da Silva, Francisco Airton P and do Nascimento, Leandro M and Martins, Dhiego A O and Garcia, Vinicius C},
  keywords={Software, Quality assessment, Context, Computer architecture, Adaptation models, Heuristic algorithms, Runtime},
  abstract={Dynamic Software Product Lines (DSPL) have gained significant attention in academic community by involving aspects of product lines and runtime adaptable systems development. Managing dynamic variations demands is a challenge addressed by DSPL paradigm. In this context, this paper introduces the results of a systematic literature review that involved 2,084 studies, with the objective of understanding how the dynamic derivation in DSPL is made. The contributions of this study are: a) an embracing analysis and classification of scientific literature in DSPL area, b) the definition of inputs that are needed to perform the dynamic derivation, c) the description of what composes these inputs, and d) the understanding of the process to perform the dynamic derivation. We conclude that due to the lack of maturity in the dynamic derivation field, there are many open research opportunities still available.}
}

@article{rayyan-727967833,
  title={Blockchain technology and implementation : A systematic literature review},
  year={2018},
  pages={370-374},
  author={Andrian, Henry Rossi and Kurniawan, Novianto Budi and Suhardi},
  keywords={SLR, Blockchain, Smart contracts, Cryptography, Digital forensics, Distributed databases, Peer-to-peer computing, technology},
  abstract={As research on blockchain continues to grow, blockchain technology was adopted to develop several information systems. There are many opportunities to examine the utilization of blockchain technology to be used in developing systems as needed. This paper summarizes the conditions of blockchain research in terms of technology and its implementation. This paper was written using a systematic literature review (SLR) as one of the methodologies used to solve problems by tracing the results of previous studies. The problem that you want to study in SLR is usually referred to as a research question (RQ). The defined RQ is related to the topic and clarifies each question by tracing previous research papers indexed in reputable journal databases such as IEEE Xplore, Springerlink, Scopus, and ScienceDirect. After synthesizing 41 articles, the result is: blockchain can be used in many applications, some applications that adopt blockchain technology are banking applications, e-voting applications and digital forensic applications. Often, applications that use blockchain technology only focus on developing one of the blockchain technologies that suits their needs. Some developers maximize the components of the contract on the blockchain, some further develop the data structure of the blockchain itself. The use of blockchain technology is still wide open for the implementation of other information systems. The expected contribution of this paper is to provide a general overview for researchers who want to build applications that use blockchain as a basis for researching so they can conduct further studies to better understand whether the applications they will develop are suitable for using blockchain technology as a basis.}
}

@article{rayyan-727967834,
  title={Process mining for cloud-based applications: A systematic literature review},
  year={2019},
  pages={34-43},
  author={El-Gharib, Najah Mary and Amyot, Daniel},
  keywords={Data mining, Cloud computing, Monitoring, Process mining, Web services, Big Data, Requirements elicitation, Computational modeling, Heuristic algorithms, Cloud applications, User behavior},
  abstract={Process mining uses event log data to discover processes, hence enabling multiple requirements elicitation activities. As the number of applications deployed on a cloud infrastructure is increasing, it becomes important to understand their processes and the ways these existing systems are actually used. However, the cloud brings new challenges to process mining that deserve special attention. This paper reports on a systematic literature review based on a selection of 27 papers. The aim is to assess the applicability of process mining techniques to cloud-based applications, to document the processes of these existing systems. We observe there is a growing interest in applying process mining to these areas, and we report on algorithms, tools, and validation approaches taken. We also report on many cloud-specific challenges for process mining, which require further attention from the research community.}
}

@article{rayyan-727967835,
  title={Business process ambidexterity and its impact on business-it alignment. A systematic literature review},
  year={2019},
  pages={1-12},
  author={Helbin, Tomek and Van Looy, Amy},
  keywords={Systematics, SLR, Bibliographies, Databases, Business process management, Organizations, Process control, Business Process Ambidexterity, Business Process Management, Business-IT alignment, Organizational Ambidexterity, Paradoxical Thinking, Functional Laterality},
  abstract={In the age of digital disruption, organizations face the growing need to both optimize existing processes, and to radically innovate and disrupt them. Business Process Management (BPM) has proven great value for process control and process optimization, however not for process disruption. Our Systematic Literature Review of Business Process Ambidexterity provides an overview of this nascent domain. In our research, we have divided all articles into two main strands of research, focusing on: (1) organizational capabilities enabling Business Process Ambidexterity, and (2) the actual dynamic balance between exploration and exploitation in BPM, which is enabled by the modelling and optimization stages in the business process lifecycle. As there is no widely accepted definition of Business Process Ambidexterity, we propose one for future use, based on the concept of paradoxical thinking. Business Process Ambidexterity may both enable, and be facilitated by digitalization; however, there is limited evidence that Business Process Ambidexterity enables Business-IT alignment. The main research gap is the lack of conceptual and practical guidelines on Business Process Ambidexterity implementation. Hence, this article encourages future research and provides preliminary guidance for practitioners.}
}

@article{rayyan-727967836,
  title={Computer-supported collaborative learning in programming education: A systematic literature review},
  year={2020},
  pages={1086-1095},
  author={Silva, Leonardo and Mendes, António José and Gomes, Anabela},
  keywords={computer-supported collaborative learning, introductory programming, programming learning},
  abstract={Social dimension plays a crucial role in the learning process. The use of technological resources to stimulate and mediate the interaction between students is known as Computer-supported collaborative learning (CSCL). Despite being widely used in programming education, the summarization of the academic literature about this topic is scarce. To create that body of knowledge, a systematic literature review was performed. The findings provide an understanding of how collaboration is explored in introductory programming, resources used to stimulate them and challenges in the process. Opportunities for future research are discussed, especially related to motivation, self-efficacy and engagement in CSCL, and the exploitation of learning analytics.}
}

@article{rayyan-727967837,
  title={Systematic literature review of knowledge sharing barriers and facilitators in global software development organizations using concept maps},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={24231-24247},
  author={Anwar, Rayhab and Rehman, Mobashar and Wang, Khor Siak and Hashmani, Manzoor Ahmed},
  keywords={Software, Systematics, Bibliographies, Data mining, Task analysis, Organizations, Industries, cultural barriers, geographical barriers, global software development organizations, Knowledge sharing barriers, knowledge sharing facilitators},
  abstract={Knowledge is the most important resource in software development. The success of software development relies on knowledge sharing between software developers working across the globe. Global software development has brought many benefits to the software industry; however, at the same, time knowledge sharing across diverse team members is one of the main concerns of global software development organizations. This paper provides a systematic literature review of 42 studies on knowledge sharing barriers and facilitators from 2010 to 2017 and classifies them into five main categories: Individual, Organizational, Technological, Cultural, and Geographical. In order to synthesize and represent the complexity of the knowledge sharing factors in a more manageable and visual manner, this paper proposes concept maps for each category. The identified factors can be strategically used as the guidelines in the global software development organizations to boost the culture of knowledge sharing.}
}

@article{rayyan-727967838,
  title={Product roadmap – from vision to reality: A systematic literature review},
  year={2019},
  pages={1-8},
  author={Münch, Jürgen and Trieflinger, Stefan and Lang, Dominic},
  keywords={Systematics, Bibliographies, Organizations, Computer science, Conferences, Technological innovation, agile development, product discovery, product management, product roadmap, product strategy, product vision, roadmapping},
  abstract={Context: Companies in highly dynamic markets increasingly struggle with their ability to plan product development and to create reliable roadmaps. A main reason is the decreasing lack of predictability of markets, technologies, and customer behaviors. New approaches for product roadmapping seem to be necessary in order to cope with today's highly dynamic conditions. Little research is available with respect to such new approaches. Objective: In order to better understand the state of the art and to identify research gaps, this article presents a review of the scientific literature with respect to product roadmapping. Method: We performed a systematic literature review (SLR) with respect to identify papers in the field of computer science. Results: After filtering, the search resulted in a set of 23 relevant papers. The identified papers focus on different aspects such as roadmap types, processes for creating and updating roadmaps, problems and challenges with roadmapping, approaches to visualize roadmaps, generic frameworks and specific aspects such as the combination of roadmaps with business modeling. Overall, the scientific literature covers many important aspects of roadmapping but does provide only little knowledge on how to create product roadmaps under highly dynamic conditions. Research gaps address, for instance, the inclusion of goals or outcomes into product roadmaps, the alignment of a roadmap with a product vision, and the inclusion of product discovery activities in product roadmaps. In addition, the transformation from traditional roadmapping processes to new ways of roadmapping is not sufficiently addressed in the scientific literature.}
}

@article{rayyan-727967839,
  title={Designing engaging games for education: A systematic literature review on game motivators and design principles},
  year={2020},
  journal={IEEE Transactions on Learning Technologies},
  issn={1939-1382},
  volume={13},
  number={4},
  pages={804-821},
  author={Laine, Teemu H and Lindberg, Renny S N},
  keywords={Systematics, Bibliographies, Taxonomy, Education, Business, taxonomy, Games, gamification, educational games, Design principles (DPs), Entertainment industry, game design, motivation, serious games},
  abstract={Effective educational interventions require sufficient learner engagement, which can be difficult to achieve if the learner is inadequately motivated. Games have been shown to possess powerful motivators that fuel a person's desire to engage in unattractive activities, such as learning theoretical material. However, to design an educational game that is capable of providing motivated engagement is a challenging task. Previous research has proposed various game motivators and game design principles to alleviate this, but a comprehensive synthesis has yet to appear. In this article, we conducted a systematic literature review that yielded two major contributions: 1) a taxonomy of 56 game motivators in 14 classes; and 2) a taxonomy of 54 educational game design principles in 13 classes, with linkages to the identified game motivators. As a minor contribution, we have also presented a classification of gamification-related terms and proposed different strategies for applying gamification. The results of this article are available for educational game designers and researchers to use as a practical toolkit for the creation and evaluation of motivating educational games that keep players engaged. Moreover, this article is the first step toward the creation of a unified gamification framework.}
}

@article{rayyan-727967840,
  title={Smart campus features, technologies, and applications: A systematic literature review},
  year={2017},
  pages={384-391},
  author={Muhamad, Wardani and Kurniawan, Novianto Budi and Suhardi and Yazid, Setiadi},
  keywords={SLR, research challenge, smart campus, summary},
  abstract={Research in the smart campus area is still growing, where every researcher defines the concept of smart campus with a less thorough perspective that has not been conical in the same conception of the concept. In this paper, we summarize the existing condition of smart campus development in term of features, supported technologies, and applications were built using systematic literature review (SLR) as the standard methodology used to solve any problems by tracing the results of previous research. The problems declared in SLR are commonly called as research question (RQ). To achieve that goal, we define some RQs related to that scope and clarify each question by tracing previous research papers which are indexed in reputable journal databases such as IEEE Xplore, Scopus, Springerlink, and ScienceDirect. After synthesizing 29 articles, the results are: contactless technology provides an easier way to enter data when accessing a particular room or equipment than using a keyboard; IoT supports an easier way to report real-time environment status; cloud computing is used to organize various information effectively and provide data services; iCampus becomes a popular smart campus model and if we map the applications that have been built into iCampus; there is no applications as part of iHealth domain. The main contribution of smart campus development based on previous research is to make easier in all campus aspect life. The contribution expected through this paper is to provide an overview for researchers who want to build applications in a campus as research challenge so that they can use appropriate technology and meet the characteristics of smart campus.}
}

@article{rayyan-727967841,
  title={Security and privacy for big data: A systematic literature review},
  year={2016},
  pages={3693-3702},
  author={Nelson, Boel and Olovsson, Tomas},
  keywords={Security, Data privacy, Big data, Privacy, Data visualization, Conferences, Distributed databases},
  abstract={Big data is currently a hot research topic, with four million hits on Google scholar in October 2016. One reason for the popularity of big data research is the knowledge that can be extracted from analyzing these large data sets. However, data can contain sensitive information, and data must therefore be sufficiently protected as it is stored and processed. Furthermore, it might also be required to provide meaningful, proven, privacy guarantees if the data can be linked to individuals. To the best of our knowledge, there exists no systematic overview of the overlap between big data and the area of security and privacy. Consequently, this review aims to explore security and privacy research within big data, by outlining and providing structure to what research currently exists. Moreover, we investigate which papers connect security and privacy with big data, and which categories these papers cover. Ultimately, is security and privacy research for big data different from the rest of the research within the security and privacy domain? To answer these questions, we perform a systematic literature review (SLR), where we collect recent papers from top conferences, and categorize them in order to provide an overview of the security and privacy topics present within the context of big data. Within each category we also present a qualitative analysis of papers representative for that specific area. Furthermore, we explore and visualize the relationship between the categories. Thus, the objective of this review is to provide a snapshot of the current state of security and privacy research for big data, and to discover where further research is required.}
}

@article{rayyan-727967842,
  title={Open source software evaluation, selection, and adoption: a systematic literature review},
  year={2020},
  pages={437-444},
  author={Lenarduzzi, Valentina and Taibi, Davide and Tosi, Davide and Lavazza, Luigi and Morasca, Sandro},
  keywords={Software, Systematics, Data mining, Tools, Open source software, Libraries, Analytical models, Open-source software, soft-ware adoption, software quality models, software selection},
  abstract={Background. Open Source Software (OSS) is experiencing an increasing popularity both in industry and in academia. Aim. We investigated models for the selection, evaluation, and adoption of OSS, focusing on factors that affect most the evaluation of OSS. Method. We conducted a Systematic Literature Review of 262 studies published until the end of 2019, to understand whether OSS selection is still an interesting topic for researchers, and which factors are considered by stakeholders and are assessed by the available models. Result. We selected 60 primary studies: 20 surveys and 5 lessons learned studies elicited the motivations for OSS adoption; 35 papers proposed several OSS evaluation models focusing on different technical aspects. This Systematic Literature Review provides an overview of the available OSS evaluation methods, highlighting their limits and strengths, based on the wide range of technicalities and aspects explored by the selected primary studies. Conclusion. OSS producers can benefit from our results by checking if they are providing all the information commonly required by potential adopters. Users can learn how models work and which models cover the relevant characteristics of OSS they are most interested in.}
}

@article{rayyan-727967844,
  title={Analysis of non-functional properties in software product lines: A systematic review},
  year={2014},
  pages={328-335},
  author={Soares, Larissa Rocha and Potena, Pasqualina and Do Carmo Machado, Ivan and Crnkovic, Ivica and de Almeida, Eduardo},
  keywords={Software, Systematic Literature Review, Data mining, Unified modeling language, Reliability, Predictive models, Runtime, Non-functional Properties, Product Derivation, Software Product Lines},
  abstract={Software Product Lines (SPL) approach has been widely developed in academia and successfully applied in industry. Based on the selection of features, stakeholders can efficiently derive tailor-made programs satisfying different requirements. While SPL was very successful at building products based on identified features, achievements and preservation of many nonfunctional properties (NFPs) remain challenging. A knowledge how to deal with NFPs is still not fully obtained. In this paper, we present a systematic literature review of NFPs analysis for SPL products, focusing on runtime NFPs. The goal of the paper is twofold: (i) to present an holistic overview of SPL approaches that have been reported regarding the analysis of runtime NFPs, and (ii) to categorize NFPs treated in the scientific literature regarding development of SPLs. We analyzed 36 research papers, and identified that system performance attributes are typically the most considered. The results also aid future research studies in NFPs analysis by providing an unbiased view of the body of empirical evidence and by guiding future research directions.}
}

@article{rayyan-727967845,
  title={Effort estimation for ERP projects — A systematic review},
  year={2017},
  pages={96-103},
  author={Ömüral, Neslihan Küçükateş and Demirörs, Onur},
  keywords={systematic literature review, Systematics, Estimation, Databases, Business, Analytical models, Predictive models, Data models, effort estimation, enterprise resource planning},
  abstract={Enterprise Resource Planning (ERP) systems are large scale integrated systems covering most of the business processes of an enterprise. ERP projects differ from software projects with customization, modification, integration and data conversion phases. Most of the time effort and time estimations are performed in an ad-hoc fashion in ERP projects and as a result they frequently suffer from time and budget overruns. Although there is no consensus on a methodology to estimate size, effort and cost of ERP projects there are various research studies in the field. The purpose of this paper is to review the literature on effort estimation methods for ERP projects, their validations and limitations. The systematic literature review used online journal indexes between January 2000 and December 2016. Studies focusing on effort estimation for ERP projects were selected. Two reviewers assessed all studies and 41 were shortlisted. In most of the studies, cost factors for ERP projects were investigated and validated. Our findings showed that effort estimation methods have mostly used function points as an input. Validations of these methods were mostly done by using history-based validation approaches.}
}

@article{rayyan-727967848,
  title={Implementation of the ISO/IEC 29110 standard in agile environments: A systematic literature review},
  year={2018},
  pages={1-6},
  author={Munoz, Mirna and Mejia, Jezreel and Lagunas, Arturo},
  keywords={Software, Organizations, Standards organizations, ISO Standards, Silicon compounds, IEC Standards, practices, agile, ISO/IEC 29110},
  abstract={Nowadays, around 76% of software is developed by very small entities or small entities in México. Thus, there have been emerging new models and standards focused in this type of organizations, such as ISO/IEC 29110 standard. Nevertheless, the lack of process culture, guides, support tools and practices make difficult its implementation in these organizations. This study presents a literature review to identify how the ISO/IEC 29110 standard is being implemented focusing on support tools, practices from other models, standards or agile methodologies which help in its implementation.}
}

@article{rayyan-727967850,
  title={Gamification in requirements engineering: A systematic review},
  year={2018},
  pages={119-125},
  author={Cursino, Rodrigo and Ferreira, Daniel and Lencastre, Maria and Fagundes, Roberta and Pimentel, João},
  keywords={Software, Systematics, Search problems, Task analysis, Requirements engineering, Requirements Engineering, Systematic Review, Gamification, Games, Libraries},
  abstract={Gamification has been applied to a large diversity of settings in recent years, with encouraging and promising results. In the Software Engineering context, there are some research works that focused on the application of gamification in Requirements Engineering that need to be better analyzed and understood. Does gamification impact RE? What are the gamification elements that have been used? What sub-processes and RE tasks have been the subject of gamification? The objective of this paper is to carry out a systematic review to characterize the state of the art of gamification in RE, answering those and other questions, identifying gaps and opportunities for further research. It was conducted a systematic review to find the primary studies in the existent literature which objectives is applying gamification to RE and its sub-processes. As a result of the systematic review, 8 primary studies were analyzed. They were published between 2012 and 2017 and most of them focus on the application of gamification onto elicitation, negotiation and prioritization.}
}

@article{rayyan-727967851,
  title={Multilingual source code analysis: A systematic literature review},
  year={2017},
  journal={IEEE Access},
  issn={2169-3536},
  volume={5},
  pages={11307-11336},
  author={Mushtaq, Zaigham and Rasool, Ghulam and Shehzad, Balawal},
  keywords={Software, Software engineering, Systematics, Bibliographies, Data mining, Manuals, software maintenance, Analytical models, software architecture, reverse engineering, Reverse engineering, software design},
  abstract={Contemporary software applications are developed using cross-language artifacts, which are interdependent with each other. The source code analysis of these applications requires the extraction and examination of artifacts, which are build using multiple programming languages along with their dependencies. A large number of studies presented on multilingual source code analysis and its applications in the last one and half decade. The objective of this systematic literature review (SLR) is to summarize state of the art and prominent areas for future research. This SLR is based on different techniques, tools, and methodologies to analyze multilingual source code applications. We finalized 56 multi-discipline published papers relevant to multilingual source code analysis and its applications out of 3820 papers, filtered through multi-stage search criterion. Based on our findings, we highlight research gaps and challenges in the field of multilingual applications. The research findings are presented in the form of research problems, research contributions, challenges, and future prospects. We identified 46 research issues and requirements for analyzing multilingual applications and grouped them in 13 different software engineering domains. We examined the research contributions and mapped them with individual research problems. We presented the research contributions in the form of tools techniques and approaches that are presented in the form of research models, platforms, frameworks, prototype models, and case studies. Every research has its limitations or prospects for future research. We highlighted the limitations and future perspectives and grouped them in various software engineering domains. Most of the research trends and potential research areas are identified in static source code analysis, program comprehension, refactoring, reverse engineering, detection, and traceability of cross-language links, code coverage, security analysis, cross-language parsing, and abstraction of source code models.}
}

@article{rayyan-727967852,
  title={A systematic review of goal-oriented requirements management frameworks for business process compliance},
  year={2011},
  pages={25-34},
  author={Ghanavati, Sepideh and Amyot, Daniel and Peyton, Liam},
  keywords={Systematic literature review, Databases, Unified modeling language, Organizations, Analytical models, requirements engineering, Law, business process, goal modeling, legal compliance},
  abstract={Legal compliance has been an active topic in Software Engineering and Information Systems for many years. However, business analysts and others recently started exploiting Requirements Engineering techniques, and in particular goal-oriented approaches, to model and reason about legal documents in system design and business process management. Many contributions involve extracting legal requirements, providing law-compliant business processes, as well as managing and maintaining compliance. In this paper, we report on a systematic literature review focusing on goal-oriented legal compliance of business processes. 88 papers were selected out of nearly 800 unique papers extracted from five search engines, with manual additions from the Requirements Engineering Journal and four relevant conferences. We grouped these papers in eight categories based on a set of criteria and then highlight their main contributions. We found that the main areas for contributions have been in extracting legal requirements, modeling them with goal modeling languages, and integrating them with business processes. We identify gaps and opportunities for future work in areas related to prioritization to improve compliance, templates for generating law-compliant processes, general links between legal requirements, goal models, and business processes, and semi-automation of legal compliance and analysis.}
}

@article{rayyan-727967854,
  title={Literature review of empirical research studies within the domain of acceptance testing},
  year={2016},
  pages={181-188},
  author={Weiss, Johannes and Schill, Alexander and Richter, Ingo and Mandl, Peter},
  keywords={Software, systematic literature review, Software engineering, Systematics, Bibliographies, Data mining, Testing, Context, empirical software engineering, acceptance testing},
  abstract={Acceptance test driven development is a promising method to support agile software development. It is aiming to improve development efficiency by automation of test execution and detailed communication of domain knowledge. In this paper a systematic literature review in the field of acceptance test driven development is reported, with the aim of studying existing knowledge and observations in this area. Our search strategy resulted in finding 26 research studies, with 14 experiment papers and 12 use cases papers. We investigated the studies according to a predefined data extraction form. The review investigates the findings of identified empirical research studies. The results are categorized and discussed within the context of previous related reviews.}
}

@article{rayyan-727967855,
  title={Current trends in usability evaluation methods: A systematic review},
  year={2014},
  pages={11-15},
  author={Paz, Freddy and Pow-Sang, José Antonio},
  keywords={systematic review, Systematics, evaluation methods, Testing, Inspection, Usability, usability, human-computer interaction, ISO standards, User interfaces, user-centered design},
  abstract={Since usability is considered as a critical success factor for any software application, several evaluation methods have been developed. Nowadays, it is possible to find many proposals in the literature that address to evaluate usability issues. However, there is still discussion about what usability evaluation method is the most widely accepted by the scientific community. In this research, a systematic review was performed to identify the evaluation methods that have been more employed over the last three years in order to assess the level of usability of a software application. From these results, it has been possible to establish clear evidence about the current trends in this field. A total of 274 usability studies have allowed to reach useful information for scholars in this area.}
}

@article{rayyan-727967858,
  title={A systematic literature review for development, implementation and deployment of MOOCs focused on older people},
  year={2017},
  pages={287-294},
  author={Beltran, Paola and Rodriguez-Ch, Paul and Cedillo, Priscila},
  keywords={Systematics, Manuals, Quality assessment, Education, MOOCs, techniques, Buildings, Libraries, Planning, learning, andragogy, older people, sistematic review, strategies},
  abstract={According to Administration of Aging (AoA), by the year 2060, the older people will represent among the 98 million of people of the total population. That is, much of this priority group will be involved with technology. Hence, the Massive Open Online Courses (MOOCs) are a good alternative for lifelong learning. Therefore, it should be taken into account the needs of older people according to their learning styles by using andragogical techniques, strategies and accessibility criteria. However, nowadays many courses are offered in different platforms, but they are not oriented to older people with special characteristics according to the age. Moreover, the methodologies reviewed do not take into account accessibility criteria and andragogical techniques and strategies for building MOOCs.}
}

@article{rayyan-727967861,
  title={A systematic literature review of assessment tools for programming assignments},
  year={2016},
  pages={147-156},
  author={Souza, Draylson M and Felizardo, Katia R and Barbosa, Ellen F},
  keywords={Systematics, Bibliographies, Data mining, Mapping study, Databases, Education, Programming profession, Assessment tools, Programming assignments},
  abstract={The benefits of using assessment tools for programming assignments have been widely discussed in computing education. However, as both researchers and instructors are unaware of the characteristics of existing tools, they are either not used or are reimplemented. This paper presents the results of a study conducted to collect and evaluate evidence about tools that assist in the assessment of programming assignments. To achieve our goal, we performed a systematic literature review since it provides an objective procedure for identifying the quantity of existing research related to a research question. The results identified subjects in the development of new assessment tools that researchers could better investigate and characteristics of assessment tools that could help instructors make selections for their programming courses.}
}

@article{rayyan-727967862,
  title={Effect analysis of the introduction of AUTOSAR: A systematic literature review},
  year={2011},
  pages={239-246},
  author={Dersten, Sara and Axelsson, Jakob and Froberg, Joakim},
  keywords={Software, Systematics, Automotive engineering, Complexity theory, Computer architecture, Companies, Hardware, software architecture, automotive systems, AUTOSAR, distributed systems, effect analysis, embedded systems, system evolution, system refactoring},
  abstract={Many complex software-intensive systems have a long life time, and undergo substantial evolution. These evolutions are either additions of functionality or system refactoring, i.e., updating the architecture to improve quality attributes without changing functionality. However, the return of investment for such a system refactoring is not easily measured due to a lack of understanding of its effects. In order to improve our understanding of these effects, we have conducted a systematic literature review of the reported effects of one such refactoring: the introduction of AUTOSAR, an open automotive software architecture standard. The effects include both benefits, like lower complexity and more efficient system development, and costs, like performance risks. We have investigated how the effects depend on different elements in AUTOSAR, and how the reports correspond to the stated objectives of the standard. It is also discussed to what extent these effects can be generalized to other types of refactoring.}
}

@article{rayyan-727967865,
  title={Development of critical embedded systems using model-driven and product lines techniques: A systematic review},
  year={2014},
  pages={74-83},
  author={Gadelha Queiroz, Paulo Gabriel and Vaccare Braga, Rosana Teresinha},
  keywords={Systematics, Embedded software, Systematic Review, Embedded systems, Libraries, Computer architecture, Computational modeling, Real-time systems, Model-driven Engineering, Product Lines Engineering, Safety-Critical Embedded Systems},
  abstract={Several methodologies have been proposed in the last decades to improve the quality of Safety-Critical Embedded Systems (SCES) and, at the same time, keep costs and schedule compatible with project plans. In particular, approaches such as Product Line Engineering (PLE) and Model-Driven Engineering (MDE) offer an interesting solution to reduce development complexity and time to market due to their synergy and common goals. However, the current state of how MDE and PLE can be combined to enhance productivity in the domain of SCES is not clear yet. This paper presents a systematic literature review, with the purpose of obtaining the state of the art of the aproaches, methods and methodologies whose goal is the combination of PLE and MDE for the development of SCES, and to verify the existence of empirical studies that demonstrate the application of these techniques in this type of development. We drew the following conclusions from the review results: (1) The number of studies using PLE with MDE to build SCES is relatively small, but has increased gradually in recent years. (2) The approaches diverge about what is needed to build Model-driven Product Lines. (3) Most of the approaches do not consider to differentiate between hardware and software variabilities. (4) Most of the studies propose the use of UML and feature diagrams. (5) The studies present case studies implemented in different tools and most of them are free. (6) The approaches do not cover the entire development lifecycle.}
}

@article{rayyan-727967866,
  title={Comparing local and global software effort estimation models – reflections on a systematic review},
  year={2007},
  pages={401-409},
  author={MacDonell, Stephen G and Shepperd, Martin J},
  keywords={systematic review, Software engineering, Software measurement, Protocols, Mathematics, Mathematical model, prediction, Costs, Predictive models, D.2.9.b Cost estimation, empirical analysis., Management information systems, project effort, Reflection, Technology management, Software},
  abstract={The availability of multi-organisation data sets has made it possible for individual organisations to build and apply management models, even if they do not have data of their own. In the absence of any data this may be a sensible option, driven by necessity. However, if both cross-company (or global) and within-company (or local) data are available, which should be used in preference? Several research papers have addressed this question but without any apparent convergence of results. We conduct a systematic review of empirical studies comparing global and local effort prediction systems. We located 10 relevant studies: 3 supported global models, 2 were equivocal and 5 supported local models. The studies do not have converging results. A contributing factor is that they have utilised different local and global data sets and different experimental designs thus there is substantial heterogeneity. We identify the need for common response variables and for common experimental and reporting protocols.}
}

@article{rayyan-727967868,
  title={Automated testing of android apps: A systematic literature review},
  year={2019},
  journal={IEEE Transactions on Reliability},
  issn={1558-1721},
  volume={68},
  number={1},
  pages={45-66},
  author={Kong, Pingfan and Li, Li and Gao, Jun and Liu, Kui and Bissyandé, Tegawendé F and Klein, Jacques},
  keywords={Systematics, survey, Bibliographies, Ecosystems, Testing, literature review, Android, Java, Androids, Humanoid robots, automated testing, Methyltestosterone},
  abstract={Automated testing of Android apps is essential for app users, app developers, and market maintainer communities alike. Given the widespread adoption of Android and the specificities of its development model, the literature has proposed various testing approaches for ensuring that not only functional requirements but also nonfunctional requirements are satisfied. In this paper, we aim at providing a clear overview of the state-of-the-art works around the topic of Android app testing, in an attempt to highlight the main trends, pinpoint the main methodologies applied, and enumerate the challenges faced by the Android testing approaches as well as the directions where the community effort is still needed. To this end, we conduct a systematic literature review during which we eventually identified 103 relevant research papers published in leading conferences and journals until 2016. Our thorough examination of the relevant literature has led to several findings and highlighted the challenges that Android testing researchers should strive to address in the future. After that, we further propose a few concrete research directions where testing approaches are needed to solve recurrent issues in app updates, continuous increases of app sizes, as well as the Android ecosystem fragmentation.}
}

@article{rayyan-727967872,
  title={Users' involvement in requirements engineering and system success},
  year={2013},
  pages={24-31},
  author={Bano, Muneera and Zowghi, Didar},
  keywords={Software, systematic literature review, Systematics, Guidelines, Uncertainty, Organizations, Psychology, Cultural differences, requirements engineering, software development lifecycle, users' involvement},
  abstract={Involving users in software development in general, and in Requirements Engineering (RE) in particular, has been considered for over three decades. It is axiomatically believed to contribute significantly to a successful system. However, not much attention has been paid to ascertain in which phases of software development life cycle involvement or participation of users is most beneficial. In this paper we present an investigation into the concept of users' involvement during RE activities and explore its relationship with system success. We have conducted a systematic literature review (SLR) using guidelines of Evidence Based Software Engineering. Our SLR identified 87 empirical studies from the period of 1980 to 2012. Only 13 studies focused specifically on investigating users' involvement in RE and 9 of these confirmed benefits of involving users in requirements analysis and 4 remain inconclusive. Effective involvement of users in RE may reduce the need for their more active involvement in the rest of software development. This paper also offers a checklist we have created from the identified factors of all 87 empirical studies that should be utilised for effective users' involvement in RE.}
}

@article{rayyan-727967874,
  title={A systematic review and comparison of security ontologies},
  year={2008},
  pages={813-820},
  author={Blanco, Carlos and Lasheras, Joaquin and Valencia-García, Rafael and Fernández-Medina, Eduardo and Toval, Ambrosio and Piattini, Mario},
  keywords={systematic review, comparison, Software engineering, Data mining, Ontologies, Privacy, ontology, Information security, security, Proposals, Software libraries, Abstracts, Availability, Data security},
  abstract={The use of ontologies for representing knowledge provides us with organization, communication and reusability. Information security is a serious requirement which must be carefully considered. Concepts and relations managed by any scientific community need to be formally defined and ontological engineering supports their definition. In this paper, the method of systematic review is applied with the purpose of identifying, extracting and analyzing the main proposals for security ontologies. The main identified proposals are compared using a formal framework and we conclude by stating their early state of development and the need of additional research efforts.}
}

@article{rayyan-727967876,
  title={The impact of human factors on agile projects},
  year={2015},
  pages={87-91},
  author={Chagas, Aline and Santos, Melquizedequi and Santana, Célio and Vasconcelos, Alexandre},
  keywords={Software, Software engineering, Systematics, Collaboration, Decision making, Agile software development, Human factors, Agile Software Development, Human Factors, Systematic Literature Review., Humanities, Humanism, Humans},
  abstract={This research aims to provide more evidences about the impact of human factors in agile software projects. In this light we have conducted a systematic literature review (SLR) to investigate which human factors impact agile projects and conducted a survey in software companies in order to verify their perceptions. Considering the SLR, we found 48 resulting studies where most cited human factors were: Communication (23 papers), Collaboration (6 papers) and Trust (8 papers). The survey was answered for 186 companies that consider communication the most important factor. So we conclude that Communication, Trust and Collaboration are important factors in projects using agile methods but others factors need to be more investigated due the perception of its value to the industry.}
}

@article{rayyan-727967880,
  title={Software security in open source development: A systematic literature review},
  year={2017},
  pages={364-373},
  author={Wen, Shao-Fang},
  keywords={Systematics, Security, Knowledge management, Open source software, Buildings, Focusing, Software},
  abstract={Despite the security community's emphasis on the importance of building secure open source software (OSS), the number of new vulnerabilities found in OSS is increasing. In addition, software security is about the people that develop and use those applications and how their vulnerable behaviors can lead to exploitation. This leads to a need for reiteration of software security studies for OSS developments to understand the existing security practices and the security weakness among them. In this paper, a systematic review method with a sociotechnical analysis approach is applied to identify, extract and analyze the security studies conducted in the context of open source development. The findings include: (1) System verification is the most cited security area in OSS research; (2) The socio-technical perspective has not gained much attention in this research area; and (3) No research has been conducted focusing on the aspects of security knowledge management in OSS development.}
}

@article{rayyan-727967881,
  title={Open source adoption Factors—A systematic literature review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={94594-94609},
  author={Sánchez, Víctor Rea and Ayuso, Pablo Neira and Galindo, José A and Benavides, David},
  keywords={Software, Systematics, Data mining, Guidelines, Databases, Organizations, Economics, Free software adoption, libre software adoption, open source adoption},
  abstract={Nowadays, Free/Libre/OpenSource Software (FLOSS) is becoming a strategic option for many organizations in the public and the private sector. The lack of well defined guidelines for IT managers may jeopardize the FLOSS adoption process. FLOSS adoption procedures are developed ad-hoc in every organization, hence, leading to potential wheel reinvention situations. Identifying factors that influence and determine adoption is crucial. In this article, we survey existing literature through systematic review methodologies to make visible the technical, organizational and economic factors that must be evaluated in the adoption process. We also provide hints for researchers on publications and the type of research that already covered this topic in the past. We studied almost 500 papers from which we selected a final set of 54 primary studies directly related to FLOSS adoption. We found twenty-two different adoption factors categorized as technical (nine), organizational (nine) and economic (four). This article aims to provide the basic building blocks to step into the creation of a guide for the FLOSS adoption. All the data we used in this study is available at this online repository: https://github.com/jagalindo/rea.victor.19-foss and doi: https://doi.org/10.5281/zenodo.2632543.}
}

@article{rayyan-727967883,
  title={A systematic review of empirical studies on learning analytics dashboards: A self-regulated learning perspective},
  year={2020},
  journal={IEEE Transactions on Learning Technologies},
  issn={1939-1382},
  volume={13},
  number={2},
  pages={226-245},
  author={Matcha, Wannisa and Uzir, Nora'ayu Ahmad and Gašević, Dragan and Pardo, Abelardo},
  keywords={Systematics, Bibliographies, Recommender systems, Australia, empirical research, Informatics, Analytical models, Computational modeling, Dashboards, feedback, information visualization, learning analytics, self-regulated learning, Learning},
  abstract={This paper presents a systematic literature review of learning analytics dashboards (LADs) research that reports empirical findings to assess the impact on learning and teaching. Several previous literature reviews identified self-regulated learning as a primary focus of LADs. However, there has been much less understanding how learning analytics are grounded in the literature on self-regulated learning and how self-regulated learning is supported. To address this limitation, this review analyzed the existing empirical studies on LADs based on the well-known model of self-regulated learning proposed by Winne and Hadwin. The results show that existing LADs are rarely grounded in learning theory, cannot be suggested to support metacognition, do not offer any information about effective learning tactics and strategies, and have significant limitations in how their evaluation is conducted and reported. Based on the findings of the study and through the synthesis of the literature, the paper proposes that future research and development should not make any a priori design decisions about representation of data and analytic results in learning analytics systems such as LADs. To formalize this proposal, the paper defines the model for user-centered learning analytics systems (MULAS). The MULAS consists of the four dimensions that are cyclically and recursively interconnected including: theory, design, feedback, and evaluation.}
}

@article{rayyan-727967884,
  title={A systematic review of software maintainability prediction and metrics},
  year={2009},
  pages={367-377},
  author={Riaz, Mehwish and Mendes, Emilia and Tempero, Ewan},
  keywords={Software engineering, Software measurement, Software performance, Software quality, Software maintenance, Software systems, Strontium, Costs, Predictive models, State estimation, Metronidazole, Software},
  abstract={This paper presents the results of a systematic review conducted to collect evidence on software maintainability prediction and metrics. The study was targeted at the software quality attribute of maintainability as opposed to the process of software maintenance. The evidence was gathered from the selected studies against a set of meaningful and focused questions. 710 studies were initially retrieved; however of these only 15 studies were selected; their quality was assessed; data extraction was performed; and data was synthesized against the research questions. Our results suggest that there is little evidence on the effectiveness of software maintainability prediction techniques and models.}
}

@article{rayyan-727967887,
  title={Speech recognition using deep neural networks: A systematic review},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={19143-19165},
  author={Nassif, Ali Bou and Shahin, Ismail and Attili, Imtinan and Azzeh, Mohammad and Shaalan, Khaled},
  keywords={systematic review, Neural networks, Deep learning, Computer architecture, Feature extraction, Acoustics, deep neural network, Hidden Markov models, Speech recognition, Nerve Net, Neural Networks (Computer), Speech},
  abstract={Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics.}
}

@article{rayyan-727967888,
  title={A systematic review protocol on shared transportation},
  year={2016},
  pages={1-4},
  author={Silva, Elis and Rossetti, Rosaldo J F and Kokkinogenis, Zafeiris and Pinto, José},
  keywords={Artificial intelligence, Systematics, Systematic Review, Methodology, Computer science, Protocols, Mobility, Protocol, Public transportation, Shared Transportation, Signal to noise ratio},
  abstract={Recently, many studies in the literature have been intensified in the scope of mobility services, presenting new technological solutions that can minimize problems, such as traffic congestion and the emission of greenhouse gases resulting from the population growth in large cities. Some services, namely shared services, are mainly dedicated to trying to encourage people to use transport that can be shared. In this paper, we propose a systematic literature review protocol oriented to shared transportation, so as to support bibliographical reviews by researchers on this domain. From the proposed systematic review methodology, we present preliminary results of a survey conducted on shared services.}
}

@article{rayyan-727967892,
  title={Convergence analysis of ISO/IEC 12207 and CMMI-DEV: A systematic literature review},
  year={2016},
  pages={1-8},
  author={Crisóstomo, Javier and Flores, Luis and Melendez, Karin and Dávila, Abraham},
  keywords={Software, Context modeling, CMM, CMMI, Libraries, ISO Standards, IEC Standards, Benchmark testing, CMMI-DEV, Convergence, ISO/IEC 12207, model harmonization},
  abstract={The organizations and people are demanding more and better software products and services, which implies adequate processes for its development. In the context of the software industry, there are two models, the CMMI-DEV and ISO/IEC 12207 that are influencing it. Though, they are evolving separately, recurrently they have been compared to determine its coverage (in both directions). In this study is analyzed the results of those comparisons (partials and completed) to determine if the models ISO/IEC 12207 and CMMI-DEV converge at processes level. This study identified eight articles where the comparison is carried out between ISO/IEC 12207 and CMMI-DEV. The results show that technique most used is the mapping comparisons between the models and according to the analyzed studies is not possible to determine whether there is convergence in the time. However, we found some items and criterions for use in comparisons.}
}

@article{rayyan-727967895,
  title={Systematic literature review on penetration testing for mobile cloud computing applications},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={173524-173540},
  author={Al-Ahmad, Ahmad Salah and Kahtan, Hasan and Hujainah, Fadhl and Jalab, Hamid A},
  keywords={Software testing, Cloud computing, Mobile cloud computing, Complexity theory, Analytical models, penetration testing, Penetration testing, cloud testing, mobile testing, offloading},
  abstract={Mobile cloud computing (MCC) enables mobile devices to exploit seamless cloud services via offloading, and has numerous advantages and increased security and complexity. Penetration testing of mobile applications has become more complex and expensive due to several parameters, such as the platform, device heterogeneity, context event types, and offloading. Numerous studies have been published in the MCC domain, whereas few studies have addressed the common issues and challenges of MCC testing. However, current studies do not address MCC and penetration testing. Therefore, revisiting MCC and penetration testing domains is essential to overcoming the inherent complexity and reducing costs. Motivated by the importance of revisiting these domains, this paper pursues two objectives: to provide a comprehensive systematic literature review (SLR) of the MCC, security and penetration testing domains and to establish the requirements for penetration testing of MCC applications. This paper has systematically reviewed previous penetration testing models and techniques based on the requirements in Kitchenham's SLR guidelines. The SLR outcome has indicated the following deficiencies: the offloading parameter is disregarded; studies that address mobile, cloud, and web vulnerabilities are lacking; and a MCC application penetration testing model has not been addressed by current studies. In particular, offloading and mobile state management are two new and vital requirements that have not been addressed to reveal hidden security vulnerabilities, facilitate mutual trust, and enable developers to build more secure MCC applications. Beneficial review results that can contribute to future research are presented.}
}

@article{rayyan-727967898,
  title={A comprehensive investigation of modern test suite optimization trends, tools and techniques},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={89093-89117},
  author={Kiran, Ayesha and Butt, Wasi Haider and Anwar, Muhammad Waseem and Azam, Farooque and Maqbool, Bilal},
  keywords={Software, Software testing, Tools, Optimization, Databases, multi-objective optimization, Clustering algorithms, Greedy algorithms, single objective optimization, test suite optimization},
  abstract={Software testing is an important but expensive activity of software development life cycle, as it accounts for more than 52% of entire development cost. Testing requires the execution of all possible test cases in order to find the defects in the software. Therefore, different test suite optimization approaches like the genetic algorithm and the greedy algorithm, etc., are widely used to select the representative test suite without compromising the effectiveness. Test suite optimization is frequently researched to enhance its competences but there is no study published until now that analyzes the latest developments from 2016 to 2019. Hence, in this article, we systematically examine the state-of-the-art optimizations' approaches, tools, and supporting platforms. Principally, we conducted a systematic literature review (SLR) to inspect and examine 58 selected studies that are published during 2016-2019. Subsequently, the selected researches are grouped into five main categories, i.e., greedy algorithm (seven studies), meta-heuristic (28 studies), hybrid (six studies), clustering (five studies), and general (12 studies). Finally, 32 leading tools have been presented, i.e., existing tools (25 tools) and proposed/developed tools (seven tools) along 14 platform supports. Furthermore, it is noted that several approaches aim at solving the single-objective optimization problem. Therefore, researchers should focus on dealing with the multi-objective problem, as multi-objective versions outperform the single-objective ones. Moreover, less attention has been given to clustering-based techniques. Thus, we recommend exploring the machine learning and artificial intelligence-based optimization approaches in the future. A broad exploration of tools and techniques, in this article, will help researchers, practitioners, and developers to opt for adequate techniques, tools, or platforms as per requirements.}
}

@article{rayyan-727967901,
  title={A systematic review on the effectiveness of web usability evaluation methods},
  year={2012},
  pages={52-56},
  author={Fernandez, Adrian and Abrahão, Silvia and Insfran, Emilio},
  keywords={Systematic Review, Method Effectiveness, Usability Evaluation, Web Development},
  abstract={Usability evaluation methods have become critical in the Web domain to ensure the success of Web applications. Aim: Since a large number of proposals have been presented during the last few years, a question arises: Which usability evaluation methods have proven to be the most effective in the Web domain? Method: This paper presents a systematic review that was motivated by previous results obtained from a systematic mapping study in the Web usability evaluation field. Results: A total of 18 studies were selected from an initial set of 206 in order to extract, code, and synthesize empirical data concerning the effectiveness of usability evaluation methods for the Web. Conclusions: We detected a need of more empirical studies and more standardized effectiveness measures for comparing usability evaluation methods. Our results suggest several evaluation methods which may be useful in allowing researchers and practitioners to perform effective Web usability evaluations.}
}

@article{rayyan-727967904,
  title={A systematic literature review of requirements volatility prediction},
  year={2017},
  pages={55-64},
  author={Alsalemi, Ahmed Mubark and Yeoh, Eng-Thiam},
  keywords={Software, Systematics, Bibliographies, Search problems, Databases, Market research, Predictive models, Volatilization},
  abstract={Requirements volatility is a crucial risk factor in software projects as it directly results in cost and time overruns. Accurately predicting requirements volatility is important for better project management. This paper presents a systematic literature review that focuses on the prediction of the requirements volatility. This literature review aims to answer four research questions: 1) how is requirements volatility prediction applied to different software development methods? 2) What are the machine learning algorithms used to predict requirements volatility in software development? 3) What are the attributes (predictors) used to predict requirements volatility in software development? 4) What are the performance metrics for evaluating existing prediction models? This study presents predictors used in the literature and their performances.}
}

@article{rayyan-727967905,
  title={Requirements for smart cities: Results from a systematic review of literature},
  year={2018},
  pages={1-6},
  author={Daneva, Maya and Lazarov, Boyan},
  keywords={Systematic literature review, Systematics, Data mining, Requirements engineering, Empirical study, Security, Software architecture, Instruments, Intelligent systems, Smart cities, Smart city systems},
  abstract={Smart cities are gaining increasingly more importance in both research and business circles. Much effort is spent to defining what a smart city is and how it could be realized with today's or future technologies. However, from requirements engineering perspective, our knowledge of smart cities is fragmented; little is known about the requirements for smart cities as complex systems, or as systems of systems, in specific application domains. In this paper, we elicit requirements for smart city systems by carrying out a systematic review of scientific literature focused on the so-called “hard” domains of smart cities. Based on 32 selected publications, we gathered and classified requirements in respect to three types of smart city systems (instrumented, interconnected, and intelligent systems) and four classes of requirements: end-to-end experience, architectural, security, and infrastructure requirements. Our most important findings are that: (1) most authors took a bottom-up approach to defining requirements for smart cities; their efforts focused mainly on requirements important for designing an architecture that could scale up to any size and include any device or system; and (2) very little is mentioned on the newly emerging security and privacy challenges that are critical to gain the citizens' acceptance of smart city apps.}
}

@article{rayyan-727967907,
  title={State of mobile crowdsourcing applications: A review},
  year={2015},
  pages={27-32},
  author={Mahmud, Farahidayah and Aris, Hazleen},
  keywords={systematic review, Crowdsourcing, Databases, Google, Industries, Mobile handsets, Meteorology, Mobile communication, crowdsourcing, crowdsourcing application, mobile crowdsourcing, secondary study},
  abstract={The proliferation of mobile devices has changed the way people communicate and perform their day-to-day dealings. In particular, the widespread availability of mobile devices has enabled information distribution and sharing to be done almost instantly at your fingertips. Companies and organisations are also taking advantage of this phenomenon by changing the way they accomplish their tasks. From traditionally employing people to do the tasks, they now crowdsource the tasks to the public who can easily access the tasks through their mobile devices. As a result, many mobile crowdsourcing applications have been developed for this purpose. In this paper, the result of a systematic literature review performed in an attempt to understand the current state of mobile crowdsourcing applications that exist today is presented. The aim is to identify the potential categorisation of the applications in a way that enables the researchers to understand the current situation and hence determine the direction of future research in this area. Mobile crowdsourcing applications under review came from both; research and industry. Results obtained from the review showed that mobile crowdsourcing applications from the traffic and navigation category are mostly developed and majority of the mobile crowdsourcing applications only exist in mobile form. Finding from the review also showed that most mobile crowdsourcing applications from the industry are offered in both platforms; iOS and Android.}
}

@article{rayyan-727967909,
  title={Effective collection and selection of research articles for a systematic review},
  year={2018},
  pages={1394-1399},
  author={Rožanc, I},
  abstract={The first step in any research work is to gain a better understanding of selected research topic and its placement in the research field. To achieve this a Systematic Review (SR) is usually performed in one of two forms. A Systematic Literature Review (SLR) addresses a specific research question by providing insight into selected literature, while a Systematic Mapping Study (SMS) uses a principle of classification of a large number of collected articles to present a wider picture of the research topic. In both cases, the collection and selection of proper articles are crucial. Due to a lot of available articles from different sources and its diverse quality, a lot of tedious (often manual) work is required. This article addresses the issues of effective collection and selection of an appropriate set of articles. First, the importance of using suitable guidelines for conducting an SR is presented. Then, the practical considerations for the collection of articles are shown with an emphasis on effective search in Digital Libraries (DLs). Finally, the issues connected with an effective selection of an appropriate set of articles (from all collected) is described. In this part, we advise to collect as many articles as possible and perform sequential three-step selection to efficiently eliminate the obviously incorrect ones without a tedious manual screening of entire article contents.}
}

@article{rayyan-727967910,
  title={A systematic review of literature on methodologies, practices, and tools for programming teaching},
  year={2018},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={16},
  number={5},
  pages={1468-1475},
  author={Borges, R P and Oliveira, P R F and da R. Lima, R G and de Lima, R W},
  keywords={Systematics, Tools, Education, Conferences, IEEE transactions, Programming profession, Systematic Review of Literature, Teaching of Programming},
  abstract={It has been frequent the discussion about the teaching and learning of Programming, from the initial series to the undergraduate courses. It is noticed that many students have difficulty to learn programming by several reasons: methodology, tools, programming languages, lack of programming logic in basic education, motivation, among others. Thus, this carries out a survey of the state of the art of existing and documented approaches in the literature, through a mapping of published works in the last five years (2012 to 2016) in two of Brazil's leading scientific computing platforms (CEIE and RENOTE), whose focus is to present solutions that address methodologies and tools that can be used in the different teaching modalities. As methodology was used the Systematic Review of Literature. As a result, it was found that, although studies still focus on higher education, in recent years there has been an increasing interest in programming teaching projects for children and teenagers, using gamification and tools such as Scratch. The results also demonstrate the growing interest of researchers in the search for approaches that provide better results in this area.}
}

@article{rayyan-727967911,
  title={A systematic review of software product lines applied to mobile middleware},
  year={2009},
  pages={1024-1029},
  author={Bezerra, Yuri Morais and Pereira, Thaís Alves Burity and da Silveira, Glêdson Elias},
  keywords={systematic review, Middleware, Mobile computing, Information technology, Software systems, Application software, Strontium, Communications technology, Hardware, customizable middleware, middleware, mobile computing, Personal digital assistants, software product line, Wireless communication, Software},
  abstract={Mobile computing imposes several restrictions to software development due to diversities in network connectivity, platform capability and resource availability. Middleware has been used to abstract such issues from application developers, resolving common challenges of distributed systems. However, middleware is considered a heavy-weight technology to mobile computing, as it is a general purpose solution. By enabling the customization of the set of features provided by a middleware, the adoption of Software Product Lines techniques seems to be a promising systematic approach. Nevertheless, this is an incipient subject that has been explored for few research groups. In this sense, this paper goal is to present a systematic review of Product Line techniques applied to middleware for mobile computing.}
}

@article{rayyan-727967912,
  title={A study of the publications of educational robotics: A Systematic Review of Literature},
  year={2018},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={16},
  number={4},
  pages={1193-1199},
  author={Bezerra Junior, Jose Etiene and Queiroz, Paulo Gabriel Gadelha and de Lima, Rommel Wladimir},
  keywords={Systematics, Bibliographies, Tools, Manuals, Education, IEEE transactions, Robots, Systematic Review of Literature, Educational Robotics, Pedagogical tool, Robotics},
  abstract={Educational Robotics has been presented as a great pedagogical tool because it demonstrates an attractive way of working the theoretical knowledge put into practice. Thus, several educational technologies have emerged with different approaches, with the purpose of applying robotics in the educational area in a more attractive and playful way. This article presents the conduction of a Systematic Review of Literature (SRL), whose objective is to identify the teaching approaches used with educational robotics. With this, we present experiences reports, and at the same time show the skills and competencies that are explored through robotics and education. This review uses scientific papers published in the period from 2011 to 2016.}
}

@article{rayyan-727967913,
  title={An empirical study to investigate the impact of communication issues in GSD in pakistan's IT industry},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={171648-171672},
  author={Ammad, Ghana and Iqbal Janjua, Uzair and Madni, Tahir Mustafa and Cheema, Muhammad Faisal and Shahid, Ahmed R},
  keywords={Software, systematic literature review, Systematics, Bibliographies, Organizations, global software development, empirical study, Cultural differences, Industries, distributed software development, communication challenges, communication issues, Communication risk, Face, Pakistan},
  abstract={Global software development (GSD) practice has been increasingly emerging in the recent few decades in the field of business and software industry. On the one hand, many software development organizations get the benefits of GSD, including but not limited to reduced cost, cheap labor, round the clock working and skilled professionals. On the other hand, these organizations have to face several challenges because of GSD. These challenges pose serious threats to the stability of the GSD projects. Communication between distributed team members is one of the most crucial challenges in GSD. Therefore, the current study aims to identify the communication risk in GSD and also evaluate the impact of these communication risks in GSD environment. A Systematic Literature Review (SLR) has been performed to identify all the communication-related issues in GSD. After that, a conceptual framework has been proposed for evaluating the impact of those issues on communication risk in GSD. An empirical evaluation has been performed on data collected from the software organizations of Pakistan working in GSD based environment. The finding of our study demonstrates that geographical distance, socio- temporal distance, socio-culture distance, team member's attitude, team issues, organizational & architectural issue and customer issue have a significant direct impact on communication risk in GSD. The study also shows that there is a significant correlation between findings of SLR and empirical investigation (r = 0.460, P = 0.005). Further, we believe that the results of our research can help to tackle the issues related to communication in GSD. Therefore, it will help to improve the performance of the development activities of GSD organizations.}
}

@article{rayyan-727967919,
  title={A comparison of software cost, duration, and quality for waterfall vs. iterative and incremental development: A systematic review},
  year={2009},
  pages={511-515},
  author={Mitchell, Susan M and Seaman, Carolyn B},
  keywords={Software engineering, Software measurement, Project management, Software quality, Databases, Programming, Software development management, Costs, Iterative methods, Maintenance, Software},
  abstract={The objective of this study is to present a body of evidence that will assist software project managers to make informed choices about software development approaches for their projects. In particular, two broadly defined competing approaches, the traditional ldquowaterfallrdquo approach and iterative and incremental development (IID), are compared with regards to development cost and duration, and resulting product quality. The method used for this comparison is a systematic literature review. The small set of studies we located did not demonstrate any identifiable cost, duration, or quality trends, although there was some evidence suggesting the superiority of IID (in particular XP). The results of this review indicate that further empirical studies, both quantitative and qualitative, on this topic need to be undertaken. In order to effectively compare study results, the research community needs to reach a consensus on a set of comparable parameters that best assess cost, duration, and quality.}
}

@article{rayyan-727967920,
  title={Model-driven reverse engineering approaches: A systematic literature review},
  year={2017},
  journal={IEEE Access},
  issn={2169-3536},
  volume={5},
  pages={14516-14542},
  author={Raibulet, Claudia and Arcelli Fontana, Francesca and Zanoni, Marco},
  keywords={Systematics, Bibliographies, Tools, Models, Object oriented modeling, Analytical models, Search engines, reverse engineering, Reverse engineering, legacy system, model transformation, model-driven reverse engineering},
  abstract={This paper explores and describes the state of the art for what concerns the model-driven approaches proposed in the literature to support reverse engineering. We conducted a systematic literature review on this topic with the aim to answer three research questions. We focus on various solutions developed for model-driven reverse engineering, outlining in particular the models they use and the transformations applied to the models. We also consider the tools used for model definition, extraction, and transformation and the level of automation reached by the available tools. The model-driven reverse engineering approaches are also analyzed based on various features such as genericity, extensibility, automation of the reverse engineering process, and coverage of the full or partial source artifacts. We describe in detail and compare fifteen approaches applying model-driven reverse engineering. Based on this analysis, we identify and indicate some hints on choosing a model-driven reverse engineering approach from the available ones, and we outline open issues concerning the model-driven reverse engineering approaches.}
}

@article{rayyan-727967921,
  title={Attributes and metrics of internal quality that impact the external quality of object-oriented software: A systematic literature review},
  year={2016},
  pages={1-12},
  author={Santos, Danilo and Resende, Antônio and Junior, Paulo Afonso and Costa, Heitor},
  keywords={Measurement, Software quality, Usability, Computer science, Software Quality, External Quality, Internal Quality Attributes, Internal Quality Metrics, Software reliability, Metronidazole, Software},
  abstract={Quality metrics of software can be categorized into internal quality metrics, external quality metrics, and quality in use metrics. Although existing a close relationship between internal and external quality of software systems, there are no explicit evidences in literature of what are the attributes and metrics of internal quality that impact external quality. Thus, we carried out a systematic literature review for identifying that relationship. After the analysis of 664 papers, 12 papers were studied in depth. As result, we found 65 metrics related primarily to the maintainability, usability, and reliability quality characteristics and the main attributes that impact external metrics are size, coupling, and cohesion.}
}

@article{rayyan-727967922,
  title={Software support for the Fuzzy Front End stage of the innovation process: a systematic literature review},
  year={2010},
  pages={426-431},
  author={Monteiro, Cleviton and Arcoverde, Daniel F and da Silva, Fabio Q B and Ferreira, Henrique S},
  keywords={Benefits, Informatics, Computer industry, Protocols, Software tools, Costs, Technological innovation, Collaborative tools, Computer Aided Innovation, Fuzzy Front End, Fuzzy sets, Fuzzy systems, New Product Development, Product development, Software Tools, Software},
  abstract={The early stages of new product development, called the Fuzzy Front End (FFE), are essential for the success of innovation. Therefore, various software tools have been proposed to support FFE activities. However, little evidence is provided about the benefits of using such tools. The objective of this study is to present evidence that will assist industry practitioners to make informed choices about software support tools to be used in the FFE. The method used for this study was a systematic literature review that analyzed 1090 articles published between 1997 and 2009. The results show that software tools can speed up the FFE, reduce costs, increase collaboration, improve decision quality and knowledge management, reduce risks, and enhance overall creativity.}
}

@article{rayyan-727967923,
  title={Maintenance effort estimation for open source software: A systematic literature review},
  year={2016},
  pages={32-43},
  author={Wu, Hong and Shi, Lin and Chen, Celia and Wang, Qing and Boehm, Barry},
  keywords={Software, Data mining, Measurement, Estimation, Protocols, Planning, Maintenance engineering},
  abstract={Open Source Software (OSS) is distributed and maintained collaboratively by developers all over the world. However, frequent personnel turnover and lack of organizational management makes it difficult to capture the actual development effort. Various OSS maintenance effort estimation approaches have been developed to provide a way to understand and estimate development effort. The goal of this study is to identify the current state of art of the existing maintenance effort estimation approaches for OSS. We performed a systematic literature review on the relevant studies published in the period between 2000-2015 by both automatic and manual searches from different sources. We derived a set of keywords from the research questions and established selection criteria to carefully choose the papers to evaluate. 29 out of 3,312 papers were selected based on a well designed selection process. Our results show that the commonly used OSS maintenance effort estimation methods are actual effort estimation and maintenance activity time prediction, the most commonly used metrics and factors for actual effort estimation are source code measurements and people related metrics, the most commonly mentioned activity for maintenance activity time prediction is bug fixing. Accuracy measures and cross validation is used for validating the estimation models. Based on the above findings, we identified the issues in evaluation methods for actual maintenance effort estimations and the needs for quantitative OSS maintenance effort inference from size-related metrics. Meanwhile, we highlighted individual contribution and performance measurement as a novel and promising research area.}
}

@article{rayyan-727967924,
  title={Augmented reality for learning of children and adolescents with autism spectrum disorder (ASD): A systematic review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={78779-78807},
  author={Khowaja, Kamran and Banire, Bilikis and Al-Thani, Dena and Sqalli, Mohammed Tahri and Aqle, Aboubakr and Shah, Asadullah and Salim, Siti Salwah},
  keywords={Systematics, Databases, Autism, virtual reality, Data collection, Maintenance engineering, technology, Augmented reality, autism spectrum disorder, computer, data collection, inclusive education, intervention, mixed reality, research design, smartglass, smartphone, social communication, tablet, Child Development Disorders, Pervasive, Autistic Disorder, Adolescent, Only Child, Child},
  abstract={This paper presents a systematic review of relevant primary studies on the use of augmented reality (AR) to improve various skills of children and adolescents diagnosed with autism spectrum disorder (ASD) from years 2005 to 2018 inclusive in eight bibliographic databases. This systematic review attempts to address eleven specific research questions related to the learing skills, participants, AR technology, research design, data collection methods, settings, evaluation parameters, intervention outcomes, generalization, and maintenance. The social communication skill was the highly targeted skill, and individuals with ASD were part of all the studies. Computer, smartphone, and smartglass are more frequently used technologies. The commonly used research design was pre-test and post-test. Almost all the studies used observation as a data collection method, and classroom environment or controlled research environment were used as a setting of evaluation. Most of the evaluation parameters were human-assisted. The results of the studies show that AR benefited children with ASD in learning skills. The generalization test was conducted in one study only, but the results were not reported. The results of maintenance tests conducted in five studies during a short-term period following the withdrawal of intervention were positive. Although the effect of using AR towards the learning of individuals was positive, given the wide variety of skills targeted in the studies, and the heterogeneity of the participants, a summative conclusion regarding the effectiveness of AR for teaching or learning of skills related to ASD based on the existing literature is not possible. The review also proposes the research taxonomy for ASD. Future research addressing the effectiveness of AR among more participants, different technologies supporting AR for the intervention, generalization, and maintenance of learning skills, and the evaluation in the inslusive classroom environment and other settings is warranted.}
}

@article{rayyan-727967929,
  title={A systematic review on architecting for software evolvability},
  year={2010},
  pages={13-22},
  author={Breivold, Hongyu Pei and Crnkovic, Ivica},
  keywords={Software engineering, Data mining, Guidelines, Software architecture, Australia, Software systems, Computer architecture, Computer industry, Protocols, Costs, software architecture evolution, Software evolvability, Software},
  abstract={For long-lived systems, there is a need to address evolvability (i.e. a system's ability to easily accommodate changes) explicitly during the entire lifecycle. In this paper, we undertake a systematic review to obtain an overview of the existing studies in promoting software evolvability at architectural level. The search strategy identified 58 studies that were catalogued as primary studies for this review after using multi-step selection process. The studies are classified into five main categories of themes, including techniques that support quality considerations during software architecture design, architectural quality evaluation, economic valuation, architectural knowledge management and modeling techniques. The review investigates what is currently known about architecting software evolvability at architecture level. Implications for research and practice are presented.}
}

@article{rayyan-727967930,
  title={The evolution from traditional to intelligent web security: Systematic literature review},
  year={2020},
  pages={1-9},
  author={Martinez Santander, Carlos José and Moreno, Hugo and Hernandez Alvarez, Myriam Beatriz},
  keywords={Security, Cross-site scripting, SQL injection, Vulnerabilities, Analytical models, Performance analysis, Heuristic algorithms, Attacks, Cross-site script, Defacement, Denial of Service, Dynamic programming, Web Security, Intelligence},
  abstract={Information security is fundamental in the area of computing science with new metrics and technologies developed to secure the private data of entities and individuals related to banking, defense, education, business, medical, among others. The web servers require a high-security level to guarantee data protection and transactions to store, to manage, and to allow the interaction between the user or users and the website. The number of cybercriminals is increasing, looking for vulnerable web servers or applications to obtain the necessary information, modify it, or sell it to the highest bidder. There are multiple solutions created over the years; however, the technological advance is not only to secure the data, but the cybercriminals are also updated and use sophisticated techniques; therefore, these solutions are also obsolete if there is no update. The purpose of this document is to present a systematic review of the literature on web security. Identified Studies try to mitigate various attacks or detect vulnerabilities, the solutions proposed so far are not sufficient, and most attacks occur at the application layer level. The advances in this field are dizzying, where some studies, although very small, that already use automatic learning techniques or Cognitive Security is present in this area.}
}

@article{rayyan-727967933,
  title={The use of computational tools in teaching pharmacology: A systematic review on the topic},
  year={2014},
  pages={1-6},
  author={Rauta, Leonardo Ronald Perin and Batista, Alex Fernando and da Rocha Fernandes, Anita Maria},
  keywords={systematic review, Systematics, Visualization, Tools, Abstracts, Materials, IEEE Xplore, teaching, Electronic learning, pharmacology},
  abstract={In pharmacology, one of the problems found in teaching is precisely the existing abstract concepts, because it has chemistry as a requirement for your understanding. Due to these abstract concepts, students try to end difficult to visualize and understand these concepts. To try to reduce the degree of abstraction, was started to use computational tools for teaching and learning. This paper presents a systematic literature review of computational tools which are being used for teaching Pharmacology. This systematic review included only studies published in 2008 and 2013 in three different databases and it was noted that are no many computational tools directed to the area of pharmacology.}
}

@article{rayyan-727967934,
  title={Factors promoting software project escalation: A systematic review},
  year={2020},
  volume={1},
  pages={280-289},
  author={Holgeid, Knut Kjetil and Stray, Viktoria},
  keywords={Software, Risk management, Organizations, Psychology, Informatics, Standards organizations, Investment, De-escalation, Escalation of commitment, Software Engineering Process, Fibrinogen},
  abstract={A vast amount of resources is wasted on software projects delivering less than the planned benefits. The objective of this paper is to investigate the tendency to continue a project even when it is evident that it will not provide the expected benefits, often referred to as “project escalation” or “escalation of commitment.” We aim to identify factors that empirically have been found to promote software project escalation. We examined 1376 papers related to the phenomenon of escalating commitment to software projects and found that 44 of them included relevant empirical research. After reviewing these papers, we synthesized the results. We provide an overview of 46 factors that have been found to promote software project escalation. Thirteen of the factors were project-related, 20 were psychological factors, nine were social factors, and four were structural factors related to the project's contextual dimensions. We contribute to practice by systemizing empirical evidence of software project escalation that can be of help in avoiding it in the first place and uncovering already escalated situations. As most studies are investigations of only a few factors, we propose further research to study how factors potentially interplay as they contribute to escalation of software projects.}
}

@article{rayyan-727967935,
  title={A systematic review on test suite reduction: Approaches, experiment's quality evaluation, and guidelines},
  year={2018},
  journal={IEEE Access},
  issn={2169-3536},
  volume={6},
  pages={11816-11841},
  author={Rehman Khan, Saif Ur and Lee, Sai Peck and Javaid, Nadeem and Abdul, Wadood},
  keywords={Software testing, Systematics, Guidelines, Optimization, Testing, Web services, Software systems, experiments, Clustering algorithms, guidelines, regression testing, test suite reduction},
  abstract={Regression testing aims at testing a system under test (SUT) in the presence of changes. As a SUT changes, the number of test cases increases to handle the modifications, and ultimately, it becomes practically impossible to execute all of them within limited testing budget. Test suite reduction (TSR) approaches are widely used to improve the regression testing costs by selecting representative test suite without compromising effectiveness, such as fault-detection capability, within allowed time budget. The aim of this systematic review is to identify state-of-the-art TSR approaches categories, assess the quality of experiments reported on this subject, and provide a set of guidelines for conducting future experiments in this area of research. After applying a two-facet study selection procedure, we finalized 113 most relevant studies from an initial pool of 4230 papers published in the field of TSR between 1993 and 2016. The TSR approaches are broadly classified into four main categories based on the literature including greedy, clustering, search, and hybrid approaches. It is noted that majority of the experiments in TSR do not follow any specific guidelines for planning, conducting, and reporting the experiments, which may pose validity threats related to their results. Thus, we recommend conducting experiments that are better designed for the future. In this direction, an initial set of recommendations is provided that are useful for performing well-designed experiments in the field of TSR. Furthermore, we provide a number of future research directions based on current trends in this field of research.}
}

@article{rayyan-727967937,
  title={Synthesizing a comprehensive framework for lean software development},
  year={2013},
  pages={1-8},
  author={Jonsson, Henrik and Larsson, Stig and Punnekkat, Sasikumar},
  keywords={Software, Systematics, Systematic Literature Review, State of the art, Software Process Improvement, Organizations, Product development, Concrete, Lean production, Lean Software Development},
  abstract={Lean principles, originating from Japanese automotive industry, are anticipated to be useful to improve software development processes. Albeit its popularity there is still no generally accepted, clear and detailed definition of what lean software development actually means. This makes it difficult to perform research on the effects of lean software development and determine its usefulness in various contexts. To fill in that research gap this paper analyzes the state of the art based on twenty key Lean concepts derived from nine seminal sources identified in a systematic literature review. The original explanations of the key concepts have been elaborated further and synthesized into a framework for lean software development consisting of a set of goals, recommended activities and practices. The detailed results for the key concept Value are reported. The proposed framework is expected to serve as a basis for further research and for Lean assessment of organizations.}
}

@article{rayyan-727967939,
  title={Use of augmented reality for social communication skills in children and adolescents with autism spectrum disorder (ASD): A systematic review},
  year={2019},
  pages={1-7},
  author={Khowaja, Kamran and Al-Thani, Dena and Banire, Bilikis and Salim, Siti Salwah and Shah, Asadullah},
  keywords={virtual reality, technology, autism spectrum disorder, computer, data collection, intervention, mixed reality, research design, smartphone, social communication, augmented reality, Child Development Disorders, Pervasive, Adolescent, Autistic Disorder},
  abstract={The purpose of this review is to provide a systematic analysis of studies investigating the use of augmented reality (AR) to improve the social communications skills of individuals (children and adults) diagnosed with autism spectrum disorder (ASD). This review synthesizes the AR technology, research design, data collection methods, settings, and intervention outcomes. Across the studies, the effect of using AR towards the learning of individuals was positive. However, given the wide variety of skills targeted in the shortlisted studies, and the heterogeneity of the participants, a summative conclusion regarding the effectiveness of AR for teaching social communication skills to an individual with ASD based on the existing literature is not possible. Future research addressing this area as well as the relative effectiveness of AR among more participants, different technologies supporting AR, its intervention, and the evaluation in the classroom environment is warranted.}
}

@article{rayyan-727967940,
  title={mHealth technologies for chronic diseases and elders: A systematic review},
  year={2013},
  journal={IEEE Journal on Selected Areas in Communications},
  issn={1558-0008},
  volume={31},
  number={9},
  pages={6-18},
  author={Chiarini, Giovanni and Ray, Pradeep and Akter, Shahriar and Masella, Cristina and Ganz, Aura},
  keywords={systematic review, Systematics, Databases, taxonomy, Smart phones, Diseases, Mobile communication, Senior citizens, Chronic, elderly, mobile health, technologies, ubiquitous health, Chronic Disease},
  abstract={mHealth (healthcare using mobile wireless technologies) has the potential to improve healthcare and the quality of life for elderly and chronic patients. Many studies from all over the world have addressed this issue in view of the aging population in many countries. However, there has been a lack of any consolidated evidence-based study to classify mHealth from the dual perspectives of healthcare and technology. This paper reports the results of an evidence-based study of mHealth solutions for chronic care amongst the elderly population and proposes a taxonomy of a broad range of mHealth solutions from the perspective of technological complexity. A systematic literature review was conducted over 10 online databases and the findings were classified into four categories of predominant mHealth solutions, that is, self-healthcare, assisted healthcare, supervised healthcare and continuous monitoring. The findings of the study have major implications for information management and policy development in the context of the Millennium Development Goals (MDGs) related to healthcare in the world.}
}

@article{rayyan-727967941,
  title={Mobile cloud computing for disaster emergency operation: A systematic review},
  year={2015},
  pages={1-8},
  author={Geumpana, Teuku Aulia and Rabhi, Fethi and Lewis, John and Ray, Pradeep K and Zhu, Liming},
  keywords={systematic review, Systematics, Cloud computing, Mobile applications, Context, Reliability, Computer science, reliability, Mobile communication, availability, disaster emergency technology, MCC, mobile cloud solution, Disasters, Emergencies},
  abstract={The advancement of mobile cloud computing (MCC) has the potential to improve communication and information during disaster emergency operation. Many studies from different countries have addressed different approaches to implement mobile cloud technologies during disaster operation. However, there has been a lack of any consolidated evidence-based study to evaluate the MCC from the dual perspectives of disaster emergency situation and technology. In this paper, we provide an extensive study of mobile cloud computing research as a critical system or application based on the latest literature published from 2010 to 2015, and highlights the specific challenges in implementing mobile cloud computing in disaster emergency operation. A systematic literature review was conducted over 4 prominent journals of computer science engineering (IEEE, ACM, ProQuest, Inspec/Elsevier) and the findings were classified into four key challenges of MCC implementation during disaster emergency operation. We present a taxonomy based on the key challenges in this area, and discuss the different solutions taken to solve the challenges. We conclude the paper with a critical analysis of the challenges that have not been solved, and highlight directions for future work.}
}

@article{rayyan-727967942,
  title={Architectural approaches for implementing clinical decision support systems in cloud: A systematic review},
  year={2016},
  pages={42-47},
  author={Tabares, Luis and Hernandez, Jhonatan and Cabezas, Ivan},
  keywords={systematic review, Systematics, Data mining, Cloud computing, Databases, cloud computing, Medical services, Decision support systems, software architecture, clinical decision support systems, e-health, health care, Decision Support Systems, Clinical},
  abstract={Clinical Decision Support Systems (CDSS) were explicitly introduced in the 90's with the aim of providing knowledge to clinicians in order to influence its decisions and, therefore, improve patients' health care. There are different architectural approaches for implementing CDSS. Some of these approaches are based on cloud computing, which provides on-demand computing resources over internet. The goal of this paper is to determine and discuss key issues and approaches involving architectural designs in implementing a CDSS using cloud computing. To this end, we performed a standard Systematic Literature Review (SLR) of primary studies showing the intervention of cloud computing on CDSS implementations. Twenty-one primary studies were reviewed. We found that CDSS architectural components are similar in most of studies. Cloud-based CDSS are most used in Home Healthcare and Emergency Medical Systems. Alerts/Reminders and Knowledge Service are the most common implementations. Major challenges are around security, performance and compatibility. We concluded on the benefits of implementing a cloud-based CDSS, since it allows cost-efficient, ubiquitous and elastic computing resources. We highlight that some studies show weaknesses regarding the conceptualization of a cloud-based computing approach and lack of a formal methodology in the architectural design process.}
}

@article{rayyan-727967944,
  title={Factors limiting industrial adoption of test driven development: A systematic review},
  year={2011},
  pages={337-346},
  author={Causevic, Adnan and Sundmark, Daniel and Punnekkat, Sasikumar},
  keywords={systematic review, Systematics, Data mining, Testing, Databases, Programming, empirical studies, agile software development, Protocols, Limiting, Test driven developmen, unit testing},
  abstract={Test driven development (TDD) is one of the basic practices of agile software development and both academia and practitioners claim that TDD, to a certain extent, improves the quality of the code produced by developers. However, recent results suggest that this practice is not followed to the extent preferred by industry. In order to pinpoint specific obstacles limiting its industrial adoption we have conducted a systematic literature review on empirical studies explicitly focusing on TDD as well as indirectly addressing TDD. Our review has identified seven limiting factors viz., increased development time, insufficient TDD experience/knowledge, lack of upfront design, domain and tool specific issues, lack of developer skill in writing test cases, insufficient adherence to TDD protocol, and legacy code. The results of this study is of special importance to the testing community, since it outlines the direction for further detailed scientific investigations as well as highlights the requirement of guidelines to overcome these limiting factors for successful industrial adoption of TDD.}
}

@article{rayyan-727967945,
  title={Providing a consensus definition for the term "Smart Product"},
  year={2013},
  pages={203-211},
  author={Gutiérrez, César and Garbajosa, Juan and Diaz, Jessica and Yagüe, Agustin},
  keywords={Software, systematic literature review, Systematics, SLR, Quality assessment, Ontologies, Context, Industries, Technological innovation, innovation, intelligent product, smart product, smart thing, software engineering innovation, thematic synthesis},
  abstract={The term "Smart Product" has become commonly used in recent years. This is because there has been an increasing interest in these kinds of products as part of the consumer goods industry, impacting everyday life and industry. Nevertheless, the term "Smart Product" is used with different meanings in different contexts and application domains. The use of the term "Smart Product" with different meanings and underlying semantics can create important misunderstandings and dissent. The aim of this paper is to analyze the different definitions of Smart Product available in the literature, and to explore and analyze their commonalities and differences, in order to provide a consensus definition that satisfies, and can therefore be used by, all parties. To embrace the identified definitions, the concept of "Smart Thing" is introduced. The methodology used was a systematic literature review. The definition is expressed as an ontology.}
}

@article{rayyan-727967947,
  title={Research landscape of patterns and architectures for IoT security: A systematic review},
  year={2020},
  pages={463-470},
  author={Rajmohan, Tanusan and Nguyen, Phu H and Ferry, Nicolas},
  keywords={Software, Systematics, Security, Internet of Things, Survey, Databases, Privacy, IoT, Architecture, Computer architecture, Patterns},
  abstract={We have entered a tremendous computerized rev-olution of the Internet of Things (IoT) era when everything is connected. The popularity of IoT systems makes security for the IoT of paramount importance. Security patterns consist of domain-independent time-proven security knowledge and expertise. Would they be applicable to develop secure IoT systems? We aim to draw a research landscape of patterns and architectures for IoT security by conducting a systematic literature review. From more than a thousand of candidate papers, we have systematically distinguished and analyzed twenty-two (22) papers that have been published around patterns and architectures for IoT security (and privacy). Our analysis shows a rise in the number of publications tending to security patterns and architectures in the last two years. Within this rise, we see that most patterns and architectures are applicable for all IoT systems, while some are limited within specific domains. However, there are gaps in this research area that can be filled in to promote the utilization of patterns for IoT security and privacy.}
}

@article{rayyan-727967948,
  title={Towards the guidelines for requirements change management in global software development: Client-vendor perspective},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={76985-77007},
  author={Akbar, Muhammad Azeem and Sang, Jun and Nasrullah and Khan, Arif Ali and Shafiq, Muhammad and Fazal-E-Amin},
  keywords={Software, Systematics, Global software development (GSD), systematic literature review (SLR), Organizations, Best practices, Standards organizations, Capability maturity model, client, requirements change management (RCM), vendor, best practices, empirical investigation},
  abstract={Currently, being deployed by organizations to develop high-quality software at a low cost, global software development (GSD) faces many challenges that make development activities more complex. These GSD challenges are mainly concerned with requirements to change management (RCM). RCM plays a key role in the successful execution of software projects. The objective of this paper is to identify the best practices of the RCM process by adopting a systematic literature review (SLR) and validate them using questionnaire survey with industry experts. A total of 46 best practices were identified through SLR and validated with industry experts. We have further classified the identified practices in the domain of client and vendor GSD organizations with the aim to provide a clear understanding of the RCM best practices in the context of both types of GSD organizations (client, vendor). Moreover, we have conducted a comparison analysis between SLR and questionnaire survey data and found a moderate positive correlation in the ranks of both data sets (rs = 0.522, p=0.003). In addition, the criticality of the identified best practices was assessed using the criteria of a practice having frequency ≥50%. The findings of this paper provide a framework that could help the GSD organizations to address the problems related to RCM in GSD environment.}
}

@article{rayyan-727967950,
  title={A systematic review on methods and techniques for optimizing assistive virtual keyboards},
  year={2015},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={13},
  number={8},
  pages={2687-2693},
  author={Sousa Gomide, Renato and Loja, Luiz Fernando and Lucia Flores, Edna and Pinto Lemos, Rodrigo and de Carvalho, Sirlon and de Matos Silva, Rafael},
  keywords={Software, Internet, Systematics, Optimization, Systematic Review, Portals, IEEE Xplore, Alternative and Augmentative Communication, Keyboards, Speech, Type Performance, Virtual Keyboards},
  abstract={Locked-In Syndrome is admittedly the worst case of motor and speech impairment, seriously damaging the ability of oral and gestural communication of patients. In recent years, alternative and augmentative communication technology has provided resources to restore these patients' ability to communicate. Among the various methods and existing communication software, we can highlight the virtual keyboard. However, the data entry for these keyboards is considerably slower than entering information through physical keyboards. In order to identify the main approaches employed to optimize the data entry on virtual keyboards, we performed a systematic review by searching for papers in databases. As a result, we found 250 articles and selected 31 papers among them to compose this research. Analyzing these articles, we identified five methods for optimizing data entry performance and 15 ways of implementing them. In addition, this review contains a critical analysis regarding the optimization methods and assistive virtual keyboards.}
}

@article{rayyan-727967951,
  title={Computational games in STEM courses: a systematic review of the literature},
  year={2020},
  pages={1-8},
  author={da Silva Neves Lima, Priscila and das Almas Silva, Laira and dos Santos Oliveira, João Lucas and Franco Brandão, Anarosa Alves and de Oliveira Brandão, Leônidas},
  keywords={Systematic review, Databases, Education, Games, Physics, Planning, Programming profession, Computational, digital, Higher education, STEM, STEM education},
  abstract={This full paper of Research Category presents the main results of a systematic review of the literature about the use of computer games in science, technology, engineering, and mathematics (STEM) courses. The concept of lifelong learning has often been encouraged in literature. However, it also reports students facing difficulties in exact sciences since elementary school: a significant challenge to overcome. Among the reasons for such difficulties are demotivation, disinterest, learning difficulties, and even the use of outdated teaching-learning methods. In an attempt to improve the relationship between students and exact sciences, schools are expanding the use of information technologies to offer the students interactive environments in order to enrich their classes. In this context, characteristics of digital games appear as a didactic resource that can benefit the students' learning process. If properly used, digital games can stimulate memory, creativity, socialization, and also incite curiosity. Due to the ease young students have with games and considering the benefits mentioned above, many institutions have been investing in digital games (or environments with some of their characteristics). However, these games can generate compulsive behaviors (WHO classified such disorders in 2018), and it is worth noticing that many articles reporting the use of games in education focus mainly on its acceptance instead of its teaching capabilities. In this article, we report the main findings, such as that technology is the area with the highest concentration of digital games. It is also observed that different guiding theories appear, such as those with a constructivist tendency. Among the arguments for using games stand out: the gain in cognitive skills, the possibility of using simulations, and the ease in understanding complex themes. The methods of didactic-pedagogical evaluation mostly used are questionnaires of acceptance or the student's perception. This review highlights the potential of digital games to promote learning. However, these games should not be focused solely on their ludic aspect, as they have a different purpose from regular games. Active methodologies mediated by information and communication technologies can make class more engaging as students actively participate in the construction of student learning.}
}

@article{rayyan-727967953,
  title={Implementation of case-method cycle for case-based reasoning in human medical health: A systematic review},
  year={2019},
  pages={1-6},
  author={Elisabet, Damayanti and Sensuse, Dana Indra and Al Hakim, Shidiq},
  keywords={knowledge management, health care, case-based reasoning, case-method cycle, medical health, Humanities, Humanism, Humans},
  abstract={Reasoning diagnosis and treatments in human medical health fields are a complicated task. While the effort of doctors, physicians, or clinicians to study medical journals and another source of knowledge is hardly done. Studies tried to design and develop a medical health system that imitates the way humans determine diagnoses by studying past cases and medical journals using case-based reasoning (CBR). This study reviews research publications in human medical health that used CBR using the Kitchenham method. The result of this study is identification challenge developing the human medical health system and the reason for using CBR, identification kinds of knowledge that have been used and methods for capturing knowledge, and identification of implementation using CBR in human medical health.}
}

@article{rayyan-727967956,
  title={Review of architectural patterns and tactics for microservices in academic and industrial literature},
  year={2018},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={16},
  number={9},
  pages={2321-2327},
  author={Marquez, Gaston and Osses, Felipe and Astudillo, Hernan},
  keywords={Software, Systematic literature review, Systematics, industry, Monitoring, Microservices, Taxonomy, Architectural patterns, taxonomy, Google, Silicon compounds, IEEE transactions, Academy, Architectural tactics},
  abstract={Microservices are an emerging trend for development of service-oriented software. This approach proposes to build each application as a collection of small services running on separate process and inter-communicating with lightweight mechanisms. Systematic development of microservices is hampered by the lack of a catalog of emerging recurrent architectural solutions (architectural patterns) and design decisions (architectural tactics). This article describes a systematic review of academic and industrial literature regarding architectural patterns and architectural tactics for microservices. The review yield 44 architectural patterns in academic sources and 74 in industrial ones, as well as a few architectural tactics originally proposed to address related problems. Most architectural patterns and tactics are associated to one of just five quality attributes: scalability, flexibility, testability, performance, and elasticity. Also, most microservices in academic (but not industrial) literature are related to DevOps and IoT. The findings lead to propose a new taxonomy of microservice architectural patterns.}
}

@article{rayyan-727967958,
  title={Investigating key areas of research in crowdsourcing software development},
  year={2017},
  pages={1-5},
  author={Sharma, Shruti and Hasteer, Nitasha and Van Belle, Jean-Paul},
  keywords={Software, Software engineering, Systematics, Crowdsourcing, Task analysis, Systematic Review, Information systems, Conferences, Crowdsourced platforms, Crowdsourcing Software Development},
  abstract={Crowdsourcing Software Development implies outsourcing software development to crowd through an open call. This way of development is emerging out to be beneficial for software development organisations. It involves task decomposition and broader participation by way of which we get effective and diverse solutions. This is carried out by an open call invitation to the crowd who voluntarily participate in this activity. We have carried out a systematic review of the literature to identify focus areas of the field. In this work we report the key areas of research in this emerging software development paradigm.}
}

@article{rayyan-727967961,
  title={A systematic review of the application and empirical investigation of search-based test case generation},
  year={2010},
  journal={IEEE Transactions on Software Engineering},
  issn={1939-3520},
  volume={36},
  number={6},
  pages={742-762},
  author={Ali, Shaukat and Briand, Lionel C and Hemmati, Hadi and Panesar-Walawege, Rajwinder Kaur},
  keywords={Software testing, Guidelines, Automation, Automatic testing, System testing, Scalability, Genetic algorithms, Costs, Algorithm design and analysis, Evolutionary computing and genetic algorithms, frameworks, heuristics design, Logic testing, review and evaluation, test generation, testing strategies, validation.},
  abstract={Metaheuristic search techniques have been extensively used to automate the process of generating test cases, and thus providing solutions for a more cost-effective testing process. This approach to test automation, often coined “Search-based Software Testing” (SBST), has been used for a wide variety of test case generation purposes. Since SBST techniques are heuristic by nature, they must be empirically investigated in terms of how costly and effective they are at reaching their test objectives and whether they scale up to realistic development artifacts. However, approaches to empirically study SBST techniques have shown wide variation in the literature. This paper presents the results of a systematic, comprehensive review that aims at characterizing how empirical studies have been designed to investigate SBST cost-effectiveness and what empirical evidence is available in the literature regarding SBST cost-effectiveness and scalability. We also provide a framework that drives the data collection process of this systematic review and can be the starting point of guidelines on how SBST techniques can be empirically assessed. The intent is to aid future researchers doing empirical studies in SBST by providing an unbiased view of the body of empirical evidence and by guiding them in performing well-designed and executed empirical studies.}
}

@article{rayyan-727967963,
  title={Identifying risks of software project management in Global Software Development: An integrative framework},
  year={2016},
  pages={1-7},
  author={Chadli, Saad Yasser and Idri, Ali and Fernández-Alemán, José Luis and Ros, Joaquín Nicolás and Toval, Ambrosio},
  keywords={systematic review, Software, Systematics, Project management, Risk management, Context, Software Project Management, Organizations, Libraries, Global Software Development, risk identification},
  abstract={Global Software Development (GSD) poses inherent risks to projects success. Project managers are now faced with new challenges related to the geographical, temporal and socio-cultural distances between stakeholders. The objective of this research is to identify challenges associated with Software Project Management (SPM) activities in a GSD context and present an integrative framework encompassing them. Using a Systematic Literature Review (SLR), 39 risk factors were identified and later compiled into a framework inspired from the model of organizational change.}
}

@article{rayyan-727967964,
  title={The use of artificial neural networks in network intrusion detection: A systematic review},
  year={2018},
  pages={1-6},
  author={ÖNEY, Mehmet Uğur and PEKER, Serhat},
  keywords={Systematics, Bibliographies, Data mining, Search problems, Databases, Neural networks, Literature Review, Systematic Mapping, ANNs, Intrusion detection, Network Intrusion Detection, Neural Networks, Nerve Net, Neural Networks (Computer)},
  abstract={Network intrusion detection is an important research field and artificial neural networks have become increasingly popular in this subject. Despite this, there is a lack of systematic literature review on that issue. In this manner, the aim of this study to examine the studies concerning the application artificial neural network approaches in network intrusion detection to determine the general trends. For this purpose, the articles published within the last decade from 2008 to 2018 were systematically reviewed and 43 articles were retrieved from commonly used databases by using a search strategy. Then, these selected papers were classified by the publication type, the year of publication, the type of the neural network architectures they employed, and the dataset they used. The results indicate that there is a rising trend in the usage of ANN approaches in the network intrusion detection with the gaining popularity of deep neural networks in recent years. Moreover, the KDD'99 dataset is the most commonly used dataset in the studies of network intrusion detection using ANNs. We hope that this paper provides a roadmap to guide future research on network intrusion detection using ANNs.}
}

@article{rayyan-727967967,
  title={Analysing the concept of quality in model-driven engineering literature: A systematic review},
  year={2014},
  pages={1-12},
  author={Giraldo, Fáber D and España, Sergio and Pastor, Oscar},
  keywords={systematic review, Software, Context modeling, Context, Unified modeling language, Model quality, software quality, Proposals, Computational modeling, Data models, model-driven engineering, modelling language quality},
  abstract={The Model-Driven Engineering (MDE) research must manage a diversity of conceptions despite the global truth about the use of conceptual models as one way for representing and managing the development of complex information systems. Due to this diversity of conceptions and the multiple MDE compliance interpretations, a pletora of definitions about quality in models are emerging, each one tackling specific dimensions involved in MDE projects. In order to explore a consensus about quality in models and model-driven contexts an identification of the previous proposals for quality in models is needed. The main contribution of this work is the identification of representative trends about quality definition in MDE, and therefore, exposing the implications of the multiple quality interpretations as consequence of the diversity in MDE compliance works.}
}

@article{rayyan-727967968,
  title={Architecting for the cloud: A systematic review},
  year={2014},
  pages={312-318},
  author={Breivold, Hongyu Pei and Crnkovic, Ivica and Radosevic, Iva and Balatinac, Ivan},
  keywords={Data mining, Security, Cloud computing, Architecture, Cloud Computing, Business, Computer architecture, cloud-based architecture, concerns, Elasticity},
  abstract={Cloud Computing has emerged as a new paradigm in the field of network-based services within many industrial and application domains. The major benefits that it provides in terms of IT efficiency and business agility represent a huge competitive advantage for an organization. However, building new services in the cloud or designing cloud-based solutions into existing business context in general is a complex decision process involving many factors. In this paper, we undertake a systematic review to obtain an overview of the existing studies in designing cloud-based solutions. In particular, we investigate the main challenges and concerns when building cloud-based architectures and different architectural approaches and design considerations that are proposed in literatures to meet these specific concerns. The search strategy identified 72 studies that were catalogued as primary studies for this review after using multi-step selection process. The main challenges and concerns are classified into four main categories: security and trustworthiness, elasticity, portability and interoperability, and cloud resilience. We have also categorized studies that describe architectural approaches and design considerations when architecting for the cloud. Implications for research and practice are presented as well.}
}

@article{rayyan-727967969,
  title={Data mining in sports: A systematic review},
  year={2018},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={16},
  number={1},
  pages={232-239},
  author={Parmezan Bonidia, Robson and Duilio Brancher, Jacques and Marques Busto, Rosangela},
  keywords={Systematics, Data mining, Data Mining, Google, Libraries, Electronic mail, IEEE transactions, Training, Data Mining in Sports, Sports},
  abstract={Data mining technique has attracted attention in the information industry and society as a whole, because of the big amount of data and the imminent need to transform that data into useful information and knowledge. Recently conducted studies with successfully demarcated results using this technique, to estimate several parameters in a variety of domains. However, the effective use of data in some areas is still developing, as is the case of sports, which has shown moderate growth. In this context, the objective of this article is to present a systematic review of the literature about research involving sports data mining. As systematic searches were made out in five databases, resulting in 21 articles that answered a question that grounded this article.}
}

@article{rayyan-727967970,
  title={A systematic review on the use of LEGO® robotics in education},
  year={2018},
  pages={1-9},
  author={Souza, Isabelle M L and Andrade, Wilkerson L and Sampaio, Lívia M R and Araujo, Ana Liz Souto O},
  keywords={Systematics, Education, Computer languages, Programming environments, Educational robots, Erbium, Robotics},
  abstract={Educational Robotics (ER) has revealed several benefits in the educational context, not only helping the teaching of disciplines, but also making possible the development of several abilities, such as teamwork, problem-solving, and creativity. Among various robotics kits, LEGO® Robotics has been shown one of the best results considering some evaluated criteria (modularity level, hardware, curriculum, price, etc.). Some studies analyze the teaching practices, some compare technologies, and others evaluate the kits in a pedagogical way. However, it is essential to investigate all these contexts together in order to improve the impact produced by the ER in education and to know the best teaching practices associated with the most powerful technologies. The objective of this Research Full Paper is to identify: a) environments and programming languages adopted in the LEGO® Robotics context, b) educational practices applied during classes based on LEGO® Robotics, and c) the educational levels in which robotics has been applied with positive results. To achieve these goals, we planned and carried out a systematic review of the literature. Our main findings are: a) the most widely used environment and programming language are LabVIEW along with the LEGO®'s block-based programming language, b) we identified LEGO® Robotics is used for teaching programming, interdisciplinary contents, participation in tournaments, robotics, and computational thinking, c) LEGO® Robotics is used with success by students of different levels, such as K12, undergraduate, and graduated. Finally, we discuss some problems and limitations related to ER and point out that there is no standardization of teaching practices or methodologies for evaluating results, indicating that more research is needed to find the best scenario regarding technologies, methods, and target audience.}
}

@article{rayyan-727967971,
  title={Computational intelligence techniques used for stock market prediction: A systematic review},
  year={2020},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={18},
  number={4},
  pages={744-755},
  author={Zavadzki, S and Kleina, M and Drozda, F and Marques, M},
  keywords={Literature Review, Computational intelligence, Computational modeling, Biological system modeling, Artificial neural networks, Autoregressive processes, Computational Intelligence, Economic Engineering, Financial Model, Stock Market Forecast, Stock markets, Intelligence},
  abstract={With the advancement of various computational techniques and the growing search for assertive predictive models, computational intelligence methods have attracted much attention. They are data-based methodologies and mainly include fuzzy logic, artificial neural networks and evolutionary computation. In the economic environment, more specifically, in the stock market forecast, where there is the challenge of the time series volatility, these methods have stood out. In this context, the objective of this paper is to present a systematic review of the literature on recent research involving forecasting techniques in the stock market, and the computational intelligence were the ones that stood out. To define these techniques, articles were collected from four large databases and a keyword filter was applied, which reduced the initial volume. So we selected the articles from the most published journals and remove duplicated articles. The most articles applied hybrid models and for the selection of featured techniques were choose those most frequent ones. A brief description was also made of the most used methods as well as of the selected articles. The review was done with articles published between the years 2014 and 2018 taken from four databases and, after some selection criteria, 24 articles were selected by relation to the subject studied.}
}

@article{rayyan-727967972,
  title={Health ontology and information systems: A systematic review},
  year={2017},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={15},
  number={1},
  pages={103-120},
  author={Corral Diaz, Maria Alexandra and Antonelli, Leandro and Sanchez, Luis Enrique},
  keywords={Software, Ontology, Ontologies, Interoperability, Semantics, Medical services, Biomedical informatics, Health, Medical information system, Semantic, Information Systems},
  abstract={One of the most important aspects for the development of information systems is that they were interoperable, so many initiatives consider that ontologies as useful tools for their development, especially when the application is in complex and dynamic domains as the case of health. In this article, a systematic review (SR) of the existing literature related to ontologies used in the health sector is carried out, not only to interpret and synthesize the available studies but also to provide a framework as a basis for conducting new researches. Recent publications (2010- 2016) in which topics such as the use and impact of ontologies in the development of information systems are discussed, taking into account the organizational objectives and the involved stakeholders were considered. The number of published studies shows a growing interest by researchers because they consider ontologies artifacts that facilitate interoperability, understanding of information and communication structures.}
}

@article{rayyan-727967973,
  title={Virtual reality and fetal medicine — A systematic review},
  year={2017},
  pages={1-10},
  author={Yoshida, Emilia A and Castro, Márcia L A and Martins, Valéria F},
  keywords={Software, Visualization, Virtual reality, Medical diagnostic imaging, Fetal Medicine, Fetus, Lasers, Virtual Reality},
  abstract={This work brings a Systematic Review on the use of Virtual Reality in Fetal Medicine in order to recover the state of the art on the use of Virtual Reality tools in Fetal Medicine and also which Fetal Medicine areas has been focus of Virtual Reality application. The keywords “Virtual Reality” and “Fetal Medicine”, “Virtual Reality” and “Fetus” were used in both Portuguese and English and the “And” operator, where 24 papers were found after using inclusion and exclusion criteria, from 2001 to 2014. It presents some statistics on studied items and uses the most relevant papers found in virtual databases, to present the results and benefits this technology can bring to the field of fetal medicine, especially in the analysis of diseases, abnormalities and birth defects, as well existing and used tools.}
}

@article{rayyan-727967976,
  title={Decision support system for risk assessment and management strategies in distributed software development},
  year={2017},
  journal={IEEE Access},
  issn={2169-3536},
  volume={5},
  pages={20349-20373},
  author={Aslam, Adeel and Ahmad, Naveed and Saba, Tanzila and Almazyad, Abdulaziz S and Rehman, Amjad and Anjum, Adeel and Khan, Abid},
  keywords={Software, Bibliographies, Guidelines, Decision making, Risk management, Distributed software development, Companies, Decision support systems, decision support system, risk analysis, Risk Assessment},
  abstract={Risk management in distributed software development (DSD) is a well-researched area, providing different methods for assessing risks and suggesting control strategies. However, some of these methods are narrow in scope, only considering few risks, and are too complex to be used in practice whereas others provide many rules and guidelines which are often implicit. Moreover, the knowledge related to risks in DSD is scattered over different publications which make it difficult to find relevant information to be used in practice. This research aims to develop an automated decision support system to aid practitioners in assessing risks and deciding on suitable control strategies. In order to construct the knowledge base for the proposed decision support system, a systematic literature review (SLR) is conducted. Results of SLR are used to identify required questions, options and set of rules to implement our decision support system (DSS). In total 80 studies were identified from which 49 aspects, 53 questions, and a set of rules are extracted. DSS is evaluated through multiple case studies. The results indicate that the developed DSS supports decision-making process in risk assessment and selection of control strategy.}
}

@article{rayyan-727967981,
  title={The impact of scope creep on project success: An empirical investigation},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={125755-125775},
  author={Komal, Bakhtawar and Janjua, Uzair Iqbal and Anwar, Fozia and Madni, Tahir Mustafa and Cheema, Muhammad Faisal and Malik, Muhammad Noman and Shahid, Ahmad Raza},
  keywords={Software, Systematics, Bibliographies, Project management, Scope management, Organizations, Mathematical model, Creep, partial least squares structural equation modeling, requirement creep, scope creep, software project success},
  abstract={Advocates of software engineering and software project management stated in the literature that creeping of scope is one of the most common causes for the failure of software projects. Also, advocates believed that it could occur in almost every software project, which leads to compromise in quality, delayed schedules, increase cost and decreased customer satisfaction. However, the lack of empirical evidence demands a comprehensive investigation to identify the factors of scope creep and to propose a conceptual framework to empirically evaluate the impact of scope creep on software project success. To determine the scope creep factors in this study, two exploratory methods, i.e. a Systematic Literature Review (SLR) and interview from experts are performed. Following the analysis of these methods, a conceptual framework is proposed. To empirically evaluate the proposed conceptual framework, data is collected through a survey method. Next, the collected data is analyzed through Partial Least Squares' Structural Equation Modelling (PLS-SEM). From the results, it is evident that the identified factors of scope creep are negatively associated with software project success. The results of empirical evaluation also second the findings of SLR. The outcome of the study may help the practitioners to understand the dynamics of factors, which undermine scope creep in software SMEs and to assist them in the development of effective control and mitigation strategies, therefore, to increase the project success rate.}
}

@article{rayyan-727967984,
  title={Strategies focused on the teaching of programming logic: A systematic review of brazilian literature},
  year={2018},
  pages={292-298},
  author={de Oliveira, Tiago and Stringhini, Denise and Corrêa, Deborah Godoy Martins},
  keywords={Education, Games, Informatics, Conferences, Portals, robotics, Programming profession, games, multiple intelligences, programming logic, Scratch},
  abstract={This article aims to present the results obtained from the systematic of the Brazilian literature on teaching and learning the discipline of Programming Logic (LP), considering the articles published in the Brazilian Journal of Informatics in Education (RBIE), in the annals of the Brazilian Symposium on Informatics (SBIE), in the annals of the Computer Science Workshops (WIE), in the Brazilian Congress of Informatics in Education (CBIE) and in the Journey of Updating in Computer Science at School (JAIE) between 2012 and 2017. From this mapping the strategies used in teaching LP in Basic Education, High School and Higher Education were analyzed, and was verified that the subject remains a great challenge to be overcome. Additionally, this work investigates if Multiple Intelligences are being considered in the adoption of teaching techniques - the goal is to establish a future work on this subject. Results show that Scratch and Games are the most cited in Brazilian literature and that Multiple Intelligences are still an open research field in this context.}
}

@article{rayyan-727967985,
  title={A widening digital platform gap: A systematic review of the sharing economy for small and micro enterprises},
  year={2019},
  pages={1-12},
  author={Abebe, Sertse and Twinomurinzi, Hossana},
  keywords={Market research, Technological innovation, Employment, Entrepreneurship, Manufacturing, Three-dimensional displays, Two dimensional displays},
  abstract={Information and Communication Technology (ICT) presents immense opportunities to SMEs by providing platforms to share resources and to collaborate better. The umbrella concept that explains the coordinated effort of people to share resources and collaborate through digital platforms is generally known as the Sharing Economy (SE). This study investigated SE research trends and gaps from the context of SMEs. The exploration analyzed six different SE aspects from 77 previous SE studies in the context of SMEs. These aspects included SE forms, values of SE for SMEs, SMEs sectors, the context of nations, geographic origin of data and cases, and methodological.}
}

@article{rayyan-727967990,
  title={A study of ontology-based knowledge management system in academic domain},
  year={2019},
  pages={1-5},
  author={Rokhman, Mokhammad Fathoni and Indra Sensuse, Dana and Hakim, Shidiq Al and Satria, Deki},
  keywords={systematic review, Data mining, Search problems, Quality assessment, Knowledge management, Ontologies, ontology, Taxonomy, Libraries, knowledge management, academic},
  abstract={The purpose of this paper is to review the use of ontology in the field of knowledge management in the academic domain. To conducting this systematic review, we used the guidelines from Kitchenham and used collected data sources from IEEE Xplore, Scopus, Emerald Insight, and ACM Digital Library. We collect paper from data sources by using boolean search through available tools in each publisher. The papers collected were only limited to the last five years and those using ontology as taxonomies. Our data search results found 346 articles, and there were 26 suitable articles selected based on the selection criteria we defined. Our findings concluded six types of ontology models contained in ontology-based knowledge management and three areas that mostly used ontology-based knowledge management systems. Finally, we also found important classes that form the basis for making an ontology used in knowledge management.}
}

@article{rayyan-727967991,
  title={Survey of applications for apartment energy consumption monitoring},
  year={2019},
  pages={283-288},
  author={Saari, Mika and Sillberg, Pekka and Grönman, Jere and Rantanen, Petri and Jaakkola, Hannu and Henno, Jaak},
  keywords={Systematic literature review, IoT, Energy consumption, API, Energy saving, Network API, Sensor Networks, Sensors and Monitoring},
  abstract={Nowadays energy consumption and especially energy saving are hot topics. The news about global warming has increased the need to save energy. In Finland, one of the major energy consumers is housing. The heating of residential buildings accounts for up to 68% of housing energy consumption. The second largest consumer of energy is heating water, at 15%. Therefore, it is not surprising that apartment energy consumption is a popular research topic in Finland. In particular, this study tries to find ways to increase energy savings - without forgetting comfortable living. This paper introduces the results of a study exploring the research subjects of energy saving in the area of real estate and housing. The research methodology is a literature survey and primary articles were selected by means of a systematic literature review. This study presents a way to categorize research papers with diverse themes. In addition, the survey reveals the most recent trends in research and practical applications of energy saving as well as efforts toward energy saving in the area of real estate and housing.}
}

@article{rayyan-727967992,
  title={A taxonomy of quality metrics for cloud services},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={131461-131498},
  author={Guerron, Ximena and Abrahão, Silvia and Insfran, Emilio and Fernández-Diego, Marta and González-Ladrón-De-Guevara, Fernando},
  keywords={systematic literature review, Systematics, Cloud computing, Measurement, Software quality, Quality of service, Taxonomy, metrics, Elasticity, cloud services, NIST, Metronidazole},
  abstract={A large number of metrics with which to assess the quality of cloud services have been proposed over the last years. However, this knowledge is still dispersed, and stakeholders have little or no guidance when choosing metrics that will be suitable to evaluate their cloud services. The objective of this paper is, therefore, to systematically identify, taxonomically classify, and compare existing quality of service (QoS) metrics in the cloud computing domain. We conducted a systematic literature review of 84 studies selected from a set of 4333 studies that were published from 2006 to November 2018. We specifically identified 470 metric operationalizations that were then classified using a taxonomy, which is also introduced in this paper. The data extracted from the metrics were subsequently analyzed using thematic analysis. The findings indicated that most metrics evaluate quality attributes related to performance efficiency (64%) and that there is a need for metrics that evaluate other characteristics, such as security and compatibility. The majority of the metrics are used during the Operation phase of the cloud services and are applied to the running service. Our results also revealed that metrics for cloud services are still in the early stages of maturity - only 10% of the metrics had been empirically validated. The proposed taxonomy can be used by practitioners as a guideline when specifying service level objectives or deciding which metric is best suited to the evaluation of their cloud services, and by researchers as a comprehensive quality framework in which to evaluate their approaches.}
}

@article{rayyan-727968002,
  title={State of the art of machine learning for product sustainability},
  year={2020},
  pages={197-202},
  author={Singhal, Swasti and Ahuja, Laxmi and Monga, Himanshu},
  keywords={Systematic literature review, Systematics, Search problems, Machine learning, Production, Business, Predictive models, Sustainable development, Machine Learning (ML), Product sustainability},
  abstract={Nowadays, the feasibility and life-time for every business venture is dependent on the generation of sustainable products and services. Almost all businesses and industries have endorsed Machine Learning (ML) technologies. The application of Machine Learning in determining the sustainability aspects is quite a challenging process. ML models can help in capturing the decision-making processes or predict the sustainability evaluation metrics assuming some key aspects such as triple bottom line and life-cycle factors are provided to the models. The main aim of this paper is to present a systematic review of studies related to the product sustainability assessments, framework development using Machine Learning techniques. Search strategies are applied to the most common computer science digital database libraries from 2010 to 2020 in the field of product sustainability using machine learning techniques. 15 out of 23 papers are shortlisted as was considered suitable for this research. A set of the research queries are defined and addressed by the review process. Based on the findings obtained in this literature review, future outlook in the field of Machine Learning for sustainable production is represented.}
}

@article{rayyan-727968003,
  title={Big data applied to tax evasion detection: A systematic review},
  year={2016},
  pages={435-440},
  author={Abrantes, Paulo Cesar and Ferraz, Felipe},
  keywords={big data, Scientific computing, Computational intelligence, 5G mobile communication, financial fraud, tax evasion, tax fraud detection},
  abstract={Tax evasion fraud is an issue faced by all governments in the world and one way to improve its detection is the application of big data technologies. This work performs a systematic literature review with the objective of identifying primary studies that address the fraud tax detection by the use of big data. This review resulted in the finding of 56 works of which 5 were identified as primary study. An overview of the results is presented categorized by the studies that address the problem by the use of pattern recognition methodologies, natural language processing and data analytics in auditing. The results also present algorithms and models used in each solution.}
}

@article{rayyan-727968004,
  title={Adapting software with affective computing: a systematic review},
  year={2019},
  journal={IEEE Transactions on Affective Computing},
  issn={1949-3045},
  pages={1},
  author={Aranha, Renan Vinicius and Corrêa, Cléber Gimenez and Nunes, Fátima L S},
  keywords={Software, Systematics, Protocols, Affective Computing, Affective Adaptation, Affective computing, Computer applications, Emotion recognition},
  abstract={Strategies aimed at keeping the user's interest in using computer applications are being studied to provide greater user engagement, and can influence how people interact with computers. One of the approaches that can promote user engagement is Affective Computing (AC), based on the premise of recognizing the user's emotional state and adjusting the computer application to respond to such state in real-time. Although it is a relatively new area, over the past few years many research works have investigated the use of AC in various activities and objectives. To provide an overview on the use of AC in computer applications, this article presents a systematic literature review based on available articles on the main scientific databases of the Computer Science area. The main contribution of this review is the analysis of different types of applications. Based on the 58 articles analyzed, the main emotion recognition techniques and approaches to the adaptation of computer applications, as well as the limitations and challenges to be overcome were compiled. Our conclusions present the limitations and challenges still to be overcome in the area of automatic adaptation of computer applications by means of AC.}
}

@article{rayyan-727968005,
  title={Microservices identification strategies : A review focused on model-driven engineering and domain driven design approaches},
  year={2020},
  pages={1-6},
  author={Schmidt, Roger Anderson and Thiry, Marcello},
  keywords={Systematics, Databases, Unified modeling language, MDE, Protocols, Proposals, Data models, microservices, DDD, decomposition, domain-driven., granularity, identification, model-driven},
  abstract={A proper architectural design for a microservices system is crucial for its success. Although there are several design strategies to identify software components in general, microservices demands special consideration. In this context of distributed systems, the component size directly impacts on nonfunctional requirements, such as performance, flexibility, reusability, etc. Design practices of coupling and cohesion have to be fine-tuned to determine the ideal microservices granularity. In order to shed light on this question, this study conducted a Systematic Literature Review that investigates microservices identification proposals. From procedures and guidelines inspired by Kitchenham et al., a rigorous research protocol was defined and performed, that covers publications from 2013 to 2019. Starting with an initial screening of 715 papers, 27 studies were considered relevant to answer four research questions. Besides microservices decomposition strategies, this review underlines Model Driven Engineering and Domain Driven Design, once they represent valuable approaches to support this challenging task. Moreover, this work highlights that only a few studies had explored these approaches in their strategies, which opens promising potential for further research.}
}

@article{rayyan-727968006,
  title={Risks and uncertainties in cloud computing: Literature review, trends and gaps},
  year={2017},
  journal={IEEE Latin America Transactions},
  issn={1548-0992},
  volume={15},
  number={2},
  pages={349-357},
  author={Zied Milian, Eduardo and Mesquita Spinola, Mauro and Monteiro Carvalho, Marly},
  keywords={Cloud computing, Uncertainty, Computational modeling, Software as a service, NIST, Laser radar, Risks and Uncertainties, Silicon, Systematic Review of the Literature},
  abstract={This study aims to characterize risks and uncertainties in the cloud computing context. A Systematic Review of the cloud computing literature was conducted focusing on publications on risks and uncertainties and combining techniques such as bibliometric analysis, network analysis and content analysis. Using the definitions of risk and uncertainty, this review maps how these concepts are used and in which contexts they occur. The study find that the main sources of risks and uncertainties were: strategic viability of outsourcing or offering certain services, weaknesses in the business model, vendor maturity, behavioral tradition and hiring of third party services.}
}

@article{rayyan-727968008,
  title={Test driven development contribution in universities in producing quality software: A systematic review},
  year={2014},
  pages={1-6},
  author={Yahya, Norzariyah and Awang Abu Bakar, Normi Sham},
  keywords={experiment, Decision support systems, university, quality, perception, Test driven development, Software},
  abstract={Test driven development (TDD) is one of the Agile techniques adopted in education. TDD is an ideal approach to be taught in university due to its capability in producing quality software and at the same time teaching novice programmers to test and develop a product simultaneously. It helps novice programmers to think before they develop rather than using “trial-and-error” approach in their project. However, based on the existing research, TDD contribution in producing a better quality and the perception among novice programmers towards it needs to be analyzed. This systematic review will identify the quality of a product produced by the students in university and also their perception towards TDD.}
}

@article{rayyan-727968009,
  title={A systematic review of cloud lock-in solutions},
  year={2013},
  volume={2},
  pages={363-368},
  author={Silva, Gabriel Costa and Rose, Louis M and Calinescu, Radu},
  keywords={Systematics, Cloud computing, interoperability, Interoperability, Computer science, Industries, Semantics, Standards, cloud lock-in, portability, review},
  abstract={The heterogeneity of cloud semantics, technology and interfaces limits application and platform portability and interoperability, and can easily lead to vendor lock-in. We identify, analyse and classify existing solutions to cloud vendor lock-in, and highlight unresolved challenges. Our survey is based on a systematic review of 721 primary studies that describe the state-of-the-art in managing cloud lock-in, portability and interoperability. 78 of these primary studies were selected and used for a thorough analysis of cloud standards, commercial products and academic work related to cloud lock-in. Our review shows that most solutions proposed so far are platforms, APIs or architectures addressing infrastructure-as-a-service (IaaS) interoperability. From our review, we identify a need for: (i) exploiting established solutions from areas that are closely related to cloud computing, (ii) increasing empirical evidence to raise confidence in existing solutions, and (iii) addressing the socio-technical and business challenges related to cloud lock-in.}
}

@article{rayyan-727968019,
  title={Towards a collaborative repository for the documentation of service-based antipatterns and bad smells},
  year={2019},
  pages={95-101},
  author={Bogner, Justus and Boceck, Tobias and Popp, Matthias and Tschechlov, Dennis and Wagner, Stefan and Zimmermann, Alfred},
  keywords={Collaboration, SOA, Service-oriented architecture, Microservices, Taxonomy, Libraries, Search engines, Documentation, antipatterns, bad smells, service-based systems, Smell},
  abstract={While the concepts of object-oriented antipatterns and code smells are prevalent in scientific literature and have been popularized by tools like SonarQube, the research field for service-based antipatterns and bad smells is not as cohesive and organized. The description of these antipatterns is distributed across several publications with no holistic schema or taxonomy. Furthermore, there is currently little synergy between documented antipatterns for the architectural styles SOA and Microservices, even though several antipatterns may hold value for both. We therefore conducted a Systematic Literature Review (SLR) that identified 14 primary studies. 36 service-based antipatterns were extracted from these studies and documented with a holistic data model. We also categorized the antipatterns with a taxonomy and implemented relationships between them. Lastly, we developed a web application for convenient browsing and implemented a GitHub-based repository and workflow for the collaborative evolution of the collection. Researchers and practitioners can use the repository as a reference, for training and education, or for quality assurance.}
}

@article{rayyan-727968028,
  title={A systematic review: B-cell conformational epitope prediction from epitope characteristics view},
  year={2017},
  pages={93-98},
  author={Solihah, Binti and Winarko, Edi and Afiahayati and Hartati, Sri and Wibowo, Moh. Edi},
  keywords={Systematics, Bibliographies, Databases, Feature extraction, 3D structure based feature, Amino acids, conformational epitope prediction method, epitope characteristics, Prediction methods, Sun},
  abstract={B-cell conformational epitope identification is the crucial issue in vaccinology. Limitation on experimental methods in the biological side, dataset and availability of computational resources opens a chance on developing prediction method which can accelerate epitope identification. A number of methods have been developed but their performance is still medium. Epitope prediction is a knowledge-based method. Presenting the statistical or computational based epitope characteristics together with epitope prediction method will facilitate the newcomer on identifying importance feature, improve the existing feature and propose the new feature. To reach the goal of the review, the research papers are collected from both epitope analysis research and epitope prediction methods research. The prediction methods are evaluated on what characteristics of epitope have been implemented on feature representation and are shown in a mapping table.}
}

@article{rayyan-727968055,
  title={Acceptance of blockchain based supply chain management system: Research model proposal},
  year={2019},
  pages={1-6},
  author={Gökalp, Ebru and Çoban, Selin and Gökalp, Mert Onuralp},
  keywords={Blockchain, Organizational Acceptance, Supply Chain Management, Technology-Organization-Environment Framework},
  abstract={Blockchain technology provides emerging solutions including decentralized management, security, privacy and robustness. In Supply Chain Management (SCM) applications, blockchain technology enable us to increase customer satisfaction, operational excellence, and to decrease operational costs and risks. Despite of these significant benefits, there are limited number of studies that combines SCM and blockchain in the literature. The main aim of this study is to investigate the factors influencing the adoption and acceptance of the blockchain based SCM in organizations. To this end, a comprehensive systematic literature review is conducted and a research model based on Technology-Organization-Environment (TOE) framework is proposed. The proposed research model consists of factors of the relative advantage, complexity, interoperability/compatibility, standardization, trust and scalability in the context of technology; organization's IT resource, top management support, organization size and financial resources in the context of organization; competitive pressure, trading partner pressure, government policy and regulations and inter-organizational trust in the context of environment.}
}

@article{rayyan-727968064,
  title={Towards taxonomical-based situational model to improve the quality of agile distributed teams},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={6812-6826},
  author={Sarwar, Amber and Hafeez, Yaser and Hussain, Shariq and Yang, Shunkun},
  keywords={Software, Systematics, Bibliographies, Software architecture, Databases, Modeling, Organizations, Agile distributed taxonomy, agile distributed teams, situational agile distributed development, situational model, taxonomical model},
  abstract={At present, software organizations are developing software products that employ global software development (GSD) teams. Organizations tend to adopt new methodologies for global software development, among which is the use of agile in the GSD industry, which yields both benefits and challenges. However, software development teams do not consider situational needs that delay software delivery, resulting in the late discovery of incompatible assumptions and architecture level rework. In this study, we conduct a systematic literature review (SLR) to identify the situational factors that need to be considered by software development teams before developing a software product. We further present taxonomical classification and comprehensively map the situational factors that impact design development and advancement in the proposed Situational Agile Distributed Development (SADD) model. We propose 18 directed hypotheses against each situational factor that supports our SADD model. In order to evaluate our directed hypotheses, statistical analysis method is used, and the level of confidence of each directed hypothesis is validated. The result of our study confirms that global software development teams are highly reliant on the SADD Model. Our study will largely contribute by devising a multilevel taxonomy of situational factors that elevate the performance of global software development teams. This taxonomical classification will allow to better map the relationships between multiple situational factors and elevate the process of creating a holistic model to handle situational needs in the context of Agile Distributed Software Development (ADSD).}
}

@article{rayyan-727968065,
  title={Set of usability heuristics for quality assessment of mobile applications on smartphones},
  year={2019},
  journal={IEEE Access},
  issn={2169-3536},
  volume={7},
  pages={116145-116161},
  author={Parente Da Costa, Ruyther and Canedo, Edna Dias and De Sousa, Rafael Timóteo and De Oliveira Albuquerque, Robson and García Villalba, Luis Javier},
  keywords={Task analysis, Mobile applications, Usability, usability, ISO Standards, Smart phones, IEC Standards, cognitive load, heuristic evaluation, usability heuristics},
  abstract={The innovations proposed by the cell phone market have grown steadily in recent years, along with the increasing complexity of the hardware, operating systems, and applications available in this market. These changes bring new challenges related to usability that need to be considered during the development process of these applications since the new forms of user-application interactions increasingly require adapting the behavior of smartphone users. In this situation, usability is an important issue that depends on factors such as the Users, their characteristics and abilities, the Task which the users intend to achieve and also the application usage Context. This work presents a systematic literature review with the objective of identifying the heuristics and usability metrics used in the literature and/or industry. Based on the review results, this work presents another contribution with a proposal of a set of usability heuristics focused in mobile applications on smartphones, considering the User, Task and Context as usability factors and Cognitive Load as an important attribute of usability. The components of this set are detailed in a model intended to be used in empirical validations allowing to dynamically incorporate improvements to the proposal.}
}

@article{rayyan-727968066,
  title={Exploring user centered design in healthcare: A literature review},
  year={2020},
  pages={1-8},
  author={Chandran, Srijith and Al-Sa'di, Ahmed and Ahmad, Esraa},
  keywords={Software, Systematics, Bibliographies, Literature Review, Healthcare, Best practices, Medical services, UCD, UCD Methods, User centered design, User Centered Design},
  abstract={Recently User Centered Design (UCD) has been frequently used in software development to place the user's needs and goals in the centre of the development process to deliver a highly usable system. This paper aims to capture the current usage of UCD methods in healthcare system development and briefly discusses the best usage of these methods. We conducted a systematic review of the literature using selection criteria and resulted in retrieving 20 relevant publications. The results were analyzed to identify the most common use of UCD methods in the healthcare system. We hope this paper will contribute to the body of knowledge on healthcare software development,by providing a broad overview of the existing works on UCD in healthcare along with identifying the best practices of the most common method in UCD.}
}

@article{rayyan-727968067,
  title={Evaluating code readability and legibility: An examination of human-centric studies},
  year={2020},
  pages={348-359},
  author={Oliveira, Delano and Bruno, Reydne and Madeiral, Fernanda and Castor, Fernando},
  keywords={Software engineering, Systematics, Bibliographies, Task analysis, Software maintenance, Programming, Taxonomy, code legibility, Code readability, code understandability, code understanding, program comprehension, Humanities, Humanism, Humans},
  abstract={Reading code is an essential activity in software maintenance and evolution. Several studies with human subjects have investigated how different factors, such as the employed programming constructs and naming conventions, can impact code readability, i.e., what makes a program easier or harder to read and apprehend by developers, and code legibility, i.e., what influences the ease of identifying elements of a program. These studies evaluate readability and legibility by means of different comprehension tasks and response variables. In this paper, we examine these tasks and variables in studies that compare programming constructs, coding idioms, naming conventions, and formatting guidelines, e.g., recursive vs. iterative code. To that end, we have conducted a systematic literature review where we found 54 relevant papers. Most of these studies evaluate code readability and legibility by measuring the correctness of the subjects' results (83.3%) or simply asking their opinions (55.6%). Some studies (16.7%) rely exclusively on the latter variable. There are still few studies that monitor subjects' physical signs, such as brain activation regions (5%). Moreover, our study shows that some variables are multi-faceted. For instance, correctness can be measured as the ability to predict the output of a program, answer questions about its behavior, or recall parts of it. These results make it clear that different evaluation approaches require different competencies from subjects, e.g., tracing the program vs. summarizing its goal vs. memorizing its text. To assist researchers in the design of new studies and improve our comprehension of existing ones, we model program comprehension as a learning activity by adapting a preexisting learning taxonomy. This adaptation indicates that some competencies, e.g., tracing, are often exercised in these evaluations whereas others, e.g., relating similar code snippets, are rarely targeted.}
}

@article{rayyan-727968069,
  title={Is there a "Golden" rule for code reviewer recommendation? : —An experimental evaluation},
  year={2020},
  pages={497-508},
  author={Hu, Yuanzhe and Wang, Junjie and Hou, Jie and Li, Shoubin and Wang, Qing},
  keywords={Systematics, Guidelines, Task analysis, Software quality, Software reliability, code review, experimental evaluation, reviewer recommendation, Sensitivity, Training data},
  abstract={Peer code review has been proven to be an effective practice for quality assurance, and widely adopted by commercial companies and open source communities as GitHub. However, identifying an appropriate code reviewer for a pull request is a non-trivial task considering the large number of candidate reviewers. Several approaches have been proposed for reviewer recommendation, yet none of them has conducted a complete comparison to explore which one is more effective. This paper aims at conducting an experimental evaluation of the commonly-used and state-of-the-art approaches for code reviewer recommendation. We begin with a systematic review of approaches for code reviewer recommendation, and choose six approaches for experimental evaluation. We then implement these approaches and conduct reviewer recommendation on 12 large-scale open source projects with 53,005 pull requests spanning two years. Results show that there is no golden rule when selecting code reviewer recommendation approaches, and the best approach varies in terms of different evaluation metrics (e.g., Top-5 Accuracy, MRR) and experimental projects. Nevertheless, TIE, which utilizes the textual similarity and file path similarity, is the most promising one. We also explore the sensitivity of these approaches to training data, and compare their time cost. This approach provides new insights and practical guidelines for choosing approaches for reviewer recommendation.}
}

@article{rayyan-727968103,
  title={Layered architecture revisited — Comparison of research and practice},
  year={2009},
  pages={317-320},
  author={Savolainen, Juha and Myllarniemi, Varvana},
  keywords={Guidelines, Software architecture, Software design, Databases, Software systems, Computer architecture, Computer industry, Protocols, Books, Organizing},
  abstract={Organizing a software architecture into layers has been one of the earliest architectural styles ever used. Even today layered structure is a very common architectural style used in various industrial systems. However, we have observed that the usage of layered architectural style varies greatly in different contexts. This paper aims to compare the notion of software architecture layers in research literature as well as in industrial practice. Firstly, we performed a systematic literature review of research articles on layered software architectures; we also reviewed selected books of software architecture. Secondly, to understand the practice, we investigated a number different recent architecture documents to cover the current usage of layered architectures. Our results indicate that there is very little actual research done on layered architectures. The current usage of layered structures seems to be more complex than reported before. This gap between the research and practice needs to be bridged by researchers.}
}

@article{rayyan-727968105,
  title={Barriers to implement electronic health records},
  year={2016},
  pages={1-6},
  author={Carlos, Maldonado and Sussy, Bayona Oré},
  keywords={Systematics, Security, barriers, ISO Standards, Silicon compounds, EHR, electronic healt records, Electronic medical records, HCE},
  abstract={The aim of implementing Electronic Health Record (EHR) is to replace the use of handwritten medical records in patient care. Despite of the benefits of EHR implementation, still there are still limitations. The aim of this study is to identify the barriers that impact the EHR implementation in health. A systematic review was conducted in order to identify the barriers. As a result 156 articles were identified and finally were selected 9 primary articles and 8 articles based on systematic review of the literature. A list of barriers were identified and categorized. Financial, technological, security, and organizational aspects are the most important limitations.}
}

@article{rayyan-727968107,
  title={Computer-aided diagnosis of chronic kidney disease in developing countries: A comparative analysis of machine learning techniques},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={25407-25419},
  author={Sobrinho, Alvaro and Queiroz, Andressa C M Da S and Dias Da Silva, Leandro and De Barros Costa, Evandro and Eliete Pinheiro, Maria and Perkusich, Angelo},
  keywords={Software, machine learning, Guidelines, Machine learning, Diseases, Developing countries, Kidney, medical diagnosis, Reviews, Kidney Diseases, Developing Countries, Acquired Immunodeficiency Syndrome, Developed Countries},
  abstract={The high incidence and prevalence of chronic kidney disease (CKD), often caused by late diagnoses, is a critical public health problem, especially in developing countries such as Brazil. CKD treatment therapies, such as dialysis and kidney transplantation, increase the morbidity and mortality rates, besides the public health costs. This study analyses the usage of machine learning techniques to assist in the early diagnosis of CKD in developing countries. Qualitative and quantitative comparative analyses are, respectively, conducted using a systematic literature review and an experiment with machine learning techniques, with the k-fold cross-validation method based on the Weka© software and a CKD dataset. These analyses enable a discussion on the suitability of machine learning techniques for screening for CKD risk, focusing on low-income and hard-to-reach settings of developing countries, due to the specific problems faced by them, e.g., inadequate primary health care. The study results show that the J48 decision tree is a suitable machine learning technique for such screening in developing countries, due to the easy interpretation of its classification results, with 95.00% accuracy, reaching a nearly perfect agreement with an experienced nephrologist`s opinion. Conversely, random forest, naive Bayes, support vector machine, multilayer perceptron, and k-nearest neighbor techniques, respectively, yield 93.33%, 88.33%, 76.66%, 75.00%, and 71.67% accuracy, presenting at least moderate agreement with the nephrologist, at the cost of a more difficult interpretation of the classification results.}
}

@article{rayyan-727968108,
  title={Psychological effects and their role in online privacy interactions: A review},
  year={2020},
  journal={IEEE Access},
  issn={2169-3536},
  volume={8},
  pages={21236-21260},
  author={Kitkowska, Agnieszka and Shulman, Yefim and Martucci, Leonardo A and Wästlund, Erik},
  keywords={Visualization, Bibliographies, Decision making, Privacy, Psychology, Economics, privacy, design, attitude, behavior, decision-making, Government, HCI, visual cues},
  abstract={Because of the increasing dependency on online technologies in even the most ordinary activities, people have to make privacy decisions during everyday online interactions. Visual design often influences their choices. Hence, it is in the hands of choice architects and designers to guide users towards specific decision outcomes. This “nudging” has gained much interest among scholars in interdisciplinary research, resulting in experimental studies with visual cues that may have the potential to alter attitudes and behaviors. Attitude and behavior changes are often attributed to several psychological effects manifesting in cognitive processing and decision-making. This article presents the results of a systematic literature review carried out to identify which psychological effects have been previously studied in the context of online privacy interactions. Subsequently, fifteen articles were selected and thoroughly reviewed, resulting in the identification of twenty psychological effects. The visual cues triggering these effects were recognized and classified against their capabilities to alter privacy attitudes and behaviors. Specifically, the visual cues were divided into two categories: privacy-enhancing and privacy-deteriorating. This review discusses the applicability of such cues in research and UI design. Further, the findings are discussed against the existing research on digital nudges. The authors conclude with a discussion on issues of research quality in the privacy-related field and outline the road to improvement.}
}

@article{rayyan-727968109,
  title={Enterprise architects should follow the money},
  year={2014},
  volume={1},
  pages={135-142},
  author={van den Berg, Martin and van Vliet, Hans},
  keywords={Systematics, Bibliographies, Decision making, Information systems, Organizations, Investment, enterprise architecture, IT decision-making, IT governance},
  abstract={Enterprise architecture (EA) offers ways to steer and guide the design and evolution of the enterprise including its information technology (IT). One of the outputs of EA is improved decision-making about IT. Objective: This study aims to provide EA researchers and practitioners with insights into how IT decision-making actually takes place and what that means for them. Method: A systematic literature review was conducted in order to find and analyze primary studies about IT decision-making. Results: We found that IT investment and prioritization is by far the largest decision category. Money seems much more important than content. The IT decision-making process itself is subject to different variables and factors making every IT decision unique. We also found that both rational and bounded rational approaches are used in IT decision-making. EA has not a prominent role in IT decision-making. Conclusions: IT decision-making is a messy and complex process where money plays a prominent role. We argue that, if enterprise architects want to influence IT decision-making, they should follow the money by combining content with investment planning and prioritization. Further research is required into what distinguishes enterprise architects that are successful in IT decision-making, from those that are less successful.}
}

@article{rayyan-727968111,
  title={How to design tools for supporting self-regulated learning in MOOCs? Lessons learned from a literature review from 2008 to 2016},
  year={2016},
  pages={1-12},
  author={Pérez-Álvarez and Pérez-Sanagustín, R and Maldonado, M Jorge J},
  keywords={Software, Bibliographies, Tools, Literature review, Monitoring, Libraries, Silicon compounds, Mobile communication, Design tools, MOOC, Online, Self-Regulated Learning, System, Technologies},
  abstract={This paper presents a systematic literature review that examines and analyzes the articles from 2008 to 2016 that have addressed the development of tools to support Self-Regulated Learning (SRL) in online and MOOC environments. The findings denote that: (1) there is a lack of tools to support SRL in MOOC environments; (2) the evaluation of the existing tools are not aligned whit the objectives of the research; (3) current research presents proposal of tools but very few achieve the stage of implementation; and (4) current existing tools tend to support many SRL strategies at the same time. We end up with a set of lessons learned for guiding the implementation of tools to support SRL strategies in MOOCs environments.}
}

@article{rayyan-727968112,
  title={Bridging the gap between software architecture and business model development: A literature study},
  year={2019},
  pages={1519-1524},
  author={Hyrynsalmi, Sami and Rauti, Sampsa and Kaila, Erkki},
  keywords={Systematics, Software architecture, literature review, Software systems, Computer architecture, Companies, software architecture, Pricing, business model, mercury business, software-intensive business, Software},
  abstract={The software architecture plan describes the high-level structure and logic of a software system. The architectural plan acts as a constitution and dictates the fundamental principles of the system; therefore, the plan also eventually determines which kinds of business models the software system can support. In the modern mercury business, there is need for experimentation in business model and flexibility in architecture. This paper uses a systematic literature review method to collect primary studies from the extant literature addressing business models and software architectures. The aim is to summarize the current knowledge. The selected primary studies (n=10) are qualitatively analyses and synthesized. The results show that the area remain mostly unaddressed and there is need to develop new methods to support flexible architecture design, tools and development methods.}
}

@article{rayyan-727968113,
  title={Urban cableway systems: State-of-art and analysis of the emirates air line, london},
  year={2020},
  pages={1-8},
  author={Tiessler, Michaela and Ricci, Gysele Lima and Bogenberger, Klaus},
  keywords={Systematics, Bibliographies, Planning, Maintenance engineering, Public transportation, Urban areas, Automobiles, London},
  abstract={Cableway systems are often associated with mountains and skiing. Nonetheless, they established in several cities for public transportation in the last years. This paper describes the state of the art in urban cable car systems and focuses especially on advances and experiences of planning processes in Germany. For this purpose, we conduct a systematic review of academic literature regarding urban ropeway systems, including analyses of the international context, the methodologies used and different perspectives on the topic in an international context. Additionally, we investigate the Emirates Air Line which operates since 2012 in London in order to identify the challenges for urban ropeway systems for Germany. The results indicate that urban ropeway systems have a potential to establish in public transportation in German cities, but still exist several obstacles that need to be settled.}
}

@article{rayyan-727968114,
  title={Mobile mental health: A review of applications for depression assistance},
  year={2019},
  pages={708-713},
  author={Teles, Ariel and Rodrigues, Ivan and Viana, Davi and Silva, Francisco and Coutinho, Luciano and Endler, Markus and Rabêlo, Ricardo},
  keywords={Systematics, Monitoring, Quality assessment, Mobile applications, Mobile Applications, Psychology, Google, mHealth, Depression, Mental disorders, Mobile Mental Health},
  abstract={Depression is a mental disorder characterized by persistent sadness, loss of interest, and a set of behavioral changes. The high prevalence of depression imposes a significant burden on the world population, demanding methods capable of monitoring and treating this mental disorder. Currently, a large number of mobile applications have been designed to provide support to depressive people. This paper aims to identify, analyze and characterize the current state of mobile applications focused on depression. To do so, we conducted a systematic review of applications for depression assistance. The two most popular mobile app stores (Google Play Store and Apple App Store) have been explored to find the most relevant apps. After applying the inclusion and exclusion criteria and performing the quality assessment of the results, 216 applications were selected for the data extraction phase, where we summarized their benefits and limitations and identified gaps and trends. The results of this review evidenced that there is a growth in the diversity of apps' purposes such as chatbot, online therapy, educational tools, mood tracker, testing, and self-help.}
}

@article{rayyan-727968116,
  title={Metrics to evalute fuctional quality: A sistematic review},
  year={2012},
  pages={1-6},
  author={Carrillo, Alberto Blanco and Mateo, Pedro Reales and Monje, Moisés Rodríguez},
  keywords={Software, Measurement, metrics, Silicon compounds, ISO standards, IEC standards, Functional Quality, ISO, ISO 25010, Sistematic Review, Metronidazole},
  abstract={Nowadays, quality assurance of software products is very important. To assure this quality, there exist several international standards like the standard ISO 25010. These standards define quality models, characteristics and sub-characteristics that must be taken into account in order to evaluate the quality of a software product. In this context, metrics are needed to evaluate quality objectively. This document shows a systematic review of the literature about the existing metrics that can be used to measure functional quality (as defined in the international standard ISO 25010) of a software product. As results of the conducted review, 23 metrics were found, most of them based on tests. The conclusions obtained from this study show that, although more metrics should be defined, there exists a enough number of metrics to measure all the functional quality characteristics defined in the international standard ISO 25010.}
}

@article{rayyan-727968208,
  title={On the need to study the impact of model driven engineering on software processes},
  year={2014},
  issn={978-1-4503-2754-1},
  pages={164-168},
  author={Hebig, Regina and Bendraou, Reda},
  url={https://doi.org/10.1145/2600821.2600846},
  publisher={Association for Computing Machinery},
  series={ICSSP 2014},
  keywords={model-driven engineering, literature survey, Software process tailoring, Software},
  abstract={There is an increasing use of model-driven engineering (MDE) in the industry. Despite the existence of research proposals for MDE-specific processes, the question arises whether and how the processes that are already used within a company can be reused, when MDE is introduced. In this position paper we report on a systematic literature review on the question how standard processes, such as SCRUM or the V-Model XT, can be combined with MDE. We come up with the observation that - although it is in some cases possible to reuse standard processes - the combination with MDE can also result in heavyweight changes to a process. Our goal is to draw attention to two arising research needs: the need to collect systematic knowledge about the influence of MDE on software processes and the need to provide guidance for the tailoring of processes based on the set of used MDE techniques.}
}

@article{rayyan-727968210,
  title={Understanding usability evaluation setup for VR products in industry: A review study},
  year={2020},
  journal={SIGAPP Appl. Comput. Rev.},
  issn={1559-6915},
  volume={19},
  number={4},
  pages={17-27},
  author={Karre, Sai Anirudh and Mathur, Neeraj and Reddy, Y Raghu},
  url={https://doi.org/10.1145/3381307.3381309},
  keywords={metrics, virtual reality, usability testing, industrial practices, usability evaluation},
  abstract={VR development practices have a diverse set of practices compared to traditional software development. Tasks like scene design, acoustic design, vergence manipulation, image depth, etc. are specific to VR apps and hence require evaluation processes that may be different from the traditional means. Usability Evaluation is one such process which is being executed in an unconventional way by Industrial Practitioners today. In this paper, the researchers detail a Systematic Literature Review of the Usability Evaluation Methods practised by Industrial researchers while building VR Products. The researchers found that VR Product teams follow unique methods to improve usability in their products. Further, the researchers consolidate these methods and provide insights into choosing the best to build a real-world VR Product based on the defined product constraints}
}

@article{rayyan-727968211,
  title={An empirical evaluation of OSGi dependencies best practices in the eclipse IDE},
  year={2018},
  issn={978-1-4503-5716-6},
  pages={170-180},
  author={Ochoa, Lina and Degueule, Thomas and Vinju, Jurgen},
  url={https://doi.org/10.1145/3196398.3196416},
  publisher={Association for Computing Machinery},
  series={MSR '18},
  abstract={OSGi is a module system and service framework that aims to fill Java's lack of support for modular development. Using OSGi, developers divide software into multiple bundles that declare constrained dependencies towards other bundles. However, there are various ways of declaring and managing such dependencies, and it can be confusing for developers to choose one over another. Over the course of time, experts and practitioners have defined "best practices" related to dependency management in OSGi. The underlying assumptions are that these best practices (i) are indeed relevant and (ii) help to keep OSGi systems manageable and efficient. In this paper, we investigate these assumptions by first conducting a systematic review of the best practices related to dependency management issued by the OSGi Alliance and OSGi-endorsed organizations. Using a large corpus of OSGi bundles (1,124 core plug-ins of the Eclipse IDE), we then analyze the use and impact of 6 selected best practices. Our results show that the selected best practices are not widely followed in practice. Besides, we observe that following them strictly reduces classpath size of individual bundles by up to 23% and results in up to ±13% impact on performance at bundle resolution time. In summary, this paper contributes an initial empirical validation of industry-standard OSGi best practices. Our results should influence practitioners especially, by providing evidence of the impact of these best practices in real-world systems.}
}

@article{rayyan-727968216,
  title={Investigating the model-driven development for systems-of-systems},
  year={2014},
  issn={978-1-4503-2778-7},
  author={Graciano Neto, Valdemar Vicente and Guessi, Milena and Oliveira, Lucas Bueno R and Oquendo, Flavio and Nakagawa, Elisa Yumi},
  url={https://doi.org/10.1145/2642803.2642825},
  publisher={Association for Computing Machinery},
  series={ECSAW '14},
  keywords={Model-Driven Development, Software Generation, System-of-Systems},
  abstract={Software-intensive systems have become increasingly large and complex and new techniques and methodologies are necessary to deal with such complexity. Model-Driven Development (MDD) has been used to deal with complex scenarios, since software models, despite details, facilitate the visualization of the whole. Moreover, MDD has been widely recognized as a way to assure quality, reducing time and effort, and making possible the automatic transformation of models to generate source code. In this direction, software-intensive Systems-of-Systems (SoS) is a class of software systems that have emerged over the iminence of large systems which have a high-level of complexity. Considering the success of MDD in other areas, we decided to investigate how MDD has been used in the context of SoS. This paper presents results of a Systematic Literature Review conducted to scrutinize and bring to light the state of the art in the field of MDD for SoS. Besides that, we discuss future research directions and perspectives, aiming at contributing to the development of SoS.}
}

@article{rayyan-727968217,
  title={Social barriers faced by newcomers placing their first contribution in open source software projects},
  year={2015},
  issn={978-1-4503-2922-4},
  pages={1379-1392},
  author={Steinmacher, Igor and Conte, Tayana and Gerosa, Marco Aurélio and Redmiles, David},
  url={https://doi.org/10.1145/2675133.2675215},
  publisher={Association for Computing Machinery},
  series={CSCW '15},
  keywords={barriers, entry, joining, new contributor, newcomers, onboarding, online communities, open collaboration, open source software, qualitative study, social barriers, socialization, Software},
  abstract={Newcomers' seamless onboarding is important for online communities that depend upon leveraging the contribution of outsiders. Previous studies investigated aspects of the joining process and motivation in open collaboration communities, but few have focused on identifying and understanding the critical barriers newcomers face when placing their first contribution, a period that frequently leads to dropout. This is important for Open Source Software (OSS) projects, which receive contributions from many one-time contributors. Focusing on OSS, our study qualitatively analyzed social barriers that hindered newcomers' first contributions. We defined a conceptual model composed of 58 barriers including 13 social barriers. The barriers were identified from a qualitative data analysis considering different sources: a systematic literature review; open question responses gathered from OSS projects' contributors; students contributing to OSS projects; and semi-structured interviews with 36 developers from 14 different projects. This paper focuses on social barriers and its contributions include gathering empirical evidence of the barriers faced by newcomers, organizing and better understanding these barriers, surveying the literature from the perspective of the barriers, and identifying new potential research streams.}
}

@article{rayyan-727968221,
  title={Big data on cloud for government agencies: Benefits, challenges, and solutions},
  year={2018},
  issn={978-1-4503-6526-0},
  author={Rashed, Alaa Hussain and Karakaya, Ziya and Yazici, Ali},
  url={https://doi.org/10.1145/3209281.3209360},
  publisher={Association for Computing Machinery},
  series={dg.o '18},
  keywords={benefits, big data, cloud computing, challenges, big data on cloud, government agencies, solutions, Government Agencies},
  abstract={Big Data and Cloud computing are the most important technologies that give the opportunity for government agencies to gain a competitive advantage and improve their organizations. On one hand, Big Data implementation requires investing a significant amount of money in hardware, software, and workforce. On the other hand, Cloud Computing offers an unlimited, scalable and on-demand pool of resources which provide the ability to adopt Big Data technology without wasting on the financial resources of the organization and make the implementation of Big Data faster and easier. The aim of this study is to conduct a systematic literature review in order to collect data to identify the benefits and challenges of Big Data on Cloud for government agencies and to make a clear understanding of how combining Big Data and Cloud Computing help to overcome some of these challenges. The last objective of this study is to identify the solutions for related challenges of Big Data. Four research questions were designed to determine the information that is related to the objectives of this study. Data is collected using literature review method and the results are deduced from there.}
}

@article{rayyan-727968222,
  title={An assessment of tools for UML class diagram modeling: Support to adaptation and integration with other tools},
  year={2019},
  issn={978-1-4503-7282-4},
  pages={10-19},
  author={Massago, Mamoru and Colanzi, Thelma Elita},
  url={https://doi.org/10.1145/3364641.3364643},
  publisher={Association for Computing Machinery},
  series={SBQS'19},
  keywords={Diagrama de Classes, Ferramentas CASE, Revisão Sistemática},
  abstract={The software development process comprises a set of activities with the goal of developing high quality software. The software architecture design is a key activity of the software development processs as it allows the specification and visualization of products from different and structured point of views. One of the most used architectural views is the logical one, which represents the classes and their relationships. For this reason, the UML class diagram is one of the most used UML diagrams by software engineers [1]. Many companies use CASE (Computer-Aided Software Engineering) tools to carry out several software engineering activities, including modeling class diagrams. They are looking for independence and flexibility to adapt and integrate tools through the adoption of open-source tools, but this is not an easy task as there are a lot of CASE tools and most of them are incompatible. This problem arises when it is necessary to integrate tools to perform software engineering activity that needs to receive a UML class diagram as input. In this sense, the objective of this work is to assist software engineers in the selection of the tools by presenting results of a systematic review, whose goal was identifying existing free and open-source tools for UML class diagram modeling and analyzing their support to adaptation and integration with other tools. Twelve tools for UML class diagrams modeling were found and an analysis of their support to adaptation and integration with other tools was carried out. This analysis is useful in the choice and use of such kind of tool, either in industry or academic research.}
}

@article{rayyan-727968223,
  title={A literature review and comparison of three feature location techniques using ArgoUML-SPL},
  year={2019},
  issn={978-1-4503-6648-9},
  author={Cruz, Daniel and Figueiredo, Eduardo and Martinez, Jabier},
  url={https://doi.org/10.1145/3302333.3302343},
  publisher={Association for Computing Machinery},
  series={VAMOS '19},
  keywords={reverse engineering, benchmark, feature location, software product lines, variability mining},
  abstract={Over the last decades, the adoption of Software Product Line (SPL) engineering for supporting software reuse has increased. An SPL can be extracted from one single product or from a family of related software products, and feature location strategies are widely used for variability mining. Several feature location strategies have been proposed in the literature and they usually aim to map a feature to its source code implementation. In this paper, we present a systematic literature review that identifies and characterizes existing feature location strategies. We also evaluated three different strategies based on textual information retrieval in the context of the ArgoUML-SPL feature location case study. In this evaluation, we compare the strategies based on their ability to correctly identify the source code of several features from ArgoUML-SPL ground truth. We then discuss the strengths and weaknesses of each feature location strategy.}
}

@article{rayyan-727968229,
  title={Gathering current knowledge about quality evaluation in software product lines},
  year={2009},
  pages={91-100},
  author={Montagud, Sonia and Abrahão, Silvia},
  publisher={Carnegie Mellon University},
  series={SPLC '09},
  keywords={⛔ No DOI found, Software},
  abstract={Recently, a number of methods and techniques for assessing the quality of software product lines have been proposed. However, to the best of our knowledge, there is no study which summarizes all the existing evidence about them. This paper presents a systematic review that investigates what methods and techniques have been employed (in the last 10 years) to evaluate the quality of software product lines and how they were employed. A total of 39 research papers have been reviewed from an initial set of 1388 papers. The results show that 25% of the papers reported evaluations at the Design phase of the Domain Engineering phase. The most widely used mechanism for modeling quality attributes was extended feature models and the most evaluated artifact was the base architecture. In addition, the results of the review have identified several research gaps. Specifically, 77% of the papers employed case studies as a "proof of concept" whereas 23% of the papers did not perform any type of validation. Our results are particularly relevant in positioning new research activities and in the selection of quality evaluation methods or techniques that best fit a given purpose.}
}

@article{rayyan-727968234,
  title={A systematic survey of self-protecting software systems},
  year={2014},
  journal={ACM Transactions on Autonomous and Adaptive Systems},
  issn={1556-4665},
  volume={8},
  number={4},
  author={Yuan, Eric and Esfahani, Naeem and Malek, Sam},
  url={https://doi.org/10.1145/2555611},
  keywords={self-adaptive systems, adaptive security, autonomic computing, self-* properties, Self-protection, Software},
  abstract={Self-protecting software systems are a class of autonomic systems capable of detecting and mitigating security threats at runtime. They are growing in importance, as the stovepipe static methods of securing software systems have been shown to be inadequate for the challenges posed by modern software systems. Self-protection, like other self-* properties, allows the system to adapt to the changing environment through autonomic means without much human intervention, and can thereby be responsive, agile, and cost effective. While existing research has made significant progress towards autonomic and adaptive security, gaps and challenges remain. This article presents a significant extension of our preliminary study in this area. In particular, unlike our preliminary study, here we have followed a systematic literature review process, which has broadened the scope of our study and strengthened the validity of our conclusions. By proposing and applying a comprehensive taxonomy to classify and characterize the state-of-the-art research in this area, we have identified key patterns, trends and challenges in the existing approaches, which reveals a number of opportunities that will shape the focus of future research efforts.}
}

@article{rayyan-727968237,
  title={Identifying and mitigating risks of software project management in global software development},
  year={2017},
  issn={978-1-4503-4853-9},
  pages={12-22},
  author={Chadli, Saad Yasser and Idri, Ali},
  url={https://doi.org/10.1145/3143434.3143453},
  publisher={Association for Computing Machinery},
  series={IWSM mensura '17},
  keywords={Software},
  abstract={Managing global software projects is a difficult task further complicated by the emergence of new risks inherent to the dispersion of stakeholders. Project managers of Global Software Development (GSD) projects deal with challenges related to geographical, temporal and socio-cultural distance. The aim of this paper is to identify mitigation strategies intended to counter partially or fully the effects of risk factors related to the management of GSD projects that are available in literature and update the list of risk factors proposed in a previous research. This study proposes a framework for the Software Risk Management (SRM) of GSD projects designed to help practitioners identify risk factors and alleviate their effects through a list of recommended mitigation strategies. Using a systematic literature review (SLR), 39 risk factors and 58 mitigation strategies were identified and classified using a framework inspired from Leavitt's model of organizational change. Results show that the mitigation strategies identified in this SLR target 38 out of 39 risk factors, indicating a high academic interest in resolving the challenges of managing GSD projects. Results also reveal that the list of risk factors submitted in this paper and compiled using a different set of selected studies, concurs with the list introduced in a previous research.}
}

@article{rayyan-727968240,
  title={Integrating ethics within machine learning courses},
  year={2019},
  journal={ACM Transactions on Computing Education},
  volume={19},
  number={4},
  author={Saltz, Jeffrey and Skirpan, Michael and Fiesler, Casey and Gorelick, Micha and Yeh, Tom and Heckman, Robert and Dewar, Neil and Beard, Nathan},
  url={https://doi.org/10.1145/3341164},
  keywords={Machine learning, education, ethics, Learning},
  abstract={This article establishes and addresses opportunities for ethics integration into Machine-learning (ML) courses. Following a survey of the history of computing ethics and the current need for ethical consideration within ML, we consider the current state of ML ethics education via an exploratory analysis of course syllabi in computing programs. The results reveal that though ethics is part of the overall educational landscape in these programs, it is not frequently a part of core technical ML courses. To help address this gap, we offer a preliminary framework, developed via a systematic literature review, of relevant ethics questions that should be addressed within an ML project. A pilot study with 85 students confirms that this framework helped them identify and articulate key ethical considerations within their ML projects. Building from this work, we also provide three example ML course modules that bring ethical thinking directly into learning core ML content. Collectively, this research demonstrates: (1) the need for ethics to be taught as integrated within ML coursework, (2) a structured set of questions useful for identifying and addressing potential issues within an ML project, and (3) novel course models that provide examples for how to practically teach ML ethics without sacrificing core course content. An additional by-product of this research is the collection and integration of recent publications in the emerging field of ML ethics education.}
}

@article{rayyan-727968242,
  title={Uma revisão SistemáTica sobre MéTodos de avaliação de usabilidade aplicados em software de telefones celulares},
  year={2011},
  issn={978-85-7669-257-7},
  pages={197-201},
  author={Gonçalves, Vinícius P and Neris, Vânia P A and Morandini, Marcelo and Nakagawa, Elisa Y and Ueyama, Jó},
  publisher={Brazilian Computer Society},
  series={IHC+CLIHC '11},
  keywords={dispositives móveis, métodos de avaliação, revisão sistemática, telefones celulares, usabilidade, Software},
  abstract={Many of the personal computer features were transported to the cell phones. In Brazil, the number of cell phones sold is greater than the number of landlines. However, most of the features available in cell phone software are not used. It is important that usability aspects are observed in these applications. Thus, this paper presents a systematic review of evaluation methods applied to software usability of cell phones. Three main questions were addressed in the review: Which usability evaluation methods have been applied?. What are the recurrent problems found in these evaluations? and what are the solutions?. This article presents results based on papers found in five knowledge bases. The systematic review resulted in 221 works-related which 21 were included, 93 excluded, and 107 considered repeated. The test results suggest that less than half of the evaluations consider traditional methods such as Heuristic Evaluation. The problems mentioned are related to navigation and interface elements visibility. Only 30% of the included papers indicate suggestions for solving found problems.}
}

@article{rayyan-727968243,
  title={The augmented web: Rationales, opportunities, and challenges on browser-side transcoding},
  year={2015},
  journal={ACM Transactions on the Web},
  issn={1559-1131},
  volume={9},
  number={2},
  author={Díaz, Oscar and Arellano, Cristóbal},
  url={https://doi.org/10.1145/2735633},
  keywords={adaptation, JavaScript, Personalization, transcoding},
  abstract={Today's web personalization technologies use approaches like user categorization, configuration, and customization but do not fully support individualized requirements. As a significant portion of our social and working interactions are migrating to the web, we can expect an increase in these kinds of minority requirements. Browser-side transcoding holds the promise of facilitating this aim by opening personalization to third parties through web augmentation (WA), realized in terms of extensions and userscripts. WA is to the web what augmented reality is to the physical world: to layer relevant content/layout/navigation over the existing web to improve the user experience. From this perspective, WA is not as powerful as web personalization since its scope is limited to the surface of the web. However, it permits this surface to be tuned by developers other than the sites' webmasters. This opens up the web to third parties who might come up with imaginative ways of adapting the web surface for their own purposes. Its success is backed up by millions of downloads. This work looks at this phenomenon, delving into the “what,” the “why,” and the “what for” of WA, and surveys the challenges ahead for WA to thrive. To this end, we appraise the most downloaded 45 WA extensions for Mozilla Firefox and Google Chrome as well as conduct a systematic literature review to identify what quality issues received the most attention in the literature. The aim is to raise awareness about WA as a key enabler of the personal web and point out research directions.}
}

@article{rayyan-727968245,
  title={Automatic detection of depression from text data: A systematic literacture review},
  year={2020},
  issn={978-1-4503-8873-3},
  author={Magami, Felipe and Digiampietri, Luciano Antonio},
  url={https://doi.org/10.1145/3411564.3411603},
  publisher={Association for Computing Machinery},
  series={SBSI'20},
  keywords={Sentiment analysis, Detection of depression, Social networks},
  abstract={Depression is a mental disorder that affects hundreds of millions of people worldwide, with potentially serious consequences if left without treatment. Despite that, many people still suffer from depression without a diagnosis. Recently, the amount of studies related to the automatic detection of depression has improved. The objective of this paper is to identify the methods and techniques used by studies about depression detection through text data, by conducting a systematic review.}
}

@article{rayyan-727968254,
  title={Why are industrial agile teams using metrics and how do they use them?},
  year={2014},
  issn={978-1-4503-2854-8},
  pages={23-29},
  author={Kupiainen, Eetu and Mäntylä, Mika V and Itkonen, Juha},
  url={https://doi.org/10.1145/2593868.2593873},
  publisher={Association for Computing Machinery},
  series={WETSoM 2014},
  keywords={Agile software development, metrics, measurement, Metronidazole},
  abstract={Agile development methods are increasing in popularity, yet there are limited studies on the reasons and use of metrics in industrial agile development. This paper presents preliminary results from a systematic literature review. Based on our study, metrics and their use are focused to the following areas: Iteration planning, Iteration tracking, Motivating and improving, Identifying process problems, Pre-release quality, Post-release quality and Changes in processes or tools. The findings are mapped against agile principles and it seems that the use of metrics supports the principles with some deviations. Surprisingly, we find little evidence of the use of code metrics. Also, we note that there is a lot of evidence on the use of planning and tracking metrics. Finally, the use of metrics to motivate and enforce process improvements as well as applicable quality metrics can be interesting future research topics.}
}

@article{rayyan-727968257,
  title={Quest for the golden approach: An experimental evaluation of duplicate crowdtesting reports detection},
  year={2020},
  issn={978-1-4503-7580-1},
  author={Huang, Yuekai and Wang, Junjie and Wang, Song and Liu, Zhe and Hu, Yuanzhe and Wang, Qing},
  url={https://doi.org/10.1145/3382494.3410694},
  publisher={Association for Computing Machinery},
  series={ESEM '20},
  keywords={information retrieval, machine learning, deep learning, Crowdtesting, duplicate detection},
  abstract={Background: Given the invisibility and unpredictability of distributed crowdtesting processes, there is a large number of duplicate reports, and detecting these duplicate reports is an important task to help save testing effort. Although, many approaches have been proposed to automatically detect the duplicates, the comparison among them and the practical guidelines to adopt these approaches in crowdtesting remain vague.Aims: We aim at conducting the first experimental evaluation of the commonly-used and state-of-the-art approaches for duplicate detection in crowdtesting reports, and exploring which is the golden approach.Method: We begin with a systematic review of approaches for duplicate detection, and select ten state-of-the-art approaches for our experimental evaluation. We conduct duplicate detection with each approach on 414 crowdtesting projects with 59,289 reports collected from one of the largest crowdtesting platforms.Results: Machine learning based approach, i.e., ML-REP, and deep learning based approach, i.e., DL-BiMPM, are the best two approaches for duplicate reports detection in crowdtesting, while the later one is more sensitive to the size of training data and more time-consuming for model training and prediction.Conclusions: This paper provides new insights and guidelines to select appropriate duplicate detection techniques for duplicate crowdtesting reports detection.}
}

@article{rayyan-727968258,
  title={Model-driven performance engineering of self-adaptive systems: A survey},
  year={2012},
  issn={978-1-4503-1346-9},
  pages={117-122},
  author={Becker, Matthias and Luckey, Markus and Becker, Steffen},
  url={https://doi.org/10.1145/2304696.2304716},
  publisher={Association for Computing Machinery},
  series={QoSA '12},
  keywords={model-driven performance engineering, self-*, self-adaptation, software performance},
  abstract={To meet quality-of-service requirements in changing environments, modern software systems adapt themselves. The structure, and correspondingly the behavior, of these systems undergoes continuous change. Model-driven performance engineering, however, assumes static system structures, behavior, and deployment. Hence, self-adaptive systems pose new challenges to model-driven performance engineering. There are a few surveys on self-adaptive systems, performance engineering, and the combination of both in the literature. In contrast to existing work, here we focus on model-driven performance analysis approaches. Based on a systematic literature review, we present a classification, identify open issues, and outline further research.}
}

@article{rayyan-727968260,
  title={Bayesian concepts in software testing: An initial review},
  year={2015},
  issn={978-1-4503-3813-4},
  pages={41-46},
  author={Rodriguez, Daniel and Dolado, Javier and Tuya, Javier},
  url={https://doi.org/10.1145/2804322.2804329},
  publisher={Association for Computing Machinery},
  series={A-test 2015},
  keywords={Bayesian networks, software testing, Bayesian statistics, probabilistic graphical models, Software},
  abstract={This work summarizes the main topics that have been researched in the area of software testing under the umbrella of “Bayesian approaches” since 2010. There is a growing trend on the use of the so-called Bayesian statistics and Bayesian concepts in general and software testing in particular. Following a Systematic Literature Review protocol using the main digital libraries and repositories, we selected around 40 references applying Bayesian approaches in the field of software testing since 2010. Those references summarise the current state of the art and foster better focused research. So far, the main observed use of the Bayesian concepts in the software testing field is through the application of Bayesian networks for software reliability and defect prediction (the latter is mainly based on static software metrics and Bayesian classifiers). Other areas of application are software estimation and test data generation. There are areas not fully explored beyond the basic Bayesian approaches, such as influence diagrams and dynamic networks.}
}

@article{rayyan-727968265,
  title={The state of empirical evaluation in static feature location},
  year={2018},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  volume={28},
  number={1},
  author={Razzaq, Abdul and Wasala, Asanka and Exton, Chris and Buckley, Jim},
  url={https://doi.org/10.1145/3280988},
  keywords={bug location, concept location, Feature location, requirement traceability},
  abstract={Feature location (FL) is the task of finding the source code that implements a specific, user-observable functionality in a software system. It plays a key role in many software maintenance tasks and a wide variety of Feature Location Techniques (FLTs), which rely on source code structure or textual analysis, have been proposed by researchers. As FLTs evolve and more novel FLTs are introduced, it is important to perform comparison studies to investigate “Which are the best FLTs?” However, an initial reading of the literature suggests that performing such comparisons would be an arduous process, based on the large number of techniques to be compared, the heterogeneous nature of the empirical designs, and the lack of transparency in the literature. This article presents a systematic review of 170 FLT articles, published between the years 2000 and 2015. Results of the systematic review indicate that 95% of the articles studied are directed towards novelty, in that they propose a novel FLT. Sixty-nine percent of these novel FLTs are evaluated through standard empirical methods but, of those, only 9% use baseline technique(s) in their evaluations to allow cross comparison with other techniques. The heterogeneity of empirical evaluation is also clearly apparent: altogether, over 60 different FLT evaluation metrics are used across the 170 articles, 272 subject systems have been used, and 235 different benchmarks employed. The review also identifies numerous user input formats as contributing to the heterogeneity. Analysis of the existing research also suggests that only 27% of the FLTs presented might be reproduced from the published material. These findings suggest that comparison across the existing body of FLT evaluations is very difficult. We conclude by providing guidelines for empirical evaluation of FLTs that may ultimately help to standardise empirical research in the field, cognisant of FLTs with different goals, leveraging common practices in existing empirical evaluations and allied with rationalisations. This is seen as a step towards standardising evaluation in the field, thus facilitating comparison across FLTs.}
}

@article{rayyan-727968276,
  title={A literature review of automatic traceability links recovery for software change impact analysis},
  year={2020},
  issn={978-1-4503-7958-8},
  pages={14-24},
  author={Aung, Thazin Win Win and Huo, Huan and Sui, Yulei},
  url={https://doi.org/10.1145/3387904.3389251},
  publisher={Association for Computing Machinery},
  series={ICPC '20},
  keywords={natural language processing, change impact analysis, traceability, Software},
  abstract={In large-scale software development projects, change impact analysis (CIA) plays an important role in controlling software design evolution. Identifying and accessing the effects of software changes using traceability links between various software artifacts is a common practice during the software development cycle. Recently, research in automated traceability-link recovery has received broad attention in the software maintenance community to reduce the manual maintenance cost of trace links by developers. In this study, we conducted a systematic literature review related to automatic traceability link recovery approaches with a focus on CIA. We identified 33 relevant studies and investigated the following aspects of CIA: traceability approaches, CIA sets, degrees of evaluation, trace direction and methods for recovering traceability link between artifacts of different types. Our review indicated that few traceability studies focused on designing and testing impact analysis sets, presumably due to the scarcity of datasets. Based on the findings, we urge further industrial case studies. Finally, we suggest developing traceability tools to support fully automatic traceability approaches, such as machine learning and deep learning.}
}

@article{rayyan-727968278,
  title={Patterns for integrating agile development processes and user centred design},
  year={2015},
  issn={978-1-4503-3847-9},
  author={Salah, Dina and Paige, Richard and Cairns, Paul},
  url={https://doi.org/10.1145/2855321.2855341},
  publisher={Association for Computing Machinery},
  series={EuroPLoP '15},
  keywords={agile, agile user centred design integration, agile user centred design integration patterns, user centred design},
  abstract={The aim of this paper is to report the patterns that emerged as a result of conducting two studies: first, a Systematic Literature Review (SLR) that investigated Agile and User Centred Design Integration (AUCDI) challenges, strategies and success factors and included a total of 71 AUCDI experience reports, lessons learned, and success and failure AUCDI case studies. Second, an interview study that investigated challenges and practices faced by industrial AUCDI attempts.The patterns that emerged are related to various aspects of the integration process, for example, design, prioritizing User Centred Design (UCD) activities, usability testing, UCD practitioners, documentation and communication between the customer and the development team.}
}

@article{rayyan-727968287,
  title={Accessibility in rich internet applications: People and research},
  year={2012},
  issn={978-85-7669-262-1},
  pages={3-12},
  author={Almeida, Leonelo Dell Anhol and Baranauskas, Maria Cecília Calani},
  publisher={Brazilian Computer Society},
  series={IHC '12},
  keywords={systematic literature review, web 2.0, accessibility, people, RIA, Internet},
  abstract={Accessibility in Rich Internet Applications (RIAs) is still far from reality for most of the Web applications currently available. Some factors that influence this scenario are the novelty of research and products for developing RIAs, and the challenging activity of identifying and involving representatives of RIAs target people. Aiming at clarifying the state-of-the-art of this research topic we conducted a Systematic Literature Review of studies addressing accessibility and awareness of others in RIAs. This paper presents our findings related to the overall contributions of the reviewed studies and analyzes the target people and the methods employed for involving them in the research lifecycle.}
}

@article{rayyan-727968297,
  title={Assessing software defection prediction performance: Why using the matthews correlation coefficient matters},
  year={2020},
  issn={978-1-4503-7731-7},
  pages={120-129},
  author={Yao, Jingxiu and Shepperd, Martin},
  url={https://doi.org/10.1145/3383219.3383232},
  publisher={Association for Computing Machinery},
  series={EASE '20},
  keywords={Software defect prediction, Classification metrics, Software engineering experimentation, Software},
  abstract={Context: There is considerable diversity in the range and design of computational experiments to assess classifiers for software defect prediction. This is particularly so, regarding the choice of classifier performance metrics. Unfortunately some widely used metrics are known to be biased, in particular F1.Objective: We want to understand the extent to which the widespread use of the F1 renders empirical results in software defect prediction unreliable.Method: We searched for defect prediction studies that report both F1 and the Matthews correlation coefficient (MCC). This enabled us to determine the proportion of results that are consistent between both metrics and the proportion that change.Results: Our systematic review identifies 8 studies comprising 4017 pairwise results. Of these results, the direction of the comparison changes in 23% of the cases when the unbiased MCC metric is employed.Conclusion: We find compelling reasons why the choice of classification performance metric matters, specifically the biased and misleading F1 metric should be deprecated.}
}

@article{rayyan-727968299,
  title={Do software process improvements lead to ISO 9126 architectural quality factor improvement},
  year={2011},
  issn={978-1-4503-0851-9},
  pages={11-17},
  author={Lavallée, Mathieu and Robillard, Pierre N},
  url={https://doi.org/10.1145/2024587.2024592},
  publisher={Association for Computing Machinery},
  series={WoSQ '11},
  keywords={systematic review, software process improvement, capability maturity model, impacts on developers, quality improvement, Software},
  abstract={This paper presents preliminary results of a systematic review performed to determine the impacts of Software Process Improvements (SPI) on developers' activities and on architectural quality. The analysis shows that most SPI research focuses on the motivations of developers like quality of work life and participation incentives, but provides little detail on the impacts of SPI on their day-to-day tasks. The impacts on product quality are limited to defect reduction, and do not consider architectural quality factors, such as changeability and stability. This study shows a very weak link between process quality, as defined by the CMMI, and architectural quality, as defined by ISO 9126. The SPI literature found by this review is mostly concerned with requirement process improvements, which are related to problem definition quality, but not to architectural quality. Future quality-oriented SPI research should therefore focus on improving design and development processes with an eye to considering architectural quality factors, or what the ISO 9126 terms "architectural capabilities".}
}

@article{rayyan-727968300,
  title={How to elicit and specify software requirements from BPMN diagrams?},
  year={2018},
  issn={978-1-4503-6559-8},
  author={Sorgatto, Doglas W and Paiva, Débora M B and Cagnin, Maria Istela},
  url={https://doi.org/10.1145/3229345.3229403},
  publisher={Association for Computing Machinery},
  series={SBSI'18},
  keywords={Systematic Review, BPMN, Requirement Elicitation, Software},
  abstract={Different techniques for eliciting requirements from business process models have arisen due to the importance of software requirements to be aligned with the business in order to achieve organizational goals. Although there are several ways to represent these models, the BPMN notation has been considered the most adequate for facilitating the communication between different types of stakeholders. This paper aims to present a systematic review with the support of the snowballing technique, to raise studies on how to elicit and specify requirements from business process models in BPMN. As main results it is pointed out that this type of elicitation is recent, well automated, uses supporting heuristics, is mainly concerned with functional requirements, and the most of primary studies specify the requirements as use cases.}
}

@article{rayyan-727968304,
  title={Factors affecting software development productivity: An empirical study},
  year={2019},
  issn={978-1-4503-7651-8},
  pages={307-316},
  author={Canedo, Edna Dias and Santos, Giovanni Almeida},
  url={https://doi.org/10.1145/3350768.3352491},
  publisher={Association for Computing Machinery},
  series={SBES 2019},
  keywords={Empirical study, Measurement, Productivity, Metrics, Influence Factors, Software, Fibrinogen},
  abstract={The competitiveness has demanded from the software industry shorter delivery times for its products resulting in optimized life cycles, generating a need to increase its performance to maintain competitiveness in the markets where they operate. This context has made productivity study so fundamental that organizations not only evaluate their performance, but also provide means to improve it. The main goal of this paper is to investigate which factors affect productivity in software development projects and in open-source projects. In this work a Systematic Literature Review (SLR) was carried out in order to answer the research questions and a survey with practitioners community about their perception in relation to the factors of the productivity of the team. This empirical study led to the discovery of interesting factors that show how the different factors do (or do not) affect productivity. It was also found out that some factors appear to allow independence and responsibility of team, while others appear to cause a better distribution of tasks. The results show how factors such as people, product, organization, investment in technology, lack of contractual relations and engagement of open-source project contributors influence productivity.}
}

@article{rayyan-727968306,
  title={CASE tool support for variability management in software product lines},
  year={2017},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={50},
  number={1},
  author={Bashroush, Rabih and Garba, Muhammad and Rabiser, Rick and Groher, Iris and Botterweck, Goetz},
  url={https://doi.org/10.1145/3034827},
  keywords={Software engineering, computer-aided software engineering, software variability, Software},
  abstract={Software product lines (SPL) aim at reducing time-to-market and increasing software quality through extensive, planned reuse of artifacts. An essential activity in SPL is variability management, i.e., defining and managing commonality and variability among member products. Due to the large scale and complexity of today's software-intensive systems, variability management has become increasingly complex to conduct. Accordingly, tool support for variability management has been gathering increasing momentum over the last few years and can be considered a key success factor for developing and maintaining SPLs. While several studies have already been conducted on variability management, none of these analyzed the available tool support in detail. In this work, we report on a survey in which we analyzed 37 existing variability management tools identified using a systematic literature review to understand the tools' characteristics, maturity, and the challenges in the field. We conclude that while most studies on variability management tools provide a good motivation and description of the research context and challenges, they often lack empirical data to support their claims and findings. It was also found that quality attributes important for the practical use of tools such as usability, integration, scalability, and performance were out of scope for most studies.}
}

@article{rayyan-727968309,
  title={Data quality: Cinderella at the software metrics ball?},
  year={2011},
  issn={978-1-4503-0593-8},
  pages={1-4},
  author={Shepperd, Martin},
  url={https://doi.org/10.1145/1985374.1985376},
  publisher={Association for Computing Machinery},
  series={WETSoM '11},
  keywords={empirical research, data quality, software metrics, Research Design, Metronidazole, Software},
  abstract={In this keynote I explore what exactly do we mean by data quality, techniques to assess data quality and the very significant challenges that poor data quality can pose. I believe we neglect data quality at our peril since - whether we like it or not - our research results are founded upon data and our assumptions that data quality issues do not confound our results. A systematic review of the literature suggests that it is a minority practice to even explicitly discuss data quality. I therefore suggest that this topic should become a higher priority amongst empirical software engineering researchers.}
}

@article{rayyan-727968311,
  title={Is there a "Golden" feature set for static warning identification? An experimental evaluation},
  year={2018},
  issn={978-1-4503-5823-1},
  author={Wang, Junjie and Wang, Song and Wang, Qing},
  url={https://doi.org/10.1145/3239235.3239523},
  publisher={Association for Computing Machinery},
  series={ESEM '18},
  keywords={static analysis, experimental evaluation, actionable warning identification},
  abstract={Background: The most important challenge regarding the use of static analysis tools (e.g., FindBugs) is that there are a large number of warnings that are not acted on by developers. Many features have been proposed to build classification models for the automatic identification of actionable warnings. Through analyzing these features and related studies, we observe several limitations that make the users lack practical guides to apply these features.Aims: This work aims at conducting a systematic experimental evaluation of all the public available features, and exploring whether there is a golden feature set for actionable warning identification.Method: We first conduct a systematic literature review to collect all public available features for warning identification. We employ 12 projects with totally 60 revisions as our subject projects. We then implement a tool to extract the values of all features for each project revision to prepare the experimental data.Results: Experimental evaluation on 116 collected features demonstrates that there is a common set of features (23 features) which take effect in warning identification for most project revisions. These features can achieve satisfied performance with far less time cost for warning identification.Conclusions: These commonly-selected features can be treated as the golden feature set for identifying actionable warnings. This finding can serve as a practical guideline for facilitating real-world warning identification.}
}

@article{rayyan-727968319,
  title={User studies on end-user service composition: A literature review and a design framework},
  year={2019},
  journal={ACM Transactions on the Web},
  issn={1559-1131},
  volume={13},
  number={3},
  author={Zhao, Liping and Loucopoulos, Pericles and Kavakli, Evangelia and Letsholo, Keletso J},
  url={https://doi.org/10.1145/3340294},
  keywords={systematic review, empirical studies, service-oriented computing, design guideline, end-user service composition, mapshups, qualitative studies, review framework, User studies, web services},
  abstract={Context: End-user service composition (EUSC) is a service-oriented paradigm that aims to empower end users and allow them to compose their own web applications from reusable service components. User studies have been used to evaluate EUSC tools and processes. Such an approach should benefit software development, because incorporating end users' feedback into software development should make software more useful and usable. Problem: There is a gap in our understanding of what constitutes a user study and how a good user study should be designed, conducted, and reported. Goal: This article aims to address this gap. Method: The article presents a systematic review of 47 selected user studies for EUSC. Guided by a review framework, the article systematically and consistently assesses the focus, methodology and cohesion of each of these studies. Results: The article concludes that the focus of these studies is clear, but their methodology is incomplete and inadequate, their overall cohesion is poor. The findings lead to the development of a design framework and a set of questions for the design, reporting, and review of good user studies for EUSC. The detailed analysis and the insights obtained from the analysis should be applicable to the design of user studies for service-oriented systems as well and indeed for any user studies related to software artifacts.}
}

@article{rayyan-727968326,
  title={The role of anxiety when learning to program: A systematic review of the literature},
  year={2016},
  issn={978-1-4503-4770-9},
  pages={61-70},
  author={Nolan, Keith and Bergin, Susan},
  url={https://doi.org/10.1145/2999541.2999557},
  publisher={Association for Computing Machinery},
  series={Koli calling '16},
  keywords={systematic review, computer science, learning, programming, anxiety, Anxiety},
  abstract={According to the World Health Organisation the number one global health issue for young people is their mental health. For students, mental well-being is associated with effective learning, and their ability to navigate through university/college, having the resilience to cope with the challenges and stresses of student life.In Ireland, Computer Science (CS) non-progression rates are alarming, with a large number of students failing to progress each year. Currently non-progression rates are 25% in CS, significantly higher than the national average of 16% across all other fields of study. On top of the normal stressors of transitioning or returning to university, CS students are arguably exposed to a unique set of factors that could further induce anxiety. First, they typically have no formal CS exposure or training to draw on. Second, the number of contact hours and workload are high. Third, CS courses includes programming modules. For some, learning to program is diffcult and many struggle to master the core concepts. Learning typically takes place in a lab environment where inexperienced programmers will begin to type (code") shortly after being presented with a problem rather than spending time designing a solution. Thus the lab becomes active and busy from the onset, making struggling students cripplingly perceive their peers know more. Further, novice programmers use the compiler to constantly monitor their progress and error messages can be perceived as negative feedback. Such an environment can create or compound anxiety and stress. At our institution a large number of CS students register for counselling services or leave.In this paper we present a systematic literature review on the role of anxiety when learning to program. The work is novel, valuable, and timely. The approach used is systematic, in that a structured search of electronic resources has been conducted and the results are presented and quantitatively analysed. A detailed discussion on the findings is provided and important implications for the teaching and learning of programming are described.}
}

@article{rayyan-727968330,
  title={Variability management in software product lines: A systematic review},
  year={2009},
  pages={81-90},
  author={Chen, Lianping and Ali Babar, Muhammad and Ali, Nour},
  publisher={Carnegie Mellon University},
  series={SPLC '09},
  keywords={⛔ No DOI found, systematic reviews, software product lines, variability management, Software},
  abstract={Variability Management (VM) in Software Product Line (SPL) is a key activity that usually affects the degree to which a SPL is successful. SPL community has spent huge amount of resources on developing various approaches to dealing with variability related challenges over the last decade. To provide an overview of different aspects of the proposed VM approaches, we carried out a systematic literature review of the papers reporting VM in SPL. This paper presents and discusses the findings from this systematic literature review. The results reveal the chronological backgrounds of various approaches over the history of VM research, and summarize the key issues that drove the evolution of different approaches. This study has also identified several gaps that need to be filled by future efforts in this line of research.}
}

@article{rayyan-727968333,
  title={Plagiarism in programming assessments: A systematic review},
  year={2019},
  journal={ACM Transactions on Computing Education},
  volume={20},
  number={1},
  author={Albluwi, Ibrahim},
  url={https://doi.org/10.1145/3371156},
  keywords={academic integrity, cheating, Introductory programming, plagiarism},
  abstract={This article is a systematic review of work in the computing education literature on plagiarism. The goal of the review is to summarize the main results found in the literature and highlight areas that need further work. Despite the the large body of work on plagiarism, no systematic reviews have been published so far.The reviewed papers were categorized and analyzed using a theoretical framework from the field of Fraud Deterrence named the Fraud Triangle. According to this framework, fraudulent behavior occurs when the person is under pressure, perceives the availability of an opportunity to commit fraud, and rationalizes the fraudulent behavior in a way that makes it seem not unethical to him or her.The review found the largest amount of the reviewed papers to discuss ways for reducing the opportunity to plagiarize, as well as tools for detecting plagiarism. However, there is a clear lack of empirical work evaluating the deterrent efficacy of these strategies and tools. The reviewed papers also included mentions of a wide range of rationalizations used by computing students when justifying plagiarism, the most important of which are rationalizations that stem from confusion about what constitutes plagiarism. Finally, work on the relationship between pressure in computing courses and plagiarism was found to be very scarce and incommensurate with the significant contribution of this factor to plagiarism.}
}

@article{rayyan-727968334,
  title={The evolution of the laws of software evolution: A discussion based on a systematic literature review},
  year={2013},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={46},
  number={2},
  author={Herraiz, Israel and Rodriguez, Daniel and Robles, Gregorio and Gonzalez-Barahona, Jesus M},
  url={https://doi.org/10.1145/2543581.2543595},
  keywords={software evolution, Laws of software evolution, Software},
  abstract={After more than 40 years of life, software evolution should be considered as a mature field. However, despite such a long history, many research questions still remain open, and controversial studies about the validity of the laws of software evolution are common. During the first part of these 40 years, the laws themselves evolved to adapt to changes in both the research and the software industry environments. This process of adaption to new paradigms, standards, and practices stopped about 15 years ago, when the laws were revised for the last time. However, most controversial studies have been raised during this latter period. Based on a systematic and comprehensive literature review, in this article, we describe how and when the laws, and the software evolution field, evolved. We also address the current state of affairs about the validity of the laws, how they are perceived by the research community, and the developments and challenges that are likely to occur in the coming years.}
}

@article{rayyan-727968335,
  title={IoT architectural concerns: A systematic review},
  year={2017},
  issn={978-1-4503-4774-7},
  author={Gill, Asif Qumer and Behbood, Vahid and Ramadan-Jradi, Rania and Beydoun, Ghassan},
  url={https://doi.org/10.1145/3018896.3025166},
  publisher={Association for Computing Machinery},
  series={ICC '17},
  keywords={IoT, architecture, internet of things, enterprise architecture, digital-physical ecosystem},
  abstract={There is increasing interest in studying and applying Internet of Things (IoT) within the overall context of digital-physical ecosystems. Most recently, much has been published on the benefits and applications of IoT. The main question is: what are the key IoT architectural concerns, which must be addressed to effectively develop and implement an IoT architecture? There is a need to systematically review and synthesize the literature on IoT architectural challenges or concerns. Using the SLR approach and applying customised search criteria derived from the research question, 22 relevant studies were identified and reviewed in this paper. The data from these papers were extracted to identify the IoT architectural challenges and relevant solutions. These results were organised into to 9 major challenge and 7 solution categories. The results of this research will serve as a resource for practitioners and researchers for the effective adoption, and setting future research priorities and directions in this emerging area of IoT architecture.}
}

@article{rayyan-727968340,
  title={State of the art for risk management in software acquisition},
  year={2009},
  journal={SIGSOFT Softw. Eng. Notes},
  issn={0163-5948},
  volume={34},
  number={4},
  pages={1-10},
  author={Calvo-Manzano Villalón, Jose A and Agustín, Gonzalo Cuevas and Hurtado, Gloria Gasca and San Feliu Gilabert, Tomás},
  url={https://doi.org/10.1145/1543405.1543426},
  keywords={systematic review, software engineering, process improvement, risk management, software acquisition, Risk Management, Software},
  abstract={This paper presents the state of the art for risk management in software acquisition. To determine it, a systematic review protocol for Software Engineering is used. Furthermore, the systematic re-view focuses on identifying initiatives and reports of risk manage-ment proposals for software acquisition in small settings. Results show increasing research in risk management and the need for more in-depth studies.}
}

@article{rayyan-727968343,
  title={E-government inter-organizational integration: Types and success factors},
  year={2020},
  issn={978-1-4503-7690-7},
  pages={216-221},
  author={Putri, Mieke Eka and Sensuse, Dana Indra and Mishbah, Muhammad and Prima, Pudy},
  url={https://doi.org/10.1145/3378936.3378955},
  publisher={Association for Computing Machinery},
  series={ICSIM '20},
  keywords={systematic literature review, e-government, success factors, integration, inter-organizational, kitchenham},
  abstract={The rapid development of ICT in Indonesia encourages governments to implement e-government for supporting their services so they can improve their service delivery, strengthen accountability, and increase transparency. Unfortunately, there is a major drawback regarding the implementation of e-government. One of the drawbacks is that most organizations develop silos online services. This condition reflects a lack of e-government inter-organizational integrations. E-government integration among organizations or agencies is necessary to promote a more efficient process, accurate information, and seamless services, which are the objectives of the e-government itself. E-government integration is a complicated process as stakeholders need to consider and plan several factors to make it successful. This study identified the types of e-government inter-organizational integrations through a systematic literature review using the Kitchenham method. The study reveals the success factors which need to be concerned to implement e-government successfully. This study can be used as a reference by stakeholders to initiate an implementation of e-government inter-organizational integration.}
}

@article{rayyan-727968344,
  title={Teaching discrete structures: A systematic review of the literature},
  year={2011},
  issn={978-1-4503-0500-6},
  pages={275-280},
  author={Power, James F and Whelan, Thomas and Bergin, Susan},
  url={https://doi.org/10.1145/1953163.1953247},
  publisher={Association for Computing Machinery},
  series={SIGCSE '11},
  keywords={computing curriculum, discrete mathematics, discrete structures},
  abstract={This survey paper reviews a large sample of publications on the teaching of discrete structures and discrete mathematics in computer science curricula. The approach is systematic, in that a structured search of electronic resources has been conducted, and the results are presented and quantitatively analyzed. A number of broad themes in discrete structures education are identified relating to course content, teaching strategies and the means of evaluating the success of a course.}
}

@article{rayyan-727968346,
  title={Inventory routing problem with time windows: A systematic review of the literature},
  year={2018},
  issn={978-1-4503-6559-8},
  author={Alves, Pedro Yuri A L and Delgado, Karina Valdivia and da Silva, Valdinei Freire},
  url={https://doi.org/10.1145/3229345.3229376},
  publisher={Association for Computing Machinery},
  series={SBSI'18},
  keywords={Inventory Routing Problem, Time Windows, Vehicle Routing Problem},
  abstract={The integration of inventory management, vehicle routing, and scheduling decisions is known as Inventory Routing Problem (IRP). In this problem, the main objective is to determine: (i) the quantity of products to be delivered based on customer's demand; (ii) the delivery periods and (iii) the route of vehicles. IRPs that include time window service constraints are found in real scenarios and the attendance of this type of constraints brings benefits to both the supplier and the customer. This systematic review of the literature aims to identify trends in the area that studies Inventory Routing Problems with time windows. We identify and analyze the proposed approaches, the characteristics of the solved problems and the type of experiments performed in 9 primary studies.}
}

@article{rayyan-727968347,
  title={Traveling salesperson problem with hotel selection: A systematic review of the literature},
  year={2019},
  issn={978-1-4503-7237-4},
  author={de Sousa, Marques Moreira and Ochi, Luiz Satoru and de Lima Martins, Simone},
  url={https://doi.org/10.1145/3330204.3330243},
  publisher={Association for Computing Machinery},
  series={SBSI'19},
  keywords={Combinatorial Optimization, Hotel Selection, Traveling Salesperson Problem, Travel},
  abstract={The Traveling Salesperson Problem with Hotel Selection (TSPHS) is a novel variant of the classical Traveling Salesperson Problem. In this variant, the main objective is to minimize the number of trips and total traveled time. This problem is found in real scenarios like delivery of products by electric vehicles that need to be recharged along a tour. This systematic review of the literature aims to analyse techniques and trends to solve this logistic problem using combinatorial optimization. We have applied a search string related to TSPHS for three search engines, filtered 33 returned results and analyzed the proposed approaches to identify the following aspects: (i) characteristics of the solved problems, (ii) if statistics analyses have been performed for parameter tuning in case of heuristics approaches, (iii) characteristics of instances solved by exact methods and (iv) types of experiments. Furthermore, we have observed that the Lin-Kernighan heuristic performs well to generate initial solution for heuristics, the hotels order sequence has major impact on final solution quality and the complexity of this problem still represents for modern Information Systems a constraint to solve large instances using exact approaches.}
}

@article{rayyan-727968348,
  title={Evaluating strategies for study selection in systematic literature studies},
  year={2014},
  issn={978-1-4503-2774-9},
  author={Ali, Nauman Bin and Petersen, Kai},
  url={https://doi.org/10.1145/2652524.2652557},
  publisher={Association for Computing Machinery},
  series={ESEM '14},
  keywords={systematic review, inclusion and exclusion, study selection},
  abstract={Context: The study selection process is critical to improve the reliability of secondary studies. Goal: To evaluate the selection strategies commonly employed in secondary studies in software engineering. Method: Building on these strategies, a study selection process was formulated and evaluated in a systematic review. Results: The selection process used a more inclusive strategy than the one typically used in secondary studies, which led to additional relevant articles. Conclusions: The results indicates that a good-enough sample could be obtained by following a less inclusive but more efficient strategy, if the articles identified as relevant for the study are a representative sample of the population, and there is a homogeneity of results and quality of the articles.}
}

@article{rayyan-727968349,
  title={QoS-Aware autonomic resource management in cloud computing: A systematic review},
  year={2015},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={48},
  number={3},
  author={Singh, Sukhpal and Chana, Inderveer},
  url={https://doi.org/10.1145/2843889},
  keywords={cloud computing, self-management, autonomic computing, autonomic cloud computing, autonomic management, grid computing, quality of service, resource management, Resource provisioning, resource scheduling, self-configuring, self-healing, self-optimizing, self-protecting, service-level agreement},
  abstract={As computing infrastructure expands, resource management in a large, heterogeneous, and distributed environment becomes a challenging task. In a cloud environment, with uncertainty and dispersion of resources, one encounters problems of allocation of resources, which is caused by things such as heterogeneity, dynamism, and failures. Unfortunately, existing resource management techniques, frameworks, and mechanisms are insufficient to handle these environments, applications, and resource behaviors. To provide efficient performance of workloads and applications, the aforementioned characteristics should be addressed effectively. This research depicts a broad methodical literature analysis of autonomic resource management in the area of the cloud in general and QoS (Quality of Service)-aware autonomic resource management specifically. The current status of autonomic resource management in cloud computing is distributed into various categories. Methodical analysis of autonomic resource management in cloud computing and its techniques are described as developed by various industry and academic groups. Further, taxonomy of autonomic resource management in the cloud has been presented. This research work will help researchers find the important characteristics of autonomic resource management and will also help to select the most suitable technique for autonomic resource management in a specific application along with significant future research directions.}
}

@article{rayyan-727968350,
  title={Validating software metrics: A spectrum of philosophies},
  year={2013},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  volume={21},
  number={4},
  author={Meneely, Andrew and Smith, Ben and Williams, Laurie},
  url={https://doi.org/10.1145/2377656.2377661},
  keywords={systematic literature review, Software metrics, validation criterion, Metronidazole, Software, Software Validation},
  abstract={Context. Researchers proposing a new metric have the burden of proof to demonstrate to the research community that the metric is acceptable in its intended use. This burden of proof is provided through the multi-faceted, scientific, and objective process of software metrics validation. Over the last 40 years, however, researchers have debated what constitutes a “valid” metric.Aim. The debate over what constitutes a valid metric centers on software metrics validation criteria. The objective of this article is to guide researchers in making sound contributions to the field of software engineering metrics by providing a practical summary of the metrics validation criteria found in the academic literature.Method. We conducted a systematic literature review that began with 2,288 papers and ultimately focused on 20 papers. After extracting 47 unique validation criteria from these 20 papers, we performed a comparative analysis to explore the relationships amongst the criteria.Results. Our 47 validation criteria represent a diverse view of what constitutes a valid metric. We present an analysis of the criteria's categorization, conflicts, common themes, and philosophical motivations behind the validation criteria.Conclusions. Although the 47 validation criteria are not conflict-free, the diversity of motivations and philosophies behind the validation criteria indicates that metrics validation is complex. Researchers proposing new metrics should consider the applicability of the validation criteria in terms of our categorization and analysis. Rather than arbitrarily choosing validation criteria for each metric, researchers should choose criteria that can confirm that the metric is appropriate for its intended use. We conclude that metrics validation criteria provide answers to questions that researchers have about the merits and limitations of a metric.}
}

@article{rayyan-727968352,
  title={Feature weighting techniques for CBR in software effort estimation studies: A review and empirical evaluation},
  year={2014},
  issn={978-1-4503-2898-2},
  pages={32-41},
  author={Sigweni, Boyce and Shepperd, Martin},
  url={https://doi.org/10.1145/2639490.2639508},
  publisher={Association for Computing Machinery},
  series={PROMISE '14},
  keywords={meta-analysis, systematic literature review, case-based reasoning, software effort estimation, feature subset selection, feature weighting, Software},
  abstract={Context: Software effort estimation is one of the most important activities in the software development process. Unfortunately, estimates are often substantially wrong. Numerous estimation methods have been proposed including Case-based Reasoning (CBR). In order to improve CBR estimation accuracy, many researchers have proposed feature weighting techniques (FWT).Objective: Our purpose is to systematically review the empirical evidence to determine whether FWT leads to improved predictions. In addition we evaluate these techniques from the perspectives of (i) approach (ii) strengths and weaknesses (iii) performance and (iv) experimental evaluation approach including the data sets used.Method: We conducted a systematic literature review of published, refereed primary studies on FWT (2000–2014).Results: We identified 19 relevant primary studies. These reported a range of different techniques. 17 out of 19 make benchmark comparisons with standard CBR and 16 out of 17 studies report improved accuracy. Using a one-sample sign test this positive impact is significant (p = 0.0003).Conclusion: The actionable conclusion from this study is that our review of all relevant empirical evidence supports the use of FWTs and we recommend that researchers and practitioners give serious consideration to their adoption.}
}

@article{rayyan-727968353,
  title={An investigation of smart parking tools, technologies, & challenges},
  year={2020},
  issn={978-1-4503-7721-8},
  pages={198-203},
  author={Zahoor, Tayyba and Azam, Farooque and Anwar, Muahmmad Waseem and Tariq, Ayesha and Javaid, Haider Ali},
  url={https://doi.org/10.1145/3436829.3436851},
  publisher={Association for Computing Machinery},
  series={ICSIE 2020},
  keywords={Systematic Literature Review, Smart Parking, Smart Parking Challenges, Smart Parking Technologies, Smart Parking Tools},
  abstract={Urbanization, exceptional increase in population and advancement in technology caused the automotive industry to grow rapidly & automobiles become essential part of daily life. Consequently, finding a parking space particularly in populous zones, is a challenging task. Researchers have proposed different solutions to assist the developments in smart parking systems. In this paper, we have investigated the key tools, techniques & challenges proposed in the recent research studies. Primarily, a Systematic Literature Review is carried out, total 35 studies are explored during time interval of (2015-2019). Subsequently, five major areas are recognized where smart parking is often functional i.e. Internet of Things (IoT) (13 studies), Cloud Computing (2 studies), Model-Driven Engineering (4 studies), Fog Computing (6 studies) and Artificial Intelligence (11 studies). Furthermore, (15) primary tools and (25) algorithms are presented. This article also portray the challenges cited by different studies. The findings of this study will definitely assist the practitioners while deciding the appropriate selections.}
}

@article{rayyan-727968356,
  title={Gaps between industry expectations and the abilities of graduates},
  year={2013},
  issn={978-1-4503-1868-6},
  pages={525-530},
  author={Radermacher, Alex and Walia, Gursimran},
  url={https://doi.org/10.1145/2445196.2445351},
  publisher={Association for Computing Machinery},
  series={SIGCSE '13},
  keywords={systematic literature review, knowledge deficiency},
  abstract={Although computer science, information systems, and information technology educators often do an exemplary job of preparing their students for jobs in industry or for further education, there are still many areas where these students do not possess the necessary skills or knowledge based on the expectations of employers or academia. These gaps between the abilities of graduating students and those expected to have can prevent them from succeeding in their careers. This paper presents the results of a systematic literature review conducted to determine which areas graduating students most frequently fall short of the expectations of industry or macademia. The results of this review indicate that graduating students are lacking in many different areas, including technical abilities (design, testing, configuration management tools, etc.) personal skills (communication, teamwork, etc.) and professional qualities (e.g. ethics). By raising awareness of these areas, it is possible for educators to become aware of areas where students most frequently fail to meet expectations and to make curriculum changes or adjustments to address these problems}
}

@article{rayyan-727968357,
  title={A review of peer code review in higher education},
  year={2020},
  journal={ACM Transactions on Computing Education},
  volume={20},
  number={3},
  author={Indriasari, Theresia Devi and Luxton-Reilly, Andrew and Denny, Paul},
  url={https://doi.org/10.1145/3403935},
  keywords={systematic review, systematic literature review, Peer review, code review, higher education, peer code review, programming course, Peer Review},
  abstract={Peer review is the standard process within academia for maintaining publication quality, but it is also widely employed in other settings, such as education and industry, for improving work quality and for generating actionable feedback to content authors. For example, in the software industry peer review of program source code—or peer code review—is a key technique for detecting bugs and maintaining coding standards. In a programming education context, although peer code review offers potential benefits to both code reviewers and code authors, individuals are typically less experienced, which presents a number of challenges. Some of these challenges are similar to those reported in the educational literature on peer review in other academic disciplines, but reviewing code presents unique difficulties. Better understanding these challenges and the conditions under which code review can be taught and implemented successfully in computer science courses is of value to the computing education community. In this work, we conduct a systematic review of the literature on peer code review in higher education to examine instructor motivations for conducting peer code review activities, how such activities have been implemented in practice, and the primary benefits and difficulties that have been reported. We initially identified 187 potential studies and analyzed 51 empirical studies pertinent to our goals. We report the most commonly cited benefits (e.g., the development of programming-related skills) and barriers (e.g., low student engagement), and we identify a wide variety of tools that have been used to facilitate the peer code review process. While we argue that more empirical work is needed to validate currently reported results related to learning outcomes, there is also a clear need to address the challenges around student motivation, which we believe could be an important avenue for future research.}
}

@article{rayyan-727968358,
  title={Understanding the effects of lecturer intervention on computer science student behaviour},
  year={2018},
  issn={978-1-4503-5627-5},
  pages={105-124},
  author={Szabo, Claudia and Falkner, Nickolas and Knutas, Antti and Dorodchi, Mohsen},
  url={https://doi.org/10.1145/3174781.3174787},
  publisher={Association for Computing Machinery},
  series={ITiCSE-WGR '17},
  keywords={systematic literature review, intervention},
  abstract={Providing effective support and feedback to students is critical to ensure engagement and retention within Computer Science courses. Individual student learning experiences and challenges vary from student to student, and effective intervention is further hampered in a large scale context. In addition, there are a plethora of possible interventions for any given learning challenge, and it is difficult for an educator to establish which intervention is the most effective or quickest to implement. To this, we report on the outcomes of a systematic literature review focused on interventions in Computer Science classrooms. To provide an understanding of the types of interventions possible in a Computer Science course, we propose a taxonomy of intervention types with low mutual information and classify the 129 selected papers based on it. We identify the most effective interventions as presented in their respective studies and discuss gaps in the study of several intervention types. We then present an overview of two of the most popular types of interventions in the published literature: those focused on introducing technical cooperations within courses, and those focused on changing the way the course content is presented to students. To understand how interventions have evolved over time, we present the evolution of sub-classes of interventions over the years.}
}

@article{rayyan-727968361,
  title={Towards an understanding of value creation in agile software development},
  year={2019},
  issn={978-1-4503-7237-4},
  author={Neto, Geraldo Torres G and Santos, Wylliams B and Fagundes, Roberta A A and Margaria, Tiziana},
  url={https://doi.org/10.1145/3330204.3330256},
  publisher={Association for Computing Machinery},
  series={SBSI'19},
  keywords={Systematic Literature Review, Agile Software Development, Business Value, Software},
  abstract={Recently, studies involving the creation of business value in Agile Software Development (ASD) have been growing substantially. However, the concept of value creation in ASD has not yet been clearly defined. Besides, the literature does not define practices that can create business value for ASD. Identifying these practices can change the mindset of agile teams, since surveys indicate that, from the point of view of the agile team, the creation of value is poorly understood. Thus, this study carried out a Systematic Literature Review to identify how value creation is defined in ASD, and how practices can improve this value creation. Despite the lack of studies on the subject, we identified practices and its positive and negative influence on value creation.}
}

@article{rayyan-727968362,
  title={Energy management in embedded systems: Towards a taxonomy},
  year={2012},
  issn={978-1-4673-1832-7},
  pages={41-44},
  author={Ramesh, Umesh Balaji Kothandapani and Sentilles, Severine and Crnkovic, Ivica},
  publisher={IEEE Press},
  series={GREENS '12},
  keywords={systematic review, embedded systems, energy consumption},
  abstract={Energy is an important constraint in embedded systems, and there exists a huge expertise in this domain about monitoring, managing and optimizing energy consumption in the computer systems. The aim of this paper is to present the energy management addressed in the research literature. Based on a systematic review, the paper presents a taxonomy of energy consumption and management in embedded systems.}
}

@article{rayyan-727968366,
  title={An insight into the capabilities of professionals and teams in agile software development: A systematic literature review},
  year={2018},
  issn={978-1-4503-5414-1},
  pages={10-19},
  author={Vishnubhotla, Sai Datta and Mendes, Emilia and Lundberg, Lars},
  url={https://doi.org/10.1145/3185089.3185096},
  publisher={Association for Computing Machinery},
  series={ICSCA 2018},
  keywords={Systematic literature review, agile software development, capability measurement, capability prediction, competence, individual capability, team capability, Software},
  abstract={Background: Previous studies investigated key characteristics of software engineers and factors influencing the performance of individuals, productivity of teams and project success within agile software development (ASD). They aided in the active investigation of human aspects in ASD. However, capability measurement and prediction with respect to agile workforce, owing to its importance, is an area that needs spotlight.Objective: The objective of this paper is to present the state of the art relating to capability measurement of software engineers and teams working in ASD projects.Method: We carried out a systematic literature review (SLR) focused on identifying attributes used for measuring and predicting the capabilities of individual software engineers and teams.Results: Evidence from 16 studies showed attributes that can measure capabilities of engineers and teams, and also attributes that can be used as capability predictors. Further, different instruments used to measure those attributes were presented.Conclusions: The SLR presented a wide list of attributes that were grouped into various categories. This information can be used by project managers as, for example, a checklist to consider when allocating software engineers to teams and in turn teams to a project. Further, this study indicated the necessity for an investigation into capability prediction models.}
}

@article{rayyan-727968367,
  title={Digitization of public services: A systematic literature review},
  year={2018},
  issn={978-1-4503-6565-9},
  pages={91-100},
  author={Leão, Heloise Acco Tives and Canedo, Edna Dias},
  url={https://doi.org/10.1145/3275245.3275255},
  publisher={Association for Computing Machinery},
  series={SBQS},
  keywords={Brazilian Government, Digital Governance, Digital Transformation Kit, Service Digitization, Service Pricing},
  abstract={This paper presents a systematic literature review of the digitization of services carried out by the governments of several countries. The main contribution of this work is the identification of the processes and methodologies adopted by these governments to provide their services to the citizen. These results serve as inputs to guide an analysis of the initial efforts of the Brazilian Government in the construction of a digital platform for the provision of its services directed to the citizen, seeking to analyze their needs and improving the services currently provided.}
}

@article{rayyan-727968368,
  title={A systematic review to assist in identifying teaching approaches to guide the application of an interdisciplinary software factory in IT undergraduation},
  year={2017},
  issn={978-1-4503-5326-7},
  pages={384-391},
  author={de Souza, M da C O and Oliveira, S R B and Meira, S R L},
  url={https://doi.org/10.1145/3131151.3131176},
  publisher={Association for Computing Machinery},
  series={SBES'17},
  keywords={systematic review, interdisciplinary, IT higher courses, learning process, Software factory, Software},
  abstract={The market is increasingly demanding in relation to the quality of information and communication technology professionals. The industry claims educational institutions to train future employees of technology with quality. In this context, there are software factories, whose investments in this branch of activity have been made not only by governmental entities, but also by the national and international private sector, which has also motivated the emergence of a new modality of software factory: that installed in institutions of higher education, which aims of supporting the learning process in a practical way for the students. With a focus on answering the objective of identifying, understanding and discussing evidence on teaching methodologies, in order to understand the use, benefits and difficulties in applying these practices in a software factory in the IT courses, in this work a systematic review of literature (SRL) was made in the IEEE Xplorer, Scopus, ACM Digital Library and Engineering Village databases from 2003 to 2015. Of the total of 118 preselected papers, this work identified 14 papers, in which 9 papers report some kind of experience in driving software factory in IT higher courses, these works were conducted through a systematic mapping. It was also observed that some works demonstrate greater maturity in this practice and others are starting the experiments, but all apply this environment in different ways.}
}

@article{rayyan-727968370,
  title={Test case prioritization: A systematic review and mapping of the literature},
  year={2017},
  issn={978-1-4503-5326-7},
  pages={34-43},
  author={de S. Campos Junior, Heleno and Araújo, Marco Antônio P and David, José Maria N and Braga, Regina and Campos, Fernanda and Ströele, Victor},
  url={https://doi.org/10.1145/3131151.3131170},
  publisher={Association for Computing Machinery},
  series={SBES'17},
  keywords={systematic literature review, Regression testing, systematic literature mapping, software testing},
  abstract={Test case prioritization (TCP) techniques aim to reorder test cases execution according to a goal. One common goal is fault detection, in which test cases that have a higher chance of detecting a fault are executed first than the remaining test cases. The goal of this study is to investigate TCP empirical studies in order to synthesize reported effectiveness results and provide a basis for future research. We conducted a systematic literature mapping to characterize TCP empirical studies and a systematic literature review to analyze reported TCP techniques effectiveness results. Among selected studies from 1999 to 2016, we found that there is a high amount of empirical studies evaluating many TCP techniques. However, when we applied our quality assessment criteria, most of them were discarded, indicating that they might have methodological problems. Analyzed studies reported results of coverage-based TCP techniques. Furthermore, we found that some context factors regarding faults, test cases of the application being tested and coverage granularity considered by TCP techniques may significantly affect the effectiveness of their execution. These results suggest that more rigorous empirical methodology is needed when evaluating TCP techniques and also, authors need to compare effectiveness results of their proposed TCP techniques with well established techniques to generate more evidences Furthermore, our analysis of significant factors on TCP techniques effectiveness can guide researchers when planning empirical evaluations and help them choosing features to compose new techniques.}
}

@article{rayyan-727968372,
  title={A systematic literature review of continuous blood glucose monitoring and suggesting the quantity of insulin or artificial pancreas (AP) for diabetic type 1 patients},
  year={2019},
  issn={978-1-4503-6600-7},
  pages={539-545},
  author={Asad, Muhammad and Qamar, Usman and Khan, Aimal and Safdar, Rahmat Ullah},
  url={https://doi.org/10.1145/3318299.3318352},
  publisher={Association for Computing Machinery},
  series={ICMLC '19},
  keywords={AP, CDSS closed loop systems and PID, CGM, insulin prediction, MPC, T1DM, Glucose, Blood Glucose, Blood Glucose Self-Monitoring},
  abstract={Background: Diabetes Mellitus is one of the most common diseases, which is rapidly increasing worldwide. Early detection of Blood Glucose Level not only helps in better management of Diabetes Mellitus but also decreases the cost of treatment. In the recent past, numerous researches have been carried out to monitor blood glucose level which suggests the quantity of insulin i.e. artificial pancreas. Method: In this paper, we summarize and analyze the past work of continuous blood glucose monitoring and automatic insulin suggestion, in a systematic way. Particularly, 24 journal studies from 2015 to 2018 are identified and analyzed. The paper provided a dynamic study of insulin-glucose regulators by identifying some research questions and answering from the literature. Moreover, it provides brief of the methodology of each study and how it contributes towards this field. It also underlines the advantages of the methods used in past and how they lack in determining other aspects for achieving a completely autonomous, adaptive and individualized model. Results: A comprehensive investigation of the selected studies leads to identify four major areas i.e. Machine learning techniques (8 studies), MPC (6 studies), PID (2 studies), mixed (6) and others (2 studies).Conclusion: This study is helpful in opening a gateway for new researchers to have an overview of the past work on continuous glucose monitoring and insulin suggestion. It identifies the challenges in this particular domain in order to lay the foundation for future research. The survey discovers the most popular techniques used for blood glucose monitoring and insulin suggestion, exogenous or intravenous (Subcutaneous) or artificial pancreas. For future work, the nonlinear autoregressive neural network based model predictive controller is suggested.}
}

@article{rayyan-727968373,
  title={A gamification requirements catalog for educational software: Results from a systematic literature review and a survey with experts},
  year={2017},
  issn={978-1-4503-4486-9},
  pages={1108-1113},
  author={Peixoto, Mariana and Silva, Carla},
  url={https://doi.org/10.1145/3019612.3019752},
  publisher={Association for Computing Machinery},
  series={SAC '17},
  keywords={systematic literature review, survey, requirements engineering, educational software, gamification catalog, Software},
  abstract={Gamification is an emerging phenomenon for using in educational software in order to engage, motivate and improve the performance of students inside the learning context. However, despite its importance, the identification of significant gamification requirements for educational software is not trivial and a consensus of such requirements has not been reached. Motivated by this situation, the objective of this paper is to present a gamification requirements catalog for educational software. The requirements were identified from a systematic literature review, subsequently prioritized and validated through a survey conducted with 64 experts in the field. The results suggest that the requirements of the catalog are important to be applied in educational software.}
}

@article{rayyan-727968375,
  title={An overview of researches on digital accessibility before and after the great challenges of SBC 2006-2016: A systematic literature review},
  year={2017},
  issn={978-1-4503-6377-8},
  author={Coelho, Thais and Barbosa, Glívia A R and Silva, Ismael S and Coutinho, Flávio R dos S and da Silva, Fábio R},
  url={https://doi.org/10.1145/3160504.3160537},
  publisher={Association for Computing Machinery},
  series={IHC 2017},
  keywords={Systematic Literature Review, Digital accessibility},
  abstract={Digital accessibility contributes to digital and social inclusion of people. Faced with this potential contribution, in 2006, the Brazilian Computer Society (SBC) presented the "Participative and universal access to knowledge for the Brazilian citizen" as one of the great challenges of computing in Brazil for a decade (i.e., 2006-2016). Through this challenge, SBC sought to stimulate and support research in Brazil related to the theme that includes initiatives to promote accessibility. Ten years after the launch of great challenges of SBC, there is a demand to characterize the researches in digital accessibility in Brazil in order to demonstrate the investments and evolution in this area. This work presents an overview of the investments in digital accessibility in Brazil, through the comparative characterization of the research carried out in the country ten years before and ten years after the challenge launched by SBC. The perspective of the presented characterization is relevant because it allows reflecting on how this theme has been explored in the country in the scientific scope, besides evidencing the relevance of maintaining digital accessibility as an important investment area in Brazil.}
}

@article{rayyan-727968378,
  title={Effective regression test case selection: A systematic literature review},
  year={2017},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={50},
  number={2},
  author={Kazmi, Rafaqut and Jawawi, Dayang N A and Mohamad, Radziah and Ghani, Imran},
  url={https://doi.org/10.1145/3057269},
  keywords={Software testing, SLR, cost effectiveness, coverage, fault detection ability},
  abstract={Regression test case selection techniques attempt to increase the testing effectiveness based on the measurement capabilities, such as cost, coverage, and fault detection. This systematic literature review presents state-of-the-art research in effective regression test case selection techniques. We examined 47 empirical studies published between 2007 and 2015. The selected studies are categorized according to the selection procedure, empirical study design, and adequacy criteria with respect to their effectiveness measurement capability and methods used to measure the validity of these results.The results showed that mining and learning-based regression test case selection was reported in 39% of the studies, unit level testing was reported in 18% of the studies, and object-oriented environment (Java) was used in 26% of the studies. Structural faults, the most common target, was used in 55% of the studies. Overall, only 39% of the studies conducted followed experimental guidelines and are reproducible.There are 7 different cost measures, 13 different coverage types, and 5 fault-detection metrics reported in these studies. It is also observed that 70% of the studies being analyzed used cost as the effectiveness measure compared to 31% that used fault-detection capability and 16% that used coverage.}
}

@article{rayyan-727968381,
  title={A systematic review of service level management in the cloud},
  year={2015},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={48},
  number={3},
  author={Faniyi, Funmilade and Bahsoon, Rami},
  url={https://doi.org/10.1145/2843890},
  keywords={survey, Cloud computing, QoS, software architecture, autonomic, self-adaptive, self-awareness, SLA},
  abstract={Cloud computing make it possible to flexibly procure, scale, and release computational resources on demand in response to workload changes. Stakeholders in business and academia are increasingly exploring cloud deployment options for their critical applications. One open problem is that service level agreements (SLAs) in the cloud ecosystem are yet to mature to a state where critical applications can be reliably deployed in clouds. This article systematically surveys the landscape of SLA-based cloud research to understand the state of the art and identify open problems. The survey is particularly aimed at the resource allocation phase of the SLA life cycle while highlighting implications on other phases. Results indicate that (i) minimal number of SLA parameters are accounted for in most studies; (ii) heuristics, policies, and optimisation are the most commonly used techniques for resource allocation; and (iii) the monitor-analysis-plan-execute (MAPE) architecture style is predominant in autonomic cloud systems. The results contribute to the fundamentals of engineering cloud SLA and their autonomic management, motivating further research and industrial-oriented solutions.}
}

@article{rayyan-727968382,
  title={Usability evaluation of VR products in industry: A systematic literature review},
  year={2019},
  issn={978-1-4503-5933-7},
  pages={1845-1851},
  author={Karre, Sai Anirudh and Mathur, Neeraj and Reddy, Y Raghu},
  url={https://doi.org/10.1145/3297280.3297462},
  publisher={Association for Computing Machinery},
  series={SAC '19},
  keywords={metrics, virtual reality, usability testing, industrial practices, usability evaluation},
  abstract={VR development practices have a diverse set of practices compared to traditional software development. Tasks like scene design, acoustic design, vergence manipulation, image depth, etc. are specific to VR apps and hence require evaluation processes that may be different from the traditional means. Usability Evaluation is one such process which is being executed in an unconventional way by Industrial Practitioners today. In this paper, the researchers detail a Systematic Literature Review of the Usability Evaluation Methods practised by Industrial researchers while building VR Products. The researchers found that VR Product teams follow unique methods to improve usability in their products. Further, the researchers consolidate these methods and provide insights into choosing the best to build a real-world VR Product based on the defined product constraints.}
}

@article{rayyan-727968383,
  title={Architectural description of embedded systems: A systematic review},
  year={2012},
  issn={978-1-4503-1347-6},
  pages={31-40},
  author={Guessi, Milena and Nakagawa, Elisa Yumi and Oquendo, Flavio and Maldonado, José Carlos},
  url={https://doi.org/10.1145/2304656.2304661},
  publisher={Association for Computing Machinery},
  series={ISARCS '12},
  keywords={systematic review, embedded systems, reference architectures},
  abstract={Embedded systems have gained more and more attention, as variety and complexity of these systems have increased. In particular, many of these systems are also critical regarding dependability, safety, security, among others. In parallel, since software architectures and reference architectures form the backbone of any successful system, including embedded systems, an important and even essential activity is to properly describe such architectures. However, to our best knowledge, there is no detailed panorama on how software architectures and reference architectures for embedded systems could be represented. Thus, the main contribution of this paper is to present and discuss results of a systematic review, aiming at providing this wide and, at the same time, deep panorama. We found out that different approaches have been proposed and used, lacking of consensus on how to better represent architectures of embedded systems. We also identified a range of quality requirements and constraints that have been considered in the architectural description of these systems. Furthermore, these results can be considered as valuable means to identify research lines that need to be further investigated.}
}

@article{rayyan-727968385,
  title={Undergraduate teaching assistants in computer science: A systematic literature review},
  year={2019},
  issn={978-1-4503-6185-9},
  pages={31-40},
  author={Mirza, Diba and Conrad, Phillip T and Lloyd, Christian and Matni, Ziad and Gatin, Arthur},
  url={https://doi.org/10.1145/3291279.3339422},
  publisher={Association for Computing Machinery},
  series={ICER '19},
  keywords={cs1, cs2, undergraduate teaching assistants},
  abstract={We present a systematic literature review of the prior work on Undergraduate Teaching Assistants (UTAs) in Computer Science with two goals: (1) to create a taxonomy of practices that relate to the design and implementation of UTA programs, (2) to identify the benefits of using UTAs as claimed by the literature and characterize the level of evidence for those claims. We analyze 336 excerpts from 40 papers related to these goals. We use content analysis on excerpts describing practices to extract high-level themes that include recruiting, UTA and program coordinator duties, training, evaluation and organization of UTA programs. We perform a more fine-grained analysis within each theme to identify specific questions about UTA programs and the answers provided by the literature. Using a similar technique, we report on the claimed benefits of UTA programs to students, UTAs, instructors and institutions. Our analysis follows well-defined protocols involving multiple reviewers and we report on the inter-rater reliability. The results provided in this paper lay the groundwork for developing evidence-based best practices in UTA programs and inform practice and policy related to the use of UTAs at tertiary institutions. As such, it is relevant to educators establishing a new UTA program, expanding an existing program, or continuously improving an established program, as well as those designing research studies of such programs.}
}

@article{rayyan-727968386,
  title={A systematic review of automated feature engineering solutions in machine learning problems},
  year={2020},
  issn={978-1-4503-8873-3},
  author={Prado, Fernando F and Digiampietri, Luciano A},
  url={https://doi.org/10.1145/3411564.3411610},
  publisher={Association for Computing Machinery},
  series={SBSI'20},
  keywords={Auto Learning, Feature Engineering, Feature Generation, Feature Selection},
  abstract={During the last decades, machine learning has played an important role in building data-driven experiments. Based on information extracted from a variety of sources, new patterns can be identified, predictions can be made more easily and decisions made faster and more effective. The specialized application of machine learning solutions requires specific knowledge in areas such as math, computation, and statistics, as well as being extremely costly in time and having a high chance of incurring any kind of human error during the process. Automated Machine Learning Techniques (AutoML) seek to automate parts of the process of building machine learning applications, allowing non-experts to perform this process. An important part of this kind of problem is the feature engineering part which creates a transformation in the data, making it more representative for the final model. This paper presents a systematic review of automated feature engineering solutions in machine learning problems. With the main objective of identifying and analyzing the existing methods and techniques for performing the automated feature engineering step within the framework of machine learning problems.}
}

@article{rayyan-727968389,
  title={Pragmatic assessment of research intensive areas in cloud: A systematic review},
  year={2013},
  journal={SIGSOFT Softw. Eng. Notes},
  issn={0163-5948},
  volume={38},
  number={3},
  pages={1-6},
  author={Hasteer, Nitasha and Bansal, Abhay and Murthy, B K},
  url={https://doi.org/10.1145/2464526.2464533},
  keywords={systematic review, cloud computing, cloud services, cloud deployment, cloud migration, cloud security, networking},
  abstract={Cloud computing is a name given to a set of systems for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. Cloud computing is aimed at making an organization more agile and cost effective. Due to the rapid evolution of Cloud Computing in the recent past, it is relevant to investigate the key areas of research of this technology. In this paper, we present a systematic review of research intensive areas in the field of cloud computing. Research papers in the period from 2009 to 2012 were gathered. A total of 36 research papers were reviewed systematically and categorized into four broad categories based on the issues addressed by them. We identified that the majority of the research papers focused on Cloud Security. By systematically analyzing the work accomplished so far, the gaps and yet to be explored areas in this field are brought to light.}
}

@article{rayyan-727968390,
  title={Cross- vs. within-Company cost estimation studies revisited: An extended systematic review},
  year={2014},
  issn={978-1-4503-2476-2},
  author={Mendes, Emilia and Kalinowski, Marcos and Martins, Daves and Ferrucci, Filomena and Sarro, Federica},
  url={https://doi.org/10.1145/2601248.2601284},
  publisher={Association for Computing Machinery},
  series={EASE '14},
  keywords={systematic review, cost estimation models, cross-company data, estimation accuracy, within-company data},
  abstract={[Objective] The objective of this paper is to extend a previously conducted systematic literature review (SLR) that investigated under what circumstances individual organizations would be able to rely on cross-company based estimation models. [Method] We applied the same methodology used in the SLR we are extending herein (covering the period 2006-2013) based on primary studies that compared predictions from cross-company models with predictions from within-company models constructed from analysis of project data. [Results] We identified 11 additional papers; however two of these did not present independent results and one had inconclusive findings. Two of the remaining eight papers presented both, trials where cross-company predictions were not significantly different from within-company predictions and others where they were significantly different. Four found that cross-company models gave prediction accuracy significantly different from within-company models (one of them in favor of cross-company models), while two found no significant difference. The main pattern when examining the study related factors was that studies where cross-company predictions were significantly different from within-company predictions employed larger within-company data sets. [Conclusions] Overall, half of the analyzed evidence indicated that cross-company estimation models are not significantly worse than within-company estimation models. Moreover, there is some evidence that sample size does not imply in higher estimation accuracy, and that samples for building estimation models should be carefully selected/filtered based on quality control and project similarity aspects. The results need to be combined with the findings from the SLR we are extending to allow further investigating this topic.}
}

@article{rayyan-727968393,
  title={A systematic review of the use of bloom's taxonomy in computer science education},
  year={2018},
  issn={978-1-4503-5103-4},
  pages={441-446},
  author={Masapanta-Carrión, Susana and Velázquez-Iturbide, J Ángel},
  url={https://doi.org/10.1145/3159450.3159491},
  publisher={Association for Computing Machinery},
  series={SIGCSE '18},
  keywords={Bloom's taxonomy, computer science education, difficulties},
  abstract={Bloom's taxonomy is a model that allows characterizing students' learning achievements. It is frequently used in computer science education (CSE), but its use is not straightforward. We present a systematic review conducted to know actual use of the taxonomy in CSE. We found that it was mostly used in programming education and to assess students' performance. A more relevant contribution is a classification of authors' difficulties. In particular, the most often reported difficulty is determining the level of the taxonomy where an assessment task can be classified. In addition, we present authors' hypotheses about possible causes of the difficulties and the solutions they adopted.}
}

@article{rayyan-727968394,
  title={Features of second screen applications: A systematic review},
  year={2016},
  issn={978-1-4503-4512-5},
  pages={83-86},
  author={do Nascimento, Francisca Joamila Brito and de Souza, Cidcley Teixeira},
  url={https://doi.org/10.1145/2976796.2988169},
  publisher={Association for Computing Machinery},
  series={Webmedia '16},
  keywords={systematic review, applications, features, mobile devices, digital tv, second screen},
  abstract={In this paper, we present a systematic literature review, whose object of study are the available features in second screen applications. The second screen is the ability to interact with the TV programming by using mobile devices. The research was conducted in order to find out what the most common features in second screen apps. The selected articles refer to 16 different features, which were grouped into 5 categories. Interactivity was the category with more features mentioned in the researched works. Therefore, we concluded the features that provide interactivity between users and TV programming are the most common on the second screen.}
}

@article{rayyan-727968396,
  title={Research in concurrent software testing: A systematic review},
  year={2011},
  issn={978-1-4503-0809-0},
  pages={1-5},
  author={Souza, Simone R S and Brito, Maria A S and Silva, Rodolfo A and Souza, Paulo S L and Zaluska, Ed},
  url={https://doi.org/10.1145/2002962.2002964},
  publisher={Association for Computing Machinery},
  series={PADTAD '11},
  keywords={systematic review, software testing, testing tools, bug classification, concurrent program, concurrent program testing, Software},
  abstract={The current increased demand for distributed applications in domains such as web services and cloud computing has significantly increased interest in concurrent programming. This demand in turn has resulted in new testing methodologies for such systems, which take account of the challenges necessary to test these applications. This paper presents a systematic review of the published research related to concurrent testing approaches, bug classification and testing tools. A systematic review is a process of collection, assessment and interpretation of the published papers related to a specific search question, designed to provide a background for further research. The results include information about the research relationships and research teams that are working in the different areas of concurrent programs testing.}
}

@article{rayyan-727968401,
  title={Empirical evaluation of cloud-based testing techniques: A systematic review},
  year={2012},
  journal={SIGSOFT Softw. Eng. Notes},
  issn={0163-5948},
  volume={37},
  number={3},
  pages={1-9},
  author={Priyanka and Chana, Inderveer and Rana, Ajay},
  url={https://doi.org/10.1145/2180921.2180938},
  keywords={software testing, cloud testing, performance testing, cloud-based testing, metamorphic testing, privacy-aware testing, security testing, symbolic execution, testing cloud services},
  abstract={Software Testing is a challenging activity for many software engineering projects, especially for large scale systems. The amount of tests cases can range from a few hundred to several thousands, requiring significant computing resources and lengthy execution times. Cloud computing offers the potential to address both of these issues: it offers resources such as virtualized hardware, effectively unlimited storage, and software services that can aid in reducing the execution time of large test suites in a cost-effective manner. In this paper we report on a systematic review of cloud based testing techniques published in major software engineering journals and conferences conducted by other researchers. Research papers were gathered from various scholarly databases using provided search engines within a given period of time. A total of 82 research papers are analyzed in this systematic review and we classified it into four categories according to issues addressed by them. We identified majority of the research papers focused on Cloud based Testing and Issues (38 papers) and 23 papers focused on Cloud based Testing Frameworks. By looking at the areas focused by existing researchers, gaps and untouched areas of cloud based testing can be discovered}
}

@article{rayyan-727968404,
  title={On vulnerability and security log analysis: A systematic literature review on recent trends},
  year={2020},
  issn={978-1-4503-8025-6},
  pages={175-180},
  author={Svacina, Jan and Raffety, Jackson and Woodahl, Connor and Stone, Brooklynn and Cerny, Tomas and Bures, Miroslav and Shin, Dongwan and Frajtak, Karel and Tisnovsky, Pavel},
  url={https://doi.org/10.1145/3400286.3418261},
  publisher={Association for Computing Machinery},
  series={RACS '20},
  keywords={Machine Learning, Log Analysis, Log Mining, Anomaly Detection, Intrusion Detection},
  abstract={Log analysis is a technique of deriving knowledge from log files containing records of events in a computer system. A common application of log analysis is to derive critical information about a system's security issues and intrusions, which subsequently leads to being able to identify and potentially stop intruders attacking the system. However, many systems produce a high volume of log data with high frequency, posing serious challenges in analysis. This paper contributes with a systematic literature review and discusses current trends, advancements, and future directions in log security analysis within the past decade. We summarized current research strategies with respect to technology approaches from 34 current publications. We identified limitations that poses challenges to future research and opened discussion on issues towards logging mechanism in the software systems. Findings of this study are relevant for software systems as well as software parts of the Internet of Things (IoT) systems.}
}

@article{rayyan-727968410,
  title={Introductory programming: A systematic literature review},
  year={2018},
  issn={978-1-4503-6223-8},
  pages={55-106},
  author={Luxton-Reilly, Andrew and Simon and Albluwi, Ibrahim and Becker, Brett A and Giannakos, Michail and Kumar, Amruth N and Ott, Linda and Paterson, James and Scott, Michael James and Sheard, Judy and Szabo, Claudia},
  url={https://doi.org/10.1145/3293881.3295779},
  publisher={Association for Computing Machinery},
  series={ITiCSE 2018 companion},
  keywords={systematic review, overview, systematic literature review, SLR, literature review, introductory programming, review, CS1, ITiCSE working group, novice programming},
  abstract={As computing becomes a mainstream discipline embedded in the school curriculum and acts as an enabler for an increasing range of academic disciplines in higher education, the literature on introductory programming is growing. Although there have been several reviews that focus on specific aspects of introductory programming, there has been no broad overview of the literature exploring recent trends across the breadth of introductory programming. This paper is the report of an ITiCSE working group that conducted a systematic review in order to gain an overview of the introductory programming literature. Partitioning the literature into papers addressing the student, teaching, the curriculum, and assessment, we explore trends, highlight advances in knowledge over the past 15 years, and indicate possible directions for future research.}
}

@article{rayyan-727968411,
  title={The adoption of capture-recapture in software engineering: A systematic literature review},
  year={2015},
  issn={978-1-4503-3350-4},
  author={Liu, Gaoxuan and Rong, Guoping and Zhang, He and Shan, Qi},
  url={https://doi.org/10.1145/2745802.2745816},
  publisher={Association for Computing Machinery},
  series={EASE '15},
  keywords={systematic literature review, capture-recapture method, defect estimation, software inspection, Software},
  abstract={Context: Capture-recapture method has long been adopted in software engineering as a relatively objective way for defect estimation. While many relevant studies have been carried out to evaluate various capture-recapture models and estimators, there still lacks common understanding on the adoption status of the method in software engineering. It is necessary to systematically collect empirical evidence of Capture-recapture adoption hence form necessary understanding on the method.Objective: This study aims to synthesize relevant primary studies on the adoption of capture-recapture method in software engineering, and try to identify possible gaps between the state-of-practice and the state-of-art so as to provide clues for future research.Method: By following the guidelines of Kitchenham, we conducted a Systematic Literature Review(SLR) on studies of the adoption of capture-recapture method in software engineering.Results: From 5 common digital libraries, we retrieved 506 published articles, among them 44 were identified as relevant primary studies. We identified 18 capture-recapture estimators under 4 basic models. Types of the currently existing studies as well as the relevant influencing factors to adoption of the capture-recapture method are also discussed.Conclusion: Results show that there are no conclusive decisions on the best capture-recapture models and estimators. Besides, the number of inspectors and their capability to detect defects as well as the difficulty to detect defects are most critical influencing factors. In addition, lacking of industrial application may be the major issue of current adoption status of capture-recapture method in software engineering.}
}

@article{rayyan-727968412,
  title={A systematic literature review on global software development life cycle},
  year={2015},
  journal={SIGSOFT Softw. Eng. Notes},
  issn={0163-5948},
  volume={40},
  number={2},
  pages={1-14},
  author={Jain, Ritu and Suman, Ugrasen},
  url={https://doi.org/10.1145/2735399.2735408},
  keywords={systematic literature review, software engineering, challenges, global software development, tools, process, distributed software development, software development life cycle, best practices, problems, Software},
  abstract={Global software development (GSD) has now become a prominent software development paradigm. Software companies are increasingly adopting GSD approaches in order to produce high quality software. GSD's popularity has attracted the researchers to investigate this field, but most of the research work related to global software development cycle is scattered. Therefore, there is a need to integrate and compile all research work related to GSD life cycle to provide a consolidated understanding for software practitioners as well as researchers. In this paper, we report our findings through systematic literature review that aimed at identifying the challenges faced by the globally distributed teams during various phases of software development. We have also discussed suggested best practices, and tools that can be helpful in alleviating these challenges.}
}

@article{rayyan-727968413,
  title={A systematic literature review of improved knowledge management in agile software development},
  year={2019},
  issn={978-1-4503-6642-7},
  pages={102-105},
  author={Al Hafidz, Mochamad Umar and Sensuse, Dana Indra},
  url={https://doi.org/10.1145/3305160.3305192},
  publisher={Association for Computing Machinery},
  series={ICSIM 2019},
  keywords={Systematic literature review, ⚠️ Invalid DOI, agile software development, knowledge management, improvement, Software},
  abstract={Agile Software Development (ASD) is an adaptive software development approach that easily adapts to changing software requirements. It offers an advantage in time management but has disadvantages such as lack of software documentation and knowledge management. This research aims to understand more about research development in the knowledge management improvisation in Agile Software Development by collecting various themes of improved area and method used. To achieve this goal, 226 articles written in 2009-2018 are screened by using Kitchenham method to produce 15 best articles. This systematic literature review (SLR) results in a summary of improvements in knowledge management. The summary includes various approaches of several themes such as documentation, tools or technology, and others. The areas that need improvement are tools for supporting communication and documentation. The suggested improvement that has been proposed by researcher focuses mostly on artifact documentation, decision making, effort estimation and tools. In these studies, research question can be identified, analyzed, and answered.}
}

@article{rayyan-727968414,
  title={A systematic literature review on interaction flow modeling language (IFML)},
  year={2018},
  issn={978-1-4503-5431-8},
  pages={134-138},
  author={Hamdani, Maryum and Butt, Wasi Haider and Anwar, Muhammad Waseem and Azam, Farooque},
  url={https://doi.org/10.1145/3180374.3181333},
  publisher={Association for Computing Machinery},
  series={ICMSS 2018},
  keywords={SLR, IFML, Interaction flow modeling language, MDA},
  abstract={Design of front-end interfaces in software applications is a complex process. In this context, Interaction Flow Modeling Language (IFML) is an emerging standard introduced in 2013 by Object Management Group (OMG). In this article, a Systematic Literature Review (SLR) is performed to examine the applications of IFML. Particularly, 22 research studies (2014-2017) are identified and analyzed. Consequently, four major areas are recognized where IFML is frequently applied i.e. mobile applications (9 studies), web applications (8 studies), others (4 studies) and desktop applications (1 study). Furthermore, 9 leading IFML tools are presented i.e. Modeling (3) and model transformation (6). It has been concluded that IFML certainly simplifies the design and implementation of front-end interfaces. However, the existing IFML tools are not mature enough to be utilized for complex and large software applications.}
}

@article{rayyan-727968415,
  title={A systematic literature review of traceability approaches between software architecture and source code},
  year={2014},
  issn={978-1-4503-2476-2},
  author={Javed, Muhammad Atif and Zdun, Uwe},
  url={https://doi.org/10.1145/2601248.2601278},
  publisher={Association for Computing Machinery},
  series={EASE '14},
  keywords={systematic literature review, software architecture, traceability, source code, Software},
  abstract={The links between the software architecture and the source code of a software system should be based on solid traceability mechanisms in order to effectively perform quality control and maintenance of the software system. There are several primary studies on traceability between software architecture and source code but so far no systematic literature review (SLR) has been undertaken. This study presents an SLR which has been carried out to discover the existing traceability approaches and tools between software architecture and source code, as well as the empirical evidence for these approaches, their benefits and liabilities, their relations to software architecture understanding, and issues, barriers, and challenges of the approaches. In our SLR the ACM Guide to Computing Literature has been electronically searched to accumulate the biggest share of relevant scientific bibliographic citations from the major publishers in computing. The search strategy identified 742 citations, out of which 11 have been included in our study, dated from 1999 to July, 2013, after applying our inclusion and exclusion criteria. Our SLR resulted in the identification of the current state-of-the-art of traceability approaches and tools between software architecture and source code, as well as gaps and pointers for further research. Moreover, the classification scheme developed in this paper can serve as a guide for researchers and practitioners to find a specific approach or set of approaches that is of interest to them.}
}

@article{rayyan-727968416,
  title={A systematic literature review of technical debt prioritization},
  year={2020},
  issn={978-1-4503-7960-1},
  pages={1-10},
  author={Alfayez, Reem and Alwehaibi, Wesam and Winn, Robert and Venson, Elaine and Boehm, Barry},
  url={https://doi.org/10.1145/3387906.3388630},
  publisher={Association for Computing Machinery},
  series={TechDebt '20},
  keywords={software, software maintenance, technical debt, prioritization, software management},
  abstract={Repaying all technical debt (TD) present in a system may be unfeasible, as there is typically a shortage in the resources allocated for TD repayment. Therefore, TD prioritization is essential to best allocate such resources to determine which TD items are to be repaid first and which items are to be delayed until later releases. This study conducts a systematic literature review (SLR) to identify and analyze the currently researched TD prioritization approaches. The employed search strategy strove to achieve high completeness through the identification of a quasi-gold standard set, which was used to establish a search string to automatically retrieve papers from select research databases. The application of selection criteria, along with forward and backward snowballing, identified 24 TD prioritization approaches. The analysis of the identified approaches revealed a scarcity of approaches that account for cost, value, and resources constraint and a lack of industry evaluation. Furthermore, this SLR unveils potential gaps in the current TD prioritization research, which future research may explore.}
}

@article{rayyan-727968417,
  title={Outcomes of a community workshop to identify and rank barriers to the systematic literature review process},
  year={2014},
  issn={978-1-4503-2476-2},
  author={Hassler, Edgar and Carver, Jeffrey C and Kraft, Nicholas A and Hale, David},
  url={https://doi.org/10.1145/2601248.2601274},
  publisher={Association for Computing Machinery},
  series={EASE '14},
  keywords={systematic literature review, empirical software engineering, workshop},
  abstract={Systematic Literature Reviews (SLRs) are an important tool used by software engineering researchers to summarize the state of knowledge about a particular topic. Currently, SLR authors must perform the difficult, time-consuming task in largely manual fashion. To identify barriers faced by SLR authors, we conducted an interactive community workshop prior to ESEM'13. Workshop participants generated a total of 100 ideas that, through group discussions, formed 37 composite barriers to the SLR process. Further analysis reveals the barriers relate to latent themes regarding the SLR process, primary studies, the practitioner community, and tooling. This paper describes the barriers identified during the workshop along with a ranking of those barriers that is based on votes by workshop attendees. The paper concludes by describing the impact of these barriers on three important constituencies: SLR Methodology Researchers, SLR Authors and SLR consumers.}
}

@article{rayyan-727968418,
  title={A systematic literature review for software portability measurement: Preliminary results},
  year={2020},
  issn={978-1-4503-7665-5},
  pages={152-157},
  author={Ghandorh, Hamza and Noorwali, Abdulfattah and Nassif, Ali Bou and Capretz, Luiz Fernando and Eagleson, Roy},
  url={https://doi.org/10.1145/3384544.3384569},
  publisher={Association for Computing Machinery},
  series={ICSCA 2020},
  keywords={Software measurement, Empirical study, Software quality, Software portability, Software},
  abstract={Software developers agree that software portability is a desirable attribute for their software quality. Software portability is mostly acquired by ad-hoc techniques when trying to port existing products. There is a lack of unified measuring approach of software portability in most computing platforms. This paper presents preliminary results of a systematic literature review, conducted to collect evidence on measuring software portability. The evidence was gathered from selected studies and based on a set of meaningful and focused questions. 49 studies of these were selected for data extraction performed against the research questions. We provide an overview of usedproposed measurement metrics of software portability. Our results suggested that there are scattered efforts to understand measurement of software portability, and no census has been achieved.}
}

@article{rayyan-727968419,
  title={A systematic literature review of UML-Based domain-specific modeling languages for self-adaptive systems},
  year={2018},
  issn={978-1-4503-5715-9},
  pages={87-93},
  author={da Silva, João Pablo S and Ecar, Miguel and Pimenta, Marcelo S and Guedes, Gilleanes T A and Franz, Luiz Paulo and Marchezan, Luciano},
  url={https://doi.org/10.1145/3194133.3194136},
  publisher={Association for Computing Machinery},
  series={SEAMS '18},
  keywords={systematic literature review (SLR), unified modeling language (UML), domain-specific modeling language (DSML), self-adaptive systems (SaS), snowballing technique},
  abstract={Self-adaptive Systems (SaSs) operate under uncertainty conditions and have intrinsic properties that make their modeling a non-trivial activity. This complexity can be minimized by using Domain-Specific Modeling Languages (DSMLs), which may be created by extending Unified Modeling Language (UML). In face of this, we propose investigating how the UML has been customized to create DSMLs that provide proper support for SaSs modeling. To achieve this, we performed a Systematic Literature Review (SRL) by retrieving studies with snowballing technique, selecting studies according to inclusion and exclusion criteria, and extracting and analyzing data to answer our research questions. As the outcome, we retrieved 786 studies and selected 16 primary studies published between 2005 and 2017. The results reveal that the class diagram has been customized through the profile-based mechanism to provide proper support to analysis and design of context-awareness and self-adaptiveness properties.}
}

@article{rayyan-727968420,
  title={A systematic literature review to support the selection of user acceptance testing techniques},
  year={2018},
  issn={978-1-4503-5663-3},
  pages={418-419},
  author={Santos, Ernani César Dos and Vilain, Patrícia and Longo, Douglas Hiura},
  url={https://doi.org/10.1145/3183440.3195036},
  publisher={Association for Computing Machinery},
  series={ICSE '18},
  keywords={techniques, classification, features, user acceptance testing},
  abstract={User Acceptance Testing (UAT) aims to determine whether or not a software satisfies users acceptance criteria. Although some studies have used acceptance tests as software requirements, no previous study has collected information about available UAT techniques and established a comparison of them, to support an organization in the selection of one over another. This work presents a Systematic Literature Review on UAT to find out available techniques and compare their main features. We selected 80 studies and found out 21 UAT techniques. As result, we created a comparative table summarizing these techniques and their features.}
}

@article{rayyan-727968421,
  title={A systematic review on cloud testing},
  year={2019},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={52},
  number={5},
  author={Bertolino, Antonia and Angelis, Guglielmo De and Gallego, Micael and García, Boni and Gortázar, Francisco and Lonetti, Francesca and Marchetti, Eda},
  url={https://doi.org/10.1145/3331447},
  keywords={systematic literature review, Cloud computing, testing},
  abstract={A systematic literature review is presented that surveyed the topic of cloud testing over the period 2012–2017. Cloud testing can refer either to testing cloud-based systems (testing of the cloud) or to leveraging the cloud for testing purposes (testing in the cloud): both approaches (and their combination into testing of the cloud in the cloud) have drawn research interest. An extensive paper search was conducted by both automated query of popular digital libraries and snowballing, which resulted in the final selection of 147 primary studies. Along the survey, a framework has been incrementally derived that classifies cloud testing research among six main areas and their topics. The article includes a detailed analysis of the selected primary studies to identify trends and gaps, as well as an extensive report of the state-of-the-art as it emerges by answering the identified Research Questions. We find that cloud testing is an active research field, although not all topics have received enough attention and conclude by presenting the most relevant open research challenges for each area of the classification framework.}
}

@article{rayyan-727968422,
  title={A model-based approach to systematic review of research literature},
  year={2017},
  issn={978-1-4503-4856-0},
  pages={15-25},
  author={Barat, Souvik and Clark, Tony and Barn, Balbir and Kulkarni, Vinay},
  url={https://doi.org/10.1145/3021460.3021462},
  publisher={Association for Computing Machinery},
  series={ISEC '17},
  keywords={Systematic Literature Review, Systematic Mapping Study, Literature Review, Meta Modeling, Model Based Literature Review},
  abstract={A systematic approach to develop a literature review is attractive because it aims to achieve a repeatable, unbiased and evidence-based outcome. However the existing form of systematic review such as Systematic Literature Review (SLR) and Systematic Mapping Study (SMS) are known to be an effort, time, and intellectual intensive endeavour. To address these issues, this paper proposes a model-based approach to Systematic Review (SR) production. The approach uses a domain-specific language expressed as a meta-model to represent research literature, a meta-model to specify SR constructs in a uniform manner, and an associated development process all of which can benefit from computer-based support. The meta-models and process are validated using real-life case study. We claim that the use of meta-modeling and model synthesis lead to a reduction in time, effort and the current dependence on human expertise.}
}

@article{rayyan-727968423,
  title={A systematic literature review on factors impacting agile adaptation in global software development},
  year={2019},
  issn={978-1-4503-7195-7},
  pages={158-163},
  author={Altaf, Areebah and Fatima, Urooj and Butt, Wasi Haider and Anwar, Muhammad Waseem and Hamdani, Maryum},
  url={https://doi.org/10.1145/3348445.3348463},
  publisher={Association for Computing Machinery},
  series={ICCCM 2019},
  keywords={XP, Agile practices, global software development, scrum, Software},
  abstract={Agile practices are considered as a major attraction for global software development (GSD) projects owing to its flexible nature. Beside the major benefits it offers to GSD, there are few challenges that hinders its implementation across the global software industry. This study contributes in constructing a systematic literature review for exploring the major factors impacting the agile adaptation at global level. We have identified and analyzed 28 research studies (2015-2019). These selected studies have revealed Scrum and Extreme Programming (XP) as the most popular agile practices that are adapted irrespective of the software type and organizational structure. Furthermore 5 tool categories are also presented i.e. modeling, requirement elicitation, data tracking tools etc. that are commonly used while practicing agile. The major findings of this study conclude that these agile methodologies are heavily adapted due to their iterative model and quick code delivery but basic challenges like poor customer involvement and lack of documentation are badly affecting its growth at global level.}
}

@article{rayyan-727968424,
  title={A systematic review of web resource estimation},
  year={2012},
  issn={978-1-4503-1241-7},
  pages={49-58},
  author={Azhar, Damir and Mendes, Emilia and Riddle, Patricia},
  url={https://doi.org/10.1145/2365324.2365332},
  publisher={Association for Computing Machinery},
  series={PROMISE '12},
  keywords={systematic review, web resource estimation, Health Resources},
  abstract={Background: Web development plays an important role in today's industry, so an in depth view into Web resource estimation would be valuable. However a systematic review (SR) on Web resource estimation in its entirety has not been done.Aim: The aim of this paper is to present a SR of Web resource estimation in order to define the current state of the art, and to identify any research gaps that may be present.Method: Research questions that would address the current state of the art in Web resource estimation were first identified. A comprehensive literature search was then executed resulting in the retrieval of 84 empirical studies that investigated any aspect of Web resource estimation. Data extraction and synthesis was performed on these studies with these research questions in mind.Results: We have found that there are no guidelines with regards to what resource estimation technique should be used in a particular estimation scenario, how it should be implemented, and how its effectiveness should be evaluated. Accuracy results vary widely and are dependent on numerous factors. Research has focused on development effort/cost estimation, neglecting other facets of resource estimation like quality and maintenance. Size measures have been used in all but one study as a resource predictor.Conclusions: Our results suggest that there is plenty of work to be done in the field of Web resource estimation whether it be investigating a more comprehensive approach that considers more than a single resource facet, evaluating other possible resource predictors, or trying to determine guidelines that would help simplify the process of selecting a resource estimation technique.}
}

@article{rayyan-727968425,
  title={A systematic review of system-of-systems architecture research},
  year={2013},
  issn={978-1-4503-2126-6},
  pages={13-22},
  author={Klein, John and van Vliet, Hans},
  url={https://doi.org/10.1145/2465478.2465490},
  publisher={Association for Computing Machinery},
  series={QoSA '13},
  keywords={systematic review, architecture, system of systems},
  abstract={Context: A system of systems is an assemblage of components which individually may be regarded as systems, and which possesses the additional properties that the constituent systems are operationally independent, and are managerially independent. Much has been published about the field of systems of systems by researchers and practitioners, often with the assertion that the system-of-systems design context necessitates the use of architecture approaches that are somewhat different from system-level architecture. However, no systematic review has been conducted to provide an extensive overview of system of systems architecture research.Objective: This paper presents such a systematic review. The objective of this review is to classify and provide a thematic analysis of the reported results in system of systems architecture.Method: The primary studies for the systematic review were identified using a predefined search strategy followed by an extensive manual selection process.Results: We found the primary studies published in a large number of venues, mostly domain-oriented, with no obvious center of a research community of practice. The field seems to be maturing more slowly than other software technologies: Most reported results described individuals or teams working in apparent isolation to develop solutions to particular system-of-systems architecture problems, with no techniques gaining widespread adoption.Conclusions: A comprehensive research agenda for this field should be developed, and further studies should be performed to determine whether the information system-related problems of system of systems architecture are covered by existing software architecture knowledge, and if not, to develop general methods for system-of-systems architecture.}
}

@article{rayyan-727968426,
  title={Criteria for software process tailoring: A systematic review},
  year={2013},
  issn={978-1-4503-2062-7},
  pages={171-180},
  author={Kalus, Georg and Kuhrmann, Marco},
  url={https://doi.org/10.1145/2486046.2486078},
  publisher={Association for Computing Machinery},
  series={ICSSP 2013},
  keywords={Systematic Literature Review, Software Process, Tailoring, Software},
  abstract={Independently from which software process was selected for a company or a project, the selected software process usually cannot be applied without any customization. Although the need to tailor a software process to specific project requirements seems to be widely accepted and unquestioned, the way of doing the tailoring remains unclear and is, therefore, often left to the expertise of process engineers or project managers. What are the criteria to be applied in the tailoring? What are dependencies between different criteria and how should certain criteria influence the software process? In this paper we investigate concrete tailoring criteria for the tailoring of software processes. To this end, we present a collection of 49 tailoring criteria as the outcomes of a systematic literature review. We further analyze the impact of the discovered tailoring criteria by relating them to a set of 20 exemplary tailoring actions, which affect the project-specific software process. Our outcomes show that the factors influencing the tailoring are well understood, however, the consequences of the criteria remain abstract and need to be interpreted on a project-per-project basis.}
}

@article{rayyan-727968427,
  title={'Follow the moon' development: Writing a systematic literature review on global software engineering education},
  year={2015},
  issn={978-1-4503-4020-5},
  pages={1-4},
  author={Clear, Tony},
  url={https://doi.org/10.1145/2828959.2835019},
  publisher={Association for Computing Machinery},
  series={Koli calling '15},
  keywords={systematic literature review, evidence-based software engineering, global software development, research methodology, capstone, global software engineering education, international collaboration, open ended group project, teaching and learning, Software},
  abstract={This presentation reflects on method and practice in Computer Science Education Research, through introducing the process of conducting a Systematic Literature Review. While Systematic Literature Reviews are an established research method within the Software Engineering discipline, they are a relatively unfamiliar research approach within Computer Science Education. Yet research disciplines can be strengthened by borrowing and adapting methods from other fields. I reflect on the rationale and underlying philosophy behind Systematic Reviews, and the implications for conducting a rigorous study and the quality of the resulting outputs. This chronicle of the journey of an ITiCSE working group, outlines the process we adopted and reflects on the methodological and logistical challenges we had to overcome in producing a review titled Challenges and Recommendations for the Design and Conduct of Global Software Engineering Courses. I conclude by discussing how systematic literature reviews can be adapted to an undergraduate teaching setting.}
}

@article{rayyan-727968428,
  title={Protocol for a systematic literature review of research on the wikipedia},
  year={2009},
  issn={978-1-60558-829-2},
  author={Okoli, Chitu and Schabram, Kira},
  url={https://doi.org/10.1145/1643823.1643912},
  publisher={Association for Computing Machinery},
  series={MEDES '09},
  keywords={literature review, open source, open content, Wikipedia},
  abstract={Context: Wikipedia has become one of the ten-most visited sites on the Web, and the world's leading source of Web reference information. Its rapid success has attracted over 1,000 scholarly studies that treat Wikipedia as a major topic or data source. Objectives: This article presents a protocol for conducting a systematic mapping (a broad-based literature review) of research on Wikipedia. It identifies what research has been conducted; what research questions have been asked, which have been answered; and what theories and methodologies have been employed to study Wikipedia. Methods: This protocol follows the rigorous methodology of evidence-based software engineering to conduct a systematic mapping study. Results and conclusions: This protocol reports a study in progress.}
}

@article{rayyan-727968429,
  title={Challenges and recommendations for the design and conduct of global software engineering courses: A systematic review},
  year={2015},
  issn={978-1-4503-4146-2},
  pages={1-39},
  author={Clear, Tony and Beecham, Sarah and Barr, John and Daniels, Mats and McDermott, Roger and Oudshoorn, Michael and Savickaite, Airina and Noll, John},
  url={https://doi.org/10.1145/2858796.2858797},
  publisher={Association for Computing Machinery},
  series={ITICSE-WGR '15},
  keywords={systematic literature review, global software development, global software engineering, capstone, international collaboration, open ended group project, teaching and learning, Software},
  abstract={Context: Global Software Engineering (GSE) has become the predominant form of software development for global companies and has given rise to a demand for students trained in GSE. In response, universities are developing courses and curricula around GSE and researchers have begun to disseminate studies of these new approaches. Problem: GSE differs from most other computer science fields, however, in that practice is inseparable from theory. As a result, educators looking to create GSE courses face a daunting task: integrating global practice into the local classroom. Aim: This study aims to ameliorate the very difficult task of teaching GSE by delineating the challenges and providing some recommendations for overcoming them. Method: To meet our aims we pose two research questions ("When teaching GSE to students in Higher Education, what are the (a) challenges, and (b) recommendations for addressing them") and then conduct a systematic literature review (SLR) to determine the answers to these questions. Our SLR follows a carefully designed and validated protocol.Results: We found 82 papers that addressed our research questions. Our findings indicate that in addition to the challenges posed by GSE in general, particular problems arise in educational situations. The majority of these challenges fall into the "global distance" category, though teamwork challenges and people issues (such as trust) also commonly arise. Organizational differences between institutions, differing skill sets between students in different locations, and varying cultural work norms, for example, all operate within educational settings in quite different ways than in professional development teams. Integrating cultural training, conducting teamwork exercises to build trust, and instructor monitoring of team communication are all examples of techniques that have been used successfully by educators according to our review Conclusion: Despite the severity of the challenges in GSE education, many institutions have successfully developed courses and curricula targeting GSE. Indeed, for each of the challenges we have identified in the literature there are numerous recommendations for overcoming them. Instructors can use the recommendations given in this study as a starting point to running successful GSE courses.}
}

@article{rayyan-727968430,
  title={Software visualization today: Systematic literature review},
  year={2016},
  issn={978-1-4503-4367-1},
  pages={262-271},
  author={Mattila, Anna-Liisa and Ihantola, Petri and Kilamo, Terhi and Luoto, Antti and Nurminen, Mikko and Väätäjä, Heli},
  url={https://doi.org/10.1145/2994310.2994327},
  publisher={Association for Computing Machinery},
  series={AcademicMindtrek '16},
  keywords={systematic literature review, human-centered computing, software visualization, Software},
  abstract={Software visualization means visualizing various aspects and artifacts related to software. By this definition a wide range of different software engineering aspects from program comprehension to understanding software process and usage are covered. This paper presents the results of systematic literature review spanning six years of software visualization literature. The main result shows that the most studied topics in the past six years are related to software structure, behavior and evolution. Software process and usage are addressed only in few studies. In the future studying the adoption of software visualization tools in industry context would be beneficial.}
}

@article{rayyan-727968431,
  title={Systematic review of software behavioral model consistency checking},
  year={2017},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={50},
  number={2},
  author={ul Muram, Faiz and Tran, Huy and Zdun, Uwe},
  url={https://doi.org/10.1145/3037755},
  keywords={systematic literature review, consistency checking, consistency types, Software behavioral model, Software},
  abstract={In software development, models are often used to represent multiple views of the same system. Such models need to be properly related to each other in order to provide a consistent description of the developed system. Models may contain contradictory system specifications, for instance, when they evolve independently. Therefore, it is very crucial to ensure that models conform to each other. In this context, we focus on consistency checking of behavior models. Several techniques and approaches have been proposed in the existing literature to support behavioral model consistency checking. This article presents a Systematic Literature Review (SLR) that was carried out to obtain an overview of the various consistency concepts, problems, and solutions proposed regarding behavior models. In our study, the identification and selection of the primary studies was based on a well-planned search strategy. The search process identified a total of 1770 studies, out of which 96 have been thoroughly analyzed according to our predefined SLR protocol. The SLR aims to highlight the state-of-the-art of software behavior model consistency checking and identify potential gaps for future research. Based on research topics in selected studies, we have identified seven main categories: targeted software models, types of consistency checking, consistency checking techniques, inconsistency handling, type of study and evaluation, automation support, and practical impact. The findings of the systematic review also reveal suggestions for future research, such as improving the quality of study design and conducting evaluations, and application of research outcomes in industrial settings. For this purpose, appropriate strategy for inconsistency handling, better tool support for consistency checking and/or development tool integration should be considered in future studies.}
}

@article{rayyan-727968432,
  title={How are hybrid development approaches organized? A systematic literature review},
  year={2020},
  issn={978-1-4503-7512-2},
  pages={145-154},
  author={Prenner, Nils and Unger-Windeler, Carolin and Schneider, Kurt},
  url={https://doi.org/10.1145/3379177.3388907},
  publisher={Association for Computing Machinery},
  series={ICSSP '20},
  keywords={systematic literature review, agile software development, software process, Hybrid software development},
  abstract={Agile software development methods promise shorter time-to-market and higher product quality, but lack the ability of long-term planning or coping with large projects. However, software companies often also want the ability of long-term planning, promised by traditional or plan-based methods. To benefit from the strengths of both approaches, software companies often use a combination of agile and plan-based methods, known as hybrid development approaches. These approaches strongly depend on the individual context and are customized. Therefore, companies have to organize their hybrid development approach individually. However, practitioners often have difficulties with the organization of hybrid approaches. The organization considers how the phases, activities, roles, and artifacts are arranged and connected. Research lacks the necessary detailed insight into how hybrid development approaches are organized to support practitioners. To gain better understanding of the organization of hybrid approaches, we conducted a systematic literature review to gather descriptions of hybrid approaches. We analyzed the found papers thoroughly and could identify three general patterns of how hybrid approaches are organized. We found that all these patterns are still based on Royce's waterfall model and use the standard software engineering activities. Our findings shall help to lead further research and help practitioners to better organize their individual development approach.}
}

@article{rayyan-727968434,
  title={Software process simulation modeling: Preliminary results from an updated systematic review},
  year={2014},
  issn={978-1-4503-2754-1},
  pages={50-54},
  author={Gao, Chao and Jiang, Shu and Rong, Guoping},
  url={https://doi.org/10.1145/2600821.2600844},
  publisher={Association for Computing Machinery},
  series={ICSSP 2014},
  keywords={systematic literature review, Software process simulation modeling, QGS, Software},
  abstract={Software Process Simulation Modeling (SPSM) has raised research interest since 1980s. However, it is observed that SPSM studies published in the ICSSP community may have dropped in recent years. The objective of this research is to update the recent status of this area. We conducted a Systematic Literature Review (SLR) using the QGS-based search strategy. The review identified 74 primary studies in the past five years (2008-2012). This paper presents the preliminary results from this updated SLR by answering the first four research questions. Based on the findings from this updated review, it can be concluded that in terms of the number of SPSM studies found in the overall software engineering community, there is no significant change (drop) compared to the former review stage (1998-2007).}
}

@article{rayyan-727968435,
  title={Towards process improvement in DevOps: A systematic literature review},
  year={2020},
  issn={978-1-4503-7731-7},
  pages={427-433},
  author={Badshah, Sher and Khan, Arif Ali and Khan, Bilal},
  url={https://doi.org/10.1145/3383219.3383280},
  publisher={Association for Computing Machinery},
  series={EASE '20},
  keywords={systematic review, DevOps, process improvement, Continuous software engineering, maturity models},
  abstract={In recent years, the software release cost has been reduced dramatically due to the alteration from traditional shrink-wrapped software to software as a service. Organizations that can deliver their services continuously and with a high frequency have a higher ability to compete in the market. As a response to this, a substantial number of software companies acquired DevOps to establish a culture of effective communication and collaboration between development and operation teams and in order to enhance the production release frequency as well as to maintain the product quality. However, the DevOps environment requires a platform that aid in evaluating the performance of existing processes and provide improvement recommendations. On top of that, organizations can only achieve the perceived benefits of DevOps if their processes are mature and continuously measured. The objective of this research is to investigate the process improvement contributions made by researchers in the DevOps field. For this purpose, we performed a systematic literature review that resulted in several maturity models and best practices. Our ultimate aim is to develop a DevOps maturity model that can appraise and improve the processes in the DevOps environment.}
}

@article{rayyan-727968436,
  title={Effort estimation in agile software development: A systematic literature review},
  year={2014},
  issn={978-1-4503-2898-2},
  pages={82-91},
  author={Usman, Muhammad and Mendes, Emilia and Weidt, Francila and Britto, Ricardo},
  url={https://doi.org/10.1145/2639490.2639503},
  publisher={Association for Computing Machinery},
  series={PROMISE '14},
  keywords={systematic literature review, agile software development, effort estimation, Software},
  abstract={Context: Ever since the emergence of agile methodologies in 2001, many software companies have shifted to Agile Software Development (ASD), and since then many studies have been conducted to investigate effort estimation within such context; however to date there is no single study that presents a detailed overview of the state of the art in effort estimation for ASD. Objectives: The aim of this study is to provide a detailed overview of the state of the art in the area of effort estimation in ASD. Method: To report the state of the art, we conducted a systematic literature review in accordance with the guidelines proposed in the evidence-based software engineering literature. Results: A total of 25 primary studies were selected; the main findings are: i) Subjective estimation techniques (e.g. expert judgment, planning poker, use case points estimation method) are the most frequently applied in an agile context; ii) Use case points and story points are the most frequently used size metrics respectively; iii) MMRE (Mean Magnitude of Relative Error) and MRE (Magnitude of Relative Error) are the most frequently used accuracy metrics; iv) team skills, prior experience and task size are cited as the three important cost drivers for effort estimation in ASD; and v) Extreme Programming (XP) and SCRUM are the only two agile methods that are identified in the primary studies. Conclusion: Subjective estimation techniques, e.g. expert judgment-based techniques, planning poker or the use case points method, are the one used the most in agile effort estimation studies. As for the size metrics, the ones that were used the most in the primary studies were story points and use case points. Several research gaps were identified, relating to the agile methods, size metrics and cost drivers, thus suggesting numerous possible avenues for future work.}
}

@article{rayyan-727968437,
  title={Omission of quality software development practices: A systematic literature review},
  year={2018},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={51},
  number={2},
  author={Ghanbari, Hadi and Vartiainen, Tero and Siponen, Mikko},
  url={https://doi.org/10.1145/3177746},
  keywords={systematic literature review, Behavioral software engineering, technical debt, Software},
  abstract={Software deficiencies are minimized by utilizing recommended software development and quality assurance practices. However, these recommended practices (i.e., quality practices) become ineffective if software professionals purposefully ignore them. Conducting a systematic literature review (n = 4,838), we discovered that only a small number of previous studies, within software engineering and information systems literature, have investigated the omission of quality practices. These studies explain the omission of quality practices mainly as a result of organizational decisions and trade-offs made under resource constraints or market pressure. However, our study indicates that different aspects of this phenomenon deserve further research. In particular, future research must investigate the conditions triggering the omission of quality practices and the processes through which this phenomenon occurs. Especially, since software development is a human-centric phenomenon, the psychological and behavioral aspects of this process deserve in-depth empirical investigation. In addition, futures research must clarify the social, organizational, and economical consequences of ignoring quality practices. Gaining in-depth theoretically sound and empirically grounded understandings about different aspects of this phenomenon enables research and practice to suggest interventions to overcome this issue.}
}

@article{rayyan-727968438,
  title={Continuous development and testing of access and usage control: A systematic literature review},
  year={2020},
  issn={978-1-4503-7762-1},
  pages={51-59},
  author={Daoudagh, Said and Lonetti, Francesca and Marchetti, Eda},
  url={https://doi.org/10.1145/3393822.3432330},
  publisher={Association for Computing Machinery},
  series={ESSE 2020},
  keywords={Systematic Literature Review, Testing, DevOps, Access Control, XACML},
  abstract={Context: Development and testing of access/usage control systems is a growing research area. With new trends in software development such as DevOps, the development of access/usage control also has to evolve. Objective: The main aim of this paper is to provide an overview of research proposals in the area of continuous development and testing of access and usage control systems. Method: The paper uses a Systematic Literature Review as a research method to define the research questions and answer them following a systematic approach. With the specified search string, 210 studies were retrieved. After applying the inclusion and exclusion criteria in two phases, a final set of 20 primary studies was selected for this review. Results: Results show that primary studies are mostly published in security venues followed by software engineering venues. Furthermore, most of the studies are based on the standard XACML access control language. In addition, a significant portion of the proposals for development and testing is automated with test assessment and generation the most targeted areas. Some general guidelines for leveraging continuous developing and testing of the usage and access control systems inside the DevOps process are also provided.}
}

@article{rayyan-727968439,
  title={Strategies for use case modeling: A systematic literature review},
  year={2019},
  issn={978-1-4503-7651-8},
  pages={254-263},
  author={Bispo, Cristiana and Fernandes, Sergio and Magalhães, Ana Patrícia},
  url={https://doi.org/10.1145/3350768.3351795},
  publisher={Association for Computing Machinery},
  series={SBES 2019},
  keywords={Systematic Review, Requirement, Software Modeling, Strategy for Use Case Modeling, Use Case},
  abstract={A major challenge in teaching use-case modeling (UCM) is to mitigate the difficulties of students that prevent them from producing use-case models with quality. The strategies for UCM are scattered in the literature in several areas, and may not be known to the students, who therefore fail to receive the benefits that would mitigate their difficulties. This paper aims to present a systematic literature review (SLR) to identify, gather and analyze strategies for UCM. During the SLR, two thousand two hundred sixty-six studies published between 2008 and 2018 were returned from 6 bases (ACM, IEEE, Scopus, Science Direct, SpringerLink and Engineering Village), which resulted in the selection of 39 primary studies. These were classified, following the coding procedures of Grounded Theory, into 13 categories of different strategies for UCM. The results can help teachers in the adoption of the most appropriate UCM strategies for their students. Besides, they provide a quick reference for teachers and researchers interested in conducting additional studies on teaching strategies for UCM.}
}

@article{rayyan-727968441,
  title={Agile project management challenges and mapping solutions: A systematic literature review},
  year={2020},
  issn={978-1-4503-7690-7},
  pages={123-129},
  author={Raharjo, Teguh and Purwandari, Betty},
  url={https://doi.org/10.1145/3378936.3378949},
  publisher={Association for Computing Machinery},
  series={ICSIM '20},
  keywords={Systematic Literature Review, Agile, Agile Approach, Agile Project Management},
  abstract={The Project Management Institute reported that the Agile approach is widely being used for project management practices. This approach has a significant impact on business growth and project performance. However, its implementation is challenging. Therefore, a systematic literature review (SLR) is used to reveal the challenges faced in Agile project execution. The Project Management Body of Knowledge (PMBOK) knowledge areas were adopted to classify the challenges. A total of 23 papers from 400 were identified as the result of SLR extraction. The challenges from related studies were categorized into the PMBOK knowledge areas. A mapping from the challenges to the solutions was performed using the PMBOK Guide, Prince2 Agile, Agile Practice Guide, and other related references. This study provides a list of Agile challenges and their mapped solutions. The biggest challenge arises from stakeholder management, which includes challenges related to Agile adaption, Agile transition, and Agile transformation. Other challenges include project resource management, project integration management, project scope management, and project schedule management. For academicians, this study provides a new understanding of Agile challenges and their suitable solutions from the perspective of project management. For practitioners, the findings provide potential lessons learned and recommendations to deal with the challenges.}
}

@article{rayyan-727968443,
  title={Usability of requirements techniques: A systematic literature review},
  year={2016},
  issn={978-1-4503-3739-7},
  pages={1270-1275},
  author={Bombonatti, Denise and Gralha, Catarina and Moreira, Ana and Araújo, João and Goulão, Miguel},
  url={https://doi.org/10.1145/2851613.2851758},
  publisher={Association for Computing Machinery},
  series={SAC '16},
  keywords={systematic literature review, usability, requirements engineering approaches},
  abstract={The usability of requirements engineering (RE) techniques has been recognised as a key factor for their successful adoption by industry. RE techniques must be accessible to stakeholders with different backgrounds, so they can be empowered to effectively and efficiently contribute to building successful systems. When selecting an appropriate requirements engineering technique for a given context, one should consider the usability supported by each of the candidate techniques. The first step towards achieving this goal is to gather the best evidence available on the usability of RE approaches by performing a systematic literature review, to answer one research question: How is the usability of requirements engineering techniques and tools addressed? We systematically review articles published in the Requirements Engineering Journal, one of the main sources for mature work in RE, to motivate a research roadmap to make RE approaches more accessible to stakeholders with different backgrounds.}
}

@article{rayyan-727968444,
  title={E-government usability evaluation: Insights from a systematic literature review},
  year={2019},
  issn={978-1-4503-6642-7},
  pages={249-253},
  author={Lyzara, Ria and Purwandari, Betty and Zulfikar, Muhammad Fadhil and Santoso, Harry Budi and Solichah, Iis},
  url={https://doi.org/10.1145/3305160.3305178},
  publisher={Association for Computing Machinery},
  series={ICSIM 2019},
  keywords={Systematic Literature Review (SLR), ⚠️ Invalid DOI, Usability Evaluation, E-government},
  abstract={E-Government aims to deliver benefits to government and citizens by improving transparency, efficiency, trust, and citizen participation. However, e-government initiatives face several barriers. One of them is poor usability. To advance quality of usability, literatures indicate that usability evaluation is a key success factor. There are many approaches to conduct usability evaluation. Each of it has advantages and challenges. On the other hand, there are several aspects that must be considered related to usability evaluation in e-government context. It includes large stakeholders and their diversity, extra needs for ethical practices, as well as high privacy. Therefore, it is crucial to investigate the right usability evaluation method in e-government. In order to address this issue, a study using Systematic Literature Review (SLR) was conducted to identify the suitable usability evaluation methods. There are 519 literatures that have been selected in the initial stage. It was then followed by an extraction process, which produced 22 selected references. Each method was grouped into usability testing, inspection, and inquiry. These results can guide academics and practitioners to carry out usability evaluation in e-government.}
}

@article{rayyan-727968445,
  title={A systematic review on the use of definition of done on agile software development projects},
  year={2017},
  issn={978-1-4503-4804-1},
  pages={364-373},
  author={Silva, Ana and Araújo, Thalles and Nunes, João and Perkusich, Mirko and Dilorenzo, Ednaldo and Almeida, Hyggo and Perkusich, Angelo},
  url={https://doi.org/10.1145/3084226.3084262},
  publisher={Association for Computing Machinery},
  series={EASE'17},
  keywords={Systematic Literature Review, Agile Software Development, Definition of Done, Software},
  abstract={Background: Definition of Done (DoD) is a Scrum practice that consists of a simple list of criteria that adds verifiable or demonstrable value to the product. It is one of the most popular agile practices and assures a balance between short-term delivery of features and long-term product quality, but little is known of its actual use in Agile teams.Objective: To identify possible gaps in the literature and define a starting point to define DoD for practitioners through the identification and synthesis of the DoD criteria used in agile projects as presented in the scientific literature.Method: We applied a Systematic Literature Review of studies published up to (and including) 2016 through database search and backward and forward snowballing.Results: In total, we evaluated 2326 papers, of which 8 included DoD criteria used in agile projects. We identified that some studies presented up to 4 levels of DoD, which include story, sprint, release or project. We identified 62 done criteria, which are related to software verification and validation, deploy, code inspection, test process quality, regulatory compliance, software architecture design, process management, configuration management and non-functional requirements.Conclusion: The main implication for research is a need for more and better empirical studies documenting and evaluating the use of the DoD in agile software development. For the industry, the review provides a map of how DoD is currently being used in the industry and can be used as a starting point to define or compare with their own DoD definition.}
}

@article{rayyan-727968446,
  title={On the application of genetic algorithms for test case prioritization: A systematic literature review},
  year={2012},
  issn={978-1-4503-1509-8},
  pages={9-14},
  author={Catal, Cagatay},
  url={https://doi.org/10.1145/2372233.2372238},
  publisher={Association for Computing Machinery},
  series={EAST '12},
  keywords={systematic literature review, software engineering, software testing, regression testing, genetic algorithms, test case prioritization, evolutionary computation, Algorithms},
  abstract={We conducted a Systematic Literature Review (SLR) to investigate the effectiveness of genetic algorithms for test case prioritization. The search string retrieved 120 test case prioritization papers, but after we read them in full, we identified that genetic algorithm was used in seven primary studies. One paper does not provide any experimental data. Based on the results of these six papers, we conclude that there is evidence that genetic algorithm-based techniques are effective for test case prioritization and the field is still open for further research.}
}

@article{rayyan-727968448,
  title={A systematic review of business and information technology alignment},
  year={2013},
  journal={ACM Transactions on Management Information Systems},
  issn={2158-656X},
  volume={4},
  number={1},
  author={Ullah, Azmat and Lai, Richard},
  url={https://doi.org/10.1145/2445560.2445564},
  keywords={Systematic review, alignment measurement, alignment phases, business, business environment modeling, business issues, IT alignment, IT issues, IT support, literature},
  abstract={Business organizations have become heavily dependent on information technology (IT) services. The process of alignment is defined as the mutual synchronization of business goals and IT services. However, achieving mature alignment between business and IT is difficult due to the rapid changes in the business and IT environments. This article provides a systematic review of studies on the alignment of business and IT. The research articles reviewed are based on topics of alignment, the definition of alignment, history, alignment challenges, phases of alignment, alignment measurement approaches, the importance of alignment in business industries, how software engineering helps in better alignment, and the role of the business environment in aligning business with IT. It aims to present a thorough understanding of business-IT alignment and to provide a list of future research directions regarding alignment. To perform the systematic review, we used the guidelines developed by Kitchenham for reviewing the available research papers relevant to our topic.}
}

@article{rayyan-727968449,
  title={A systematic review for smart city data analytics},
  year={2018},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={51},
  number={5},
  author={Moustaka, Vaia and Vakali, Athena and Anthopoulos, Leonidas G},
  url={https://doi.org/10.1145/3239566},
  keywords={systematic review, Data mining, Internet of Things, taxonomy, crowd-sensing, crowd-sourcing, data harvesting, open data, smart cities, smart dimensions, smart services},
  abstract={Smart cities (SCs) are becoming highly sophisticated ecosystems at which innovative solutions and smart services are being deployed. These ecosystems consider SCs as data production and sharing engines, setting new challenges for building effective SC architectures and novel services. The aim of this article is to “connect the pieces” among Data Science and SC domains, with a systematic literature review which identifies the core topics, services, and methods applied in SC data monitoring. The survey focuses on data harvesting and data mining processes over repeated SC data cycles. A survey protocol is followed to reach both quantitative and semantically important entities. The review results generate useful taxonomies for data scientists in the SC context, which offers clear guidelines for corresponding future works. In particular, a taxonomy is proposed for each of the main SC data entities, namely, the “D Taxonomy” for the data production, the “M Taxonomy” for data analytics methods, and the “S Taxonomy” for smart services. Each of these taxonomies clearly places entities in a classification which is beneficial for multiple stakeholders and for multiple domains in urban smartness targeting. Such indicative scenarios are outlined and conclusions are quite promising for systemizing.}
}

@article{rayyan-727968450,
  title={A systematic literature review on combining ontology with bayesian network to support logical and probabilistic reasoning},
  year={2017},
  issn={978-1-4503-5488-2},
  pages={1-12},
  author={Setiawan, Foni Agus and Budiardjo, Eko K and Basaruddin, T and Aminah, Siti},
  url={https://doi.org/10.1145/3178212.3178223},
  publisher={Association for Computing Machinery},
  series={ICSEB 2017},
  keywords={Ontology, Bayesian network, Logical reasoning, Ontology-based application, Probabilistic reasoning},
  abstract={Reasoning in ontology is currently limited to logical reasoning. It is because ontology does not have a standard for probabilistic reasoning. Various approaches have been made by researchers to add the ability for ontological reasoner to do probabilistic reasoning. The approach is done by combining ontology with Bayesian network that does have probabilistic reasoning abilities. This study mapped out various approaches performed in combining ontologies with Bayesian networks to realize logical and probabilistic reasoning simultaneously. We use a systematic literature review method to identify the primary studies on combining ontology with Bayesian network following a predefined review protocol. We searched from four indexing services (SCOPUS, IEEE Xplore, ACM Digital Library, and SpringerLink) and got the result of 74 papers accepted for the review. We extracted properties from these studies and found 8 motivations of the studies, 5 contexts, 4 factors involved, and 5 techniques used in combining ontology with Bayesian network. The aim and the context are clearly stated in most of the studies, while most of the authors did not completely discuss the threats in their papers. As for the method and findings, most of the studies describe and discuss it moderately.}
}

@article{rayyan-727968451,
  title={Towards a behavioral software engineering},
  year={2014},
  issn={978-1-4503-2860-9},
  pages={48-55},
  author={Lenberg, Per and Feldt, Robert and Wallgren, Lars-Göran},
  url={https://doi.org/10.1145/2593702.2593711},
  publisher={Association for Computing Machinery},
  series={CHASE 2014},
  keywords={Psychology, Behavioral Software Engineering, Software},
  abstract={Throughout the history of Software Engineering (SE) it has been repeatedly found that the humans involved, i.e. the engineers and developers in addition to other stakeholders, are a key factor in determining project outcomes and success. However, the amount of research that focuses on human aspects has been limited compared to research with technology or process focus. With increasing maturity of the field, interest in agile methods and a growing dissatisfaction with the continued challenges of developing high-quality software on time, the amount of SE research putting human aspect in primary focus has increased. In this paper we argue that a synthesized view of the emerging human-focused SE research is needed and can add value through giving focus, direction and help identify gaps. Taking cues from the addition of Behavioral Economics as an important part of the area of Economics we propose the term Behavioral Software Engineering (BSE) as an umbrella concept for research that focus on behavioral and social aspects in the work activities of software engineers. We propose that a model based on three units of analysis can give structure and point to concepts that are important for BSE. To add detail to this model we are conducting a systematic review to map out what is currently known. To exemplify the model and the area we here present the results from a subset of the identified concepts.}
}

@article{rayyan-727968453,
  title={An overview of published agile studies: A systematic literature review},
  year={2010},
  issn={978-1-4503-0026-1},
  author={Hasnain, Eisha},
  url={https://doi.org/10.1145/1890810.1890813},
  publisher={Association for Computing Machinery},
  series={NSEC '10},
  keywords={agile methods, academics, empirical and experience, practitioners},
  abstract={In recent years, agile methods have become more popular in the software industry. Agile methods are a new approach compared to plan-driven approaches. This paper aims to provide a basis for the improvement of agile methods research through a systematic review of previous work. By doing this systematic literature review, I will help Software Engineer managers, Software Engineers, and researchers to determine the current state of research and knowledge in agile methods. My systematic approach to analyzing published studies enables us to find gaps in the existing body of work. I have reviewed 183 papers published in the 4 IEEE Agile conferences from 2003-2007. I found that fewer academics than practitioners publish their findings in these IEEE agile conferences; few empirical studies are presented at the conferences, and most papers at these conferences address agile methods only at a general level.}
}

@article{rayyan-727968454,
  title={Applicability of the semiotic inspection method: A systematic literature review},
  year={2011},
  issn={978-85-7669-257-7},
  pages={177-186},
  author={De S. Reis, Soraia and Prates, Raquel O},
  publisher={Brazilian Computer Society},
  series={IHC+CLIHC '11},
  keywords={systematic literature review, applicability, semiotic engineering, semiotic inspection method},
  abstract={In 2006 the Semiotic Inspection Method (SIM) was proposed and the authors raised the hypothesis that it was a technology and domain independent evaluation method. The aim of this study was to investigate whether published studies describing the use of SIM support this claim. In order to identify the papers to be analyzed a systematic literature review was conducted. Analysis of the papers indicated that SIM has been applied without adaptations to different domains and in each of them it has been able to identify issues specific to the domain. Hence, our findings support the claim that the method is independent of both domain and technology.}
}

@article{rayyan-727968457,
  title={Environment modeling in model-based testing: Concepts, prospects and research challenges: A systematic literature review},
  year={2015},
  issn={978-1-4503-3350-4},
  author={Siavashi, Faezeh and Truscan, Dragos},
  url={https://doi.org/10.1145/2745802.2745830},
  publisher={Association for Computing Machinery},
  series={EASE '15},
  keywords={systematic literature review, software testing, environment model, model-based testing},
  abstract={In this paper, we describe a systematic literature review (SLR) on the use of environment models in model-based testing (MBT). By applying selection criteria, we narrowed down the identified studies from two hundred ninety seven papers to sixty one papers which are used in this analysis. The results show that environment models are especially useful in testing systems with high complexity and nondeterministic behaviors in terms of facilitating automatic test generation. However, building environment models is not a trivial task due to the lack of a systematic methodology and of supporting tools for automation.}
}

@article{rayyan-727968458,
  title={Landscaping performance research at the ICPE and its predecessors: A systematic literature review},
  year={2015},
  issn={978-1-4503-3248-4},
  pages={91-96},
  author={Danciu, Alexandru and Kroß, Johannes and Brunnert, Andreas and Willnecker, Felix and Vögele, Christian and Kapadia, Anand and Krcmar, Helmut},
  url={https://doi.org/10.1145/2668930.2688039},
  publisher={Association for Computing Machinery},
  series={ICPE '15},
  keywords={systematic literature review, icpe, performance engineering, performance research, sipew, wosp, Intracranial Hypertension},
  abstract={This paper conducts a systematic literature review of papers published in the proceedings of the International Conference on Performance Engineering (ICPE) and its predecessors. It provides an overview of prevailing topics within the community over time. We look at research and contribution facets that have been used to address these topics. Trends are outlined in terms of evaluation methods to validate contributions. The results are complemented with a geographical and organizational dimension. The paper concludes with a look at the top ten contributing countries and organizations for this purpose.}
}

@article{rayyan-727968459,
  title={Awareness supporting technologies used in collaborative systems: A systematic literature review},
  year={2017},
  issn={978-1-4503-4335-0},
  pages={808-820},
  author={Lopez, Gustavo and Guerrero, Luis A},
  url={https://doi.org/10.1145/2998181.2998281},
  publisher={Association for Computing Machinery},
  series={CSCW '17},
  keywords={systematic literature review, awareness, cscw, notification mechanisms},
  abstract={Since the establishment of Computer Supported Collaborative Work as a research area, computer advances have change the paradigm of how technology is applied to improve the performance in collaborative scenarios. Notifications are an important part of this improvement. Technological systems have been applied in order to provide collaborators with the sufficient awareness to keep a task going. In this paper we present the protocol and results of a Systematic Literature Review that delves in the application of new technologies to provide awareness in collaborative systems. Moreover, we classify the collaborative systems found in literature using two traditional taxonomies for CSCW in order to understand which notification mechanisms are used to support which systems. Our review covers the last 10 years and classifies system prototypes based on the context in which they are applied, the notification and information gathering mechanism used, and the assessment performed. With over 400 papers reviewed, 83 that met the review requirements were included. The review results show that traditional interfaces and mobile devices are still the most common notification mechanisms. However, ubiquitous devices and non-traditional interfaces have also been used.}
}

@article{rayyan-727968460,
  title={Frameworks for collective intelligence: A systematic literature review},
  year={2020},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={53},
  number={1},
  author={Suran, Shweta and Pattanaik, Vishwajeet and Draheim, Dirk},
  url={https://doi.org/10.1145/3368986},
  keywords={systematic literature review, Web 2.0, crowdsourcing, Collective intelligence, human computer interaction, wisdom of crowds, Intelligence},
  abstract={Over the last few years, Collective Intelligence (CI) platforms have become a vital resource for learning, problem solving, decision-making, and predictions. This rising interest in the topic has to led to the development of several models and frameworks available in published literature. Unfortunately, most of these models are built around domain-specific requirements, i.e., they are often based on the intuitions of their domain experts and developers. This has created a gap in our knowledge in the theoretical foundations of CI systems and models, in general. In this article, we attempt to fill this gap by conducting a systematic review of CI models and frameworks, identified from a collection of 9,418 scholarly articles published since 2000. Eventually, we contribute by aggregating the available knowledge from 12 CI models into one novel framework and present a generic model that describes CI systems irrespective of their domains. We add to the previously available CI models by providing a more granular view of how different components of CI systems interact. We evaluate the proposed model by examining it with respect to six popular, ongoing CI initiatives available on the Web.}
}

@article{rayyan-727968461,
  title={Energy-efficient networking solutions in cloud-based environments: A systematic literature review},
  year={2015},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={47},
  number={4},
  author={Moghaddam, Fahimeh Alizadeh and Lago, Patricia and Grosso, Paola},
  url={https://doi.org/10.1145/2764464},
  keywords={systematic literature review, cloud, Energy efficiency, networking},
  abstract={The energy consumed by data centers hosting cloud services is increasing enormously. This brings the need to reduce energy consumption of different components in data centers. In this work, we focus on energy efficiency of the networking component. However, how different networking solutions impact energy consumption is still an open question. We investigate the state of the art in energy-efficient networking solutions in cloud-based environments. We follow a systematic literature review method to select primary studies. We create a metamodel based on the codes extracted from our primary studies using the Coding analytical method. Our findings show three abstraction levels of the proposed networking solutions to achieve energy efficiency in cloud-based environments: Strategy, Solution, and Technology. We study the historical trends in the investigated solutions and conclude that the emerging and most widely adopted one is the Decision framework.}
}

@article{rayyan-727968462,
  title={A systematic review of the use of requirements engineering techniques in model-driven development},
  year={2010},
  issn={3-642-16128-6},
  pages={213-227},
  author={Loniewski, Grzegorz and Insfran, Emilio and Abrahão, Silvia},
  publisher={Springer-Verlag},
  series={MODELS'10},
  keywords={systematic review, requirements engineering, model-driven development},
  abstract={Model-Driven Development (MDD) emphasizes the use of models at a higher abstraction level in the software development process and argues in favor of automation via model execution, transformation, and code generation. However, one current challenge is how to manage requirements during this process whilst simultaneously stressing the benefits of automation. This paper presents a systematic review of the current use of requirements engineering techniques in MDD processes and their actual automation level. 72 papers from the last decade have been reviewed from an initial set of 884 papers. The results show that although MDD techniques are used to a great extent in platform-independent models, platform-specific models, and at code level, at the requirements level most MDD approaches use only partially defined requirements models or even natural language. We additionally identify several research gaps such as a need for more efforts to explicitly deal with requirements traceability and the provision of better tool support.}
}

@article{rayyan-727968463,
  title={Strength of evidence in systematic reviews in software engineering},
  year={2008},
  issn={978-1-59593-971-5},
  pages={178-187},
  author={Dyb, Tore and Dings, Torgeir},
  url={https://doi.org/10.1145/1414004.1414034},
  publisher={Association for Computing Machinery},
  series={ESEM '08},
  keywords={systematic review, quality assessment, strength of evidence, Software},
  abstract={Systematic reviews are only as good as the evidence they are based on. It is important, therefore, that users of systematic reviews know how much confidence they can place in the conclusions and recommendations arising from such reviews. In this paper we present an overview of some of the most influential systems for assessing the quality of individual primary studies and for grading the overall strength of a body of evidence. We also present an example of the use of such systems based on a systematic review of empirical studies of agile software development. Our findings suggest that the systems used in other disciplines for grading the strength of evidence for and reporting of systematic reviews, especially those that take account of qualitative and observational studies are of particular relevance for software engineering.}
}

@article{rayyan-727968464,
  title={Software paradigms, assessment types and non-functional requirements in model-based integration testing: A systematic literature review},
  year={2014},
  issn={978-1-4503-2476-2},
  author={Häser, Florian and Felderer, Michael and Breu, Ruth},
  url={https://doi.org/10.1145/2601248.2601257},
  publisher={Association for Computing Machinery},
  series={EASE '14},
  keywords={systematic literature review, non-functional requirements, assessment types, model-based integration testing, Software},
  abstract={Context: In modern systems, like cyber-physical systems, where software and physical services are interacting, safety, security or performance play an important role. In order to guarantee the correct interoperability of such systems, with respect to functional and non-functional requirements, integration testing is an effective measure to achieve this. Model-based testing moreover not only enables early definition and validation, but also test automation. This makes it a good choice to overcome urgent challenges of integration testing. Objective: Many publications on model-based integration testing (MBIT) approaches can be found. Nevertheless, a study giving a systematic overview on the underlying software paradigms, measures for guiding the integration testing process as well as non-functional requirements they are suitable for, is missing. The aim of this paper is to find and synthesize the relevant primary studies to gain a comprehensive understanding of the current state of model-based integration testing. Method: For synthesizing the relevant studies, we conducted a systematic literature review (SLR) according to the guidelines of Kitchenham. Results: The systematic search and selection retrieved 83 relevant studies from which data has been extracted. Our review identified three assessment criteria for guiding the testing process, namely static metrics, dynamic metrics and stochastic &random. In addition it shows that just a small fraction considers non-functional requirements. Most approaches are for component-oriented systems. Conclusion: Results from the SLR show that there are two major research gaps. First, there is an accumulated need for approaches in the MBIT field that support non-functional requirements, as they are gaining importance. Second, means for steering the integration testing process, especially together with automation, need to evolve.}
}

@article{rayyan-727968465,
  title={A systematic review on mining techniques for crosscutting concerns},
  year={2013},
  issn={978-1-4503-1656-9},
  pages={1080-1087},
  author={Durelli, Rafael S and Santibáñez, Daniel S M and Anquetil, Nicolas and Delamaro, Márcio E and de Camargo, Valter Vieira},
  url={https://doi.org/10.1145/2480362.2480567},
  publisher={Association for Computing Machinery},
  series={SAC '13},
  keywords={systematic review, aspect mining, concern mining, cross-cutting concerns},
  abstract={¡u¿Background:¡/u¿ The several maintenance tasks a system is submitted during its life usually cause its architecture deviates from the original conceivable design, ending up with scattered and tangled concerns across the software. The research area named concern mining attempts to identify such scattered and tangled concerns to support maintenance and reverse-engineering. ¡u¿Objectives:¡/u¿ The aim of this paper is threefold: (i) identifying techniques employed in this research area, (ii) extending a taxonomy available on the literature and (iii) recommending an initial combination of some techniques. ¡u¿Results:¡/u¿ We selected 62 papers by their mining technique. Among these papers, we identified 18 mining techniques for crosscutting concern. Based on these techniques, we have extended a taxonomy available in the literature, which can be used to position each new technique, and to compare it with the existing ones along relevant dimensions. As consequence, we present some combinations of these techniques taking into account high values of precision and recall that could improve the identification of both Persistence and Observer concerns. The combination that we recommend may serve as a roadmap to potential users of mining techniques for crosscutting concerns.}
}

@article{rayyan-727968466,
  title={Taxonomy of performance testing tools: A systematic literature review},
  year={2020},
  issn={978-1-4503-6866-7},
  pages={1997-2004},
  author={Costa, Victor and Girardon, Gustavo and Bernardino, Maicon and Machado, Rodrigo and Legramante, Guilherme and Neto, Anibal and Basso, Fábio Paulo and de Macedo Rodrigues, Elder},
  url={https://doi.org/10.1145/3341105.3374006},
  publisher={Association for Computing Machinery},
  series={SAC '20},
  keywords={systematic review, taxonomy, performance testing tools},
  abstract={Background: The knowledge and application of tools to automate performance testing is essential to ensure software reliability and therefore its quality. Aims: To identify and characterize existing performance testing tools reported in the literature. Method: A protocol was formulated and executed according to the guidelines for performing systematic literature reviews in Software Engineering. Results: The performance testing tools were classified according to their relevance in the literature, highlighting the most commonly used tools, their supported input approaches, workload approaches, monitored metrics and logging strategies. From the analysis of these results a taxonomy on performance testing tools was proposed using a Feature Model. Conclusion: With the results of this study, it was possible to quantify and qualify research related to existing performance testing technologies in the literature, and also to characterize them for decision-making purposes. Thus, contributing for professionals, researchers and academic students looking for these assets through certain features from performance testing strategies.}
}

@article{rayyan-727968467,
  title={An investigation into inner source software development: Preliminary findings from a systematic literature review},
  year={2018},
  issn={978-1-4503-5936-8},
  author={Edison, Henry and Carroll, Noel and Conboy, Kieran and Morgan, Lorraine},
  url={https://doi.org/10.1145/3233391.3233529},
  publisher={Association for Computing Machinery},
  series={OpenSym '18},
  keywords={systematic literature review, open source, inner source, inner source software development, Software},
  abstract={Given the value and effectiveness of open source software development to date, practitioners are keen to replicate these practices inside their respective corporations. This application of open source practices inside the confines of a corporate entity has been coined inner source software development. However, while organisations have found ways to directly benefit from revenue streams as a result of leveraging open source practices internally, the current research on inner source is scattered among different areas. Thus gaining clarity on the state-of-the-art in inner source research is challenging. In particular, there is no systematic literature review of known research to date on inner source. We address this challenge by presenting a systematic literature review that identifies, critically evaluates and integrates the findings of 29 primary studies on inner source. Case study approach is the common research approach undertaken in the area. We also identified 8 frameworks/methods, models and tools proposed in the literature to support inner source, as well as a set of benefits and challenges associated with inner source. We envision future work to perform deeper analysis and synthesis on the empirical research on inner source software development.}
}

@article{rayyan-727968468,
  title={Natural language processing in business process identification and modeling: A systematic literature review},
  year={2018},
  issn={978-1-4503-6559-8},
  author={de Almeida Bordignon, Ana Cláudia and Thom, Lucinéia Heloisa and Silva, Thanner Soares and Dani, Vinicius Stein and Fantinato, Marcelo and Ferreira, Renato Cesar Borges},
  url={https://doi.org/10.1145/3229345.3229373},
  publisher={Association for Computing Machinery},
  series={SBSI'18},
  keywords={Systematic Literature Review, Natural Language Processing, Business Process Management, Process Discovery, Process Analysis},
  abstract={Business Process Management (BPM) has been receiving increasing attention in recent years. Many organizations have been adapting their business to a process-centered view since they started noticing its potential to reduce costs, improve productivity and achieve higher levels of quality. However, implementing BPM in organizations requires time, making the automation of process identification and discovery highly desirable. To achieve this expectation, the application of Natural Language Processing (NLP) techniques and tools has emerged to generate process models from unstructured text. In this paper, we provide the results of a systematic literature review conducted in preparation and processing of natural language text aiming the extraction of business processes and process quality assurance. The study presents techniques applied to the BPM life-cycle phases of process identification, process discovery and process analysis as well as tools to support process discovery. This review covered papers from 2009 up to 2016 and identifies 518 articles of which 33 were selected as relevant to our work. The results of the present study may be valuable to support research in extraction of business process models from natural language text.}
}

@article{rayyan-727968469,
  title={Software process simulation over the past decade: Trends discovery from a systematic review},
  year={2008},
  issn={978-1-59593-971-5},
  pages={345-347},
  author={Zhang, He and Kitchenham, Barbara and Pfahl, Dietmar},
  url={https://doi.org/10.1145/1414004.1414077},
  publisher={Association for Computing Machinery},
  series={ESEM '08},
  keywords={systematic literature review, software process simulation, Software},
  abstract={Software Process Simulation (SPS) research has increased since 1998 when the first ProSim Workshop was held. This paper aims to reveal how SPS has evolved during the past 10 years based on the preliminary results from the systematic literature review of SPS publications from 1998 to 2007. Trends over the period showed that interest in continuous modelling was decreasing and interest in micro-processes was increasing. Hybrid models were based primarily on system dynamics and discrete event simulation and were all implemented by vertical integration.}
}

@article{rayyan-727968470,
  title={A systematic review of theory use in studies investigating the motivations of software engineers},
  year={2009},
  journal={ACM Trans. Softw. Eng. Methodol.},
  issn={1049-331X},
  volume={18},
  number={3},
  author={Hall, Tracy and Baddoo, Nathan and Beecham, Sarah and Robinson, Hugh and Sharp, Helen},
  url={https://doi.org/10.1145/1525880.1525883},
  keywords={software engineering, Motivation, Software},
  abstract={Motivated software engineers make a critical contribution to delivering successful software systems. Understanding the motivations of software engineers and the impact of motivation on software engineering outcomes could significantly affect the industry's ability to deliver good quality software systems. Understanding the motivations of people generally in relation to their work is underpinned by eight classic motivation theories from the social sciences. We would expect these classic motivation theories to play an important role in developing a rigorous understanding of the specific motivations of software engineers. In this article we investigate how this theoretical basis has been exploited in previous studies of software engineering. We analyzed 92 studies of motivation in software engineering that were published in the literature between 1980 and 2006. Our main findings are that many studies of software engineers' motivations are not explicitly underpinned by reference to the classic motivation theories. Furthermore, the findings presented in these studies are often not explicitly interpreted in terms of those theories, despite the fact that in many cases there is a relationship between those findings and the theories. Our conclusion is that although there has been a great deal of previous work looking at motivation in software engineering, the lack of reference to classic theories of motivation means that the current body of work in the area is weakened and our understanding of motivation in software engineering is not as rigorous as it may at first appear. This weakness in the current state of knowledge highlights important areas for future researchers to contribute towards developing a rigorous and usable body of knowledge in motivating software engineers.}
}

@article{rayyan-727968471,
  title={Collaborative learning as educational strategy for deaf children: A systematic literature review},
  year={2017},
  issn={978-1-4503-5229-1},
  author={Aristizábal, Leandro Flórez and Cano, Sandra and Collazos, César A and Solano, Andrés and Slegers, Karin},
  url={https://doi.org/10.1145/3123818.3123830},
  publisher={Association for Computing Machinery},
  series={Interacción '17},
  keywords={systematic review, education, cooperative learning, deaf children, Only Child, Child, Deafness},
  abstract={The education of people with disabilities requires special attention and the use of teaching and learning strategies that can be adapted to every particular disability. This study focuses on the education of deaf children as part of a larger project that aims to mix teaching strategies like Logogenia and Fitzgerald Key with interactive storytelling and collaborative learning to support literacy teaching to these children. Since deaf people learn using the visual channel as main input, we believe that technology could play a key role in the development of such environments where user interfaces should be specifically designed to attract children's attention. We conducted a systematic literature review in order to find what researchers have done to apply Collaborative or Cooperative Learning in the education of deaf children and also what kind of emerging technologies are used to enhance collaborative environments. A total of 229 studies were found in 7 different databases. The results of this study show that Collaborative Learning has been used along with different kinds of technology in the education of deaf people with positive outcomes like improving skills in sign language, literacy and communication.}
}

@article{rayyan-727968473,
  title={User involvement in software development and system success: A systematic literature review},
  year={2013},
  issn={978-1-4503-1848-8},
  pages={125-130},
  author={Bano, Muneera and Zowghi, Didar},
  url={https://doi.org/10.1145/2460999.2461017},
  publisher={Association for Computing Machinery},
  series={EASE '13},
  keywords={software development, system success, user involvement, Software},
  abstract={Context: In the last four decades involving users in the software development process is claimed to have a positive impact on the success of that software. However, previous reviews on this topic have produced conflicting results. Objectives: Our aim is to present a review on user involvement in software development process and investigate its relationship to software system success. Methods: For our exploration, we performed a Systematic Literature Review using the guidelines provided in the Evidence Based Software Engineering literature. Results: 87 relevant empirical studies were selected and reviewed that investigate various perspectives and concepts of user involvement in software development process during the period of 1980–2012. Among 87 studies reviewed, 59 report that user involvement positively contributes to system success, 7 suggest a negative contribution and 21 are uncertain. Conclusions: Our results show an overall positive impact of user involvement on system success. It also suggests that the relationship between user involvement and system success is neither direct nor simple, and it depends on many different factors and conditions surrounding systems development processes.}
}

@article{rayyan-727968474,
  title={Challenges and recommendations in DevOps education: A systematic literature review},
  year={2020},
  issn={978-1-4503-8753-8},
  pages={648-657},
  author={Fernandes, Marcelo and Ferino, Samuel and Kulesza, Uirá and Aranha, Eduardo},
  url={https://doi.org/10.1145/3422392.3422496},
  publisher={Association for Computing Machinery},
  series={SBES '20},
  keywords={DevOps, challenges, education, courses, recommendations},
  abstract={Over the last years, DevOps has gained more importance and attention from the software industry, given its role in enabling continuous software delivery. As a new area, DevOps has brought significant challenges for the academy, both in terms of research topics and teaching strategies. In this paper, we present a systematic literature review that aims to identify challenges and recommendations for teaching DevOps. Our findings show a total of 73 challenges and 85 recommendations organized into different seven categories from a total of 18 papers selected. We also discuss how existing recommendations address the challenges found in the study, thus contributing to the preparation and execution of DevOps courses. Finally, we investigate if challenges and recommendations are specific for teaching DevOps.}
}

@article{rayyan-727968478,
  title={How has the health of software ecosystems been evaluated? A systematic review},
  year={2017},
  issn={978-1-4503-5326-7},
  pages={14-23},
  author={da Silva Amorim, Simone and Neto, Félix Simas S and McGregor, John D and de Almeida, Eduardo Santana and von Flach G. Chavez, Christina},
  url={https://doi.org/10.1145/3131151.3131174},
  publisher={Association for Computing Machinery},
  series={SBES'17},
  keywords={Systematic Literature Review, Software Evaluation, Software Ecosystems Health, Software},
  abstract={The health of the software ecosystems concerns to the growing and continuity to exist remaining variable and productive over time. Research on this area is becoming more important. Even today, no studies have been available summarizing the research on evaluation approaches for the health of software ecosystems. The objective of this study is to structure and analyze the available literature on this field identifying the state-of-the-art of the research. We conducted a systematic literature review to obtain an overview of the existing studies in this area. 23 studies were selected as primary studies by applying inclusion, exclusion and quality criteria. The findings show that the research area is quite immature. There are few approaches and tools to support the evaluation work. In these studies, only 3 reported a complete evaluation of the health of ecosystems, 5 studies were considered as initial proposals, and the others evaluated the health partially.}
}

@article{rayyan-727968480,
  title={A systematic review of cloud modeling languages},
  year={2018},
  journal={ACM Computing Surveys},
  issn={0360-0300},
  volume={51},
  number={1},
  author={Bergmayr, Alexander and Breitenbücher, Uwe and Ferry, Nicolas and Rossini, Alessandro and Solberg, Arnor and Wimmer, Manuel and Kappel, Gerti and Leymann, Frank},
  url={https://doi.org/10.1145/3150227},
  keywords={Cloud computing, domain-specific languages, modeling},
  abstract={Modern cloud computing environments support a relatively high degree of automation in service provisioning, which allows cloud service customers (CSCs) to dynamically acquire services required for deploying cloud applications. Cloud modeling languages (CMLs) have been proposed to address the diversity of features provided by cloud computing environments and support different application scenarios, such as migrating existing applications to the cloud, developing new cloud applications, or optimizing them. There is, however, still much debate in the research community on what a CML is, and what aspects of a cloud application and its target cloud computing environment should be modeled by a CML. Furthermore, the distinction between CMLs on a fine-grain level exposing their modeling concepts is rarely made. In this article, we investigate the diverse features currently provided by existing CMLs. We classify and compare them according to a common framework with the goal to support CSCs in selecting the CML that fits the needs of their application scenario and setting. As a result, not only features of existing CMLs are pointed out for which extensive support is already provided but also in which existing CMLs are deficient, thereby suggesting a research agenda.}
}

@article{rayyan-727968481,
  title={Capturing cost avoidance through reuse: Systematic literature review and industrial evaluation},
  year={2016},
  issn={978-1-4503-3691-8},
  author={Irshad, Mohsin and Torkar, Richard and Petersen, Kai and Afzal, Wasif},
  url={https://doi.org/10.1145/2915970.2915989},
  publisher={Association for Computing Machinery},
  series={EASE '16},
  keywords={cost avoidance, cost savings, software reuse},
  abstract={Background: Cost avoidance through reuse shows the benefits gained by the software organisations when reusing an artefact. Cost avoidance captures benefits that are not captured by cost savings e.g. spending that would have increased in the absence of the cost avoidance activity. This type of benefit can be combined with quality aspects of the product e.g. costs avoided because of defect prevention. Cost avoidance is a key driver for software reuse. Objectives: The main objectives of this study are: (1) To assess the status of capturing cost avoidance through reuse in the academia; (2) Based on the first objective, propose improvements in capturing of reuse cost avoidance, integrate these into an instrument, and evaluate the instrument in the software industry. Method: The study starts with a systematic literature review (SLR) on capturing of cost avoidance through reuse. Later, a solution is proposed and evaluated in the industry to address the shortcomings identified during the systematic literature review. Results: The results of a systematic literature review describe three previous studies on reuse cost avoidance and show that no solution, to capture reuse cost avoidance, was validated in industry. Afterwards, an instrument and a data collection form are proposed that can be used to capture the cost avoided by reusing any type of reuse artefact. The instrument and data collection form (describing guidelines) were demonstrated to a focus group, as part of static evaluation. Based on the feedback, the instrument was updated and evaluated in industry at 6 development sites, in 3 different countries, covering 24 projects in total. Conclusion: The proposed solution performed well in industrial evaluation. With this solution, practitioners were able to do calculations for reuse costs avoidance and use the results as decision support for identifying potential artefacts to reuse.}
}

@article{rayyan-727968482,
  title={A systematic review of design diversity-based solutions for fault-tolerant SOAs},
  year={2013},
  issn={978-1-4503-1848-8},
  pages={107-118},
  author={Nascimento, Amanda S and Rubira, Cecília M F and Burrows, Rachel and Castor, Fernando},
  url={https://doi.org/10.1145/2460999.2461015},
  publisher={Association for Computing Machinery},
  series={EASE '13},
  keywords={SLR, SOA, composite services, fault tolerance},
  abstract={Context: Over recent years, software developers have been evaluating the benefits of both Service-Oriented Architecture and software fault tolerance techniques based on design diversity by creating fault-tolerant composite services that leverage functionally equivalent services, or variant services. Three major design issues need to be considered while building software fault-tolerant architectures based on design diversity namely, selection and execution of variants and selection of an adjudication algorithm to determine the correct or adjudicated result from the variants. Each design issue, in turn, can be realized by a set of alternative design solutions, which present different degrees of quality requirements (e.g. memory consumption and reliability). Objective: To investigate whether existing approaches for fault-tolerant composite services support the above mentioned design issues and to provide a detailed classification of the analysed approaches. Method: A systematic literature review of diversity-based approaches for fault-tolerant composite services, which compose our primary studies. Results: We found 17 primary studies providing direct evidence about the research question. Our findings reveal that the primary studies support a wide variety of design decisions. For example, (i) variant services may be chosen at different points during the software lifecycle; (ii) both parallel and sequential execution schemes have been addressed; and (iii) a variety of adjudication mechanisms were found amongst the target papers. Conclusion: We build up a broad picture of what design issues have been addressed by existing diversity-based approaches for fault-tolerant composite services. Finally, practical issues and difficulties are summarized and directions for future work are suggested.}
}

@article{rayyan-727968483,
  title={Empirical evaluations of regression test selection techniques: A systematic review},
  year={2008},
  issn={978-1-59593-971-5},
  pages={22-31},
  author={Engström, Emelie and Skoglund, Mats and Runeson, Per},
  url={https://doi.org/10.1145/1414004.1414011},
  publisher={Association for Computing Machinery},
  series={ESEM '08},
  keywords={systematic review, regression testing, test selection},
  abstract={Regression testing is the verification that previously functioning software remains after a change. In this paper we report on a systematic review of empirical evaluations of regression test selection techniques, published in major software engineering journals and conferences. Out of 2,923 papers analyzed in this systematic review, we identified 28 papers reporting on empirical comparative evaluations of regression test selection techniques. They report on 38 unique studies (23 experiments and 15 case studies), and in total 32 different techniques for regression test selection are evaluated. Our study concludes that no clear picture of the evaluated techniques can be provided based on existing empirical evidence, except for a small group of related techniques. Instead, we identified a need for more and better empirical studies were concepts are evaluated rather than small variations. It is also necessary to carefully consider the context in which studies are undertaken.}
}

